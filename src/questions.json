[
  {
    "id": "SAA-001",
    "domainId": "D1",
    "domain": "Design Secure Architectures",
    "section": "IAM",
    "question": "Which feature lets you grant temporary permissions to access AWS resources?",
    "choices": [
      "Resource Tags",
      "IAM Roles",
      "IAM Groups",
      "IAM Users"
    ],
    "answer": 1,
    "explanation": "IAM Roles provide temporary credentials and are commonly assumed by services/users.",
    "difficulty": "Easy",
    "choiceExplanations": {
      "0": "Tags are metadata labels (key-value pairs) used to organize, identify, and categorize AWS resources for cost allocation, automation, and access control policies, but they do not grant permissions or provide credentials themselves.",
      "2": "Groups are collections of IAM users that allow you to manage permissions for multiple users at once, but they provide permanent policy attachments rather than temporary credentials.",
      "3": "IAM Users are permanent identities with long-term credentials (passwords and access keys) for accessing AWS resources, not temporary permissions that expire automatically."
    }
  },
  {
    "id": "SAA-002",
    "domainId": "D1",
    "domain": "Design Secure Architectures",
    "section": "IAM",
    "question": "What is the best practice for the AWS account root user?",
    "choices": [
      "Share it with admins",
      "Enable MFA and avoid using it",
      "Disable it",
      "Use it daily"
    ],
    "answer": 1,
    "explanation": "Best practice: enable MFA on root and use it only for rare account tasks.",
    "difficulty": "Easy",
    "choiceExplanations": {
      "0": "Sharing root user credentials violates AWS security best practices as it eliminates accountability, increases the attack surface, and makes it impossible to track who performed actions using the root account.",
      "2": "The AWS account root user cannot be disabled or deleted; it is permanently tied to the AWS account and is required for certain account-level tasks that only the root user can perform.",
      "3": "Using the root user for daily tasks violates the principle of least privilege; AWS recommends creating IAM users or roles with appropriate permissions for routine operations and reserving root user access only for tasks that specifically require it."
    }
  },
  {
    "id": "SAA-003",
    "domainId": "D1",
    "domain": "Design Secure Architectures",
    "section": "KMS",
    "question": "Which AWS service manages encryption keys used to encrypt data in AWS services?",
    "choices": [
      "AWS KMS",
      "AWS Budgets",
      "AWS Shield",
      "Amazon Inspector"
    ],
    "answer": 0,
    "explanation": "AWS KMS manages keys and integrates with many AWS services for encryption.",
    "difficulty": "Easy",
    "choiceExplanations": {
      "1": "This is a cost management service that allows you to set custom budgets and receive alerts when costs or usage exceed thresholds; it has no encryption key management capabilities.",
      "2": "This is a managed DDoS protection service that safeguards applications running on AWS against distributed denial of service attacks; it does not manage encryption keys.",
      "3": "This is an automated security assessment service that helps identify vulnerabilities and deviations from best practices in your EC2 instances and applications; it does not manage encryption keys."
    }
  },
  {
    "id": "SAA-004",
    "domainId": "D1",
    "domain": "Design Secure Architectures",
    "section": "S3",
    "question": "Which S3 feature prevents objects from being deleted or overwritten for a retention period?",
    "choices": [
      "S3 Select",
      "S3 Transfer Acceleration",
      "S3 Inventory",
      "S3 Object Lock"
    ],
    "answer": 3,
    "explanation": "S3 Object Lock helps enforce WORM (write once, read many) retention.",
    "difficulty": "Easy",
    "choiceExplanations": {
      "0": "This feature enables applications to retrieve only a subset of data from an object using SQL expressions, improving query performance and reducing data transfer costs, but has no retention or deletion protection capabilities.",
      "1": "This feature speeds up content transfers to and from S3 by using Amazon CloudFront's globally distributed edge locations, but does not provide any object protection or retention functionality.",
      "2": "This feature provides scheduled reports listing objects and their metadata in an S3 bucket for auditing and compliance purposes, but does not prevent objects from being deleted or modified."
    }
  },
  {
    "id": "SAA-005",
    "domainId": "D1",
    "domain": "Design Secure Architectures",
    "section": "VPC",
    "question": "Which VPC component acts as a virtual firewall at the instance level?",
    "choices": [
      "Route Table",
      "Internet Gateway",
      "Network ACL",
      "Security Group"
    ],
    "answer": 3,
    "explanation": "Security Groups are stateful and apply at the ENI/instance level.",
    "difficulty": "Easy",
    "choiceExplanations": {
      "0": "Route tables determine where network traffic is directed within a VPC by containing a set of rules (routes), but they do not filter or inspect traffic like a firewall does.",
      "1": "An Internet Gateway is a horizontally scaled, redundant VPC component that enables communication between instances in a VPC and the internet, but it does not provide any firewall or traffic filtering capabilities.",
      "2": "Network ACLs operate at the subnet level, not the instance level, and are stateless firewalls that require explicit rules for both inbound and outbound traffic, making them different from the instance-level Security Groups."
    }
  },
  {
    "id": "SAA-006",
    "domainId": "D1",
    "domain": "Design Secure Architectures",
    "section": "VPC",
    "question": "Which VPC component is stateless and filters traffic at the subnet boundary?",
    "choices": [
      "NAT Gateway",
      "Network ACL",
      "VPC Peering",
      "Security Group"
    ],
    "answer": 1,
    "explanation": "Network ACLs are stateless and operate at the subnet level.",
    "difficulty": "Easy",
    "choiceExplanations": {
      "0": "This is a managed service that enables instances in private subnets to connect to the internet or other AWS services, but it does not filter traffic or operate at the subnet boundary as a security control.",
      "2": "This is a networking connection between two VPCs that enables routing traffic between them using private IP addresses, but it is not a traffic filtering mechanism.",
      "3": "While this does filter traffic, it operates at the instance level (not subnet boundary) and is stateful, meaning return traffic is automatically allowed regardless of outbound rules."
    }
  },
  {
    "id": "SAA-007",
    "domainId": "D1",
    "domain": "Design Secure Architectures",
    "section": "CloudWatch",
    "question": "Which service records AWS API calls for auditing and compliance?",
    "choices": [
      "Config",
      "CloudWatch",
      "CloudTrail",
      "X-Ray"
    ],
    "answer": 2,
    "explanation": "CloudTrail logs API activity (who did what, when, and from where).",
    "difficulty": "Easy",
    "choiceExplanations": {
      "0": "AWS Config tracks resource configuration changes and compliance over time, but it does not record API calls for auditing purposes like CloudTrail does.",
      "1": "CloudWatch is a monitoring service that collects metrics, logs, and events for AWS resources, but it does not record API calls for auditing and compliance purposes.",
      "3": "AWS X-Ray is used for analyzing and debugging distributed applications by tracing requests, not for recording API calls for auditing and compliance."
    }
  },
  {
    "id": "SAA-008",
    "domainId": "D1",
    "domain": "Design Secure Architectures",
    "section": "CloudFront",
    "question": "To block common web exploits (like SQL injection) in front of a CloudFront distribution, what should you use?",
    "choices": [
      "AWS Config",
      "Amazon EBS",
      "AWS WAF",
      "AWS KMS"
    ],
    "answer": 2,
    "explanation": "AWS WAF integrates with CloudFront (and ALB/API Gateway) to filter malicious HTTP requests.",
    "difficulty": "Easy",
    "choiceExplanations": {
      "0": "This service monitors and records AWS resource configurations for compliance auditing and change tracking, but it does not inspect or filter web traffic for security threats like SQL injection.",
      "1": "This is a block storage service for EC2 instances that provides persistent storage volumes, and has no capability to inspect or filter web application traffic.",
      "3": "This is a key management service for creating and controlling encryption keys used to encrypt data, but it does not provide web application firewall functionality to block malicious requests."
    }
  },
  {
    "id": "SAA-009",
    "domainId": "D1",
    "domain": "Design Secure Architectures",
    "section": "RDS",
    "question": "Where should you store database credentials securely with automatic rotation support?",
    "choices": [
      "AWS Secrets Manager",
      "CloudWatch Logs",
      "Hardcode in app config",
      "S3 Standard"
    ],
    "answer": 0,
    "explanation": "Secrets Manager is designed for secrets storage and rotation workflows.",
    "difficulty": "Easy",
    "choiceExplanations": {
      "1": "CloudWatch Logs is designed for storing and monitoring log data from applications and AWS services, not for securely storing secrets or providing automatic credential rotation capabilities.",
      "2": "Hardcoding credentials in application configuration files is a security anti-pattern that exposes sensitive data in source code, provides no encryption, and requires manual code changes for rotation instead of automated credential management.",
      "3": "S3 Standard is an object storage service designed for general-purpose data storage, not secrets management; it lacks native automatic rotation capabilities and is not purpose-built for secure credential storage and lifecycle management."
    }
  },
  {
    "id": "SAA-010",
    "domainId": "D1",
    "domain": "Design Secure Architectures",
    "section": "S3",
    "question": "How do you restrict S3 access so only CloudFront can read objects privately?",
    "choices": [
      "Use an Origin Access Control/Identity with bucket policy",
      "Disable Block Public Access",
      "Use S3 website hosting",
      "Make the bucket public"
    ],
    "answer": 0,
    "explanation": "Use CloudFront OAC/OAI + a bucket policy to keep S3 private.",
    "difficulty": "Easy",
    "choiceExplanations": {
      "1": "This setting controls whether public access policies can be applied to the bucket, but disabling it alone does not restrict access to only CloudFront—it actually opens the door for potential public access, which is the opposite of keeping S3 private.",
      "2": "S3 static website hosting creates a public HTTP endpoint that serves content directly to anyone, bypassing CloudFront entirely and making objects publicly accessible rather than restricting access to CloudFront only.",
      "3": "Making the bucket public allows anyone on the internet to access the objects directly, completely defeating the purpose of restricting access to only CloudFront and creating a security vulnerability."
    }
  },
  {
    "id": "SAA-011",
    "domainId": "D2",
    "domain": "Design Resilient Architectures",
    "section": "ELB",
    "question": "Which load balancer feature helps route traffic to healthy targets only?",
    "choices": [
      "TLS termination",
      "Path rewriting",
      "Health checks",
      "Sticky sessions"
    ],
    "answer": 2,
    "explanation": "Health checks detect unhealthy targets so traffic stops routing to them.",
    "difficulty": "Easy",
    "choiceExplanations": {
      "0": "This feature offloads SSL/TLS decryption from backend targets to the load balancer, reducing compute overhead on targets, but it does not determine target health or route traffic based on availability.",
      "1": "This feature modifies the URL path of incoming requests before forwarding them to targets, which is useful for routing logic but does not monitor or evaluate target health status.",
      "3": "This feature ensures that requests from the same client are consistently routed to the same target using cookies, which maintains session state but does not assess whether targets are healthy or available."
    }
  },
  {
    "id": "SAA-012",
    "domainId": "D2",
    "domain": "Design Resilient Architectures",
    "section": "Auto Scaling",
    "question": "What AWS feature automatically replaces unhealthy EC2 instances in a fleet?",
    "choices": [
      "EC2 Spot",
      "Auto Scaling Group",
      "AWS Batch",
      "Elastic Beanstalk"
    ],
    "answer": 1,
    "explanation": "ASGs can perform health checks and replace unhealthy instances.",
    "difficulty": "Easy",
    "choiceExplanations": {
      "0": "EC2 Spot Instances are a pricing model that allows you to use spare EC2 capacity at reduced costs, but they do not provide automatic health monitoring or instance replacement functionality.",
      "2": "AWS Batch is a fully managed service for running batch computing workloads at scale, managing job queues and compute environments, but it does not provide automatic health-based replacement of individual EC2 instances in a fleet.",
      "3": "While Elastic Beanstalk can replace unhealthy instances, it does so by utilizing Auto Scaling Groups under the hood; Elastic Beanstalk itself is a platform-as-a-service for deploying applications, not the core feature that performs instance replacement."
    }
  },
  {
    "id": "SAA-013",
    "domainId": "D2",
    "domain": "Design Resilient Architectures",
    "section": "RDS",
    "question": "Which RDS option provides automatic failover to a standby in another AZ?",
    "choices": [
      "Multi-AZ",
      "Reserved Instances",
      "Read Replica",
      "RDS Proxy"
    ],
    "answer": 0,
    "explanation": "Multi-AZ is for HA and automatic failover across AZs.",
    "difficulty": "Easy",
    "choiceExplanations": {
      "1": "This is a billing and pricing model that provides discounted rates for committing to a one or three-year term, and has no relation to high availability or failover capabilities.",
      "2": "Read Replicas are designed to offload read traffic and improve read scalability, not for automatic failover; they can be manually promoted to a standalone instance but this is not an automatic process.",
      "3": "RDS Proxy is a fully managed database proxy that improves application scalability, resilience to database failures, and security by pooling database connections, but it does not itself provide the standby instance or failover mechanism between Availability Zones."
    }
  },
  {
    "id": "SAA-014",
    "domainId": "D2",
    "domain": "Design Resilient Architectures",
    "section": "Route 53",
    "question": "Which Route 53 policy routes traffic to the endpoint with the lowest latency?",
    "choices": [
      "Weighted",
      "Geolocation",
      "Latency-based",
      "Failover"
    ],
    "answer": 2,
    "explanation": "Latency-based routing selects the region/endpoint with the lowest latency.",
    "difficulty": "Easy",
    "choiceExplanations": {
      "0": "This routing policy distributes traffic across multiple endpoints based on assigned weight ratios (e.g., 70/30 split), not based on network latency measurements.",
      "1": "This routing policy routes traffic based on the geographic location of the user (continent, country, or state), not based on actual network latency to endpoints.",
      "3": "This routing policy routes traffic to a primary resource and automatically fails over to a secondary standby resource when the primary is unhealthy, not based on latency considerations."
    }
  },
  {
    "id": "SAA-015",
    "domainId": "D2",
    "domain": "Design Resilient Architectures",
    "section": "S3",
    "question": "Which S3 feature replicates objects automatically to another region?",
    "choices": [
      "S3 Glacier",
      "S3 CRR",
      "S3 Object Lambda",
      "S3 Select"
    ],
    "answer": 1,
    "explanation": "Cross-Region Replication (CRR) replicates objects to another region.",
    "difficulty": "Easy",
    "choiceExplanations": {
      "0": "This is a storage class designed for long-term archival with lower costs and longer retrieval times, not a replication feature for copying objects across regions.",
      "2": "This feature allows you to add custom code to process data retrieved from S3 GET requests, transforming data as it is returned to an application, not for replicating objects to another region.",
      "3": "This feature enables applications to retrieve only a subset of data from an object using SQL expressions, improving performance and reducing costs for data retrieval, not for cross-region replication."
    }
  },
  {
    "id": "SAA-016",
    "domainId": "D2",
    "domain": "Design Resilient Architectures",
    "section": "EBS",
    "question": "EBS volumes are replicated within which scope by default?",
    "choices": [
      "Across accounts",
      "Across regions",
      "Within a single AZ",
      "Across AZs"
    ],
    "answer": 2,
    "explanation": "EBS is AZ-scoped; it replicates within the same AZ for durability.",
    "difficulty": "Easy",
    "choiceExplanations": {
      "0": "EBS volumes are not replicated across AWS accounts by default; they exist within a single account and single AZ, though snapshots can be shared across accounts manually.",
      "1": "EBS volumes are not replicated across regions by default; they are confined to a single Availability Zone within a single region, though you can copy snapshots to other regions for disaster recovery.",
      "3": "EBS volumes do not replicate across Availability Zones by default; they are bound to a single AZ, which is why an EC2 instance can only attach EBS volumes from the same AZ."
    }
  },
  {
    "id": "SAA-017",
    "domainId": "D2",
    "domain": "Design Resilient Architectures",
    "section": "DynamoDB",
    "question": "Which DynamoDB feature provides multi-region, active-active replication?",
    "choices": [
      "Global Tables",
      "TTL",
      "DAX",
      "Streams"
    ],
    "answer": 0,
    "explanation": "DynamoDB Global Tables supports multi-region active-active replication.",
    "difficulty": "Easy",
    "choiceExplanations": {
      "1": "Time to Live (TTL) is a feature that automatically deletes expired items from DynamoDB tables based on a timestamp attribute, helping manage storage costs, but it has nothing to do with replication across regions.",
      "2": "DynamoDB Accelerator (DAX) is an in-memory caching service that provides microsecond latency for read-heavy workloads within a single region, but it does not provide any cross-region replication capabilities.",
      "3": "DynamoDB Streams captures a time-ordered sequence of item-level modifications in a table and stores this information for up to 24 hours, enabling change data capture scenarios, but it is not itself a multi-region replication feature (though Global Tables uses Streams internally)."
    }
  },
  {
    "id": "SAA-018",
    "domainId": "D2",
    "domain": "Design Resilient Architectures",
    "section": "SQS",
    "question": "Which service decouples components by buffering messages for later processing?",
    "choices": [
      "EFS",
      "CloudFront",
      "SQS",
      "SNS"
    ],
    "answer": 2,
    "explanation": "SQS is a message queue used to decouple and buffer workloads.",
    "difficulty": "Easy",
    "choiceExplanations": {
      "0": "Amazon Elastic File System is a managed file storage service for EC2 instances, not a messaging service. It provides shared file storage but does not buffer messages or decouple application components.",
      "1": "Amazon CloudFront is a content delivery network (CDN) that caches and delivers content to users with low latency. It is not a messaging service and does not buffer messages between application components.",
      "3": "Amazon Simple Notification Service is a pub/sub messaging service that pushes messages immediately to subscribers rather than buffering them. Unlike SQS, SNS does not store messages for later processing; it delivers them in real-time to endpoints."
    }
  },
  {
    "id": "SAA-019",
    "domainId": "D2",
    "domain": "Design Resilient Architectures",
    "section": "Lambda",
    "question": "What happens if an SQS-triggered Lambda cannot process a message repeatedly?",
    "choices": [
      "Message disappears immediately",
      "Queue is deleted",
      "Lambda shuts down permanently",
      "Message is moved to a DLQ (if configured)"
    ],
    "answer": 3,
    "explanation": "After retries/max receive count, messages can go to a DLQ if configured.",
    "difficulty": "Easy",
    "choiceExplanations": {
      "0": "Messages do not disappear immediately; SQS retains messages and returns them to the queue after the visibility timeout expires, allowing for retry attempts until the maxReceiveCount is reached.",
      "1": "SQS queues are never automatically deleted due to message processing failures; queues persist independently of message processing outcomes and must be explicitly deleted by users.",
      "2": "Lambda functions continue to operate normally regardless of individual message processing failures; AWS Lambda is a managed service that maintains function availability and does not shut down due to processing errors."
    }
  },
  {
    "id": "SAA-020",
    "domainId": "D2",
    "domain": "Design Resilient Architectures",
    "section": "CloudFront",
    "question": "Which CloudFront feature helps keep content available if the primary origin fails?",
    "choices": [
      "Cache invalidations",
      "Origin failover",
      "Geo restriction only",
      "Signed URLs only"
    ],
    "answer": 1,
    "explanation": "Origin failover can route requests to a secondary origin if the primary fails.",
    "difficulty": "Easy",
    "choiceExplanations": {
      "0": "This feature removes cached content from CloudFront edge locations before it expires, forcing fresh content retrieval from the origin. It does not provide any failover capability when an origin becomes unavailable.",
      "2": "This feature allows you to block or allow content access based on the geographic location of viewers. It controls who can access content but provides no redundancy or failover mechanism when an origin fails.",
      "3": "This feature provides secure, time-limited access to private content by requiring authentication tokens in the URL. It is a security mechanism for content access control, not a high availability or failover solution."
    }
  },
  {
    "id": "SAA-021",
    "domainId": "D3",
    "domain": "Design High-Performing Architectures",
    "section": "CloudFront",
    "question": "What is the main benefit of CloudFront for global users?",
    "choices": [
      "Cheaper EC2",
      "Lower latency via edge caching",
      "Faster RDS writes",
      "More durable EBS"
    ],
    "answer": 1,
    "explanation": "CloudFront caches content at edge locations, reducing latency for users.",
    "difficulty": "Easy",
    "choiceExplanations": {
      "0": "CloudFront is a content delivery network (CDN) service and has no direct relationship to EC2 pricing. EC2 costs are determined by instance types, regions, and purchasing options, not by CloudFront usage.",
      "2": "CloudFront is designed for caching and delivering static and dynamic content at edge locations, not for database operations. RDS write performance is determined by instance class, storage type, and database optimization, not CDN services.",
      "3": "CloudFront does not affect EBS durability. EBS durability is an inherent characteristic of the storage service itself, with EBS volumes designed for 99.999% durability. CloudFront serves content delivery purposes, not storage durability."
    }
  },
  {
    "id": "SAA-022",
    "domainId": "D3",
    "domain": "Design High-Performing Architectures",
    "section": "S3",
    "question": "Which S3 feature lets you retrieve only a portion of an object using SQL-like queries?",
    "choices": [
      "S3 Object Lock",
      "S3 Batch Operations",
      "S3 CRR",
      "S3 Select"
    ],
    "answer": 3,
    "explanation": "S3 Select can query subsets of data from an object (like CSV/JSON) to reduce data transfer.",
    "difficulty": "Easy",
    "choiceExplanations": {
      "0": "This feature prevents objects from being deleted or overwritten for a specified retention period using WORM (Write Once Read Many) protection, but it does not provide any data querying capabilities.",
      "1": "This feature performs large-scale batch operations on S3 objects such as copying, tagging, or invoking Lambda functions across billions of objects, but it does not query or retrieve portions of object data.",
      "2": "Cross-Region Replication automatically replicates objects across S3 buckets in different AWS regions for compliance or latency purposes, but it does not provide any SQL-like querying functionality to retrieve partial object data."
    }
  },
  {
    "id": "SAA-023",
    "domainId": "D3",
    "domain": "Design High-Performing Architectures",
    "section": "EFS",
    "question": "Which storage is best for a shared POSIX file system across multiple EC2 instances?",
    "choices": [
      "S3 Standard",
      "Instance Store",
      "EBS",
      "EFS"
    ],
    "answer": 3,
    "explanation": "EFS is a managed NFS file system that can be mounted by many instances.",
    "difficulty": "Easy",
    "choiceExplanations": {
      "0": "S3 is an object storage service, not a file system, and does not provide native POSIX-compliant file system semantics required for traditional file operations like file locking and directory hierarchies.",
      "1": "Instance Store provides temporary block-level storage that is physically attached to a single host and cannot be shared across multiple EC2 instances, plus data is lost when the instance stops or terminates.",
      "2": "EBS volumes can only be attached to a single EC2 instance at a time in most configurations (except Multi-Attach for io1/io2 with specific constraints), making it unsuitable for shared file system access across multiple instances."
    }
  },
  {
    "id": "SAA-024",
    "domainId": "D3",
    "domain": "Design High-Performing Architectures",
    "section": "EC2",
    "question": "Which feature increases network throughput for supported EC2 instance types?",
    "choices": [
      "AMI Copy",
      "Placement Groups",
      "Enhanced Networking",
      "EBS Snapshots"
    ],
    "answer": 2,
    "explanation": "Enhanced networking (ENA) improves packet per second and throughput.",
    "difficulty": "Easy",
    "choiceExplanations": {
      "0": "AMI Copy is used to duplicate Amazon Machine Images across regions or within the same region for backup or deployment purposes, and has no impact on network throughput performance.",
      "1": "Placement Groups control the physical placement of EC2 instances (cluster, spread, or partition) to optimize for low latency or fault tolerance, but they do not directly increase network throughput capabilities of the instances themselves.",
      "3": "EBS Snapshots are point-in-time backups of EBS volumes stored in S3 for data protection and recovery purposes, and have no relationship to network throughput performance."
    }
  },
  {
    "id": "SAA-025",
    "domainId": "D3",
    "domain": "Design High-Performing Architectures",
    "section": "ELB",
    "question": "Which load balancer is best for HTTP/HTTPS with path-based routing?",
    "choices": [
      "ALB",
      "Classic Load Balancer only",
      "NLB",
      "GWLB"
    ],
    "answer": 0,
    "explanation": "ALB supports Layer 7 routing features like host/path-based routing.",
    "difficulty": "Easy",
    "choiceExplanations": {
      "1": "Classic Load Balancer operates at both Layer 4 and Layer 7 but does not support advanced routing features like path-based routing; it only provides basic round-robin load balancing for HTTP/HTTPS traffic.",
      "2": "Network Load Balancer operates at Layer 4 (TCP/UDP) and does not inspect HTTP headers or URL paths, making it incapable of performing path-based routing which requires Layer 7 functionality.",
      "3": "Gateway Load Balancer operates at Layer 3 (network layer) and is designed for deploying, scaling, and managing third-party virtual appliances like firewalls and intrusion detection systems, not for HTTP/HTTPS application routing."
    }
  },
  {
    "id": "SAA-026",
    "domainId": "D3",
    "domain": "Design High-Performing Architectures",
    "section": "DynamoDB",
    "question": "Which DynamoDB feature accelerates read-heavy workloads with in-memory caching?",
    "choices": [
      "DAX",
      "TTL",
      "Global Secondary Index",
      "Streams"
    ],
    "answer": 0,
    "explanation": "DynamoDB Accelerator (DAX) is an in-memory cache for read performance.",
    "difficulty": "Easy",
    "choiceExplanations": {
      "1": "Time to Live (TTL) is a feature that automatically deletes expired items from tables to reduce storage costs and manage data lifecycle, not a caching mechanism for improving read performance.",
      "2": "Global Secondary Indexes (GSIs) allow querying data using alternate partition and sort keys for flexible access patterns, but they do not provide in-memory caching to accelerate read performance.",
      "3": "DynamoDB Streams captures a time-ordered sequence of item-level modifications in a table for change data capture and event-driven architectures, not for caching or accelerating read operations."
    }
  },
  {
    "id": "SAA-027",
    "domainId": "D3",
    "domain": "Design High-Performing Architectures",
    "section": "RDS",
    "question": "What is the main purpose of an RDS Read Replica?",
    "choices": [
      "Encrypt the database",
      "Reduce storage costs",
      "Scale reads and offload reporting queries",
      "Automatic failover"
    ],
    "answer": 2,
    "explanation": "Read replicas are for scaling reads, not for automatic HA failover.",
    "difficulty": "Easy",
    "choiceExplanations": {
      "0": "Encryption is configured at the database instance level using AWS KMS, not through Read Replicas. Read Replicas inherit the encryption setting from the source database but do not provide encryption functionality themselves.",
      "1": "Read Replicas actually increase storage costs because they maintain a full copy of the data from the primary database. They are designed for read scalability, not cost reduction.",
      "3": "Automatic failover is a feature of Multi-AZ deployments, not Read Replicas. Read Replicas can be manually promoted to a standalone database but do not provide automatic failover capabilities."
    }
  },
  {
    "id": "SAA-028",
    "domainId": "D3",
    "domain": "Design High-Performing Architectures",
    "section": "EBS",
    "question": "Which EBS volume type is generally best for general-purpose SSD workloads with tunable performance?",
    "choices": [
      "gp3",
      "st1",
      "sc1",
      "Glacier Instant Retrieval"
    ],
    "answer": 0,
    "explanation": "gp3 provides good baseline performance and can be provisioned for higher IOPS/throughput.",
    "difficulty": "Easy",
    "choiceExplanations": {
      "1": "This is a Throughput Optimized HDD volume type designed for frequently accessed, throughput-intensive workloads like big data and data warehouses, not a general-purpose SSD with tunable performance.",
      "2": "This is a Cold HDD volume type designed for infrequently accessed data with the lowest storage cost, not a general-purpose SSD and does not offer tunable performance characteristics.",
      "3": "This is an Amazon S3 storage class for archival data, not an EBS volume type at all, making it completely irrelevant for block storage workloads."
    }
  },
  {
    "id": "SAA-029",
    "domainId": "D3",
    "domain": "Design High-Performing Architectures",
    "section": "SQS",
    "question": "Which SQS feature reduces empty receives by waiting for messages before returning a response?",
    "choices": [
      "FIFO ordering",
      "Dead-letter queue",
      "Message deduplication",
      "Long polling"
    ],
    "answer": 3,
    "explanation": "Long polling waits up to the configured time for messages, reducing empty responses and cost.",
    "difficulty": "Easy",
    "choiceExplanations": {
      "0": "This refers to the First-In-First-Out message ordering guarantee in SQS FIFO queues, ensuring messages are processed in the exact order they are sent, but it has no impact on reducing empty receives or polling behavior.",
      "1": "This is a queue that receives messages that cannot be processed successfully after a specified number of attempts, used for handling failed message processing rather than optimizing message retrieval efficiency.",
      "2": "This is a FIFO queue feature that prevents duplicate messages from being sent within a 5-minute deduplication interval, but it does not affect how consumers poll for messages or reduce empty receives."
    }
  },
  {
    "id": "SAA-030",
    "domainId": "D3",
    "domain": "Design High-Performing Architectures",
    "section": "SQS",
    "question": "Which SQS type preserves message order and supports exactly-once processing?",
    "choices": [
      "Standard",
      "FIFO",
      "Priority",
      "Delayed"
    ],
    "answer": 1,
    "explanation": "SQS FIFO provides ordering and exactly-once processing (within FIFO semantics).",
    "difficulty": "Easy",
    "choiceExplanations": {
      "0": "SQS Standard queues provide best-effort ordering and at-least-once delivery, meaning messages may be delivered out of order and duplicates can occur, unlike FIFO queues which guarantee ordering and exactly-once processing.",
      "2": "Priority is not a valid SQS queue type; AWS SQS only offers Standard and FIFO queue types, and does not natively support priority-based message processing.",
      "3": "Delayed is not a valid SQS queue type; delay is a configurable feature (delay queues or message timers) available on both Standard and FIFO queues, not a separate queue type."
    }
  },
  {
    "id": "SAA-031",
    "domainId": "D4",
    "domain": "Design Cost-Optimized Architectures",
    "section": "EC2",
    "question": "Which EC2 pricing model offers the biggest discount for interruptible workloads?",
    "choices": [
      "Savings Plans only",
      "Spot Instances",
      "Reserved Instances",
      "On-Demand"
    ],
    "answer": 1,
    "explanation": "Spot Instances are discounted but can be interrupted when capacity is needed.",
    "difficulty": "Easy",
    "choiceExplanations": {
      "0": "While Savings Plans offer up to 72% discount compared to On-Demand, they require a commitment to consistent compute usage and do not involve interruptible workloads, making them unsuitable for workloads that can tolerate interruption.",
      "2": "Reserved Instances provide up to 72% discount for committing to 1 or 3-year terms, but they guarantee capacity and are not interruptible, so they don't match the requirement for interruptible workloads.",
      "3": "On-Demand instances are the most expensive pricing model with no discount, as you pay full price for compute capacity by the hour or second with no long-term commitment or interruption risk."
    }
  },
  {
    "id": "SAA-032",
    "domainId": "D4",
    "domain": "Design Cost-Optimized Architectures",
    "section": "S3",
    "question": "Which S3 storage class is best for rarely accessed data with milliseconds retrieval?",
    "choices": [
      "S3 Glacier Deep Archive",
      "S3 One Zone-IA (always best)",
      "S3 Standard-IA",
      "S3 Standard"
    ],
    "answer": 2,
    "explanation": "Standard-IA is for infrequently accessed data with low storage cost and millisecond access.",
    "difficulty": "Easy",
    "choiceExplanations": {
      "0": "This storage class has retrieval times of 12-48 hours, not milliseconds, making it unsuitable when fast access is required for rarely accessed data.",
      "1": "While One Zone-IA does provide millisecond retrieval for infrequently accessed data, it is NOT always best because it stores data in only one Availability Zone, reducing durability compared to Standard-IA which replicates across multiple AZs.",
      "3": "While it provides millisecond retrieval, it is designed for frequently accessed data and has higher storage costs than Standard-IA, making it not cost-optimized for rarely accessed data."
    }
  },
  {
    "id": "SAA-033",
    "domainId": "D4",
    "domain": "Design Cost-Optimized Architectures",
    "section": "S3",
    "question": "Which S3 feature automatically moves objects between storage tiers based on access patterns?",
    "choices": [
      "S3 Object Lock",
      "S3 Select",
      "S3 Intelligent-Tiering",
      "S3 Transfer Acceleration"
    ],
    "answer": 2,
    "explanation": "Intelligent-Tiering optimizes cost by moving objects between access tiers.",
    "difficulty": "Easy",
    "choiceExplanations": {
      "0": "This feature prevents objects from being deleted or overwritten for a specified retention period using WORM (Write Once Read Many) model, but it does not move objects between storage tiers based on access patterns.",
      "1": "This feature enables applications to retrieve only a subset of data from an object using SQL expressions, reducing data transfer and processing costs, but it does not manage storage tier transitions.",
      "3": "This feature speeds up content transfers to and from S3 by using Amazon CloudFront's globally distributed edge locations, but it does not automatically move objects between storage tiers."
    }
  },
  {
    "id": "SAA-034",
    "domainId": "D4",
    "domain": "Design Cost-Optimized Architectures",
    "section": "CloudWatch",
    "question": "Which CloudWatch feature notifies you when a metric crosses a threshold?",
    "choices": [
      "CloudWatch Dashboards only",
      "CloudWatch Logs only",
      "CloudWatch Events only",
      "CloudWatch Alarms"
    ],
    "answer": 3,
    "explanation": "CloudWatch Alarms watch metrics and can trigger actions/notifications when thresholds are breached.",
    "difficulty": "Easy",
    "choiceExplanations": {
      "0": "CloudWatch Dashboards are used for visualizing and displaying metrics in customizable graphs and charts, but they do not provide notification capabilities when metrics cross thresholds.",
      "1": "CloudWatch Logs is used for collecting, storing, and analyzing log data from AWS resources and applications, not for monitoring metric thresholds and sending notifications.",
      "2": "CloudWatch Events (now Amazon EventBridge) responds to state changes in AWS resources and triggers actions based on events, but it does not monitor metric thresholds directly; that functionality belongs to CloudWatch Alarms."
    }
  },
  {
    "id": "SAA-035",
    "domainId": "D4",
    "domain": "Design Cost-Optimized Architectures",
    "section": "Auto Scaling",
    "question": "For unpredictable spiky traffic, which approach avoids paying for idle EC2 capacity most effectively?",
    "choices": [
      "Use Auto Scaling Group with policies",
      "Use Dedicated Hosts",
      "Disable scaling and accept downtime",
      "Run one very large instance"
    ],
    "answer": 0,
    "explanation": "Auto Scaling matches capacity to demand, reducing idle cost while maintaining availability.",
    "difficulty": "Easy",
    "choiceExplanations": {
      "1": "Dedicated Hosts provide physical servers dedicated to your use for licensing compliance, but they require paying for the entire host regardless of utilization, making them the opposite of cost-effective for variable workloads.",
      "2": "This approach fails to meet availability requirements and does not address cost optimization, as you would still need to provision capacity for peak loads or suffer service disruptions during traffic spikes.",
      "3": "A single large instance must be sized for peak traffic, meaning you pay for maximum capacity even during low-demand periods, resulting in significant idle capacity costs and no fault tolerance."
    }
  },
  {
    "id": "SAA-036",
    "domainId": "D4",
    "domain": "Design Cost-Optimized Architectures",
    "section": "RDS",
    "question": "Which approach can reduce RDS connection overhead for spiky Lambda traffic?",
    "choices": [
      "Increase instance size always",
      "RDS Proxy",
      "Disable backups",
      "Use Multi-AZ only"
    ],
    "answer": 1,
    "explanation": "RDS Proxy pools and reuses connections, reducing overhead in bursty workloads.",
    "difficulty": "Easy",
    "choiceExplanations": {
      "0": "While a larger instance can handle more connections, it doesn't address the fundamental problem of connection overhead from Lambda's ephemeral nature creating and destroying connections rapidly, and it increases costs unnecessarily rather than optimizing them.",
      "2": "Disabling automated backups affects data protection and recovery capabilities but has no impact on database connection management or the overhead caused by Lambda functions establishing new connections.",
      "3": "Multi-AZ deployments provide high availability through synchronous replication to a standby instance for failover purposes, but they do not address connection pooling or reduce the connection overhead from spiky Lambda traffic."
    }
  },
  {
    "id": "SAA-037",
    "domainId": "D4",
    "domain": "Design Cost-Optimized Architectures",
    "section": "EBS",
    "question": "Which action can reduce EBS snapshot storage costs over time?",
    "choices": [
      "Turn off encryption",
      "Use larger volumes",
      "Delete old/unused snapshots",
      "Disable backups forever"
    ],
    "answer": 2,
    "explanation": "Deleting unused snapshots reduces storage costs.",
    "difficulty": "Easy",
    "choiceExplanations": {
      "0": "Encryption does not add any additional cost to EBS snapshots; AWS encrypts data at rest without charging extra, so disabling encryption would not reduce storage costs.",
      "1": "Using larger volumes would actually increase costs, not reduce them, as EBS snapshot storage is charged based on the amount of data stored, and larger volumes typically result in larger snapshots.",
      "3": "While this would technically eliminate future snapshot costs, it is not a recommended practice as it removes data protection entirely, creating significant risk of data loss and is not a cost optimization strategy but rather a dangerous elimination of essential backup capabilities."
    }
  },
  {
    "id": "SAA-038",
    "domainId": "D4",
    "domain": "Design Cost-Optimized Architectures",
    "section": "S3",
    "question": "Which storage class is typically the lowest cost for long-term archival with hours retrieval?",
    "choices": [
      "S3 Standard-IA",
      "S3 Standard",
      "S3 Glacier Deep Archive",
      "S3 Glacier Flexible Retrieval"
    ],
    "answer": 2,
    "explanation": "Deep Archive is designed for lowest-cost archival with slower retrieval.",
    "difficulty": "Easy",
    "choiceExplanations": {
      "0": "This storage class is designed for infrequently accessed data with millisecond retrieval times, making it significantly more expensive than Glacier classes and not intended for long-term archival purposes.",
      "1": "This is the highest-cost storage class designed for frequently accessed data with immediate retrieval, making it unsuitable and cost-prohibitive for long-term archival use cases.",
      "3": "While this is an archival storage class with retrieval times of minutes to hours, it costs more than Glacier Deep Archive, which offers the lowest storage cost for data that can tolerate retrieval times of up to 12 hours."
    }
  },
  {
    "id": "SAA-039",
    "domainId": "D4",
    "domain": "Design Cost-Optimized Architectures",
    "section": "CloudFront",
    "question": "How can CloudFront reduce costs for a global audience?",
    "choices": [
      "By replacing IAM",
      "By caching content at the edge to reduce origin load and transfer",
      "By increasing RDS IOPS",
      "By disabling TLS"
    ],
    "answer": 1,
    "explanation": "Edge caching reduces origin requests and can reduce backend load and data transfer.",
    "difficulty": "Easy",
    "choiceExplanations": {
      "0": "CloudFront is a content delivery network (CDN) service and has no relationship with IAM, which is AWS's identity and access management service. These are completely separate services with different purposes, and CloudFront cannot replace IAM functionality.",
      "2": "CloudFront is a CDN that caches and delivers content from edge locations and has no capability to modify RDS database performance settings. RDS IOPS are configured independently through RDS provisioned IOPS storage options.",
      "3": "Disabling TLS would reduce security, not costs, and is not a CloudFront cost optimization feature. CloudFront actually supports and encourages HTTPS/TLS for secure content delivery, and TLS termination at edge locations is a standard CloudFront capability."
    }
  },
  {
    "id": "SAA-040",
    "domainId": "D4",
    "domain": "Design Cost-Optimized Architectures",
    "section": "EC2",
    "question": "Which commitment generally lowers compute cost for steady-state usage over 1–3 years?",
    "choices": [
      "Always Spot",
      "On-Demand only",
      "Always Dedicated Hosts",
      "Reserved Instances or Savings Plans"
    ],
    "answer": 3,
    "explanation": "Reservations/Savings Plans provide discounts for committed usage.",
    "difficulty": "Easy",
    "choiceExplanations": {
      "0": "While Spot Instances offer the deepest discounts (up to 90%), they can be interrupted with 2-minute notice when AWS needs capacity back, making them unsuitable for steady-state workloads that require consistent availability.",
      "1": "On-Demand pricing is the most expensive option with no commitment discounts, providing flexibility but no cost savings for predictable, steady-state workloads over 1-3 years.",
      "2": "Dedicated Hosts are the most expensive EC2 option as they provide entire physical servers for your use, typically used for licensing compliance or regulatory requirements rather than cost optimization."
    }
  },
  {
    "id": "SAA-041",
    "domainId": "D1",
    "domain": "Design Secure Architectures",
    "section": "IAM",
    "question": "In IAM evaluation, what happens if a request matches an explicit Deny and an Allow?",
    "choices": [
      "Deny wins",
      "It depends on the service",
      "The request is retried",
      "Allow wins"
    ],
    "answer": 0,
    "explanation": "Explicit Deny always overrides Allow in IAM policy evaluation.",
    "difficulty": "Easy",
    "choiceExplanations": {
      "1": "IAM policy evaluation logic is consistent across all AWS services - an explicit Deny always takes precedence over any Allow statements, regardless of which service is being accessed.",
      "2": "IAM policy evaluation is deterministic and immediate - when a Deny is matched, the request is denied outright and not retried, as retrying would produce the same result.",
      "3": "This is the opposite of how IAM works - the fundamental principle of IAM policy evaluation is that an explicit Deny always overrides any Allow, ensuring that restrictive policies cannot be circumvented."
    }
  },
  {
    "id": "SAA-042",
    "domainId": "D1",
    "domain": "Design Secure Architectures",
    "section": "VPC",
    "question": "What enables private connectivity from a VPC to supported AWS services without internet?",
    "choices": [
      "Public Subnet",
      "VPC Endpoints",
      "VPC Peering",
      "Internet Gateway"
    ],
    "answer": 1,
    "explanation": "VPC endpoints (Gateway/Interface) provide private access to AWS services.",
    "difficulty": "Easy",
    "choiceExplanations": {
      "0": "A public subnet is a subnet with a route to an Internet Gateway, which means traffic flows over the public internet rather than staying private within AWS's network.",
      "2": "VPC Peering enables private connectivity between two VPCs, not between a VPC and AWS services; it is used for VPC-to-VPC communication only.",
      "3": "An Internet Gateway enables communication between a VPC and the public internet, which is the opposite of private connectivity and requires traffic to traverse the internet."
    }
  },
  {
    "id": "SAA-043",
    "domainId": "D1",
    "domain": "Design Secure Architectures",
    "section": "KMS",
    "question": "Which S3 server-side encryption option uses KMS-managed keys?",
    "choices": [
      "SSE-S3",
      "Unencrypted",
      "Client-side only",
      "SSE-KMS"
    ],
    "answer": 3,
    "explanation": "SSE-KMS uses AWS KMS keys to encrypt S3 objects.",
    "difficulty": "Easy",
    "choiceExplanations": {
      "0": "This encryption option uses keys that are fully managed by Amazon S3 itself, not AWS KMS; S3 handles all key generation, encryption, and key management automatically without KMS involvement.",
      "1": "This option means no encryption is applied to S3 objects at all, so there is no key management of any kind involved.",
      "2": "Client-side encryption means data is encrypted before being sent to S3 using keys managed entirely by the customer's application, not by any AWS server-side service including KMS."
    }
  },
  {
    "id": "SAA-044",
    "domainId": "D2",
    "domain": "Design Resilient Architectures",
    "section": "EFS",
    "question": "EFS offers high availability primarily by being accessible across what?",
    "choices": [
      "Multiple regions by default",
      "Only one AZ",
      "Only one subnet",
      "Multiple AZs in a region"
    ],
    "answer": 3,
    "explanation": "EFS is a regional service and is designed to be accessible across multiple AZs.",
    "difficulty": "Easy",
    "choiceExplanations": {
      "0": "EFS is a regional service, not a multi-region service by default. While EFS Replication can copy data to another region, this requires explicit configuration and is not the default behavior that provides high availability.",
      "1": "This is incorrect because EFS Standard storage class stores data redundantly across multiple Availability Zones within a region, not just one AZ. Single-AZ storage is only available with the EFS One Zone storage class, which is a cost-optimized option with lower availability.",
      "2": "EFS can have mount targets in multiple subnets across different Availability Zones within a region, allowing EC2 instances in any AZ to access the file system. Limiting to one subnet would significantly reduce availability and accessibility."
    }
  },
  {
    "id": "SAA-045",
    "domainId": "D2",
    "domain": "Design Resilient Architectures",
    "section": "SQS",
    "question": "What is the main difference between SQS Standard and FIFO?",
    "choices": [
      "FIFO preserves order and supports exactly-once processing",
      "FIFO is faster for unlimited throughput always",
      "Standard requires VPC endpoints",
      "Standard is encrypted, FIFO is not"
    ],
    "answer": 0,
    "explanation": "FIFO preserves ordering and avoids duplicates (within FIFO semantics).",
    "difficulty": "Easy",
    "choiceExplanations": {
      "1": "This is incorrect because Standard queues actually support nearly unlimited throughput, while FIFO queues have a limited throughput of 300 messages per second (or 3,000 with batching) without high throughput mode, making Standard queues faster for high-volume scenarios.",
      "2": "This is incorrect because VPC endpoints are optional for both Standard and FIFO queues; they are used to privately connect your VPC to SQS without requiring internet access, but neither queue type mandates their use.",
      "3": "This is incorrect because both Standard and FIFO queues support server-side encryption (SSE) using AWS KMS keys; encryption capabilities are identical across both queue types."
    }
  },
  {
    "id": "SAA-046",
    "domainId": "D3",
    "domain": "Design High-Performing Architectures",
    "section": "VPC",
    "question": "Which design improves throughput between EC2 instances with low network latency needs?",
    "choices": [
      "Cluster Placement Group",
      "Use only public IPs",
      "Spread Placement Group",
      "Disable security groups"
    ],
    "answer": 0,
    "explanation": "Cluster placement groups provide low-latency, high-throughput networking in a single AZ.",
    "difficulty": "Easy",
    "choiceExplanations": {
      "1": "Using public IPs does not improve network throughput or latency between EC2 instances; traffic using public IPs may route through the internet gateway, potentially increasing latency rather than reducing it.",
      "2": "Spread Placement Groups are designed to place instances on distinct underlying hardware across different racks to maximize availability and fault tolerance, which actually increases physical distance between instances rather than optimizing for low latency and high throughput.",
      "3": "Security groups cannot be disabled on EC2 instances, and even if they could, security groups operate at the hypervisor level and do not significantly impact network throughput or latency between instances."
    }
  },
  {
    "id": "SAA-047",
    "domainId": "D4",
    "domain": "Design Cost-Optimized Architectures",
    "section": "S3",
    "question": "To reduce storage costs for objects with known lifecycle, what should you use?",
    "choices": [
      "S3 Lifecycle rules",
      "S3 Inventory only",
      "IAM Policy Simulator",
      "CloudTrail"
    ],
    "answer": 0,
    "explanation": "Lifecycle rules can transition objects to cheaper classes or expire them automatically.",
    "difficulty": "Easy",
    "choiceExplanations": {
      "1": "S3 Inventory provides reports about objects and their metadata in a bucket for auditing and analysis purposes, but it cannot automatically transition or delete objects to reduce storage costs.",
      "2": "IAM Policy Simulator is a tool for testing and troubleshooting IAM policies to understand their effects on access permissions, and has no functionality related to S3 storage management or cost optimization.",
      "3": "CloudTrail is a service that logs API calls and account activity for auditing and compliance purposes, but it does not manage object storage or automate transitions between storage classes."
    }
  },
  {
    "id": "SAA-048",
    "domainId": "D3",
    "domain": "Design High-Performing Architectures",
    "section": "Lambda",
    "question": "Which Lambda feature provides a built-in HTTPS endpoint without API Gateway?",
    "choices": [
      "Lambda Layers",
      "Lambda@Edge only",
      "Lambda Function URLs",
      "Provisioned Concurrency"
    ],
    "answer": 2,
    "explanation": "Lambda Function URLs expose a native HTTPS endpoint for a function.",
    "difficulty": "Easy",
    "choiceExplanations": {
      "0": "Lambda Layers is a feature for packaging and sharing common code, libraries, or dependencies across multiple Lambda functions, not for providing HTTP endpoints.",
      "1": "Lambda@Edge runs Lambda functions at CloudFront edge locations to customize CDN content delivery, but it requires CloudFront distribution and does not provide a standalone built-in HTTPS endpoint for the function itself.",
      "3": "Provisioned Concurrency is a feature that keeps Lambda function instances pre-initialized to reduce cold start latency, but it has nothing to do with providing HTTP endpoints."
    }
  },
  {
    "id": "SAA-049",
    "domainId": "D2",
    "domain": "Design Resilient Architectures",
    "section": "CloudWatch",
    "question": "Which service provides alarms based on metrics like CPUUtilization?",
    "choices": [
      "KMS",
      "CloudTrail",
      "Artifact",
      "CloudWatch"
    ],
    "answer": 3,
    "explanation": "CloudWatch provides metrics, alarms, and dashboards.",
    "difficulty": "Easy",
    "choiceExplanations": {
      "0": "AWS Key Management Service (KMS) is used for creating and managing cryptographic keys for encryption, not for monitoring metrics or creating alarms based on resource utilization.",
      "1": "AWS CloudTrail records API calls and user activity for auditing and governance purposes, but it does not provide metric-based alarms like CPUUtilization monitoring.",
      "2": "AWS Artifact is a portal for accessing AWS compliance reports and security documentation, not a monitoring or alerting service for infrastructure metrics."
    }
  },
  {
    "id": "SAA-050",
    "domainId": "D1",
    "domain": "Design Secure Architectures",
    "section": "IAM",
    "question": "Which IAM feature sets the maximum permissions an IAM role/user can have (as a boundary)?",
    "choices": [
      "VPC Endpoints",
      "Route Tables",
      "Permission Boundaries",
      "Security Groups"
    ],
    "answer": 2,
    "explanation": "Permission boundaries define the maximum permissions identity-based policies can grant.",
    "difficulty": "Easy",
    "choiceExplanations": {
      "0": "VPC Endpoints are networking components that enable private connectivity between a VPC and supported AWS services without requiring internet access, they have no relation to IAM permission management.",
      "1": "Route Tables are VPC networking components that contain rules determining where network traffic is directed, they control network routing not IAM permissions.",
      "3": "Security Groups act as virtual firewalls controlling inbound and outbound traffic at the instance level, they are network security controls not IAM permission controls."
    }
  },
  {
    "id": "SAA-051",
    "domainId": "D3",
    "domain": "Design High-Performing Architectures",
    "section": "DynamoDB",
    "question": "Which DynamoDB capacity mode is easiest for unpredictable traffic without capacity planning?",
    "choices": [
      "On-demand",
      "Provisioned",
      "Spot",
      "Reserved"
    ],
    "answer": 0,
    "explanation": "On-demand capacity scales automatically and avoids manual capacity planning.",
    "difficulty": "Easy",
    "choiceExplanations": {
      "1": "This mode requires you to manually specify read and write capacity units in advance, making it unsuitable for unpredictable traffic since you must plan and manage capacity yourself.",
      "2": "Spot is not a DynamoDB capacity mode; it is an EC2 pricing model for unused compute capacity, making this option invalid for DynamoDB.",
      "3": "Reserved is not a DynamoDB capacity mode; Reserved Capacity is a billing option for provisioned mode that requires upfront commitment, not a separate capacity mode for handling unpredictable traffic."
    }
  },
  {
    "id": "SAA-052",
    "domainId": "D3",
    "domain": "Design High-Performing Architectures",
    "section": "SQS",
    "question": "What does the SQS Visibility Timeout control?",
    "choices": [
      "How long long polling waits",
      "How long a received message is hidden from other consumers",
      "Maximum message size",
      "How long messages are stored"
    ],
    "answer": 1,
    "explanation": "Visibility timeout hides a message after receive so another consumer doesn’t process it simultaneously.",
    "difficulty": "Easy",
    "choiceExplanations": {
      "0": "This is controlled by the ReceiveMessageWaitTimeSeconds parameter (up to 20 seconds), not the visibility timeout. Long polling determines how long a receive request waits for messages to arrive before returning.",
      "2": "Message size is a separate SQS configuration with a maximum limit of 256 KB per message. This is not related to visibility timeout, which only controls message visibility duration.",
      "3": "This is controlled by the Message Retention Period setting, which can range from 1 minute to 14 days (default 4 days). Visibility timeout only affects temporary hiding of messages during processing."
    }
  },
  {
    "id": "SAA-053",
    "domainId": "D1",
    "domain": "Design Secure Architectures",
    "section": "CloudFront",
    "question": "Which AWS service provides DDoS protection that commonly protects CloudFront by default (Standard)?",
    "choices": [
      "AWS Snowball",
      "AWS Shield",
      "AWS Glue",
      "AWS Batch"
    ],
    "answer": 1,
    "explanation": "AWS Shield Standard helps protect against common DDoS attacks and is included for CloudFront.",
    "difficulty": "Easy",
    "choiceExplanations": {
      "0": "This is a physical data transport device used for large-scale data migration into and out of AWS, not a security or DDoS protection service.",
      "2": "This is a fully managed ETL (Extract, Transform, Load) service used for data preparation and integration, not for network security or DDoS protection.",
      "3": "This is a service for running batch computing workloads at scale, used for processing large volumes of data, not for protecting against DDoS attacks."
    }
  },
  {
    "id": "SAA-054",
    "domainId": "D4",
    "domain": "Design Cost-Optimized Architectures",
    "section": "Lambda",
    "question": "For short-lived, event-driven tasks, which compute option can be cost-effective?",
    "choices": [
      "Dedicated Hosts",
      "Biggest EC2 only",
      "Lambda",
      "Always-on EC2"
    ],
    "answer": 2,
    "explanation": "Lambda can be cost-effective for sporadic workloads because you pay per execution.",
    "difficulty": "Easy",
    "choiceExplanations": {
      "0": "Dedicated Hosts are physical servers dedicated to your use, designed for licensing compliance and regulatory requirements, not cost optimization for short-lived tasks. They require significant upfront commitment and are among the most expensive EC2 options.",
      "1": "Using the largest EC2 instance type would be extremely cost-inefficient for short-lived, event-driven tasks since you would pay for massive compute capacity that sits idle most of the time, and EC2 charges by the hour or second regardless of actual utilization.",
      "3": "Running an EC2 instance continuously incurs charges 24/7 even when no tasks are executing, making it highly cost-inefficient for sporadic, event-driven workloads that only run occasionally."
    }
  },
  {
    "id": "SAA-055",
    "domainId": "D3",
    "domain": "Design High-Performing Architectures",
    "section": "EC2",
    "question": "Which EC2 feature is the recommended way to define instance configuration for an Auto Scaling Group today?",
    "choices": [
      "Launch Configuration only",
      "Placement Group",
      "AMI Copy",
      "Launch Template"
    ],
    "answer": 3,
    "explanation": "Launch Templates are the modern, recommended way to define ASG instance configuration.",
    "difficulty": "Easy",
    "choiceExplanations": {
      "0": "While Launch Configurations can define instance configuration for ASGs, they are a legacy feature that AWS no longer recommends; they lack newer features like multiple instance types, versioning, and cannot be modified after creation.",
      "1": "Placement Groups control how EC2 instances are physically placed within AWS infrastructure (cluster, spread, or partition) for performance or fault tolerance, but they do not define instance configuration settings like instance type, AMI, or security groups.",
      "2": "AMI Copy is used to duplicate Amazon Machine Images across regions or accounts for disaster recovery or distribution purposes, but it does not define the complete instance configuration (instance type, networking, storage) needed for Auto Scaling Groups."
    }
  },
  {
    "id": "SAA-056",
    "domainId": "D2",
    "domain": "Design Resilient Architectures",
    "section": "RDS",
    "question": "Aurora is designed to replicate storage across how many AZs (typical design)?",
    "choices": [
      "1",
      "3",
      "2",
      "6 regions"
    ],
    "answer": 1,
    "explanation": "Aurora typically replicates storage across 3 AZs for durability.",
    "difficulty": "Easy",
    "choiceExplanations": {
      "0": "A single AZ would provide no redundancy and contradicts Aurora's core design principle of high availability through distributed storage across multiple Availability Zones.",
      "2": "While standard RDS Multi-AZ deployments replicate to 2 AZs, Aurora's architecture is specifically designed to replicate data across 3 AZs with 6 copies of data for enhanced durability.",
      "3": "Aurora replicates across 3 Availability Zones within a single region, not 6 regions; the number 6 refers to the copies of data (2 copies per AZ), not the number of regions."
    }
  },
  {
    "id": "SAA-057",
    "domainId": "D1",
    "domain": "Design Secure Architectures",
    "section": "S3",
    "question": "Which setting helps ensure all S3 uploads are encrypted automatically?",
    "choices": [
      "Default encryption",
      "Requester Pays",
      "Transfer Acceleration",
      "Disable versioning"
    ],
    "answer": 0,
    "explanation": "Default encryption ensures objects are encrypted when written to the bucket.",
    "difficulty": "Easy",
    "choiceExplanations": {
      "1": "This setting transfers data transfer costs to the requester instead of the bucket owner, but has no relation to encryption of uploaded objects.",
      "2": "This feature uses CloudFront edge locations to speed up data transfers to S3 buckets over long distances, but does not provide any encryption functionality.",
      "3": "Versioning controls whether multiple versions of objects are retained in a bucket for recovery purposes, and has no impact on whether objects are encrypted during upload."
    }
  },
  {
    "id": "SAA-058",
    "domainId": "D4",
    "domain": "Design Cost-Optimized Architectures",
    "section": "CloudWatch",
    "question": "Which action can reduce CloudWatch Logs costs?",
    "choices": [
      "Set retention policies and filter what you log",
      "Turn off encryption always",
      "Send logs to more log groups",
      "Increase log retention to never expire"
    ],
    "answer": 0,
    "explanation": "Retention policies and logging only what you need help reduce log storage/ingest costs.",
    "difficulty": "Easy",
    "choiceExplanations": {
      "1": "CloudWatch Logs encryption at rest using AWS-managed keys is free and enabled by default, so disabling it provides no cost savings and reduces security without any financial benefit.",
      "2": "Creating additional log groups does not reduce costs; it increases management overhead and does not affect the fundamental charges for log ingestion and storage, which are based on data volume.",
      "3": "Setting logs to never expire increases storage costs over time because you continue to pay for stored log data indefinitely, making this the opposite of a cost optimization strategy."
    }
  },
  {
    "id": "SAA-059",
    "domainId": "D3",
    "domain": "Design High-Performing Architectures",
    "section": "S3",
    "question": "For large file uploads to S3, which feature improves reliability and throughput?",
    "choices": [
      "S3 Batch Operations only",
      "S3 Object Lock",
      "S3 Multipart Upload",
      "S3 Static Website Hosting"
    ],
    "answer": 2,
    "explanation": "Multipart upload uploads parts in parallel and can retry parts independently.",
    "difficulty": "Easy",
    "choiceExplanations": {
      "0": "S3 Batch Operations is designed for performing bulk operations on existing objects (like copying, tagging, or restoring), not for improving upload reliability or throughput of large files.",
      "1": "S3 Object Lock is a data protection feature that prevents objects from being deleted or overwritten for a specified retention period using WORM (Write Once Read Many) model, and has no relation to upload performance.",
      "3": "S3 Static Website Hosting enables serving static web content directly from an S3 bucket via HTTP, and does not provide any upload performance or reliability improvements."
    }
  },
  {
    "id": "SAA-060",
    "domainId": "D2",
    "domain": "Design Resilient Architectures",
    "section": "VPC",
    "question": "What provides outbound internet access for private subnets without inbound internet access?",
    "choices": [
      "VPC Endpoint only",
      "NAT Gateway",
      "Internet Gateway",
      "Route 53 Resolver"
    ],
    "answer": 1,
    "explanation": "A NAT Gateway allows instances in private subnets to initiate outbound connections to the internet.",
    "difficulty": "Easy",
    "choiceExplanations": {
      "0": "VPC Endpoints provide private connectivity to AWS services (like S3 or DynamoDB) without traversing the internet, but they do not provide general outbound internet access to external websites or services.",
      "2": "An Internet Gateway allows both inbound and outbound internet access for resources with public IP addresses in public subnets, but it does not provide the one-way outbound-only access that private subnets require.",
      "3": "Route 53 Resolver handles DNS query resolution between your VPC and on-premises networks or other VPCs, but it does not provide any internet connectivity for data traffic."
    }
  },
  {
    "id": "SAA-061",
    "domainId": "D1",
    "domain": "Design Secure Architectures",
    "section": "IAM",
    "question": "Which IAM policy type is attached directly to an AWS resource like an S3 bucket?",
    "choices": [
      "Permission boundary only",
      "Identity-based policy",
      "Session policy only",
      "Resource-based policy"
    ],
    "answer": 3,
    "explanation": "Resource-based policies are attached to resources (e.g., S3 bucket policy).",
    "difficulty": "Easy",
    "choiceExplanations": {
      "0": "Permission boundaries are attached to IAM users or roles to set the maximum permissions they can have, not directly to AWS resources like S3 buckets.",
      "1": "Identity-based policies are attached to IAM identities (users, groups, or roles), not to AWS resources; they define what actions the identity can perform.",
      "2": "Session policies are passed as parameters when programmatically creating temporary sessions for roles or federated users, not attached directly to AWS resources."
    }
  },
  {
    "id": "SAA-062",
    "domainId": "D3",
    "domain": "Design High-Performing Architectures",
    "section": "ELB",
    "question": "Which ALB capability helps route traffic to different target groups based on URL path?",
    "choices": [
      "BGP routing",
      "NAT translation",
      "Layer 4 routing",
      "Path-based routing"
    ],
    "answer": 3,
    "explanation": "ALB supports Layer 7 features like host- and path-based routing.",
    "difficulty": "Easy",
    "choiceExplanations": {
      "0": "BGP (Border Gateway Protocol) is a network routing protocol used for exchanging routing information between autonomous systems on the internet, not an ALB feature for application-level traffic routing based on URL paths.",
      "1": "NAT (Network Address Translation) is used to translate private IP addresses to public IP addresses for internet connectivity, typically performed by NAT Gateways in AWS, not a routing capability of Application Load Balancers.",
      "2": "Layer 4 routing operates at the transport layer using TCP/UDP ports and is a feature of Network Load Balancers (NLB), not ALB; URL path-based routing requires Layer 7 (application layer) capabilities that only ALB provides."
    }
  },
  {
    "id": "SAA-063",
    "domainId": "D2",
    "domain": "Design Resilient Architectures",
    "section": "RDS",
    "question": "Which RDS feature enables point-in-time recovery within the backup retention window?",
    "choices": [
      "Automated backups",
      "Security groups",
      "Read replicas",
      "Manual snapshots only"
    ],
    "answer": 0,
    "explanation": "Automated backups (with transaction logs) enable point-in-time recovery.",
    "difficulty": "Easy",
    "choiceExplanations": {
      "1": "Security groups control network access to RDS instances by defining inbound and outbound traffic rules; they have no relationship to backup or recovery functionality.",
      "2": "Read replicas are used for scaling read operations and improving performance by creating readable copies of the database; they do not provide point-in-time recovery capabilities.",
      "3": "Manual snapshots capture the database state at a specific moment and can only restore to that exact point; they cannot enable point-in-time recovery because they lack the continuous transaction logs that automated backups maintain."
    }
  },
  {
    "id": "SAA-064",
    "domainId": "D4",
    "domain": "Design Cost-Optimized Architectures",
    "section": "RDS",
    "question": "Which choice can reduce cost for dev/test databases that are not used 24/7?",
    "choices": [
      "Right-size and stop/start where supported",
      "Use the largest instance",
      "Run Multi-AZ always",
      "Disable monitoring"
    ],
    "answer": 0,
    "explanation": "Right-sizing and stopping non-prod resources where possible reduces cost.",
    "difficulty": "Easy",
    "choiceExplanations": {
      "1": "Using the largest instance significantly increases costs rather than reducing them, as RDS pricing is directly tied to instance size; dev/test environments should use appropriately sized smaller instances to minimize expenses.",
      "2": "Multi-AZ deployments approximately double the cost of a database instance since AWS provisions a standby replica in another Availability Zone; this level of high availability is typically unnecessary for dev/test workloads.",
      "3": "Disabling monitoring has negligible impact on costs since basic RDS monitoring through CloudWatch is included at no additional charge, and Enhanced Monitoring costs are minimal; this approach also removes valuable operational visibility without meaningful savings."
    }
  },
  {
    "id": "SAA-065",
    "domainId": "D1",
    "domain": "Design Secure Architectures",
    "section": "VPC",
    "question": "Which is the most secure way to allow EC2 to access S3 without hardcoding keys?",
    "choices": [
      "Put keys in a public S3 bucket",
      "Share root credentials",
      "Use an IAM Role attached to the instance",
      "Store keys in code"
    ],
    "answer": 2,
    "explanation": "Attach an IAM role to the instance so it receives temporary credentials automatically.",
    "difficulty": "Easy",
    "choiceExplanations": {
      "0": "This is extremely insecure as anyone on the internet can access public S3 buckets, exposing your AWS credentials to unauthorized users and potential attackers.",
      "1": "Root credentials provide unrestricted access to all AWS resources and should never be shared or used for application access; AWS strongly recommends against using root account credentials for everyday tasks.",
      "3": "Hardcoding credentials in application code is a security anti-pattern that risks credential exposure through source control, logs, or code sharing, and makes credential rotation difficult."
    }
  },
  {
    "id": "SAA-066",
    "domainId": "D1",
    "domain": "Design Secure Architectures",
    "section": "IAM",
    "question": "A company has just set up a new AWS account for production workloads and wants to follow best practices for privileged access. Which practice should be mandated for the root user account?",
    "choices": [
      "Use the root account only for initial setup and never share credentials.",
      "Configure Multi-Factor Authentication (MFA) only for critical IAM users, as the root account is already inherently secure.",
      "Create an IAM user for all day-to-day operations and delete the root account immediately.",
      "Set a strong password policy for all IAM users, but the root account password can be simple since it's rarely used."
    ],
    "answer": 0,
    "explanation": "Root is the most privileged identity, so it should be tightly controlled and used only when absolutely necessary; never share it and keep it for account-level tasks.",
    "difficulty": "Medium",
    "choiceExplanations": {
      "1": "This is incorrect because the root account is NOT inherently secure and AWS strongly recommends enabling MFA on the root account as a critical security best practice, since it has unrestricted access to all resources and cannot be limited by IAM policies.",
      "2": "This is incorrect because the root account cannot be deleted; it is permanently tied to the AWS account. While creating IAM users for daily operations is correct, the root account must be secured and protected, not deleted.",
      "3": "This is incorrect because AWS best practices require the root account to have a strong, complex password precisely because it has unlimited privileges. The infrequent use of root makes it more critical to secure, not less."
    }
  },
  {
    "id": "SAA-067",
    "domainId": "D4",
    "domain": "Design Cost-Optimized Architectures",
    "section": "EC2",
    "question": "A company must run a critical, stateful database application with stable capacity 24/7 for the next three years and wants the best cost savings. Which EC2 purchasing option provides the greatest savings for this steady-state workload?",
    "choices": [
      "Spot Instances, leveraging up to 90% discount for non-critical workloads.",
      "Capacity Reservations, ensuring capacity in a specific AZ for any duration.",
      "Reserved Instances (3-year term, All Upfront payment).",
      "On-Demand Instances, due to the flexibility of paying per second."
    ],
    "answer": 2,
    "explanation": "A 3-year All Upfront Reserved Instance provides the largest discount for predictable, always-on workloads while keeping capacity stable.",
    "difficulty": "Medium",
    "choiceExplanations": {
      "0": "Spot Instances can be interrupted by AWS with only 2 minutes notice when capacity is needed, making them unsuitable for critical, stateful database applications that require continuous availability 24/7.",
      "1": "Capacity Reservations only guarantee that EC2 capacity will be available when needed but do not provide any billing discount; you still pay On-Demand rates unless combined with Reserved Instances or Savings Plans.",
      "3": "On-Demand Instances are the most expensive option with no discount, making them unsuitable for steady-state workloads running 24/7 for three years where Reserved Instances can provide up to 72% savings."
    }
  },
  {
    "id": "SAA-068",
    "domainId": "D1",
    "domain": "Design Secure Architectures",
    "section": "Security Groups",
    "question": "An EC2 instance security group allows inbound HTTP (port 80), but client connections time out and outbound rules are default. Based on security group fundamentals, what is the most likely cause?",
    "choices": [
      "The default Network ACL (NACL) is implicitly denying the inbound connection.",
      "The default outbound rule in the security group is denying the return traffic.",
      "The inbound security group rule is configured incorrectly or traffic is being blocked before reaching the instance, resulting in a timeout.",
      "The application server is not running, resulting in a connection refused error."
    ],
    "answer": 2,
    "explanation": "Security groups are stateful, so return traffic is allowed automatically; a timeout usually indicates the request never successfully reaches a listening service (routing/NACL/host firewall/app issue) rather than an outbound SG problem.",
    "difficulty": "Medium",
    "choiceExplanations": {
      "0": "The default NACL allows all inbound and outbound traffic by default, so it would not block connections unless it has been explicitly modified with deny rules.",
      "1": "Security groups are stateful, meaning return traffic for allowed inbound connections is automatically permitted regardless of outbound rules, so the default outbound rule cannot cause this issue.",
      "3": "When an application is not running, the client receives a 'connection refused' error (TCP RST), not a timeout; timeouts indicate the traffic never reached the instance or was dropped before reaching the application."
    }
  },
  {
    "id": "SAA-069",
    "domainId": "D2",
    "domain": "Design Resilient Architectures",
    "section": "ALB",
    "question": "An Application Load Balancer (ALB) distributes traffic across two Availability Zones for high availability. How is cross-zone load balancing configured by default on an ALB, and what is the pricing impact?",
    "choices": [
      "Disabled by default, and inter-AZ data transfer is charged if enabled.",
      "Enabled by default, but inter-AZ data transfer is charged if enabled.",
      "Enabled by default, and there are no additional charges for this cross-zone regional data transfer behavior on ALB.",
      "Disabled by default, but there are no charges for inter-AZ data transfer."
    ],
    "answer": 2,
    "explanation": "ALBs use cross-zone load balancing by default, and ALB does not add a specific cross-zone data transfer fee for this behavior.",
    "difficulty": "Medium",
    "choiceExplanations": {
      "0": "This is incorrect because cross-zone load balancing is enabled by default on ALB, not disabled, and ALB does not charge additional fees for cross-zone data transfer when using this feature.",
      "1": "While this correctly states that cross-zone load balancing is enabled by default on ALB, it incorrectly claims that inter-AZ data transfer is charged; ALB includes cross-zone load balancing without additional data transfer charges for this behavior.",
      "3": "This is incorrect because cross-zone load balancing is enabled by default on ALB, not disabled; the pricing statement about no charges is correct, but the default configuration state is wrong."
    }
  },
  {
    "id": "SAA-070",
    "domainId": "D2",
    "domain": "Design Resilient Architectures",
    "section": "SQS",
    "question": "A payment system requires messages to be processed in the exact order received and must prevent duplicate processing. Which Amazon SQS queue type meets these requirements?",
    "choices": [
      "SQS FIFO Queue.",
      "SQS Standard Queue with short polling.",
      "SQS Standard Queue with long polling.",
      "Amazon SNS topic fan-out pattern."
    ],
    "answer": 0,
    "explanation": "SQS FIFO provides ordered message processing and supports exactly-once processing semantics (with deduplication) for correctly designed consumers.",
    "difficulty": "Medium",
    "choiceExplanations": {
      "1": "SQS Standard Queues provide best-effort ordering only, meaning messages may be delivered out of order, and they offer at-least-once delivery which can result in duplicate message processing, failing both requirements.",
      "2": "While long polling reduces empty responses and API costs, it does not change the fundamental characteristics of Standard Queues, which still deliver messages in best-effort order and may deliver duplicates.",
      "3": "SNS is a pub/sub messaging service designed for broadcasting messages to multiple subscribers and does not guarantee message ordering or provide built-in deduplication for preventing duplicate processing."
    }
  },
  {
    "id": "SAA-071",
    "domainId": "D4",
    "domain": "Design Cost-Optimized Architectures",
    "section": "S3",
    "question": "A media company stores video data in S3: frequent access for 30 days, rare access from day 30 to 90 (but fast retrieval), then long-term archive after 90 days where hours of retrieval time is acceptable. Which lifecycle transition is most cost-effective while meeting access needs?",
    "choices": [
      "Standard for 30 days -> transition to S3 Standard-IA for 60 days -> transition to S3 Glacier Flexible Retrieval after 90 days.",
      "Use S3 Glacier Instant Retrieval immediately as retrieval latency is low.",
      "S3 One Zone-IA for 30 days -> S3 Standard-IA for 60 days -> S3 Glacier Instant Retrieval.",
      "S3 Intelligent-Tiering -> S3 Glacier Deep Archive after 90 days."
    ],
    "answer": 0,
    "explanation": "Standard fits frequent access, Standard-IA fits infrequent-but-fast retrieval, and Glacier Flexible Retrieval fits long-term archiving with hour-level retrieval latency.",
    "difficulty": "Medium",
    "choiceExplanations": {
      "1": "S3 Glacier Instant Retrieval is designed for rarely accessed data (once per quarter) and has higher retrieval costs, making it unsuitable and more expensive for the first 30 days when data is accessed frequently.",
      "2": "This sequence is illogical as it moves from a lower-cost tier (One Zone-IA) to a higher-cost tier (Standard-IA), and S3 Glacier Instant Retrieval is more expensive than Glacier Flexible Retrieval when hours of retrieval latency is acceptable for archival data.",
      "3": "S3 Glacier Deep Archive has retrieval times of 12-48 hours which may exceed acceptable retrieval times, and Intelligent-Tiering incurs monitoring fees that are unnecessary when access patterns are already known and predictable."
    }
  },
  {
    "id": "SAA-072",
    "domainId": "D1",
    "domain": "Design Secure Architectures",
    "section": "VPC",
    "question": "VPC flow logs show outbound traffic from a private subnet instance is ACCEPTED, but the inbound return traffic is REJECTED at the subnet level. Assuming security groups are correct, what should be checked and modified to allow the connection to succeed?",
    "choices": [
      "The NACL outbound rules for the private subnet, because NACLs are stateful.",
      "The EC2 instance security group, because security groups are stateless.",
      "The NACL inbound rules for the private subnet, ensuring the ephemeral port range is explicitly allowed.",
      "The NACL outbound rules for the public subnet, ensuring port 443 is explicitly allowed."
    ],
    "answer": 2,
    "explanation": "NACLs are stateless, so you must explicitly allow return traffic on ephemeral ports in the inbound NACL rules for the subnet.",
    "difficulty": "Medium",
    "choiceExplanations": {
      "0": "This is incorrect because NACLs are stateless, not stateful. The statement contains a factual error about NACL behavior, and since outbound traffic is already ACCEPTED according to the flow logs, the outbound rules are not the problem.",
      "1": "This is incorrect because security groups are stateful, not stateless. Security groups automatically allow return traffic, so if outbound traffic is permitted, the return traffic is automatically allowed at the security group level. The question also states security groups are correct.",
      "3": "This is incorrect because the problem is with inbound return traffic being REJECTED at the private subnet level, not with outbound traffic from a public subnet. The flow logs indicate the issue is specifically with the private subnet's inbound rules for return traffic."
    }
  },
  {
    "id": "SAA-073",
    "domainId": "D2",
    "domain": "Design Resilient Architectures",
    "section": "Aurora",
    "question": "A company uses Aurora MySQL in us-east-1 and needs cross-region expansion to eu-west-1 with very low RTO for failover (under 1 minute) and low-latency global reads. Which Aurora feature best meets both needs?",
    "choices": [
      "Aurora cross-region read replicas.",
      "Aurora Serverless deployment in eu-west-1.",
      "Aurora Global Database.",
      "RDS Multi-AZ deployment."
    ],
    "answer": 2,
    "explanation": "Aurora Global Database is designed for low-latency cross-region reads and fast disaster recovery with promoted secondary regions.",
    "difficulty": "Medium",
    "choiceExplanations": {
      "0": "While cross-region read replicas provide read scaling across regions, they use asynchronous replication with higher lag and have significantly longer failover times (typically minutes to tens of minutes) compared to Aurora Global Database's sub-minute RTO, making them unsuitable for the very low RTO requirement.",
      "1": "Aurora Serverless is designed for variable or unpredictable workloads with automatic scaling, but it is a standalone deployment that does not provide cross-region replication or disaster recovery capabilities from the us-east-1 primary database.",
      "3": "Multi-AZ provides high availability within a single region by maintaining a synchronous standby replica in a different Availability Zone, but it does not support cross-region replication needed for expansion to eu-west-1 or cross-region disaster recovery."
    }
  },
  {
    "id": "SAA-074",
    "domainId": "D1",
    "domain": "Design Secure Architectures",
    "section": "Monitoring",
    "question": "An admin wants immediate alerts when someone attempts to terminate a production EC2 instance, a history of configuration changes, and a graph of average CPU over time. Which three AWS services meet these requirements, respectively?",
    "choices": [
      "CloudWatch (CPU), CloudTrail (API calls/history), AWS Config (configuration history).",
      "CloudWatch (CPU), CloudTrail (configuration history), CloudWatch Logs (API calls).",
      "GuardDuty (alerts), EventBridge (history), AWS Config (CPU).",
      "Trusted Advisor (security), CloudWatch (CPU), S3 (history)."
    ],
    "answer": 0,
    "explanation": "CloudWatch provides metrics and graphs, CloudTrail records API activity such as termination attempts, and AWS Config tracks configuration changes over time.",
    "difficulty": "Medium",
    "choiceExplanations": {
      "1": "This incorrectly swaps the roles of CloudTrail and CloudWatch Logs. CloudTrail records API calls and activity history, not configuration history. CloudWatch Logs stores log data but does not directly capture API calls; it would need CloudTrail logs delivered to it first.",
      "2": "GuardDuty is a threat detection service for malicious activity, not for alerting on specific API actions like instance termination. EventBridge is an event bus for routing events, not for maintaining history. AWS Config tracks configuration changes, not CPU metrics.",
      "3": "Trusted Advisor provides best practice recommendations across cost, security, and performance categories, not real-time alerts for specific API actions. S3 is object storage and does not provide configuration change history or tracking capabilities on its own."
    }
  },
  {
    "id": "SAA-075",
    "domainId": "D3",
    "domain": "Design High-Performing Architectures",
    "section": "Serverless",
    "question": "Users upload large images to S3, and a serverless microservice must generate thumbnails and analyze metadata immediately after each upload. What is the most appropriate serverless pattern to trigger the processing?",
    "choices": [
      "Configure S3 event notifications to publish to an SNS topic, which then triggers the microservice running on Fargate tasks.",
      "Use AWS Batch to run the thumbnail job based on a scheduled CloudWatch Event.",
      "Use a single EC2 instance with a user data script running the thumbnail application.",
      "Configure S3 event notifications to invoke an AWS Lambda function directly."
    ],
    "answer": 3,
    "explanation": "S3 event notifications can directly trigger Lambda on object creation, providing a fully serverless, scalable event-driven pipeline.",
    "difficulty": "Medium",
    "choiceExplanations": {
      "0": "While S3 can publish to SNS, Fargate tasks cannot be directly triggered by SNS notifications and require additional orchestration (like invoking Lambda to start tasks). This adds unnecessary complexity and Fargate is container-based, not purely serverless in the same event-driven manner as Lambda.",
      "1": "AWS Batch with scheduled CloudWatch Events runs jobs on a schedule, not immediately upon file upload. This approach introduces latency and does not provide the real-time, event-driven processing required when images are uploaded.",
      "2": "EC2 instances are not serverless - they require manual scaling, management, and incur costs even when idle. User data scripts only run at instance launch, not in response to S3 upload events, making this unsuitable for event-driven processing."
    }
  },
  {
    "id": "SAA-076",
    "domainId": "D1",
    "domain": "Design Secure Architectures",
    "section": "IAM",
    "question": "A startup uses an AWS account shared by multiple teams. Developers currently attach the AdministratorAccess policy to their IAM users “temporarily” when troubleshooting, and sometimes forget to remove it.\nThe security team wants a guardrail that limits the maximum permissions developers can ever obtain, while still allowing team leads to grant temporary elevated access within that limit.\nWhich solution will meet these requirements with the LEAST operational overhead?",
    "choices": [
      "Enable AWS Config and automatically revert any policy changes detected on IAM users",
      "Use an identity-based policy that explicitly allows only read-only access for developers",
      "Create an SCP that allows AdministratorAccess only for users in a specific IAM group",
      "Attach a permissions boundary to all developer IAM users that caps their maximum permissions"
    ],
    "answer": 3,
    "explanation": "Permissions boundaries define the maximum permissions an IAM principal can receive, even if broader policies are attached later. This creates a strong guardrail without blocking legitimate temporary elevation by team leads, as long as it stays within the boundary.",
    "difficulty": "Medium",
    "choiceExplanations": {
      "0": "This is a reactive approach that introduces operational overhead through continuous monitoring and remediation, creates a window of vulnerability before changes are reverted, and doesn't actually prevent developers from temporarily having excessive permissions.",
      "1": "This approach doesn't create a guardrail on maximum permissions; it simply grants read-only access but doesn't prevent team leads or developers from attaching additional policies like AdministratorAccess that would override or expand those permissions.",
      "2": "SCPs apply to AWS accounts and OUs in AWS Organizations, not to individual IAM users or groups within an account. SCPs cannot differentiate permissions based on IAM group membership, making this solution technically impossible to implement as described."
    }
  },
  {
    "id": "SAA-077",
    "domainId": "D1",
    "domain": "Design Secure Architectures",
    "section": "S3",
    "question": "A company stores internal build artifacts in Amazon S3. The bucket must never become publicly accessible, even if someone accidentally adds a public bucket policy or object ACL.\nWhich configuration best meets the requirement?",
    "choices": [
      "Enable S3 versioning and MFA Delete",
      "Use S3 default encryption with SSE-S3",
      "Create an S3 access point for each application and disable bucket policies",
      "Enable S3 Block Public Access at the account level and for the bucket"
    ],
    "answer": 3,
    "explanation": "S3 Block Public Access can prevent public access via bucket policies and ACLs at both the account and bucket level, providing a safety net against accidental exposure. Encryption and versioning do not prevent public access.",
    "difficulty": "Medium",
    "choiceExplanations": {
      "0": "Versioning preserves object versions and MFA Delete prevents accidental deletion of objects or version history, but neither feature controls or prevents public access to the bucket or its objects.",
      "1": "Default encryption ensures objects are encrypted at rest using server-side encryption, but encryption does not prevent public access - encrypted objects can still be publicly accessible if bucket policies or ACLs allow it.",
      "2": "Access points provide simplified access management for applications, but they do not inherently block public access; someone could still configure a public access point or object ACL, and disabling bucket policies alone does not prevent public ACLs from being applied."
    }
  },
  {
    "id": "SAA-078",
    "domainId": "D1",
    "domain": "Design Secure Architectures",
    "section": "KMS",
    "question": "A security policy requires that all data stored in S3 be encrypted using customer-managed keys, and that access to decrypt the data be centrally controlled and auditable.\nWhich approach should you implement?",
    "choices": [
      "Use client-side encryption and store the encryption key in the application code repository",
      "Enable default encryption on the bucket using SSE-KMS with a customer-managed KMS key",
      "Enable default encryption on the bucket using SSE-S3",
      "Store objects unencrypted and rely on TLS in transit"
    ],
    "answer": 1,
    "explanation": "SSE-KMS with a customer-managed KMS key enforces encryption at rest and allows centralized, auditable control over key usage through KMS key policies and CloudTrail logs.",
    "difficulty": "Medium",
    "choiceExplanations": {
      "0": "Storing encryption keys in application code is a critical security anti-pattern that exposes keys to unauthorized access, and this approach does not provide centralized control or auditability through AWS services like CloudTrail.",
      "2": "SSE-S3 uses AWS-managed keys that customers cannot control or manage, and it does not provide the centralized key access control or detailed CloudTrail audit logging of key usage that customer-managed KMS keys offer.",
      "3": "TLS only protects data during transmission, not at rest; this approach completely fails to meet the requirement for encrypting stored data and provides no mechanism for centralized key management or auditability."
    }
  },
  {
    "id": "SAA-079",
    "domainId": "D1",
    "domain": "Design Secure Architectures",
    "section": "CloudTrail",
    "question": "A regulated company must retain an immutable record of all API calls in their AWS account for 7 years. The security team also wants to be alerted if CloudTrail logging is disabled or modified.\nWhich solution is MOST appropriate?",
    "choices": [
      "Enable VPC Flow Logs to S3 and store the logs for 7 years",
      "Send CloudTrail logs to an EC2 instance and back them up nightly to S3",
      "Enable AWS Config only and store configuration snapshots in S3 for 7 years",
      "Enable an organization trail (or account trail) that logs to an S3 bucket with Object Lock, and create an AWS Config rule (or CloudWatch/EventBridge alert) to detect changes to CloudTrail"
    ],
    "answer": 3,
    "explanation": "CloudTrail records API activity. Storing logs in S3 with Object Lock helps meet immutability/retention requirements, while Config and/or EventBridge/CloudWatch can alert on CloudTrail configuration changes. VPC Flow Logs capture network traffic, not API calls.",
    "difficulty": "Medium",
    "choiceExplanations": {
      "0": "VPC Flow Logs capture network traffic metadata (source/destination IPs, ports, protocols) at the network interface level, not API calls. CloudTrail is the service that records AWS API activity, making this solution fundamentally incorrect for the stated requirement.",
      "1": "This approach introduces unnecessary complexity, potential single points of failure, and does not provide immutability. Nightly backups could result in data loss, the EC2 instance adds management overhead, and standard S3 storage without Object Lock does not guarantee the immutable record required by regulations.",
      "2": "AWS Config tracks resource configuration changes and compliance state, not API calls. While Config can detect when CloudTrail settings change, it does not record the detailed API activity (who called what API, when, from where) that CloudTrail captures, so it cannot fulfill the requirement for a complete API call record."
    }
  },
  {
    "id": "SAA-080",
    "domainId": "D1",
    "domain": "Design Secure Architectures",
    "section": "VPC",
    "question": "A team is deploying a web app in private subnets. They want to allow HTTPS access to a third-party API on the internet, but block all inbound traffic from the internet.\nWhich network design meets these requirements?",
    "choices": [
      "Deploy instances in public subnets and use an S3 Gateway Endpoint for internet access",
      "Deploy instances in private subnets and attach an Internet Gateway directly to the private subnets",
      "Deploy instances in private subnets, route outbound internet traffic through a NAT Gateway in a public subnet, and keep inbound rules restrictive on security groups",
      "Deploy instances in public subnets with public IPs and restrict inbound traffic using NACLs"
    ],
    "answer": 2,
    "explanation": "Instances in private subnets have no direct inbound internet connectivity. A NAT Gateway in a public subnet provides outbound-only internet access for private instances. Security groups and route tables enforce the inbound restriction.",
    "difficulty": "Medium",
    "choiceExplanations": {
      "0": "S3 Gateway Endpoints only provide private connectivity to Amazon S3, not to third-party APIs on the internet, and placing instances in public subnets would expose them to potential inbound internet traffic.",
      "1": "An Internet Gateway cannot be attached directly to subnets; it attaches to the VPC, and private subnets by definition do not have routes to the Internet Gateway, so this configuration is architecturally invalid.",
      "3": "Instances with public IPs in public subnets are directly reachable from the internet, and while NACLs can restrict traffic, this approach does not meet the requirement of blocking all inbound internet traffic as effectively as using private subnets with a NAT Gateway."
    }
  },
  {
    "id": "SAA-081",
    "domainId": "D1",
    "domain": "Design Secure Architectures",
    "section": "ACM",
    "question": "A company hosts multiple HTTPS applications behind Application Load Balancers. The applications must use publicly trusted certificates and the team wants automatic certificate renewal.\nWhich solution should you choose?",
    "choices": [
      "Use AWS Certificate Manager Private CA to issue certificates for the ALBs",
      "Use AWS Certificate Manager (ACM) to provision public certificates and attach them to the ALB HTTPS listeners",
      "Run Let’s Encrypt certbot on each EC2 instance and manage renewals with cron",
      "Create self-signed certificates and import them to ACM"
    ],
    "answer": 1,
    "explanation": "ACM public certificates are publicly trusted, integrate directly with ALBs, and renew automatically. Private CA and self-signed certificates are not publicly trusted for internet clients.",
    "difficulty": "Medium",
    "choiceExplanations": {
      "0": "ACM Private CA issues private certificates that are only trusted within your organization's internal PKI hierarchy, not by public browsers and internet clients, so they cannot be used for publicly-facing HTTPS applications.",
      "2": "Run Let's Encrypt certbot on each EC2 instance and manage renewals with cron: This approach requires manual operational overhead to manage certificate renewals, does not integrate natively with ALB (certificates would need to be on instances rather than the load balancer), and contradicts the requirement for automatic renewal without custom management.",
      "3": "Self-signed certificates are not trusted by public browsers and will generate security warnings for users, failing the requirement for publicly trusted certificates; additionally, imported certificates in ACM do not renew automatically."
    }
  },
  {
    "id": "SAA-082",
    "domainId": "D1",
    "domain": "Design Secure Architectures",
    "section": "WAF",
    "question": "A security team wants to protect a public web application from common web exploits (SQL injection, XSS) and also wants to block known bad IP ranges. The solution must be managed and easy to update.\nWhich option best meets these requirements?",
    "choices": [
      "Use Security Groups to block SQL injection and XSS",
      "Use NACLs with deep packet inspection rules for HTTP payloads",
      "Attach AWS WAF to the application entry point (ALB or CloudFront) and use managed rule groups plus an IP set",
      "Enable AWS Shield Standard and configure it to block bad IPs"
    ],
    "answer": 2,
    "explanation": "AWS WAF provides managed protections for common web exploits and supports IP sets for allow/deny lists. Security groups and NACLs operate at L3/L4 and cannot inspect HTTP payloads for SQLi/XSS.",
    "difficulty": "Medium",
    "choiceExplanations": {
      "0": "Security Groups operate at Layer 3/4 (IP addresses and ports) and cannot inspect application layer (Layer 7) HTTP content, making them incapable of detecting or blocking SQL injection or XSS attacks which require payload inspection.",
      "1": "NACLs are stateless firewalls that operate at Layer 3/4 and only filter traffic based on IP addresses, ports, and protocols. They do not support deep packet inspection and cannot examine HTTP payloads for web exploits.",
      "3": "AWS Shield Standard provides protection against DDoS attacks (Layer 3/4) and is automatically enabled for all AWS accounts at no cost. It does not provide web application firewall capabilities, cannot inspect for SQL injection or XSS, and cannot be configured to block specific IP addresses."
    }
  },
  {
    "id": "SAA-083",
    "domainId": "D1",
    "domain": "Design Secure Architectures",
    "section": "Secrets Manager",
    "question": "An application running on ECS needs to retrieve database credentials securely. The credentials rotate every 30 days, and the app should not require redeployment when rotation happens.\nWhich solution is MOST suitable?",
    "choices": [
      "Store credentials in an S3 object encrypted with SSE-S3 and download them on container startup",
      "Store credentials in a Parameter Store standard parameter without encryption",
      "Store credentials in AWS Secrets Manager with rotation enabled and have the app retrieve them at runtime",
      "Store credentials in environment variables baked into the container image"
    ],
    "answer": 2,
    "explanation": "Secrets Manager is designed for storing and rotating secrets like database credentials. Applications can fetch the current secret value at runtime, so rotation doesn’t require rebuilding images or redeploying configs.",
    "difficulty": "Medium",
    "choiceExplanations": {
      "0": "While S3 with SSE-S3 provides encryption at rest, it lacks native credential rotation capabilities and only retrieves credentials at container startup, meaning containers would need to be restarted to pick up rotated credentials.",
      "1": "Standard parameters do not support encryption, exposing credentials in plaintext, and Parameter Store lacks the native automatic rotation functionality that Secrets Manager provides for database credentials.",
      "3": "Embedding credentials in container images is a security anti-pattern as it exposes secrets in the image layers, and any credential rotation would require rebuilding and redeploying the container image."
    }
  },
  {
    "id": "SAA-084",
    "domainId": "D1",
    "domain": "Design Secure Architectures",
    "section": "IAM",
    "question": "A company wants to prevent developers from creating IAM access keys for their own users to reduce the risk of long-lived credentials. Console access with MFA is allowed.\nWhich approach provides the strongest preventive control?",
    "choices": [
      "Use a strong password policy for IAM users",
      "Enable AWS CloudTrail and review access key creation events weekly",
      "Enable AWS Config to detect access keys and notify via email",
      "Apply an SCP (in AWS Organizations) or an IAM permissions boundary/policy that explicitly denies iam:CreateAccessKey for the developer principals"
    ],
    "answer": 3,
    "explanation": "A preventive deny (via SCP or identity policies/permissions boundaries where applicable) blocks the action from occurring. Detective controls like CloudTrail/Config only alert after access keys are created.",
    "difficulty": "Medium",
    "choiceExplanations": {
      "0": "Password policies control password complexity and rotation requirements for console access, but have no effect on preventing the creation of IAM access keys, which are separate programmatic credentials.",
      "1": "CloudTrail is a detective control that logs API activity after it occurs, meaning access keys would already be created before being discovered during the weekly review, providing no prevention capability.",
      "2": "AWS Config is a detective control that monitors configuration compliance and can alert when access keys exist, but it cannot prevent their creation in the first place, only detect them after the fact."
    }
  },
  {
    "id": "SAA-085",
    "domainId": "D1",
    "domain": "Design Secure Architectures",
    "section": "Security Groups",
    "question": "A team is confused about AWS network controls. They need a control that is stateful, supports allow rules only, and is associated directly with an ENI (instance/network interface).\nWhich AWS feature are they describing?",
    "choices": [
      "Network ACL",
      "VPC Flow Logs",
      "Security group",
      "Route table"
    ],
    "answer": 2,
    "explanation": "Security groups are stateful, contain allow rules only, and are attached to network interfaces. NACLs are stateless and support both allow and deny rules at the subnet level.",
    "difficulty": "Medium",
    "choiceExplanations": {
      "0": "NACLs are stateless (not stateful), support both allow and deny rules, and operate at the subnet level rather than being associated directly with ENIs or instances.",
      "1": "VPC Flow Logs are a monitoring feature that captures information about IP traffic going to and from network interfaces; they do not provide any traffic control or filtering capabilities.",
      "3": "Route tables determine where network traffic is directed based on destination IP addresses; they do not provide security controls, are not stateful, and do not filter traffic based on allow/deny rules."
    }
  },
  {
    "id": "SAA-086",
    "domainId": "D1",
    "domain": "Design Secure Architectures",
    "section": "GuardDuty",
    "question": "A company wants to detect potentially compromised EC2 instances, unusual API calls, and suspicious DNS activity without deploying agents.\nWhich service should they enable?",
    "choices": [
      "AWS Shield Advanced",
      "Amazon GuardDuty",
      "AWS Systems Manager",
      "Amazon Inspector"
    ],
    "answer": 1,
    "explanation": "GuardDuty is a managed threat detection service that analyzes CloudTrail, VPC Flow Logs, and DNS logs to identify suspicious activity without requiring agents on instances.",
    "difficulty": "Medium",
    "choiceExplanations": {
      "0": "This service provides protection against DDoS attacks and includes 24/7 access to the AWS DDoS Response Team, but it does not detect compromised instances, unusual API calls, or suspicious DNS activity.",
      "2": "This service provides operational management capabilities like patching, configuration management, and remote access to instances, but it requires an SSM agent and does not perform threat detection or security monitoring.",
      "3": "This service performs automated security assessments to identify vulnerabilities and deviations from best practices, but it requires an agent installed on EC2 instances and focuses on vulnerability scanning rather than detecting active threats or suspicious activity patterns."
    }
  },
  {
    "id": "SAA-087",
    "domainId": "D1",
    "domain": "Design Secure Architectures",
    "section": "Organizations",
    "question": "A company is setting up a multi-account environment and wants to ensure all accounts follow the same mandatory security controls, like disallowing changes to CloudTrail log buckets and restricting regions.\nWhich solution provides centralized governance?",
    "choices": [
      "Using VPC peering between all accounts",
      "Enabling AWS Shield Standard in every account",
      "AWS Organizations with Organizational Units (OUs) and Service Control Policies (SCPs)",
      "Creating identical IAM users in every account"
    ],
    "answer": 2,
    "explanation": "AWS Organizations allows centralized governance through OUs and SCPs that set account-wide permission guardrails. This is the standard approach for enforcing controls across many accounts.",
    "difficulty": "Medium",
    "choiceExplanations": {
      "0": "VPC peering establishes network connectivity between VPCs for resource communication, but it does not provide any governance, policy enforcement, or security controls across accounts.",
      "1": "AWS Shield Standard provides DDoS protection for AWS resources and is automatically enabled at no cost, but it does not enforce security policies, restrict regions, or protect CloudTrail configurations.",
      "3": "This approach is operationally inefficient, difficult to maintain consistently, and does not provide centralized governance since IAM policies in one account cannot enforce restrictions on other accounts."
    }
  },
  {
    "id": "SAA-088",
    "domainId": "D1",
    "domain": "Design Secure Architectures",
    "section": "S3",
    "question": "A client stores confidential reports in S3 and wants to ensure that objects cannot be deleted unless a second factor is used, even by administrators.\nWhat should you configure?",
    "choices": [
      "Enable S3 Transfer Acceleration",
      "Enable default encryption using SSE-S3",
      "Enable versioning on the bucket and enable MFA Delete",
      "Enable S3 Block Public Access"
    ],
    "answer": 2,
    "explanation": "MFA Delete (used with versioning) requires MFA to permanently delete object versions or change the versioning state, providing stronger protection against accidental or malicious deletion.",
    "difficulty": "Medium",
    "choiceExplanations": {
      "0": "This feature speeds up content transfers to and from S3 by using Amazon CloudFront's globally distributed edge locations, but it has no impact on deletion protection or access controls.",
      "1": "Server-side encryption protects data at rest by encrypting objects stored in S3, but it does not prevent or control object deletion in any way.",
      "3": "This feature prevents public access to bucket contents by blocking public ACLs and policies, but it does not restrict administrators or authenticated users from deleting objects."
    }
  },
  {
    "id": "SAA-089",
    "domainId": "D1",
    "domain": "Design Secure Architectures",
    "section": "CloudFront",
    "question": "A company serves a static website globally using CloudFront with an S3 origin. They want to ensure viewers can access content only if they are authenticated by the company’s identity provider.\nWhich CloudFront feature best supports this?",
    "choices": [
      "Enable S3 website hosting and require Basic Auth",
      "Use S3 Transfer Acceleration to restrict access",
      "Use Route 53 geolocation routing only",
      "Use signed URLs or signed cookies with CloudFront"
    ],
    "answer": 3,
    "explanation": "CloudFront signed URLs/cookies restrict access to content by requiring a valid signature, commonly used alongside an authentication system to grant time-limited access to users.",
    "difficulty": "Medium",
    "choiceExplanations": {
      "0": "S3 static website hosting does not support Basic Authentication natively, and this approach would bypass CloudFront entirely, eliminating the benefits of the CDN and not integrating with the company's identity provider.",
      "1": "S3 Transfer Acceleration is designed to speed up uploads to S3 buckets over long distances using CloudFront edge locations, not to restrict or authenticate access to content.",
      "2": "Route 53 geolocation routing directs users to different endpoints based on their geographic location, but it does not provide any authentication or access control based on user identity."
    }
  },
  {
    "id": "SAA-090",
    "domainId": "D1",
    "domain": "Design Secure Architectures",
    "section": "IAM",
    "question": "A security team wants to quickly identify S3 buckets, KMS keys, and other supported resources that have resource policies granting access to external AWS accounts.\nWhich service should they use?",
    "choices": [
      "AWS Artifact",
      "AWS Budgets",
      "AWS Trusted Advisor",
      "IAM Access Analyzer"
    ],
    "answer": 3,
    "explanation": "IAM Access Analyzer evaluates supported resource policies to identify unintended public or cross-account access, helping detect overly permissive sharing.",
    "difficulty": "Medium",
    "choiceExplanations": {
      "0": "This service provides on-demand access to AWS compliance reports and security documents (such as SOC reports and PCI-DSS certifications), not for analyzing resource policies or identifying cross-account access.",
      "1": "This service is used for setting custom cost and usage budgets with alerts when thresholds are exceeded, and has no capability to analyze resource policies or detect external account access.",
      "2": "While Trusted Advisor provides recommendations across cost optimization, security, fault tolerance, and performance, it does not specifically analyze resource-based policies to identify cross-account access like IAM Access Analyzer does."
    }
  },
  {
    "id": "SAA-091",
    "domainId": "D1",
    "domain": "Design Secure Architectures",
    "section": "VPC",
    "question": "A company wants to inspect and control outbound DNS queries from workloads in a VPC and block known malicious domains at the DNS layer.\nWhich managed AWS service capability is MOST suitable?",
    "choices": [
      "Network ACLs with domain-based rules",
      "Amazon Route 53 Resolver DNS Firewall",
      "AWS Shield Standard",
      "Security groups with DNS deny rules"
    ],
    "answer": 1,
    "explanation": "Route 53 Resolver DNS Firewall lets you define rules to allow/deny domain names for DNS queries from VPCs, providing managed DNS-layer protection. SGs/NACLs don’t filter by domain name.",
    "difficulty": "Medium",
    "choiceExplanations": {
      "0": "Network ACLs operate at the IP address and port level (Layer 3/4) and cannot filter traffic based on domain names; they only support rules using IP addresses, protocols, and port numbers.",
      "2": "AWS Shield Standard provides protection against DDoS attacks at the network and transport layers, not DNS-layer filtering or domain-based blocking of outbound queries.",
      "3": "Security groups are stateful firewalls that filter traffic based on IP addresses, protocols, and ports; they cannot inspect or filter DNS queries by domain name and do not support deny rules (only allow rules)."
    }
  },
  {
    "id": "SAA-092",
    "domainId": "D2",
    "domain": "Design Resilient Architectures",
    "section": "RDS",
    "question": "A company runs a production PostgreSQL database on Amazon RDS. They need automatic failover in case the primary AZ becomes unavailable, with minimal application changes.\nWhich solution best meets this requirement?",
    "choices": [
      "Export automated snapshots daily to S3",
      "Deploy the database on a single EC2 instance with EBS snapshots",
      "Create an RDS read replica and point the application to it",
      "Enable Multi-AZ deployment for the RDS instance"
    ],
    "answer": 3,
    "explanation": "RDS Multi-AZ provides synchronous replication to a standby in another AZ and automatic failover to maintain availability with minimal application changes. Read replicas are primarily for scaling reads and can have asynchronous replication.",
    "difficulty": "Medium",
    "choiceExplanations": {
      "0": "Snapshots provide point-in-time backup capability but do not provide automatic failover; restoring from a snapshot requires manual intervention and results in significant downtime, not meeting the automatic failover requirement.",
      "1": "A single EC2 instance provides no high availability or automatic failover capability, and EBS snapshots only provide backup functionality requiring manual restoration, which contradicts the automatic failover requirement.",
      "2": "Read replicas use asynchronous replication and are designed for read scaling, not automatic failover; promoting a read replica to primary requires manual intervention and application changes to update connection endpoints."
    }
  },
  {
    "id": "SAA-093",
    "domainId": "D2",
    "domain": "Design Resilient Architectures",
    "section": "Route 53",
    "question": "A global e-commerce site runs active applications in two AWS Regions. The business wants users to be routed to the closest healthy region and fail over automatically if one region becomes unhealthy.\nWhich Route 53 routing policy best fits?",
    "choices": [
      "Weighted routing without health checks",
      "Latency-based routing with health checks",
      "Geolocation routing without health checks",
      "Simple routing"
    ],
    "answer": 1,
    "explanation": "Latency-based routing directs users to the region that provides the lowest latency, and health checks enable automatic failover away from unhealthy endpoints.",
    "difficulty": "Medium",
    "choiceExplanations": {
      "0": "Weighted routing distributes traffic based on assigned proportions rather than routing users to the closest region, and without health checks there is no automatic failover when a region becomes unhealthy.",
      "2": "Geolocation routing directs users based on their geographic location rather than network latency to find the closest region, and without health checks it cannot automatically fail over when a region becomes unhealthy.",
      "3": "Simple routing returns all values in random order and does not support health check failover or any logic to route users to the closest or healthiest region, making it unsuitable for multi-region active-active deployments requiring automatic failover."
    }
  },
  {
    "id": "SAA-094",
    "domainId": "D2",
    "domain": "Design Resilient Architectures",
    "section": "SQS",
    "question": "A team uses Amazon SQS to decouple a web tier from a worker tier. Sometimes, the workers fail to process a message due to a transient error, and messages get retried repeatedly.\nThe team wants a safe way to isolate problematic messages for later analysis without blocking the queue.\nWhich feature should they use?",
    "choices": [
      "Enable FIFO on the queue",
      "Enable SQS long polling",
      "Configure a dead-letter queue (DLQ) with a maxReceiveCount",
      "Increase the message retention period to 14 days"
    ],
    "answer": 2,
    "explanation": "A DLQ moves messages that fail processing too many times to a separate queue for investigation, preventing them from being retried indefinitely and blocking progress.",
    "difficulty": "Medium",
    "choiceExplanations": {
      "0": "FIFO queues ensure exactly-once processing and message ordering, but they do not isolate problematic messages or prevent repeated retries of failed messages; the problematic messages would still block processing of subsequent messages in the same message group.",
      "1": "Long polling reduces empty responses and API costs by waiting for messages to arrive before returning, but it has no capability to isolate or handle messages that repeatedly fail processing.",
      "3": "Extending retention only keeps messages in the queue longer before automatic deletion; it does not isolate problematic messages or prevent them from being retried repeatedly and blocking the queue."
    }
  },
  {
    "id": "SAA-095",
    "domainId": "D2",
    "domain": "Design Resilient Architectures",
    "section": "ECS",
    "question": "A service runs on Amazon ECS with the Fargate launch type across two AZs. The team needs tasks to be automatically replaced when they fail, and wants to maintain a desired number of running tasks.\nWhich ECS feature provides this behavior?",
    "choices": [
      "An ECS service with a desired count and health checks",
      "An S3 lifecycle policy",
      "ECS Exec",
      "An ECS task definition only"
    ],
    "answer": 0,
    "explanation": "An ECS service maintains the desired number of tasks and will replace failed tasks automatically. Health checks help ECS/ALB determine unhealthy tasks and trigger replacement.",
    "difficulty": "Medium",
    "choiceExplanations": {
      "1": "This is an Amazon S3 feature used to manage object storage by automatically transitioning objects between storage classes or deleting them after specified time periods, and has no relation to ECS task management or container orchestration.",
      "2": "This feature allows you to run commands or get a shell inside a running container for debugging and troubleshooting purposes, but it does not provide any automatic task replacement or maintain desired task counts.",
      "3": "A task definition is a blueprint that describes container configurations such as CPU, memory, and image settings, but it does not manage task lifecycle or automatically replace failed tasks; an ECS service is required for that functionality."
    }
  },
  {
    "id": "SAA-096",
    "domainId": "D2",
    "domain": "Design Resilient Architectures",
    "section": "ELB/ASG",
    "question": "A web application is deployed on EC2 instances in an Auto Scaling group behind an Application Load Balancer. The team wants unhealthy instances to be replaced automatically when they fail application-level health checks.\nWhich configuration should they implement?",
    "choices": [
      "Enable detailed monitoring on EC2 instances only",
      "Use a Network Load Balancer and disable health checks",
      "Use Amazon CloudFront in front of the ALB and rely on edge caching",
      "Configure ALB target group health checks and enable Auto Scaling health checks that use ELB health status"
    ],
    "answer": 3,
    "explanation": "ALB target group health checks detect application health. When Auto Scaling uses ELB health checks, it can terminate and replace instances that fail the load balancer health checks automatically.",
    "difficulty": "Medium",
    "choiceExplanations": {
      "0": "Detailed monitoring provides more frequent CloudWatch metrics (1-minute intervals) for EC2 system-level metrics like CPU and network, but it does not perform application-level health checks or trigger Auto Scaling to replace unhealthy instances based on application health.",
      "1": "Disabling health checks would prevent any detection of unhealthy instances, and NLB operates at Layer 4 (TCP/UDP) which cannot perform the application-level (Layer 7) health checks that the question specifically requires.",
      "2": "CloudFront is a CDN service that caches content at edge locations to improve performance, but it does not monitor instance health or integrate with Auto Scaling to replace unhealthy instances; cached content would simply mask backend failures temporarily."
    }
  },
  {
    "id": "SAA-097",
    "domainId": "D2",
    "domain": "Design Resilient Architectures",
    "section": "S3",
    "question": "A company needs to protect critical S3 objects from accidental overwrites and deletions, but they also want the ability to recover previous versions.\nWhich S3 feature best meets this requirement?",
    "choices": [
      "Enable S3 Transfer Acceleration",
      "Enable S3 versioning",
      "Enable S3 Requester Pays",
      "Enable S3 static website hosting"
    ],
    "answer": 1,
    "explanation": "S3 versioning preserves multiple variants of an object in the same bucket, enabling recovery from accidental overwrites and deletions.",
    "difficulty": "Medium",
    "choiceExplanations": {
      "0": "This feature speeds up content transfers to and from S3 by using Amazon CloudFront's globally distributed edge locations, but it does not provide any protection against accidental overwrites or deletions.",
      "2": "This feature shifts the cost of requests and data transfer to the requester instead of the bucket owner, but it has no capability to protect objects from being overwritten or deleted or to recover previous versions.",
      "3": "This feature allows you to host a static website directly from an S3 bucket by serving HTML, CSS, and JavaScript files, but it provides no protection against accidental modifications or deletions and no version recovery capability."
    }
  },
  {
    "id": "SAA-098",
    "domainId": "D2",
    "domain": "Design Resilient Architectures",
    "section": "Lambda",
    "question": "A serverless workload writes items to DynamoDB. Occasionally, downstream processing fails and needs to be retried without losing events.\nWhich option provides the MOST resilient event-driven design?",
    "choices": [
      "Trigger Lambda directly from an S3 bucket event",
      "Write DynamoDB items and rely on manual reprocessing only",
      "Use DynamoDB Streams to trigger a Lambda function and configure retries with a DLQ (or on-failure destination) for failed records",
      "Have the Lambda poll DynamoDB every minute and scan the table"
    ],
    "answer": 2,
    "explanation": "DynamoDB Streams provide an ordered change log for table modifications. Lambda integrations support retries, and a DLQ/destination can capture failed records for later reprocessing, improving resilience.",
    "difficulty": "Medium",
    "choiceExplanations": {
      "0": "This approach is unrelated to DynamoDB item changes and would only capture S3 object events, not the DynamoDB writes mentioned in the scenario, making it unsuitable for processing DynamoDB table modifications.",
      "1": "Manual reprocessing is not resilient or automated, lacks built-in retry mechanisms, and risks losing events if failures are not detected promptly, making it an unreliable approach for production workloads.",
      "3": "Scanning the entire table is inefficient, costly, and does not provide an ordered change log; it cannot reliably detect which items are new or modified, and lacks the automatic retry and failure handling capabilities of DynamoDB Streams."
    }
  },
  {
    "id": "SAA-099",
    "domainId": "D2",
    "domain": "Design Resilient Architectures",
    "section": "EFS",
    "question": "A fleet of EC2 instances across multiple AZs needs shared access to the same file system for user uploads. The application requires automatic high availability across AZs.\nWhich storage service is MOST suitable?",
    "choices": [
      "Amazon S3 Glacier Deep Archive",
      "Instance store",
      "Amazon EBS",
      "Amazon EFS"
    ],
    "answer": 3,
    "explanation": "EFS is a managed, elastic NFS file system designed for shared access and is accessible from multiple AZs, supporting highly available shared storage for EC2/ECS workloads.",
    "difficulty": "Medium",
    "choiceExplanations": {
      "0": "This is designed for long-term archival storage with retrieval times of 12-48 hours, making it unsuitable for active user uploads that require immediate file system access.",
      "1": "This provides temporary block-level storage that is physically attached to the host and cannot be shared across instances or AZs, and data is lost when the instance stops or terminates.",
      "2": "EBS volumes can only be attached to EC2 instances within a single Availability Zone and cannot be simultaneously shared across multiple instances in different AZs (except for EBS Multi-Attach which is limited to a single AZ)."
    }
  },
  {
    "id": "SAA-100",
    "domainId": "D2",
    "domain": "Design Resilient Architectures",
    "section": "CloudFront",
    "question": "A company serves static and dynamic content worldwide. They want improved availability and reduced latency for static assets, and they want to reduce the impact of origin outages for cached content.\nWhich service should they use?",
    "choices": [
      "Amazon CloudFront",
      "Amazon EBS",
      "AWS Direct Connect",
      "AWS Snowball"
    ],
    "answer": 0,
    "explanation": "CloudFront caches content at edge locations, improving performance and providing some resilience by serving cached objects even when the origin is temporarily unavailable (subject to cache settings).",
    "difficulty": "Medium",
    "choiceExplanations": {
      "1": "EBS provides block-level storage volumes for EC2 instances and does not provide content delivery, caching, or global distribution capabilities to reduce latency for worldwide users.",
      "2": "Direct Connect establishes dedicated private network connections between on-premises data centers and AWS, but does not provide global content caching or edge distribution to reduce latency for worldwide end users.",
      "3": "Snowball is a physical data transfer device used for large-scale data migration into and out of AWS, not a content delivery or caching service for serving content to global users."
    }
  },
  {
    "id": "SAA-101",
    "domainId": "D2",
    "domain": "Design Resilient Architectures",
    "section": "Backup",
    "question": "A company wants to centrally manage backups for Amazon RDS, EBS volumes, and EFS file systems across multiple accounts. They need retention policies and centralized reporting.\nWhich solution is MOST suitable?",
    "choices": [
      "Use CloudTrail to store backups",
      "Rely on each team to manually create snapshots",
      "Use AWS Backup with centralized backup policies (optionally via Organizations)",
      "Create custom scripts that take snapshots and store them in S3"
    ],
    "answer": 2,
    "explanation": "AWS Backup provides centralized backup management, scheduling, retention, and reporting for supported services and can be used across accounts with Organizations integration.",
    "difficulty": "Medium",
    "choiceExplanations": {
      "0": "CloudTrail is a service for logging and auditing API calls and account activity, not for storing or managing backups of resources like RDS, EBS, or EFS.",
      "1": "Manual snapshot creation is error-prone, lacks centralized management and reporting, does not scale across multiple accounts, and cannot enforce consistent retention policies automatically.",
      "3": "Custom scripts require significant development and maintenance effort, lack built-in centralized reporting, and cannot directly store RDS or EBS snapshots in S3 as these services use their own native snapshot mechanisms."
    }
  },
  {
    "id": "SAA-102",
    "domainId": "D2",
    "domain": "Design Resilient Architectures",
    "section": "DynamoDB",
    "question": "A mobile app backend uses DynamoDB and must continue serving reads and writes even if an entire AWS Region becomes unavailable. The application requires near real-time replication between regions.\nWhich DynamoDB feature should you use?",
    "choices": [
      "DynamoDB Streams only in a single region",
      "DynamoDB TTL",
      "DynamoDB DAX",
      "DynamoDB global tables"
    ],
    "answer": 3,
    "explanation": "Global tables provide multi-region, multi-active replication for DynamoDB, enabling reads and writes in multiple regions with near real-time replication and improved regional resilience.",
    "difficulty": "Medium",
    "choiceExplanations": {
      "0": "DynamoDB Streams captures data modification events within a single table but does not provide cross-region replication by itself; it only operates within one region and cannot ensure availability if that region becomes unavailable.",
      "1": "Time to Live (TTL) is a feature that automatically deletes expired items from a table based on a timestamp attribute; it has no capability for cross-region replication or improving regional resilience.",
      "2": "DynamoDB Accelerator (DAX) is an in-memory caching service that improves read performance for DynamoDB tables within a single region; it does not provide multi-region replication or cross-region failover capabilities."
    }
  },
  {
    "id": "SAA-103",
    "domainId": "D2",
    "domain": "Design Resilient Architectures",
    "section": "SNS/SQS",
    "question": "A company needs to send an event to multiple independent processing systems. Each system must receive every message and process it at its own pace. If one system is down, others must not be impacted.\nWhich design best meets these requirements?",
    "choices": [
      "Send messages to a single SQS queue shared by all systems",
      "Send events directly to each system over HTTP from the producer",
      "Write events to an S3 bucket and have systems list objects periodically",
      "Publish to an SNS topic and subscribe multiple SQS queues (one per system)"
    ],
    "answer": 3,
    "explanation": "SNS fanout to multiple SQS queues ensures each consumer system receives its own copy of each message, decouples processing rates, and isolates failures between systems.",
    "difficulty": "Medium",
    "choiceExplanations": {
      "0": "With a single shared queue, each message is delivered to only one consumer (competing consumers pattern), meaning not all systems would receive every message as required.",
      "1": "Direct HTTP calls create tight coupling between the producer and consumers, and if one system is down, the producer must handle retries and failures, potentially impacting message delivery to other systems.",
      "2": "S3 polling is inefficient, introduces latency, and is not designed for real-time event distribution; systems would need to track which objects they have already processed, adding complexity without the reliability guarantees of a messaging service."
    }
  },
  {
    "id": "SAA-104",
    "domainId": "D2",
    "domain": "Design Resilient Architectures",
    "section": "ASG",
    "question": "A company wants to automatically scale a fleet of EC2 instances based on CPU utilization and replace unhealthy instances. They want the platform to handle capacity changes automatically.\nWhich solution best fits?",
    "choices": [
      "Use AWS OpsWorks to deploy the application but not scale",
      "Use a single large EC2 instance with vertical scaling",
      "Use an Auto Scaling group with scaling policies and health checks",
      "Use EC2 Spot Instances only and manually add instances when needed"
    ],
    "answer": 2,
    "explanation": "Auto Scaling groups provide automatic capacity management and instance replacement based on health checks and scaling policies, improving availability and resilience.",
    "difficulty": "Medium",
    "choiceExplanations": {
      "0": "AWS OpsWorks is a configuration management service that uses Chef or Puppet for deployment and configuration, but it does not provide automatic scaling based on CPU utilization or automatic replacement of unhealthy instances like Auto Scaling groups do.",
      "1": "Vertical scaling requires stopping the instance to change its size, causing downtime and not providing automatic scaling or health-based instance replacement; it also creates a single point of failure rather than a resilient fleet.",
      "3": "Manual scaling does not meet the requirement for automatic capacity management, and relying solely on Spot Instances without Auto Scaling means no automatic replacement of unhealthy or interrupted instances."
    }
  },
  {
    "id": "SAA-105",
    "domainId": "D2",
    "domain": "Design Resilient Architectures",
    "section": "S3",
    "question": "A company needs to replicate objects from an S3 bucket in us-east-1 to another bucket in eu-west-1 for disaster recovery. Replication must be automatic after objects are uploaded.\nWhich feature should be used?",
    "choices": [
      "S3 multipart upload",
      "S3 Cross-Region Replication (CRR)",
      "S3 Transfer Acceleration",
      "S3 Select"
    ],
    "answer": 1,
    "explanation": "S3 Cross-Region Replication automatically replicates objects to a bucket in another region, supporting disaster recovery and compliance use cases.",
    "difficulty": "Medium",
    "choiceExplanations": {
      "0": "This feature is designed for uploading large objects in parts to improve upload performance and reliability, not for replicating objects between buckets or regions.",
      "2": "This feature speeds up transfers to S3 by routing data through CloudFront edge locations, but it does not automatically replicate objects between buckets in different regions.",
      "3": "This feature enables retrieving a subset of data from an object using SQL expressions to reduce data transfer, but it has no replication or disaster recovery capabilities."
    }
  },
  {
    "id": "SAA-106",
    "domainId": "D3",
    "domain": "Design High-Performing Architectures",
    "section": "ELB",
    "question": "A multiplayer game uses UDP for real-time communication between clients and game servers running on EC2. The solution must distribute UDP traffic across instances with low latency.\nWhich load balancing option should you choose?",
    "choices": [
      "Network Load Balancer (NLB)",
      "CloudFront distribution",
      "Classic Load Balancer (CLB) with HTTP listeners",
      "Application Load Balancer (ALB)"
    ],
    "answer": 0,
    "explanation": "NLB operates at Layer 4 and supports UDP, providing very high performance and low latency load balancing. ALB is Layer 7 and supports HTTP/HTTPS, not UDP.",
    "difficulty": "Medium",
    "choiceExplanations": {
      "1": "CloudFront is a content delivery network (CDN) designed for HTTP/HTTPS and RTMP content delivery, not for load balancing UDP traffic across EC2 instances.",
      "2": "CLB supports TCP and HTTP/HTTPS protocols but does not support UDP traffic, making it unsuitable for real-time game communication requiring UDP.",
      "3": "ALB operates at Layer 7 (application layer) and only supports HTTP and HTTPS protocols, not UDP, which is required for this real-time gaming scenario."
    }
  },
  {
    "id": "SAA-107",
    "domainId": "D3",
    "domain": "Design High-Performing Architectures",
    "section": "DynamoDB",
    "question": "A product catalog API requires single-digit millisecond latency for reads at very high request rates. The data is key-value and read-heavy.\nWhich AWS service is MOST suitable as the primary datastore?",
    "choices": [
      "Amazon Redshift",
      "Amazon DynamoDB",
      "Amazon RDS MySQL",
      "Amazon S3 Select"
    ],
    "answer": 1,
    "explanation": "DynamoDB is a managed key-value/NoSQL database designed for single-digit millisecond latency at scale. Relational and analytics services are not optimized for this access pattern.",
    "difficulty": "Medium",
    "choiceExplanations": {
      "0": "Redshift is a data warehousing service optimized for complex analytical queries (OLAP) on large datasets, not for low-latency key-value lookups at high request rates typical of operational workloads.",
      "2": "RDS MySQL is a relational database that requires schema design and is not optimized for the simple key-value access patterns described; it also cannot match DynamoDB's consistent single-digit millisecond latency at very high request rates without significant scaling complexity.",
      "3": "S3 Select is designed to retrieve subsets of data from objects stored in S3 and has higher latency (typically hundreds of milliseconds) compared to DynamoDB, making it unsuitable for single-digit millisecond response requirements."
    }
  },
  {
    "id": "SAA-108",
    "domainId": "D3",
    "domain": "Design High-Performing Architectures",
    "section": "CloudFront",
    "question": "A company serves large static assets (images, JS, CSS) to users worldwide. They want to reduce latency and offload requests from the origin servers.\nWhich solution should they implement?",
    "choices": [
      "Use AWS Snowball to deliver content to users",
      "Move the assets to Amazon EBS",
      "Use Amazon CloudFront to cache content at edge locations",
      "Increase the EC2 instance size of the origin servers"
    ],
    "answer": 2,
    "explanation": "CloudFront caches and serves static content from edge locations close to users, reducing latency and origin load.",
    "difficulty": "Medium",
    "choiceExplanations": {
      "0": "AWS Snowball is a physical data transfer device used for large-scale data migration to and from AWS, not for serving content to end users in real-time or reducing latency for web requests.",
      "1": "Amazon EBS provides block storage attached to EC2 instances and does not provide content distribution capabilities; it would not reduce latency for global users or offload requests from origin servers.",
      "3": "While larger instances can handle more requests, this approach does not reduce latency for geographically distributed users and does not offload traffic from the origin since all requests still go directly to the origin servers."
    }
  },
  {
    "id": "SAA-109",
    "domainId": "D3",
    "domain": "Design High-Performing Architectures",
    "section": "EBS",
    "question": "A database on EC2 needs the highest possible IOPS with consistent, low-latency storage performance.\nWhich EBS volume type is MOST appropriate?",
    "choices": [
      "Cold HDD (sc1)",
      "Throughput Optimized HDD (st1)",
      "Provisioned IOPS SSD (io1/io2)",
      "Magnetic (standard)"
    ],
    "answer": 2,
    "explanation": "io1/io2 volumes are designed for high IOPS and consistent performance, which is critical for latency-sensitive databases.",
    "difficulty": "Medium",
    "choiceExplanations": {
      "0": "Designed for infrequently accessed, cold data workloads with the lowest cost, offering only 250 IOPS maximum and high latency, making it completely unsuitable for database workloads requiring high IOPS and low latency.",
      "1": "Optimized for large, sequential workloads like data warehouses and log processing where throughput (MB/s) matters more than IOPS, with a maximum of only 500 IOPS, which is inadequate for latency-sensitive database operations.",
      "3": "A previous generation volume type with inconsistent performance and limited IOPS (40-200), not suitable for production databases requiring high, consistent IOPS and low latency."
    }
  },
  {
    "id": "SAA-110",
    "domainId": "D3",
    "domain": "Design High-Performing Architectures",
    "section": "S3",
    "question": "A client uploads very large files to S3, and uploads frequently fail due to unstable connections. They want higher reliability and better throughput.\nWhich S3 feature should they use?",
    "choices": [
      "S3 Multipart Upload",
      "S3 Object Lock",
      "S3 Inventory only",
      "S3 Static Website Hosting"
    ],
    "answer": 0,
    "explanation": "Multipart Upload splits large objects into parts that can be uploaded in parallel and retried independently, improving throughput and reliability for large uploads.",
    "difficulty": "Medium",
    "choiceExplanations": {
      "1": "This feature prevents objects from being deleted or overwritten for a specified retention period (WORM model), which is used for compliance and data protection, not for improving upload reliability or throughput.",
      "2": "S3 Inventory generates reports about objects and their metadata in a bucket on a scheduled basis, which is useful for auditing and management purposes, but does not address upload reliability or performance issues.",
      "3": "This feature enables hosting static web content directly from an S3 bucket, allowing public access to HTML, CSS, and JavaScript files, but has no relation to improving upload reliability or throughput for large files."
    }
  },
  {
    "id": "SAA-111",
    "domainId": "D3",
    "domain": "Design High-Performing Architectures",
    "section": "RDS",
    "question": "An application has read-heavy traffic and uses an Amazon RDS database. The team wants to increase read throughput without changing the application’s write logic.\nWhich solution is MOST suitable?",
    "choices": [
      "Increase storage size to improve reads",
      "Add one or more RDS read replicas and direct read traffic to them",
      "Move the database to S3",
      "Enable Multi-AZ and send reads to the standby instance"
    ],
    "answer": 1,
    "explanation": "Read replicas scale out read traffic. In standard RDS Multi-AZ, the standby is for failover and typically not used for serving reads.",
    "difficulty": "Medium",
    "choiceExplanations": {
      "0": "Increasing storage size does not improve read throughput; storage size affects capacity and potentially IOPS for certain storage types, but does not scale out read operations or reduce load on the primary database instance.",
      "2": "Amazon S3 is an object storage service, not a relational database, and cannot replace RDS for transactional database workloads requiring SQL queries, ACID compliance, and relational data structures.",
      "3": "In standard RDS Multi-AZ deployments, the standby instance is a synchronous replica used only for automatic failover and cannot serve read traffic; it has no accessible endpoint for application connections."
    }
  },
  {
    "id": "SAA-112",
    "domainId": "D3",
    "domain": "Design High-Performing Architectures",
    "section": "Global Accelerator",
    "question": "A company has a global user base accessing a latency-sensitive API hosted behind an ALB in a single region. They want improved global performance without changing the application.\nWhich service can provide faster global routing to the regional endpoint?",
    "choices": [
      "AWS Snowcone",
      "Amazon S3 Glacier",
      "AWS Global Accelerator",
      "AWS Backup"
    ],
    "answer": 2,
    "explanation": "Global Accelerator uses the AWS global network to route users to the optimal endpoint, improving performance for latency-sensitive applications.",
    "difficulty": "Medium",
    "choiceExplanations": {
      "0": "This is a portable edge computing and data transfer device used for collecting, processing, and moving data in disconnected or harsh environments, not for improving global network routing or reducing latency to applications.",
      "1": "This is a low-cost storage class designed for data archiving and long-term backup with retrieval times ranging from minutes to hours, not a networking service for improving application latency or global routing.",
      "3": "This is a centralized backup service for automating and managing backups across AWS services, not a networking solution for improving global application performance or routing traffic to regional endpoints."
    }
  },
  {
    "id": "SAA-113",
    "domainId": "D3",
    "domain": "Design High-Performing Architectures",
    "section": "ElastiCache",
    "question": "A web application repeatedly queries the same small set of product data, causing high load on the database. The team wants sub-millisecond retrieval for hot items.\nWhich solution should they implement?",
    "choices": [
      "Enable EBS snapshots more frequently",
      "Add an in-memory cache layer using Amazon ElastiCache (Redis or Memcached)",
      "Use AWS CloudTrail insights",
      "Move the product data to Glacier Deep Archive"
    ],
    "answer": 1,
    "explanation": "An in-memory cache like ElastiCache reduces database load and provides very low-latency retrieval for frequently accessed data.",
    "difficulty": "Medium",
    "choiceExplanations": {
      "0": "EBS snapshots are point-in-time backups of EBS volumes used for data protection and disaster recovery, not for improving data retrieval performance or reducing database load.",
      "2": "CloudTrail Insights is used for detecting unusual API activity and operational issues in your AWS account, not for caching data or improving application query performance.",
      "3": "Glacier Deep Archive is designed for long-term archival storage with retrieval times of 12-48 hours, making it completely unsuitable for sub-millisecond access requirements for frequently accessed hot data."
    }
  },
  {
    "id": "SAA-114",
    "domainId": "D3",
    "domain": "Design High-Performing Architectures",
    "section": "SQS",
    "question": "A worker application polls an SQS queue and often receives empty responses, increasing cost and CPU usage. The team wants to reduce the number of empty receives.\nWhich feature should they enable?",
    "choices": [
      "SQS long polling",
      "SQS FIFO",
      "SQS encryption",
      "SQS dead-letter queue"
    ],
    "answer": 0,
    "explanation": "Long polling waits for messages to arrive before returning a response, reducing empty receives and lowering cost.",
    "difficulty": "Medium",
    "choiceExplanations": {
      "1": "FIFO queues ensure exactly-once processing and maintain message ordering, but they do not address the issue of empty receives or reduce polling costs.",
      "2": "Encryption protects message data at rest using AWS KMS keys for security purposes, but it has no effect on reducing empty responses or polling behavior.",
      "3": "Dead-letter queues capture messages that fail processing after a specified number of attempts, but they do not reduce empty receives or affect how the queue responds to polling requests."
    }
  },
  {
    "id": "SAA-115",
    "domainId": "D3",
    "domain": "Design High-Performing Architectures",
    "section": "ECS",
    "question": "A containerized service needs to scale horizontally based on request rate, and tasks should be distributed across multiple AZs. The team prefers a managed container platform.\nWhich AWS service is MOST appropriate?",
    "choices": [
      "AWS Snowball Edge",
      "Amazon ECS (with Fargate or EC2 launch type) using a Service and Service Auto Scaling",
      "AWS Storage Gateway",
      "Amazon S3"
    ],
    "answer": 1,
    "explanation": "ECS provides managed container orchestration, supports multi-AZ placement, and can scale services automatically based on metrics such as request count or CPU.",
    "difficulty": "Medium",
    "choiceExplanations": {
      "0": "This is a physical edge computing and data transfer device used for offline data migration and edge computing in disconnected environments, not a container orchestration platform for running scalable containerized services.",
      "2": "This is a hybrid cloud storage service that connects on-premises environments to AWS cloud storage, providing file, volume, or tape gateway functionality, not a container management or orchestration service.",
      "3": "This is an object storage service designed for storing and retrieving data, not a compute or container orchestration platform capable of running containerized applications or scaling based on request rate."
    }
  },
  {
    "id": "SAA-116",
    "domainId": "D3",
    "domain": "Design High-Performing Architectures",
    "section": "S3",
    "question": "An analytics team needs to run SQL queries on large CSV files stored in S3 without loading them into a database first.\nWhich service should they use?",
    "choices": [
      "Amazon RDS",
      "Amazon ElastiCache",
      "AWS Secrets Manager",
      "Amazon Athena"
    ],
    "answer": 3,
    "explanation": "Athena is a serverless query service that uses SQL to analyze data directly in S3, ideal for ad-hoc queries over files.",
    "difficulty": "Medium",
    "choiceExplanations": {
      "0": "RDS is a managed relational database service that requires data to be loaded into database tables before querying, which directly contradicts the requirement to query S3 files without loading them into a database first.",
      "1": "ElastiCache is an in-memory caching service (Redis or Memcached) designed to improve application performance by caching frequently accessed data, not for running SQL queries on files stored in S3.",
      "2": "Secrets Manager is a service for securely storing and managing sensitive information like database credentials, API keys, and passwords, and has no capability to query or analyze data in S3."
    }
  },
  {
    "id": "SAA-117",
    "domainId": "D3",
    "domain": "Design High-Performing Architectures",
    "section": "EC2",
    "question": "A high-performance computing job requires low-latency, high-throughput network communication between EC2 instances.\nWhich EC2 placement strategy best supports this?",
    "choices": [
      "Run instances in different regions",
      "Cluster placement group",
      "Spread placement group across multiple racks",
      "Partition placement group with isolated partitions only"
    ],
    "answer": 1,
    "explanation": "Cluster placement groups place instances close together within an AZ to achieve low-latency, high-throughput networking, suitable for tightly coupled workloads.",
    "difficulty": "Medium",
    "choiceExplanations": {
      "0": "Running instances in different regions introduces significant network latency due to geographic distance and requires traffic to traverse the public internet or inter-region connections, making it unsuitable for low-latency, high-throughput HPC workloads.",
      "2": "Spread placement groups distribute instances across distinct underlying hardware racks to maximize availability and reduce correlated failures, but this physical separation increases network latency and reduces throughput compared to cluster placement groups.",
      "3": "Partition placement groups distribute instances across logical partitions on separate racks, designed for large distributed workloads like HDFS or Cassandra that need fault isolation rather than the lowest possible network latency required for tightly coupled HPC applications."
    }
  },
  {
    "id": "SAA-118",
    "domainId": "D3",
    "domain": "Design High-Performing Architectures",
    "section": "S3",
    "question": "A company uploads files to S3 from users around the world and wants faster uploads by optimizing transfer paths to S3.\nWhich S3 feature can help?",
    "choices": [
      "S3 Object Lock",
      "S3 Transfer Acceleration",
      "S3 Glacier Deep Archive",
      "S3 Batch Operations"
    ],
    "answer": 1,
    "explanation": "Transfer Acceleration uses CloudFront edge locations to accelerate uploads to S3 over long distances, improving performance for global users.",
    "difficulty": "Medium",
    "choiceExplanations": {
      "0": "This feature prevents objects from being deleted or overwritten for a specified retention period using WORM (Write Once Read Many) model, but it does not improve upload speeds or optimize transfer paths.",
      "2": "This is a low-cost storage class designed for long-term data archival with retrieval times of 12-48 hours, not a feature for accelerating uploads or optimizing transfer performance.",
      "3": "This feature performs large-scale batch operations on existing S3 objects such as copying, tagging, or invoking Lambda functions, but it does not accelerate or optimize the upload process for new objects."
    }
  },
  {
    "id": "SAA-119",
    "domainId": "D4",
    "domain": "Design Cost-Optimized Architectures",
    "section": "S3",
    "question": "A team stores monthly reports in S3. Reports are accessed frequently for the first 30 days and then rarely accessed, but they still need millisecond retrieval when they are accessed.\nWhich storage class transition is MOST cost-effective?",
    "choices": [
      "Transition objects to S3 Glacier Flexible Retrieval immediately",
      "Transition objects to S3 Standard-IA after 30 days using a lifecycle rule",
      "Transition objects to S3 Glacier Deep Archive after 30 days",
      "Keep objects in S3 Standard forever"
    ],
    "answer": 1,
    "explanation": "Standard-IA is designed for infrequently accessed data with the same millisecond access as Standard, making it a common cost optimization after the frequent-access period.",
    "difficulty": "Medium",
    "choiceExplanations": {
      "0": "This is incorrect because Glacier Flexible Retrieval does not provide millisecond retrieval times (retrieval takes minutes to hours), and transitioning immediately would make frequently accessed reports in the first 30 days expensive and slow to retrieve.",
      "2": "This is incorrect because Glacier Deep Archive does not provide millisecond retrieval; it is designed for long-term archival with retrieval times of 12-48 hours, which fails the requirement for instant access when needed.",
      "3": "This is incorrect because it is not cost-effective; S3 Standard has higher storage costs than S3 Standard-IA, and since reports are rarely accessed after 30 days, continuing to pay Standard pricing wastes money without providing any benefit."
    }
  },
  {
    "id": "SAA-120",
    "domainId": "D4",
    "domain": "Design Cost-Optimized Architectures",
    "section": "EC2",
    "question": "A company runs a steady-state workload 24/7 for the next 1–3 years. They want lower cost than On-Demand while keeping predictable capacity.\nWhich pricing option is typically MOST cost-effective?",
    "choices": [
      "Dedicated Hosts only",
      "Reserved Instances or Savings Plans",
      "Spot Instances only",
      "On-Demand Instances only"
    ],
    "answer": 1,
    "explanation": "For long-running steady workloads, Reserved Instances or Savings Plans usually provide significant discounts compared to On-Demand, without the interruption risk of Spot.",
    "difficulty": "Medium",
    "choiceExplanations": {
      "0": "Dedicated Hosts are designed for licensing compliance and regulatory requirements, not cost optimization; they are typically more expensive than standard instances and don't provide the cost savings that Reserved Instances or Savings Plans offer for steady-state workloads.",
      "2": "While Spot Instances offer up to 90% discount, they can be interrupted with 2-minute notice when AWS needs the capacity back, making them unsuitable for steady-state workloads requiring predictable, uninterrupted capacity 24/7.",
      "3": "On-Demand pricing is the most expensive option with no commitment discounts; for a 1-3 year steady-state workload, Reserved Instances or Savings Plans can provide up to 72% savings compared to On-Demand rates."
    }
  },
  {
    "id": "SAA-121",
    "domainId": "D4",
    "domain": "Design Cost-Optimized Architectures",
    "section": "S3",
    "question": "A company stores backups in S3 that are almost never accessed. Retrieval can take hours, and the priority is minimizing storage cost.\nWhich S3 storage class is MOST suitable?",
    "choices": [
      "S3 Glacier Instant Retrieval",
      "S3 Glacier Deep Archive",
      "S3 Standard",
      "S3 Standard-IA"
    ],
    "answer": 1,
    "explanation": "Glacier Deep Archive is designed for long-term archival with the lowest storage cost, and it supports hours-level retrieval times, matching the requirement.",
    "difficulty": "Medium",
    "choiceExplanations": {
      "0": "While designed for rarely accessed data, this storage class provides millisecond retrieval times and has higher storage costs than Glacier Deep Archive, making it unsuitable when retrieval can take hours and cost minimization is the priority.",
      "2": "This storage class is designed for frequently accessed data with the highest storage cost among all S3 classes, making it inappropriate for backup data that is almost never accessed when cost minimization is the priority.",
      "3": "While designed for infrequently accessed data, this storage class has significantly higher storage costs than Glacier Deep Archive and provides immediate retrieval, which exceeds the requirements when hours-level retrieval is acceptable."
    }
  },
  {
    "id": "SAA-122",
    "domainId": "D4",
    "domain": "Design Cost-Optimized Architectures",
    "section": "NAT/VPC",
    "question": "A workload in private subnets calls Amazon S3 frequently. Using a NAT Gateway is generating significant data processing charges.\nWhich change reduces cost while keeping traffic private?",
    "choices": [
      "Use AWS Direct Connect for internet access",
      "Add another NAT Gateway in a second AZ",
      "Add an S3 Gateway VPC endpoint and route S3 traffic through it",
      "Move the instances to public subnets with public IPs"
    ],
    "answer": 2,
    "explanation": "Gateway endpoints for S3 keep traffic within the AWS network and avoid NAT Gateway data processing charges for S3 access from private subnets.",
    "difficulty": "Medium",
    "choiceExplanations": {
      "0": "Direct Connect provides dedicated private connectivity between on-premises networks and AWS, not a solution for VPC-to-S3 traffic, and would add significant cost rather than reduce it.",
      "1": "Adding a second NAT Gateway improves availability but does not reduce data processing charges; it would actually increase costs by adding another NAT Gateway's hourly and data processing fees.",
      "3": "This removes the private subnet security model the question requires maintaining, exposes instances directly to the internet, and still incurs data transfer charges for S3 traffic over the public internet."
    }
  },
  {
    "id": "SAA-123",
    "domainId": "D4",
    "domain": "Design Cost-Optimized Architectures",
    "section": "DynamoDB",
    "question": "A startup has unpredictable traffic patterns and wants to avoid capacity planning for a DynamoDB table. They prefer a pay-per-request model.\nWhich DynamoDB capacity mode should they choose?",
    "choices": [
      "On-demand capacity mode",
      "Provisioned capacity with a fixed WCU/RCU",
      "Provisioned capacity without auto scaling",
      "Local DynamoDB on EC2"
    ],
    "answer": 0,
    "explanation": "On-demand capacity charges per request and automatically scales to handle traffic without manual capacity planning, which is ideal for unpredictable workloads.",
    "difficulty": "Medium",
    "choiceExplanations": {
      "1": "This requires manual capacity planning by specifying exact read and write capacity units upfront, which contradicts the requirement to avoid capacity planning and does not follow a pay-per-request model.",
      "2": "This is even worse than provisioned with auto scaling because it requires manual capacity planning and cannot automatically adjust to traffic changes, making it unsuitable for unpredictable workloads.",
      "3": "DynamoDB Local is a downloadable version intended only for development and testing purposes, not for production workloads; it is not a managed AWS service and would require significant operational overhead."
    }
  },
  {
    "id": "SAA-124",
    "domainId": "D4",
    "domain": "Design Cost-Optimized Architectures",
    "section": "RDS",
    "question": "A development database on RDS is used only during business hours (8 AM–6 PM weekdays). Outside those hours, it can be stopped to save cost.\nWhich approach is MOST appropriate?",
    "choices": [
      "Use an EC2 instance with the database running 24/7",
      "Enable Multi-AZ so the standby is stopped automatically",
      "Move the database to a larger instance type",
      "Stop the RDS instance outside business hours using automation (for example, AWS Instance Scheduler or a scheduled Lambda), and start it when needed"
    ],
    "answer": 3,
    "explanation": "Stopping a non-production RDS instance during off-hours can reduce cost. Multi-AZ increases cost and doesn’t stop the database; larger instances cost more.",
    "difficulty": "Medium",
    "choiceExplanations": {
      "0": "Running a self-managed database on EC2 continuously would not reduce costs compared to stopping an RDS instance during off-hours, and would actually increase operational overhead while eliminating RDS managed service benefits like automated backups and patching.",
      "1": "Multi-AZ deployments do not automatically stop the standby instance; they maintain a synchronized standby replica running continuously for high availability, which actually increases costs rather than reducing them.",
      "2": "Using a larger instance type increases costs due to higher compute and memory resources, and does nothing to address the requirement of reducing costs during non-business hours when the database is not needed."
    }
  },
  {
    "id": "SAA-125",
    "domainId": "D4",
    "domain": "Design Cost-Optimized Architectures",
    "section": "S3",
    "question": "A company wants to automatically move objects to cheaper storage classes over time without changing application code.\nWhich S3 feature supports this?",
    "choices": [
      "S3 Transfer Acceleration",
      "S3 lifecycle policies",
      "S3 Object Lock",
      "S3 Select"
    ],
    "answer": 1,
    "explanation": "Lifecycle policies automate transitions between storage classes and can also expire objects, enabling cost optimization without application changes.",
    "difficulty": "Medium",
    "choiceExplanations": {
      "0": "This feature speeds up data transfers to S3 buckets over long distances by using CloudFront edge locations, but it does not manage storage class transitions or cost optimization through automated object movement.",
      "2": "This feature prevents objects from being deleted or overwritten for a specified retention period using WORM (Write Once Read Many) protection, but it has no capability to transition objects between storage classes.",
      "3": "This feature enables applications to retrieve only a subset of data from an object using SQL expressions, reducing data transfer and processing costs for queries, but it does not automate storage class transitions."
    }
  },
  {
    "id": "SAA-126",
    "domainId": "D4",
    "domain": "Design Cost-Optimized Architectures",
    "section": "CloudFront",
    "question": "A company serves static files from S3 to users worldwide. They are paying high S3 data transfer costs and users in distant regions have high latency.\nWhich solution can both improve performance and potentially reduce origin load/cost?",
    "choices": [
      "Use Glacier Deep Archive for static files",
      "Move content from S3 to EBS",
      "Use CloudFront in front of S3 to cache content at edge locations",
      "Use a single larger EC2 instance as a file server"
    ],
    "answer": 2,
    "explanation": "CloudFront edge caching reduces repeated origin fetches and improves latency for global users, which can also reduce S3 request load and overall cost depending on access patterns.",
    "difficulty": "Medium",
    "choiceExplanations": {
      "0": "Glacier Deep Archive is designed for long-term archival storage with retrieval times of 12-48 hours, making it completely unsuitable for serving static files that users need to access immediately, and it would not reduce data transfer costs or improve latency.",
      "1": "EBS volumes are block storage attached to single EC2 instances in a specific Availability Zone, which would not improve global latency, would require managing EC2 infrastructure, and would likely increase costs compared to S3 while reducing availability and scalability.",
      "3": "A single EC2 instance in one region would not improve latency for users worldwide, introduces a single point of failure, requires infrastructure management, and would likely increase costs compared to using S3 with CloudFront."
    }
  },
  {
    "id": "SAA-127",
    "domainId": "D4",
    "domain": "Design Cost-Optimized Architectures",
    "section": "EBS",
    "question": "A batch workload needs low-cost storage for infrequently accessed data, but it still requires reasonably fast access when needed.\nWhich EBS volume type is MOST cost-effective for throughput-oriented workloads?",
    "choices": [
      "Throughput Optimized HDD (st1)",
      "Provisioned IOPS SSD (io2)",
      "Magnetic (standard) for best performance",
      "Cold HDD (sc1) for high IOPS"
    ],
    "answer": 0,
    "explanation": "st1 is designed for throughput-intensive workloads at lower cost than SSD options. io2 is higher-cost and optimized for IOPS, while sc1 is lowest cost for infrequent access with lower performance.",
    "difficulty": "Medium",
    "choiceExplanations": {
      "1": "This is the most expensive EBS volume type, designed for I/O-intensive workloads requiring sustained IOPS performance, making it unsuitable for cost-optimized, infrequently accessed data scenarios.",
      "2": "Magnetic volumes are a previous generation type with the lowest performance characteristics among all EBS options, not best performance; they are deprecated and not recommended for new workloads.",
      "3": "sc1 is designed for the lowest cost storage for infrequently accessed data but provides the lowest IOPS of all EBS volume types (max 250 IOPS), making it unsuitable for high IOPS requirements."
    }
  },
  {
    "id": "SAA-128",
    "domainId": "D4",
    "domain": "Design Cost-Optimized Architectures",
    "section": "Compute",
    "question": "A company runs a fault-tolerant background processing fleet where instances can be interrupted and the workload can resume.\nThey want the lowest compute cost.\nWhich EC2 pricing option is MOST suitable?",
    "choices": [
      "Reserved Instances for 3 years only",
      "On-Demand Instances",
      "Dedicated Hosts",
      "Spot Instances"
    ],
    "answer": 3,
    "explanation": "Spot Instances provide the largest discounts for fault-tolerant workloads that can handle interruptions.",
    "difficulty": "Medium",
    "choiceExplanations": {
      "0": "While Reserved Instances offer significant discounts (up to 72%) compared to On-Demand, they still cost more than Spot Instances which can provide up to 90% savings, and RIs require long-term commitment regardless of whether the workload can handle interruptions.",
      "1": "On-Demand pricing is the most expensive EC2 option with no discount, making it unsuitable when the goal is lowest compute cost, especially for fault-tolerant workloads that can leverage cheaper alternatives.",
      "2": "Dedicated Hosts are the most expensive EC2 option as they provide physical servers dedicated to your use, typically used for licensing compliance or regulatory requirements, not for cost optimization."
    }
  },
  {
    "id": "SAA-129",
    "domainId": "D4",
    "domain": "Design Cost-Optimized Architectures",
    "section": "Logs",
    "question": "A company stores application logs in CloudWatch Logs but notices that older logs are rarely accessed. They want to reduce ongoing log storage cost.\nWhat should they do?",
    "choices": [
      "Increase log verbosity to reduce storage",
      "Set log retention policies to automatically expire older log events",
      "Disable logging entirely after 30 days",
      "Move logs to EBS volumes attached to EC2"
    ],
    "answer": 1,
    "explanation": "CloudWatch Logs retention policies automatically delete log events older than a specified period, reducing storage cost while keeping recent logs available.",
    "difficulty": "Medium",
    "choiceExplanations": {
      "0": "Increasing log verbosity would actually generate MORE log data, not less, which would increase storage costs rather than reduce them.",
      "2": "Disabling logging would stop collecting new logs entirely, which could impact troubleshooting and compliance requirements; this is different from managing retention of existing logs and is not a recommended practice.",
      "3": "Moving logs to EBS volumes would likely increase costs since EBS storage is generally more expensive than CloudWatch Logs storage, plus it adds operational overhead for managing EC2 instances and EBS volumes."
    }
  },
  {
    "id": "SAA-130",
    "domainId": "D4",
    "domain": "Design Cost-Optimized Architectures",
    "section": "S3",
    "question": "A company stores images in S3. A subset under the prefix /realtime/ must always have millisecond retrieval. Older images under /archive/ can take hours to retrieve after 90 days.\nThey want the most cost-effective lifecycle configuration.\nWhich option best meets the requirements?",
    "choices": [
      "Lifecycle rule: keep /realtime/ in Standard or Standard-IA as appropriate, and transition /archive/ to Glacier Flexible Retrieval or Deep Archive after 90 days",
      "Enable S3 Transfer Acceleration for /archive/ objects",
      "Use Intelligent-Tiering for all objects and never transition to archive tiers",
      "Move the entire bucket to Glacier Deep Archive after 90 days"
    ],
    "answer": 0,
    "explanation": "Using prefix-based lifecycle rules lets you keep the performance-critical prefix in a millisecond-access class while moving archival content to cheaper archive tiers when retrieval time allows, optimizing cost.",
    "difficulty": "Medium",
    "choiceExplanations": {
      "1": "S3 Transfer Acceleration speeds up uploads and downloads over long distances by routing through CloudFront edge locations, but it does not reduce storage costs or address the retrieval time requirements for archived data.",
      "2": "While Intelligent-Tiering automatically moves objects between access tiers, not transitioning to archive tiers means missing the significant cost savings of Glacier classes for data that can tolerate hours-long retrieval times.",
      "3": "This would violate the requirement that /realtime/ objects must always have millisecond retrieval, as Glacier Deep Archive has retrieval times of 12-48 hours and does not support instant access."
    }
  },
  {
    "id": "SAA-131",
    "domainId": "D1",
    "domain": "Design Secure Architectures",
    "section": "ACM",
    "question": "A company hosts dozens of internet-facing applications, each behind its own Application Load Balancer (ALB) across multiple Availability Zones. Each app has its own fully qualified domain name.\nThe security team requires publicly trusted SSL/TLS certificates and wants automatic renewal with minimal ongoing operations.\nWhich solution will meet these requirements with the LEAST operational overhead?",
    "choices": [
      "Use AWS Certificate Manager Private CA to issue certificates and upload the root certificate to all customer browsers",
      "Generate self-signed certificates and import them into ACM for each ALB",
      "Run Let’s Encrypt certbot on the EC2 instances behind the ALBs and manage renewals with a scheduled job",
      "Use AWS Certificate Manager (ACM) to request public certificates for each domain and associate them with the HTTPS listeners on each ALB"
    ],
    "answer": 3,
    "explanation": "ACM public certificates are publicly trusted, integrate directly with ALB listeners, and renew automatically. Private CA and self-signed certificates are not publicly trusted for general internet clients, and self-managing Let’s Encrypt introduces significant operational overhead.",
    "difficulty": "Hard",
    "choiceExplanations": {
      "0": "ACM Private CA issues private certificates that are not publicly trusted by default browsers, and distributing root certificates to all customer browsers is impractical for internet-facing applications and creates significant operational overhead.",
      "1": "Self-signed certificates are not publicly trusted by browsers and will cause security warnings for users, plus imported certificates in ACM do not benefit from automatic renewal, requiring manual management before expiration.",
      "2": "Run Let's Encrypt certbot on the EC2 instances behind the ALBs and manage renewals with a scheduled job: While Let's Encrypt provides publicly trusted certificates, managing certbot on EC2 instances with scheduled jobs introduces significant operational overhead for certificate generation, renewal monitoring, and deployment to ALBs compared to ACM's fully managed automatic renewal."
    }
  },
  {
    "id": "SAA-132",
    "domainId": "D1",
    "domain": "Design Secure Architectures",
    "section": "Organizations",
    "question": "A company uses AWS Organizations with multiple accounts. The security team mandates that no one can disable CloudTrail logging or delete CloudTrail log files, even in development accounts.\nDevelopers still need broad permissions within their accounts for day-to-day work.\nWhich combination of controls best enforces this requirement?",
    "choices": [
      "Place CloudTrail logs in each account’s local S3 bucket with bucket policies that allow deletion only by admins",
      "Attach AdministratorAccess to all developers and rely on CloudTrail alarms to detect changes",
      "Apply an SCP that denies stopping/deleting CloudTrail and denies deleting objects in the centralized log bucket; store logs in a dedicated logging account",
      "Enable AWS Config in each account and automatically revert changes to CloudTrail via a Lambda function"
    ],
    "answer": 2,
    "explanation": "SCPs provide account-level guardrails that apply even to administrators in member accounts. Centralizing CloudTrail logs in a dedicated logging account further reduces risk. Detective/auto-remediation is helpful but does not prevent the action from occurring.",
    "difficulty": "Hard",
    "choiceExplanations": {
      "0": "Place CloudTrail logs in each account's local S3 bucket with bucket policies that allow deletion only by admins: This approach keeps logs in individual accounts where local administrators can modify bucket policies or assume admin roles to delete logs, and it does not prevent disabling CloudTrail itself since bucket policies only control S3 access, not CloudTrail configuration.",
      "1": "This is a detective control only, not preventive; alarms notify after the fact but do not prevent developers with AdministratorAccess from actually disabling CloudTrail or deleting logs, violating the requirement that no one can perform these actions.",
      "3": "This is a reactive/remediation approach that allows the prohibited action to occur temporarily before being reverted, creating a window where logging gaps exist; it also does not prevent log file deletion and the Lambda function itself could be disabled by account administrators."
    }
  },
  {
    "id": "SAA-133",
    "domainId": "D1",
    "domain": "Design Secure Architectures",
    "section": "KMS",
    "question": "A partner in a separate AWS account needs read access to objects in your S3 bucket for a short-lived project. The objects are encrypted with SSE-KMS using a customer-managed KMS key in your account.\nThe partner can read the objects but gets AccessDenied when attempting to decrypt.\nWhat is the MOST appropriate fix?",
    "choices": [
      "Copy the objects to an unencrypted bucket and share that bucket publicly",
      "Enable S3 Transfer Acceleration so decryption happens at the edge",
      "Update the KMS key policy (and/or grants) to allow the partner’s IAM role to use the key for decryption, and ensure the S3 bucket policy allows the role to read the objects",
      "Disable SSE-KMS and re-upload objects with SSE-S3 so other accounts can read them"
    ],
    "answer": 2,
    "explanation": "For SSE-KMS, both S3 permissions and KMS key permissions are required. Cross-account consumers must be granted KMS decrypt permissions via the key policy or a grant, in addition to S3 read permissions.",
    "difficulty": "Hard",
    "choiceExplanations": {
      "0": "This is a severe security anti-pattern that exposes data to the entire internet, violates security best practices, and is completely unnecessary when proper cross-account permissions can be configured through KMS key policies and S3 bucket policies.",
      "1": "S3 Transfer Acceleration is a feature that speeds up data transfers to and from S3 using CloudFront edge locations, but it has nothing to do with encryption, decryption, or KMS key permissions—it does not solve the AccessDenied error caused by missing KMS decrypt permissions.",
      "3": "While SSE-S3 does simplify cross-account access by removing the need for KMS key permissions, this approach is unnecessarily disruptive, may violate compliance requirements for customer-managed keys, and the proper solution is simply to grant the partner's IAM role KMS decrypt permissions on the existing key."
    }
  },
  {
    "id": "SAA-134",
    "domainId": "D1",
    "domain": "Design Secure Architectures",
    "section": "WAF",
    "question": "A company runs many CloudFront distributions across multiple AWS accounts. The security team wants to enforce a standard AWS WAF web ACL (managed rule groups + IP reputation lists) across all distributions and have a single place to manage these policies.\nWhich solution meets these requirements with the LEAST operational overhead?",
    "choices": [
      "Use security groups on the origin EC2 instances to block malicious HTTP payloads",
      "Create identical WAF web ACLs manually in every account and attach them to each distribution",
      "Use AWS Firewall Manager to centrally deploy and manage AWS WAF policies across accounts and CloudFront distributions",
      "Enable AWS Shield Standard on CloudFront and rely on it for application-layer protections"
    ],
    "answer": 2,
    "explanation": "AWS Firewall Manager provides centralized management and enforcement of security policies like AWS WAF across multiple accounts and resources, reducing manual configuration and drift.",
    "difficulty": "Hard",
    "choiceExplanations": {
      "0": "Security groups operate at the network layer (Layer 3/4) and can only filter based on IP addresses, ports, and protocols - they cannot inspect HTTP payloads or block application-layer attacks like SQL injection or XSS, which requires AWS WAF.",
      "1": "While this would technically work, manually creating and maintaining identical WAF web ACLs across multiple accounts introduces significant operational overhead, increases the risk of configuration drift, and does not provide centralized management as required.",
      "3": "AWS Shield Standard only provides protection against DDoS attacks at the network and transport layers (Layer 3/4) - it does not provide application-layer (Layer 7) protections like managed rule groups or IP reputation lists, which require AWS WAF."
    }
  },
  {
    "id": "SAA-135",
    "domainId": "D1",
    "domain": "Design Secure Architectures",
    "section": "IAM Identity Center",
    "question": "A company wants employees to sign in to AWS using their corporate identity provider (IdP) and be assigned AWS permissions based on their job role. The solution should avoid creating IAM users and should be easy to manage as employees join/leave.\nWhich approach is MOST suitable?",
    "choices": [
      "Use Amazon Cognito user pools for employee access to the AWS console",
      "Use access keys distributed through a password manager and rotate them monthly",
      "Use AWS IAM Identity Center (AWS SSO) integrated with the corporate IdP and assign permission sets to users/groups",
      "Create an IAM user for each employee and enforce MFA"
    ],
    "answer": 2,
    "explanation": "IAM Identity Center is designed for workforce authentication and authorization into AWS accounts, integrating with external IdPs and mapping users/groups to permission sets. This avoids managing long-lived IAM users.",
    "difficulty": "Hard",
    "choiceExplanations": {
      "0": "Amazon Cognito is designed for customer-facing application authentication (web/mobile apps), not for workforce access to the AWS Management Console or AWS account resources; IAM Identity Center is the appropriate service for employee workforce identity management.",
      "1": "Access keys are long-term credentials that require manual management and rotation, creating security risks and administrative overhead; this approach does not integrate with corporate IdPs and does not meet the requirement to avoid creating IAM users since access keys are associated with IAM users.",
      "3": "This directly contradicts the requirement to avoid creating IAM users and creates significant management overhead as employees join and leave the company, requiring manual user lifecycle management rather than leveraging the corporate IdP for centralized identity management."
    }
  },
  {
    "id": "SAA-136",
    "domainId": "D1",
    "domain": "Design Secure Architectures",
    "section": "S3",
    "question": "A company stores critical compliance evidence in S3. The files must be retained for 5 years and must not be deletable or overwriteable during the retention period, even by administrators.\nWhich solution best meets these requirements?",
    "choices": [
      "Enable S3 versioning and set a lifecycle rule to transition objects to Glacier Deep Archive after 30 days",
      "Enable MFA Delete and keep the root MFA device offline",
      "Enable S3 versioning and S3 Object Lock in Compliance mode with a 5-year retention period",
      "Encrypt objects with SSE-S3 and restrict s3:DeleteObject via IAM"
    ],
    "answer": 2,
    "explanation": "S3 Object Lock in Compliance mode provides WORM protection that prevents deletion or modification of protected object versions for the retention period, even by users with high privileges. Versioning is required for Object Lock.",
    "difficulty": "Hard",
    "choiceExplanations": {
      "0": "Transitioning to Glacier Deep Archive only changes the storage class for cost optimization but does not prevent deletion or modification of objects; administrators can still delete objects regardless of their storage class.",
      "1": "MFA Delete only requires MFA authentication to delete object versions or change versioning state, but it does not provide true WORM protection; root users with MFA access can still delete objects, and this approach relies on operational controls rather than enforced immutability.",
      "3": "IAM policies can be modified by administrators with sufficient privileges, so this does not provide immutable protection; encryption protects data confidentiality but does not prevent deletion, and privileged users can simply update the IAM policies to allow deletion."
    }
  },
  {
    "id": "SAA-137",
    "domainId": "D1",
    "domain": "Design Secure Architectures",
    "section": "VPC",
    "question": "A security team requires that EC2 instances in private subnets can access AWS public services (like S3, DynamoDB, and Secrets Manager) without traversing the public internet, and that access can be controlled with IAM policies and VPC policies.\nWhich design best meets the requirement?",
    "choices": [
      "Create VPC peering to an AWS-managed VPC that hosts the AWS services",
      "Route all private subnet traffic through a NAT Gateway to reach AWS public endpoints",
      "Use an Internet Gateway and assign public IPs to the instances",
      "Create VPC endpoints: gateway endpoints for S3/DynamoDB and interface endpoints for Secrets Manager (and other services), and update route tables/DNS accordingly"
    ],
    "answer": 3,
    "explanation": "VPC endpoints keep traffic within the AWS network and avoid public internet routing. Gateway endpoints are used for S3 and DynamoDB, while interface endpoints (PrivateLink) are used for services like Secrets Manager.",
    "difficulty": "Hard",
    "choiceExplanations": {
      "0": "VPC peering to AWS-managed service VPCs is not a supported feature in AWS. AWS public services are accessed through VPC endpoints (Gateway or Interface), not through peering connections to AWS-internal infrastructure.",
      "1": "While NAT Gateway allows private instances to reach AWS services, traffic traverses the public internet to reach AWS public endpoints, which violates the requirement to avoid the public internet. Additionally, NAT Gateway does not support VPC endpoint policies for granular access control.",
      "2": "This approach routes traffic over the public internet and exposes instances directly to the internet, violating both the requirement to keep traffic private and the security principle of keeping instances in private subnets without public IP addresses."
    }
  },
  {
    "id": "SAA-138",
    "domainId": "D1",
    "domain": "Design Secure Architectures",
    "section": "CloudTrail",
    "question": "A company wants to detect and alert on suspicious root account usage (console sign-in or access key usage) in near real time. They also want a searchable history of these events.\nWhich solution is MOST suitable?",
    "choices": [
      "Enable VPC Flow Logs and create alarms when port 443 traffic increases",
      "Enable CloudTrail and create an EventBridge rule for relevant CloudTrail events that sends notifications (SNS), and store logs centrally in S3/CloudWatch Logs for search",
      "Enable AWS Config and run compliance evaluations every 24 hours",
      "Enable AWS Shield Advanced and monitor Shield events"
    ],
    "answer": 1,
    "explanation": "Root account usage is captured in CloudTrail. EventBridge can match specific CloudTrail events and trigger near-real-time notifications. Centralized log storage enables audit and search.",
    "difficulty": "Hard",
    "choiceExplanations": {
      "0": "VPC Flow Logs capture network traffic metadata (IP addresses, ports, protocols) at the VPC level, not user authentication or API activity. Root account sign-ins and API calls are identity-level events that occur outside VPC networking and cannot be detected through flow logs.",
      "2": "AWS Config tracks resource configuration changes and compliance state, not user authentication events or API activity. Additionally, 24-hour evaluation intervals do not meet the near real-time alerting requirement specified in the question.",
      "3": "AWS Shield Advanced protects against DDoS attacks on AWS resources and does not monitor or detect IAM user activity, console sign-ins, or API calls. It is designed for network-layer protection, not identity and access monitoring."
    }
  },
  {
    "id": "SAA-139",
    "domainId": "D1",
    "domain": "Design Secure Architectures",
    "section": "KMS",
    "question": "A company must encrypt EBS volumes on EC2 instances. The security team requires that encryption keys be rotated automatically, and access to use the key must be limited to a specific set of roles.\nWhich solution should you implement?",
    "choices": [
      "Use client-side encryption inside the EC2 instance and store keys in the AMI",
      "Use unencrypted EBS and enforce TLS for all disk I/O",
      "Use EBS encryption with a customer-managed KMS key, enable automatic key rotation, and restrict key usage via the key policy to approved roles",
      "Use EBS encryption with AWS-managed keys and rely on IAM user policies only"
    ],
    "answer": 2,
    "explanation": "Customer-managed KMS keys support automatic rotation and fine-grained control through key policies and grants. EBS integrates directly with KMS for encryption at rest.",
    "difficulty": "Hard",
    "choiceExplanations": {
      "0": "Storing encryption keys in an AMI is a security anti-pattern as AMIs can be shared or copied, exposing the keys. This approach also lacks automatic key rotation capabilities and does not leverage AWS-managed encryption services for EBS volumes.",
      "1": "TLS encrypts data in transit over networks, not data at rest on disk. EBS volumes store data at rest, so TLS provides no encryption protection for the stored data, failing to meet the requirement for encrypted EBS volumes.",
      "3": "AWS-managed keys (aws/ebs) do not support automatic key rotation that customers can enable or control, and you cannot modify the key policy to restrict access to specific roles. Only customer-managed KMS keys provide both automatic rotation and customizable key policies for fine-grained access control."
    }
  },
  {
    "id": "SAA-140",
    "domainId": "D1",
    "domain": "Design Secure Architectures",
    "section": "STS",
    "question": "A vendor needs temporary access to your AWS account to troubleshoot a production issue. Your company forbids sharing long-lived credentials and wants the access to automatically expire after a few hours.\nWhich solution is MOST appropriate?",
    "choices": [
      "Create a security group rule to allow the vendor’s IP and let them SSH to all instances",
      "Create an IAM role with required permissions and a trust policy for the vendor’s AWS account, and require the vendor to assume the role using STS with a short session duration",
      "Create an IAM user for the vendor and rotate the access keys after the troubleshooting session",
      "Share the root account credentials for the troubleshooting window and then change the password"
    ],
    "answer": 1,
    "explanation": "Assuming an IAM role via STS provides temporary credentials that expire automatically and avoids sharing long-lived secrets. Trust policies and session duration enforce controlled access.",
    "difficulty": "Hard",
    "choiceExplanations": {
      "0": "Create a security group rule to allow the vendor's IP and let them SSH to all instances: This approach grants network-level access rather than AWS account access, does not provide automatic expiration, violates the principle of least privilege by allowing access to all instances, and does not address AWS service-level permissions needed for troubleshooting.",
      "2": "IAM user access keys are long-lived credentials that violate the company policy against sharing long-lived credentials, and manual rotation after the session does not provide automatic expiration as required.",
      "3": "This is a severe security violation as AWS strongly recommends never sharing root account credentials, root access provides unrestricted permissions far beyond what is needed, and changing the password afterward does not prevent damage during the access window."
    }
  },
  {
    "id": "SAA-141",
    "domainId": "D1",
    "domain": "Design Secure Architectures",
    "section": "Secrets Manager",
    "question": "A microservice running on ECS retrieves DB credentials from Secrets Manager. A new compliance rule requires that services must not access secrets unless they are running in the approved VPC and use a specific VPC endpoint.\nWhich design best meets this requirement?",
    "choices": [
      "Create an interface VPC endpoint for Secrets Manager and use a resource policy/endpoint policy plus IAM conditions to restrict secret access through the endpoint",
      "Use environment variables and rotate the container image on every rotation",
      "Store the secret in an S3 bucket and restrict access with a bucket policy",
      "Use a NAT Gateway and allow the service to call Secrets Manager over the internet"
    ],
    "answer": 0,
    "explanation": "Interface endpoints allow private connectivity to Secrets Manager. Endpoint policies and IAM conditions (for example, requiring a source VPC endpoint) can enforce that secrets are accessed only through the approved private path.",
    "difficulty": "Hard",
    "choiceExplanations": {
      "1": "Environment variables expose secrets in plaintext within the container configuration, which is a security anti-pattern, and requiring container image rebuilds for credential rotation is operationally inefficient and does not enforce VPC endpoint access requirements.",
      "2": "This abandons Secrets Manager entirely, losing its automatic rotation, encryption, and auditing capabilities, and S3 bucket policies alone cannot enforce that access must occur through a specific VPC endpoint for Secrets Manager as required.",
      "3": "This routes traffic over the public internet rather than through a private VPC endpoint, directly violating the compliance requirement that secrets must only be accessed through the approved VPC using a specific VPC endpoint."
    }
  },
  {
    "id": "SAA-142",
    "domainId": "D1",
    "domain": "Design Secure Architectures",
    "section": "S3",
    "question": "A company exposes private documents to authenticated customers via CloudFront. Documents must remain private in S3, and direct access to the S3 bucket must be blocked.\nWhich architecture should you implement?",
    "choices": [
      "Make the S3 bucket public and rely on signed URLs to hide the object keys",
      "Expose the S3 bucket through an internet-facing ALB",
      "Use S3 static website hosting with Basic Auth enabled",
      "Use CloudFront with an Origin Access Control (or Origin Access Identity) so only CloudFront can read from the S3 origin, and use signed URLs/cookies for authenticated access"
    ],
    "answer": 3,
    "explanation": "OAC/OAI prevents direct access to the S3 origin by allowing only CloudFront to fetch objects. Signed URLs/cookies then restrict which viewers can access the content through CloudFront.",
    "difficulty": "Hard",
    "choiceExplanations": {
      "0": "This violates the requirement that documents must remain private in S3, as making the bucket public means anyone who discovers or guesses the object keys can access the documents directly without authentication.",
      "1": "Application Load Balancers cannot have S3 buckets as targets; ALB targets are limited to EC2 instances, IP addresses, Lambda functions, and other ALBs, making this architecture technically impossible.",
      "2": "S3 static website hosting does not support Basic Authentication natively, and enabling static website hosting requires the bucket to allow public access, which violates the requirement to keep documents private in S3."
    }
  },
  {
    "id": "SAA-143",
    "domainId": "D1",
    "domain": "Design Secure Architectures",
    "section": "VPC",
    "question": "A company wants to allow inbound SSH access to a small set of EC2 instances for administrators, but only after the administrators authenticate to AWS. The company wants to avoid managing bastion host patching and SSH keys.\nWhich solution provides secure access with the LEAST operational overhead?",
    "choices": [
      "Deploy a hardened bastion host in a public subnet and rotate SSH keys weekly",
      "Use AWS Systems Manager Session Manager for shell access and remove inbound SSH access from security groups",
      "Open port 22 to the administrators’ IP addresses and enforce strong SSH passwords",
      "Use a VPN appliance on EC2 and have admins connect over SSH"
    ],
    "answer": 1,
    "explanation": "Session Manager provides auditable, IAM-controlled access to instances without opening inbound SSH ports or managing bastion hosts and keys. It reduces operational overhead while improving security.",
    "difficulty": "Hard",
    "choiceExplanations": {
      "0": "This directly contradicts the requirement to avoid managing bastion host patching and SSH keys, as it requires ongoing maintenance of the bastion host OS, security patches, and regular SSH key rotation, resulting in significant operational overhead.",
      "2": "Open port 22 to the administrators' IP addresses and enforce strong SSH passwords: This approach still requires managing SSH access and passwords, exposes port 22 to the internet (even if restricted by IP), and password-based SSH authentication is less secure than key-based or IAM-based authentication methods.",
      "3": "This introduces additional operational overhead by requiring management of both the VPN appliance (patching, configuration, certificates) and SSH keys on the target instances, making it more complex than Session Manager which eliminates both requirements."
    }
  },
  {
    "id": "SAA-144",
    "domainId": "D1",
    "domain": "Design Secure Architectures",
    "section": "Security Hub",
    "question": "A company wants a centralized view of security findings across GuardDuty, Inspector, and Config rules for all AWS accounts. They also want to automatically open tickets when critical findings appear.\nWhich solution is MOST suitable?",
    "choices": [
      "Enable CloudWatch Logs Insights across accounts to query for security events",
      "Enable AWS Trusted Advisor in every account and export the report weekly",
      "Use AWS Budgets alerts to detect security issues",
      "Enable AWS Security Hub organization-wide, aggregate findings to a central account, and use EventBridge rules to route critical findings to an incident/ticketing workflow"
    ],
    "answer": 3,
    "explanation": "Security Hub aggregates findings from multiple AWS services and can centralize them in a delegated administrator account. EventBridge can trigger automated workflows based on finding severity.",
    "difficulty": "Hard",
    "choiceExplanations": {
      "0": "CloudWatch Logs Insights is designed for querying and analyzing log data, not for aggregating security findings from services like GuardDuty, Inspector, and Config rules. It lacks native integration with these security services and does not provide a unified security findings dashboard or automated ticketing capabilities.",
      "1": "Trusted Advisor provides best practice recommendations for cost optimization, performance, security, and fault tolerance, but it does not aggregate findings from GuardDuty, Inspector, or Config rules. Weekly manual exports do not meet the requirement for automatic ticket creation when critical findings appear.",
      "2": "AWS Budgets is designed for cost management and budget tracking, not security monitoring. It cannot detect security findings from GuardDuty, Inspector, or Config rules, and has no capability to aggregate security findings or route them to ticketing systems."
    }
  },
  {
    "id": "SAA-145",
    "domainId": "D1",
    "domain": "Design Secure Architectures",
    "section": "IAM",
    "question": "An application in Account A needs to write objects to an S3 bucket in Account B. The security team requires least privilege, no long-lived credentials, and clear separation of duties.\nWhich option best meets these requirements?",
    "choices": [
      "Create an IAM role in Account B that Account A can assume, grant it s3:PutObject to the bucket, and allow the role in the bucket policy",
      "Use pre-signed URLs generated by Account A without changing Account B",
      "Create an IAM user in Account B and share the access keys with Account A",
      "Make the bucket public-write and use object prefixes to separate writes"
    ],
    "answer": 0,
    "explanation": "Cross-account role assumption provides temporary credentials and supports least privilege. Bucket policies can restrict writes to the role, avoiding shared long-lived access keys.",
    "difficulty": "Hard",
    "choiceExplanations": {
      "1": "Pre-signed URLs can only grant permissions that the signing entity already has; Account A cannot generate valid pre-signed URLs for Account B's bucket without first being granted cross-account access through bucket policies or IAM roles.",
      "2": "This approach uses long-lived credentials (access keys), which directly violates the requirement for no long-lived credentials and introduces security risks from credential sharing between accounts.",
      "3": "Public-write access violates least privilege principles by allowing anyone on the internet to write to the bucket, creating severe security risks and failing to provide clear separation of duties or access control."
    }
  },
  {
    "id": "SAA-146",
    "domainId": "D1",
    "domain": "Design Secure Architectures",
    "section": "IAM",
    "question": "A team uses IAM roles for EC2 instances. During an incident, a developer added a broad inline policy to the instance role. Security wants to ensure that role permissions cannot be expanded beyond a predefined maximum, but still allow adding narrower permissions when needed.\nWhich control should be used?",
    "choices": [
      "Enable AWS Shield Advanced on the EC2 instance",
      "Attach a permissions boundary to the role to cap its maximum permissions",
      "Use an ACL on the EC2 instance to deny outbound network traffic",
      "Add the role to an IAM group with restricted permissions"
    ],
    "answer": 1,
    "explanation": "Permissions boundaries can be applied to roles (not just users) to limit the maximum effective permissions, preventing expansion beyond a defined scope while still allowing additional allowed permissions to be attached.",
    "difficulty": "Hard",
    "choiceExplanations": {
      "0": "AWS Shield Advanced is a DDoS protection service that safeguards against distributed denial-of-service attacks, not an IAM permission control mechanism, so it has no effect on limiting role permissions.",
      "2": "Network ACLs control network traffic flow at the subnet level and have no relationship to IAM permissions; blocking network traffic does not prevent a role from having expanded IAM permissions.",
      "3": "IAM roles cannot be added to IAM groups; groups are only for IAM users, making this option technically impossible and irrelevant to controlling role permissions."
    }
  },
  {
    "id": "SAA-147",
    "domainId": "D1",
    "domain": "Design Secure Architectures",
    "section": "S3",
    "question": "A company requires that all S3 access to a sensitive bucket must come from within their VPC over a specific VPC endpoint, and any request from the public internet must be denied, even if credentials are valid.\nWhich solution best enforces this?",
    "choices": [
      "Enable SSE-KMS on the bucket and deny kms:Decrypt from the internet",
      "Use an S3 bucket policy that denies requests unless they come through the specified VPC endpoint (aws:sourceVpce), and use an S3 Gateway VPC endpoint",
      "Enable S3 Block Public Access only",
      "Enable S3 Transfer Acceleration to force requests through edge locations"
    ],
    "answer": 1,
    "explanation": "Bucket policies can enforce network-based conditions such as requiring a particular VPC endpoint. Using an S3 gateway endpoint ensures traffic can stay within the AWS network, and the deny condition blocks any requests not coming through that endpoint.",
    "difficulty": "Hard",
    "choiceExplanations": {
      "0": "SSE-KMS encryption protects data at rest and controls decryption permissions, but it does not control the network path of S3 API requests. Users with valid credentials could still access S3 metadata and perform non-decrypt operations from the internet, and KMS policies cannot enforce VPC endpoint requirements for S3 access.",
      "2": "S3 Block Public Access prevents anonymous or public access through ACLs and bucket policies, but it does not block authenticated requests from the internet. Users with valid IAM credentials can still access the bucket from outside the VPC when Block Public Access is enabled.",
      "3": "Transfer Acceleration is a performance optimization feature that uses CloudFront edge locations to speed up uploads and downloads. It does not restrict access paths or enforce that requests must come from a VPC endpoint, and requests still originate from the public internet through edge locations."
    }
  },
  {
    "id": "SAA-148",
    "domainId": "D1",
    "domain": "Design Secure Architectures",
    "section": "Shield/WAF",
    "question": "A financial services company runs an internet-facing application behind CloudFront and ALB. They are concerned about large-scale DDoS attacks and want DDoS response support plus cost protection for scaling-related charges during an attack.\nWhich solution is MOST suitable?",
    "choices": [
      "Enable AWS Shield Standard only and rely on security groups",
      "Deploy the application only in private subnets and remove the ALB",
      "Use Amazon Inspector to detect DDoS attempts",
      "Subscribe to AWS Shield Advanced and (optionally) integrate AWS WAF for L7 protections"
    ],
    "answer": 3,
    "explanation": "Shield Advanced provides enhanced DDoS protections, access to the DDoS response team, and financial protections for scaling charges resulting from attacks. WAF complements by filtering application-layer traffic.",
    "difficulty": "Hard",
    "choiceExplanations": {
      "0": "Shield Standard provides basic DDoS protection automatically at no cost but does not include DDoS response team access or cost protection for scaling charges during attacks, which are key requirements stated in the question.",
      "1": "This approach would make the application inaccessible from the internet, which contradicts the requirement for an internet-facing application and does not address DDoS protection or cost protection needs.",
      "2": "Amazon Inspector is a vulnerability assessment service that scans EC2 instances, container images, and Lambda functions for software vulnerabilities and unintended network exposure; it is not designed to detect or mitigate DDoS attacks."
    }
  },
  {
    "id": "SAA-149",
    "domainId": "D1",
    "domain": "Design Secure Architectures",
    "section": "KMS",
    "question": "A company uses KMS keys for encrypting data. Security requires that only a specific microservice role can decrypt data, and administrators should be able to manage the key (rotate/disable) but not decrypt application data.\nWhich configuration best meets this requirement?",
    "choices": [
      "Use a customer-managed KMS key with a key policy that separates key administration permissions from key usage (encrypt/decrypt) permissions",
      "Use an AWS-managed KMS key and attach decrypt permissions to the admin role",
      "Use S3 SSE-S3 so KMS policies are not needed",
      "Store the key material in the application container and restrict access with security groups"
    ],
    "answer": 0,
    "explanation": "KMS key policies can separate administrative actions (like enabling/disabling, rotating) from cryptographic usage actions (Encrypt/Decrypt). Grant decrypt only to the microservice role while allowing admins to administer the key without data access.",
    "difficulty": "Hard",
    "choiceExplanations": {
      "1": "AWS-managed KMS keys do not allow modification of their key policies, so you cannot customize permissions to separate administrative actions from cryptographic usage. Additionally, this choice incorrectly grants decrypt permissions to admins, which violates the requirement that administrators should not be able to decrypt application data.",
      "2": "SSE-S3 uses Amazon S3-managed keys where AWS controls all key management, providing no ability to define granular access controls or separate administrative and usage permissions. This approach offers no mechanism to restrict decryption to only a specific microservice role.",
      "3": "Storing encryption keys directly in application containers is a security anti-pattern that violates AWS best practices for key management. Security groups operate at the network layer and cannot control access to data or encryption keys within a container, and this approach lacks the audit, rotation, and access control capabilities provided by KMS."
    }
  },
  {
    "id": "SAA-150",
    "domainId": "D1",
    "domain": "Design Secure Architectures",
    "section": "Config",
    "question": "A company must prove that security groups never allow inbound 0.0.0.0/0 access to SSH or RDP, and they need continuous monitoring with automatic evidence for auditors.\nWhich solution best meets these requirements?",
    "choices": [
      "Use AWS Config with managed rules (or custom rules) to evaluate security group configurations continuously, and store compliance history",
      "Enable GuardDuty and rely on findings for open ports",
      "Use VPC Flow Logs and manually inspect logs for port 22/3389 traffic",
      "Use CloudTrail only and search for AuthorizeSecurityGroupIngress calls"
    ],
    "answer": 0,
    "explanation": "AWS Config continuously evaluates resource configurations against rules and retains compliance history, which is useful for audit evidence. CloudTrail and flow logs are helpful but do not provide continuous configuration compliance evaluation by themselves.",
    "difficulty": "Hard",
    "choiceExplanations": {
      "1": "GuardDuty is a threat detection service that analyzes VPC Flow Logs, DNS logs, and CloudTrail events for malicious activity, but it does not continuously evaluate security group configurations against compliance rules or provide the configuration compliance history needed for audit evidence.",
      "2": "VPC Flow Logs capture network traffic metadata but do not evaluate security group configurations; they only show actual traffic that occurred, require manual inspection which is not continuous monitoring, and do not provide automatic compliance evidence for auditors.",
      "3": "CloudTrail logs API calls and can show when security group rules were modified, but it does not continuously evaluate the current state of security group configurations against compliance rules or automatically generate compliance reports for auditors."
    }
  },
  {
    "id": "SAA-151",
    "domainId": "D2",
    "domain": "Design Resilient Architectures",
    "section": "DR/Route 53",
    "question": "A SaaS provider runs its primary workload in Region A. The application stack includes ALB + EC2, an RDS database, and an S3 bucket for user uploads. The business requires:\n- RPO of 15 minutes for the database\n- RTO of 1 hour for the application\n- Minimal ongoing costs in the secondary region\nWhich disaster recovery strategy BEST meets these requirements?",
    "choices": [
      "Warm standby: run a fully scaled stack in Region B at all times",
      "Backup and restore only: keep no resources in Region B and rely solely on nightly backups",
      "Active-active: run the full stack at production scale in both regions at all times",
      "Pilot light: keep minimal core components running in Region B, use cross-region backups/replication (including frequent DB backups or replication) and scale up on failover"
    ],
    "answer": 3,
    "explanation": "Pilot light keeps a minimal footprint in the secondary region (lower cost than warm standby/active-active) while enabling faster recovery than backup/restore. Achieving a 15-minute RPO typically requires frequent replication/backup for the database and automated procedures to scale the rest of the stack within the 1-hour RTO.",
    "difficulty": "Hard",
    "choiceExplanations": {
      "0": "While this would meet the RPO and RTO requirements, it violates the requirement for minimal ongoing costs since it maintains a fully scaled (though possibly smaller) stack running continuously in the secondary region, which is significantly more expensive than pilot light.",
      "1": "Nightly backups cannot achieve a 15-minute RPO since data loss could be up to 24 hours, and restoring an entire infrastructure from scratch would likely exceed the 1-hour RTO requirement due to the time needed to provision and configure all resources.",
      "2": "This approach provides the best RTO and RPO but completely violates the minimal ongoing costs requirement, as it doubles infrastructure costs by running full production capacity in both regions simultaneously."
    }
  },
  {
    "id": "SAA-152",
    "domainId": "D2",
    "domain": "Design Resilient Architectures",
    "section": "RDS/Aurora",
    "question": "A company runs an Aurora MySQL cluster for a critical application. They want protection against an AZ failure with automatic failover, and they also want to be able to fail over to another region for a regional outage with the lowest RPO possible.\nWhich design is MOST appropriate?",
    "choices": [
      "Use a single-instance Aurora cluster and take manual snapshots to copy to another region",
      "Use DynamoDB global tables instead of Aurora without changing the application",
      "Use Aurora Multi-AZ (cluster with replicas in multiple AZs) and configure Aurora Global Database for cross-region replication",
      "Use RDS read replicas in the same AZ only and promote one manually"
    ],
    "answer": 2,
    "explanation": "Aurora provides Multi-AZ high availability via replicas and automatic failover within a region. Aurora Global Database provides low-latency cross-region replication to reduce RPO for regional failover scenarios.",
    "difficulty": "Hard",
    "choiceExplanations": {
      "0": "A single-instance cluster provides no automatic failover protection against AZ failure, and manual snapshots result in a high RPO (potentially hours of data loss) compared to Aurora Global Database's typical RPO of seconds.",
      "1": "Switching from Aurora MySQL to DynamoDB would require significant application changes since DynamoDB is a NoSQL key-value database with a completely different data model and API than a relational MySQL database.",
      "3": "This provides no AZ failure protection since all replicas are in the same AZ, requires manual promotion instead of automatic failover, and provides no cross-region disaster recovery capability for regional outages."
    }
  },
  {
    "id": "SAA-153",
    "domainId": "D2",
    "domain": "Design Resilient Architectures",
    "section": "SQS/Lambda",
    "question": "A company processes orders using SQS and Lambda. The same order event can be delivered more than once due to retries, and the downstream system must never create duplicate orders.\nThe team wants a resilient design that handles retries safely.\nWhich solution is MOST suitable?",
    "choices": [
      "Use SNS only without SQS so delivery happens once",
      "Make the Lambda processing idempotent using a DynamoDB table to track processed order IDs, and keep retries/DLQ for failures",
      "Increase the SQS visibility timeout to 12 hours so duplicates cannot occur",
      "Disable retries in Lambda so messages are never reprocessed"
    ],
    "answer": 1,
    "explanation": "Event-driven systems can deliver duplicates. Idempotent processing (tracking processed IDs in DynamoDB or equivalent) ensures retries do not create duplicates, while DLQs capture poison messages for investigation.",
    "difficulty": "Hard",
    "choiceExplanations": {
      "0": "SNS also provides at-least-once delivery, not exactly-once, so duplicates can still occur. Additionally, removing SQS eliminates important benefits like message buffering, retry handling, and dead-letter queue capabilities for failed messages.",
      "2": "Visibility timeout only prevents other consumers from receiving a message while it's being processed; it does not prevent SQS's inherent at-least-once delivery behavior where the same message can be delivered multiple times. This approach also creates operational issues if processing fails.",
      "3": "Disabling retries would cause messages to be lost if transient failures occur, reducing system resilience. This approach sacrifices reliability and does not address the fundamental issue that SQS standard queues can deliver the same message more than once regardless of Lambda retry settings."
    }
  },
  {
    "id": "SAA-154",
    "domainId": "D2",
    "domain": "Design Resilient Architectures",
    "section": "ECS/ALB",
    "question": "A production service runs on ECS Fargate behind an ALB. During deployments, users occasionally see 5xx errors because tasks are terminated before the new tasks are ready.\nThe team wants zero-downtime deployments with minimal effort.\nWhich approach should they implement?",
    "choices": [
      "Switch to an NLB because it does not do health checks",
      "Use an ECS service with rolling updates, configure ALB health checks, and set a deployment minimumHealthyPercent/maximumPercent so new tasks pass health checks before old tasks are drained",
      "Place CloudFront in front of the ALB and disable origin health checks",
      "Manually stop all running tasks, then start new tasks after the image is updated"
    ],
    "answer": 1,
    "explanation": "ECS service deployments can be configured to keep a minimum healthy capacity while starting new tasks. Combined with ALB health checks and connection draining, this avoids terminating old tasks until new ones are healthy.",
    "difficulty": "Hard",
    "choiceExplanations": {
      "0": "This is factually incorrect as NLB does perform health checks on targets. Additionally, switching load balancer types does not address the core deployment issue of tasks being terminated before new ones are ready, and removing health checks would actually make the problem worse by routing traffic to unhealthy targets.",
      "2": "CloudFront caching cannot prevent 5xx errors during deployments when backend tasks are unavailable, and disabling health checks does not solve the underlying issue of task termination timing. This adds unnecessary complexity without addressing the deployment coordination problem.",
      "3": "This approach guarantees downtime because there is a gap between stopping old tasks and new tasks becoming healthy. It also requires manual effort, which contradicts the requirement for minimal effort and does not provide zero-downtime deployments."
    }
  },
  {
    "id": "SAA-155",
    "domainId": "D2",
    "domain": "Design Resilient Architectures",
    "section": "Route 53",
    "question": "A company has two copies of a web application: one in us-east-1 and one in eu-west-1. They want active-active traffic distribution, but if one region fails, 100% of traffic should go to the healthy region automatically.\nWhich Route 53 configuration best meets this?",
    "choices": [
      "Use geolocation routing without health checks",
      "Use failover routing only with a single primary and no secondary health check",
      "Use multivalue answer routing without health checks",
      "Use weighted routing with health checks on each regional endpoint"
    ],
    "answer": 3,
    "explanation": "Weighted routing can split traffic across multiple endpoints and, when paired with health checks, will stop returning unhealthy endpoints—effectively shifting traffic to the healthy region automatically.",
    "difficulty": "Hard",
    "choiceExplanations": {
      "0": "Geolocation routing directs traffic based on user location, not for active-active distribution, and without health checks Route 53 cannot detect regional failures or automatically redirect traffic to the healthy region.",
      "1": "Failover routing is designed for active-passive configurations, not active-active distribution, and without a health check on the secondary endpoint, Route 53 cannot verify the secondary is healthy before routing traffic to it during failover.",
      "2": "Without health checks, Route 53 will continue returning all endpoints including unhealthy ones, meaning clients may still be directed to the failed region instead of automatically receiving only the healthy endpoint."
    }
  },
  {
    "id": "SAA-156",
    "domainId": "D2",
    "domain": "Design Resilient Architectures",
    "section": "S3",
    "question": "A company replicates data using S3 Cross-Region Replication (CRR). They recently enabled CRR but noticed that older objects that already existed in the bucket were not replicated.\nThey want all existing objects to be replicated to the destination bucket.\nWhich action should they take?",
    "choices": [
      "Disable and re-enable CRR and it will backfill all objects automatically",
      "Use S3 Batch Operations (or a one-time copy job) to replicate existing objects, since CRR applies automatically only to new objects by default",
      "Enable S3 Select so CRR can find old objects",
      "Enable S3 Transfer Acceleration to speed up replication of existing objects"
    ],
    "answer": 1,
    "explanation": "CRR typically replicates new objects after the rule is enabled; existing objects require an explicit backfill process (such as S3 Batch Operations or a copy job) to replicate them to the destination bucket.",
    "difficulty": "Hard",
    "choiceExplanations": {
      "0": "Disabling and re-enabling CRR does not trigger replication of existing objects; CRR only applies to new objects uploaded after the replication rule is enabled, regardless of how many times you toggle the setting.",
      "2": "S3 Select is a feature for retrieving subsets of data from objects using SQL expressions, not for discovering or replicating objects; it has no relationship to Cross-Region Replication functionality.",
      "3": "S3 Transfer Acceleration optimizes transfer speeds for uploads and downloads over long distances using CloudFront edge locations, but it does not replicate objects or work with CRR to backfill existing objects."
    }
  },
  {
    "id": "SAA-157",
    "domainId": "D2",
    "domain": "Design Resilient Architectures",
    "section": "ElastiCache",
    "question": "An application stores user session state in-memory on the web servers. During Auto Scaling events, users are frequently logged out because they land on new instances.\nThe company needs a resilient approach that preserves sessions even when instances scale in/out or fail.\nWhich solution is MOST suitable?",
    "choices": [
      "Enable ALB sticky sessions and store sessions only in instance memory",
      "Increase the Auto Scaling cooldown to reduce scaling events",
      "Store sessions in a centralized shared store such as Amazon ElastiCache (Redis) or DynamoDB instead of on-instance memory",
      "Use a larger instance type so scaling isn’t needed"
    ],
    "answer": 2,
    "explanation": "Storing session state in a centralized external store decouples sessions from individual instances and improves resilience across scaling and failures. Sticky sessions help but still lose sessions if an instance fails or scales in.",
    "difficulty": "Hard",
    "choiceExplanations": {
      "0": "While sticky sessions route users to the same instance, sessions are still lost when that instance terminates during scale-in events or fails, making this approach not resilient to instance failures or scaling activities.",
      "1": "This only delays scaling events rather than solving the fundamental problem; sessions will still be lost when scaling eventually occurs, and it reduces the application's ability to respond to demand changes effectively.",
      "3": "Use a larger instance type so scaling isn't needed: This approach is not resilient because a single larger instance creates a single point of failure, and it doesn't address the core issue of session state being tied to instance memory rather than being externalized."
    }
  },
  {
    "id": "SAA-158",
    "domainId": "D2",
    "domain": "Design Resilient Architectures",
    "section": "Multi-AZ",
    "question": "A critical internal service runs on EC2 instances in a single subnet in one AZ. The business requires the service to remain available during an AZ outage.\nWhich change provides the MOST reliable improvement?",
    "choices": [
      "Enable detailed monitoring on the instance",
      "Deploy the service across at least two AZs using an Auto Scaling group and a load balancer, with subnets in each AZ",
      "Increase the instance size in the current AZ",
      "Take EBS snapshots every hour"
    ],
    "answer": 1,
    "explanation": "High availability against AZ failure requires running across multiple AZs. An ASG plus a load balancer and subnets in multiple AZs ensures the service can continue even if one AZ becomes unavailable.",
    "difficulty": "Hard",
    "choiceExplanations": {
      "0": "Detailed monitoring provides metrics at 1-minute intervals instead of 5-minute intervals, which improves observability but does nothing to protect against an AZ outage since the instance still runs in a single AZ.",
      "2": "Vertical scaling improves compute capacity and performance but provides no protection against AZ failure since the instance remains in a single AZ that could become unavailable.",
      "3": "EBS snapshots provide data backup and disaster recovery capabilities, but they do not provide availability during an AZ outage since restoring from snapshots requires manual intervention and downtime."
    }
  },
  {
    "id": "SAA-159",
    "domainId": "D2",
    "domain": "Design Resilient Architectures",
    "section": "RDS",
    "question": "A company uses an RDS MySQL database. Reporting queries occasionally cause performance issues for the production workload.\nThey want to isolate reporting reads without impacting write performance and still keep production highly available.\nWhich solution is MOST suitable?",
    "choices": [
      "Scale up the primary database instance and run reporting on it",
      "Create an RDS read replica for reporting queries, and keep Multi-AZ enabled for the primary for availability",
      "Enable Multi-AZ and direct reporting queries to the standby instance",
      "Export all production data to S3 daily and query it with S3 Select"
    ],
    "answer": 1,
    "explanation": "Read replicas offload read-heavy workloads like reporting, while Multi-AZ protects availability. The standby in Multi-AZ is not designed for reads in standard RDS Multi-AZ deployments.",
    "difficulty": "Hard",
    "choiceExplanations": {
      "0": "Scaling up increases capacity but does not isolate reporting queries from production workloads, meaning reporting queries would still compete for resources with production writes and could impact performance.",
      "2": "The Multi-AZ standby instance in standard RDS deployments is not accessible for read queries; it exists solely for automatic failover purposes and cannot serve any traffic until a failover occurs.",
      "3": "This approach introduces significant data latency (up to 24 hours stale), adds operational complexity for daily exports, and S3 Select is designed for simple queries on individual objects rather than complex reporting workloads across relational data."
    }
  },
  {
    "id": "SAA-160",
    "domainId": "D2",
    "domain": "Design Resilient Architectures",
    "section": "DynamoDB",
    "question": "A company uses DynamoDB with provisioned capacity. During sudden traffic spikes, requests are throttled, causing errors.\nThe business needs the table to handle unpredictable spikes reliably while still optimizing for cost during normal traffic.\nWhich configuration is MOST appropriate?",
    "choices": [
      "Use a larger EC2 instance to host DynamoDB locally",
      "Move the table to S3 Standard to absorb spikes",
      "Disable throttling by turning off DynamoDB partitioning",
      "Enable auto scaling for provisioned read/write capacity (or use on-demand if unpredictability is extreme)"
    ],
    "answer": 3,
    "explanation": "DynamoDB auto scaling adjusts provisioned capacity based on utilization, helping handle spikes while reducing cost during low usage. For highly unpredictable patterns, on-demand capacity may be appropriate as well.",
    "difficulty": "Hard",
    "choiceExplanations": {
      "0": "DynamoDB is a fully managed serverless service and cannot be hosted on EC2 instances. This option fundamentally misunderstands DynamoDB's architecture as a managed NoSQL database service.",
      "1": "S3 is an object storage service, not a database, and cannot replace DynamoDB's NoSQL database functionality. S3 does not support the same query patterns, transactions, or low-latency access that DynamoDB provides.",
      "2": "Partitioning is a fundamental internal mechanism of DynamoDB that cannot be disabled by users. Throttling occurs when provisioned capacity is exceeded and is managed through capacity settings, not partition configuration."
    }
  },
  {
    "id": "SAA-161",
    "domainId": "D2",
    "domain": "Design Resilient Architectures",
    "section": "EventBridge",
    "question": "A company wants to decouple multiple microservices and route events based on event content (for example, route “fraud-alert” events to a specific service and “order-created” events to another).\nThey also want built-in retry and DLQ capabilities.\nWhich service is MOST suitable?",
    "choices": [
      "Amazon S3 event notifications only",
      "Amazon EC2 Auto Scaling lifecycle hooks",
      "Amazon Route 53 Resolver",
      "Amazon EventBridge with rules and targets (plus DLQ where appropriate)"
    ],
    "answer": 3,
    "explanation": "EventBridge supports content-based routing using rules and can integrate with targets that provide retry/DLQ behavior, enabling resilient event-driven architectures across services.",
    "difficulty": "Hard",
    "choiceExplanations": {
      "0": "S3 event notifications are limited to triggering on S3 bucket events (like object creation or deletion) and cannot perform content-based routing on custom event types like 'fraud-alert' or 'order-created' from microservices, nor do they provide built-in DLQ capabilities.",
      "1": "Lifecycle hooks are specifically designed to pause Auto Scaling actions during instance launch or termination to perform custom actions, not for general-purpose event routing between microservices or content-based message filtering.",
      "2": "Route 53 Resolver is a DNS service that handles DNS queries between on-premises networks and AWS VPCs, and has no capability for application event routing, message queuing, or dead-letter queue functionality."
    }
  },
  {
    "id": "SAA-162",
    "domainId": "D2",
    "domain": "Design Resilient Architectures",
    "section": "EFS",
    "question": "A media processing application runs in two AZs and writes intermediate files to a shared file system. The team wants the shared storage to remain available even if one AZ is impaired, with minimal management.\nWhich choice best meets this requirement?",
    "choices": [
      "Use S3 Glacier Deep Archive for intermediate files",
      "Use instance store on each EC2 instance",
      "Use Amazon EFS mounted from both AZs",
      "Use an EBS volume attached to one instance and share it over NFS yourself"
    ],
    "answer": 2,
    "explanation": "EFS is a managed multi-AZ file system designed for shared access from multiple AZs, providing high availability with minimal operational overhead compared to self-managed NFS on EBS.",
    "difficulty": "Hard",
    "choiceExplanations": {
      "0": "S3 Glacier Deep Archive is designed for long-term archival storage with retrieval times of 12-48 hours, making it completely unsuitable for intermediate files that require immediate read/write access during active processing workflows.",
      "1": "Instance store provides ephemeral storage that is local to each EC2 instance and cannot be shared across instances or AZs; data is lost if the instance stops, terminates, or fails, providing no cross-AZ availability or shared access.",
      "3": "EBS volumes can only be attached to instances within a single AZ and cannot span multiple AZs, so if that AZ becomes impaired, the storage becomes unavailable; additionally, self-managed NFS adds significant operational overhead compared to managed EFS."
    }
  },
  {
    "id": "SAA-163",
    "domainId": "D2",
    "domain": "Design Resilient Architectures",
    "section": "S3",
    "question": "A company wants strong protection against accidental deletions and ransomware for an S3 bucket, while still being able to recover data to a previous point in time.\nThey also need the ability to replicate data to another region for DR.\nWhich combination best meets these requirements?",
    "choices": [
      "Enable S3 Transfer Acceleration and store objects as multipart uploads",
      "Use S3 static website hosting and enable logging",
      "Use S3 Select and store query results in another region",
      "Enable S3 versioning and use S3 Object Lock (if WORM is needed) plus S3 Cross-Region Replication where appropriate"
    ],
    "answer": 3,
    "explanation": "Versioning protects against overwrites and deletions by keeping prior versions. Object Lock can provide additional WORM protection. Cross-Region Replication supports region-level disaster recovery by copying objects to another region.",
    "difficulty": "Hard",
    "choiceExplanations": {
      "0": "S3 Transfer Acceleration improves upload/download speeds over long distances, and multipart uploads are for handling large files efficiently, but neither feature provides protection against accidental deletions, ransomware, point-in-time recovery, or cross-region replication for disaster recovery.",
      "1": "S3 static website hosting is for serving web content publicly, and logging only records access requests for auditing purposes, neither of which provides data protection against deletions, ransomware protection, recovery capabilities, or cross-region replication.",
      "2": "S3 Select is a feature for retrieving subsets of data from objects using SQL expressions to reduce data transfer, not a data protection or replication mechanism, and manually storing query results does not provide automated replication, versioning, or protection against accidental deletions."
    }
  },
  {
    "id": "SAA-164",
    "domainId": "D2",
    "domain": "Design Resilient Architectures",
    "section": "CloudFront",
    "question": "A company uses CloudFront in front of an ALB. The origin sometimes becomes temporarily overloaded, and the company wants CloudFront to serve stale cached objects during brief origin outages to improve resilience.\nWhich CloudFront setting helps achieve this?",
    "choices": [
      "Configure CloudFront to serve stale content on origin errors by using appropriate cache/error settings (stale-while-revalidate / stale-if-error behavior where supported)",
      "Use Route 53 weighted routing between two CloudFront distributions",
      "Enable S3 Transfer Acceleration on the ALB",
      "Disable caching entirely so CloudFront always fetches from the origin"
    ],
    "answer": 0,
    "explanation": "Serving stale cached content during origin errors can reduce user impact during transient origin problems. This is achieved through CloudFront cache/error behavior settings that allow stale responses under certain conditions.",
    "difficulty": "Hard",
    "choiceExplanations": {
      "1": "This approach distributes traffic between distributions but does not address serving cached content during origin failures; both distributions would still fail when the single ALB origin becomes overloaded, and it adds unnecessary complexity without solving the stale content serving requirement.",
      "2": "S3 Transfer Acceleration is a feature specifically for Amazon S3 buckets to speed up uploads over long distances and cannot be enabled on an Application Load Balancer; this option is technically invalid and unrelated to serving cached content during origin outages.",
      "3": "This is the opposite of what is needed; disabling caching would ensure every request goes to the origin, making the overload problem worse and eliminating any possibility of serving cached content during origin failures."
    }
  },
  {
    "id": "SAA-165",
    "domainId": "D2",
    "domain": "Design Resilient Architectures",
    "section": "Step Functions",
    "question": "A company has a multi-step serverless workflow (validate → charge → provision → notify). They need reliable orchestration with retries, error handling, and the ability to see where executions failed.\nWhich service is MOST suitable?",
    "choices": [
      "Amazon S3",
      "AWS Step Functions",
      "Amazon SNS",
      "AWS Glue"
    ],
    "answer": 1,
    "explanation": "Step Functions provides workflow orchestration with built-in retries, error handling, state tracking, and execution history, improving resilience and observability for multi-step serverless processes.",
    "difficulty": "Hard",
    "choiceExplanations": {
      "0": "S3 is an object storage service designed for storing and retrieving data, not for orchestrating workflows; it lacks built-in capabilities for workflow coordination, retries, error handling, or execution state tracking.",
      "2": "SNS is a pub/sub messaging service for sending notifications and decoupling components, but it cannot orchestrate multi-step workflows, manage execution state, implement retry logic, or provide visibility into where failures occurred in a process.",
      "3": "Glue is a managed ETL (Extract, Transform, Load) service designed for data integration and preparation tasks, not for general-purpose serverless workflow orchestration; it lacks the flexible state machine capabilities, custom retry policies, and execution visualization needed for this use case."
    }
  },
  {
    "id": "SAA-166",
    "domainId": "D2",
    "domain": "Design Resilient Architectures",
    "section": "VPC",
    "question": "A company runs workloads in two AZs. During an AZ outage, they want their private subnets in the remaining AZ to continue having outbound internet access (for example, to reach a third-party API) without manual intervention.\nWhich design best meets the requirement?",
    "choices": [
      "Deploy a NAT Gateway in each AZ and configure route tables so each private subnet uses the NAT Gateway in the same AZ",
      "Use an Internet Gateway attached directly to the private subnets",
      "Deploy a single NAT Gateway in one AZ and route all private subnets to it",
      "Remove NAT and assign public IPs to instances in private subnets"
    ],
    "answer": 0,
    "explanation": "Using one NAT Gateway per AZ avoids a single-AZ dependency. If an AZ fails, private subnets in the remaining AZ can still route through their local NAT Gateway, maintaining outbound connectivity.",
    "difficulty": "Hard",
    "choiceExplanations": {
      "1": "Internet Gateways cannot provide outbound internet access to instances in private subnets because those instances lack public IP addresses; IGWs only enable internet connectivity for resources with public or Elastic IP addresses in public subnets.",
      "2": "A single NAT Gateway creates a single point of failure; if the AZ containing the NAT Gateway experiences an outage, all private subnets across both AZs lose outbound internet access, failing the resilience requirement.",
      "3": "Assigning public IPs to instances fundamentally changes them from private to publicly accessible resources, which violates the security principle of private subnets and exposes instances directly to the internet rather than keeping them isolated."
    }
  },
  {
    "id": "SAA-167",
    "domainId": "D2",
    "domain": "Design Resilient Architectures",
    "section": "Auto Scaling",
    "question": "An application experiences sudden bursts of traffic. The team uses an Auto Scaling group but scaling out takes several minutes due to long bootstrapping, causing errors during bursts.\nThey want a more resilient way to absorb short spikes while the ASG scales.\nWhich solution is MOST suitable?",
    "choices": [
      "Increase the instance size so scale-out is unnecessary",
      "Place an SQS queue (or similar buffer) between the request intake and the workers to absorb bursts, allowing workers to scale and drain the backlog",
      "Disable health checks to avoid replacing instances",
      "Move the application to a single larger EC2 instance"
    ],
    "answer": 1,
    "explanation": "Introducing a queue buffers bursty workloads and decouples ingestion from processing. This helps maintain resilience during spikes while compute capacity scales to handle the backlog.",
    "difficulty": "Hard",
    "choiceExplanations": {
      "0": "Vertical scaling alone cannot handle unlimited traffic bursts and still has finite capacity limits; it does not address the fundamental problem of absorbing sudden spikes and introduces a single point of failure without providing elasticity.",
      "2": "This does not address the scaling latency problem and would actually reduce resilience by allowing unhealthy instances to remain in service, potentially causing more errors rather than fewer during traffic bursts.",
      "3": "This eliminates Auto Scaling entirely, creates a single point of failure, and still has finite capacity that cannot handle unpredictable traffic bursts regardless of instance size."
    }
  },
  {
    "id": "SAA-168",
    "domainId": "D3",
    "domain": "Design High-Performing Architectures",
    "section": "CloudFront",
    "question": "A global news website serves dynamic HTML (personalized) and large static images from the same domain. Users complain that pages are slow during peak hours.\nRequirements:\n- Personalized HTML must not be cached for long\n- Images should be cached globally to reduce origin load\n- Minimal application code changes\nWhich solution BEST meets these requirements?",
    "choices": [
      "Use an NLB in front of the web servers to cache HTML",
      "Use S3 Glacier for images and serve them directly to users",
      "Use CloudFront with separate cache behaviors: cache images aggressively (path-based) and set minimal/zero caching for personalized HTML; forward only needed headers/cookies for dynamic paths",
      "Increase the origin server instance size and disable caching"
    ],
    "answer": 2,
    "explanation": "CloudFront cache behaviors allow different caching rules per path pattern. You can cache static assets heavily while keeping personalized content minimally cached and forwarding only what is required, improving performance and reducing origin load with limited code changes.",
    "difficulty": "Hard",
    "choiceExplanations": {
      "0": "Network Load Balancers operate at Layer 4 (TCP/UDP) and do not have any caching capabilities; they simply distribute traffic across targets without inspecting or caching HTTP content.",
      "1": "S3 Glacier is designed for archival storage with retrieval times ranging from minutes to hours, making it completely unsuitable for serving images that users need to access immediately; it would dramatically worsen performance rather than improve it.",
      "3": "Disabling caching would increase origin load rather than reduce it, and simply scaling up instances does not address the global distribution requirement or provide edge caching benefits needed to improve performance during peak hours."
    }
  },
  {
    "id": "SAA-169",
    "domainId": "D3",
    "domain": "Design High-Performing Architectures",
    "section": "DynamoDB/DAX",
    "question": "A shopping cart service stores cart items in DynamoDB and must serve extremely high read traffic with sub-millisecond latency for the hottest keys during flash sales.\nWrites must still be strongly consistent in DynamoDB.\nWhich solution is MOST suitable to improve read performance?",
    "choices": [
      "Add Multi-AZ to DynamoDB",
      "Move the cart data to S3 Standard and query it with Athena",
      "Add DynamoDB Accelerator (DAX) in front of DynamoDB for cached reads",
      "Use RDS read replicas for the cart table"
    ],
    "answer": 2,
    "explanation": "DAX is an in-memory caching layer for DynamoDB designed to significantly reduce read latency and improve throughput for read-heavy workloads. It complements DynamoDB, which remains the system of record for writes.",
    "difficulty": "Hard",
    "choiceExplanations": {
      "0": "DynamoDB is already a fully managed, multi-AZ service by default with automatic data replication across Availability Zones for high availability. This built-in feature provides durability and fault tolerance but does not improve read latency or address hot key performance issues.",
      "1": "S3 with Athena is designed for analytics workloads on large datasets, not transactional operations. Athena queries typically take seconds to complete, which is far from the sub-millisecond latency requirement, and S3 is not suitable for high-frequency read/write shopping cart operations.",
      "3": "RDS is a relational database service that cannot serve as read replicas for DynamoDB, which is a NoSQL database. These are completely different database services with incompatible data models, and migrating to RDS would also not achieve sub-millisecond latency for hot keys like DAX can."
    }
  },
  {
    "id": "SAA-170",
    "domainId": "D3",
    "domain": "Design High-Performing Architectures",
    "section": "ALB/NLB",
    "question": "A company runs microservices: some are HTTP/2 gRPC services, others are standard HTTP REST services, and one service uses raw TCP.\nThey want to front these services with load balancers while preserving performance and choosing the right protocol support.\nWhich design is MOST appropriate?",
    "choices": [
      "Use CloudFront as the only load balancer for TCP services",
      "Use only an ALB for all services including raw TCP",
      "Use an ALB for HTTP/HTTPS (including gRPC) services and an NLB for the TCP service",
      "Use only an NLB for all services and terminate TLS on instances"
    ],
    "answer": 2,
    "explanation": "ALB is best for Layer 7 HTTP/HTTPS use cases and supports modern features like HTTP routing and gRPC, while NLB is Layer 4 and supports TCP/UDP with high performance. Using both matches protocol needs and performance goals.",
    "difficulty": "Hard",
    "choiceExplanations": {
      "0": "CloudFront is a CDN that only supports HTTP, HTTPS, and WebSocket protocols at the edge; it cannot handle raw TCP traffic and is not designed to function as a load balancer for arbitrary TCP services.",
      "1": "ALB operates at Layer 7 and only supports HTTP, HTTPS, gRPC, and WebSocket protocols; it cannot handle raw TCP traffic, which requires a Layer 4 load balancer like NLB.",
      "3": "While NLB can handle all traffic types at Layer 4, it lacks the Layer 7 features needed for HTTP/gRPC services such as path-based routing, host-based routing, and native gRPC support; terminating TLS on instances also increases operational overhead and reduces performance optimization."
    }
  },
  {
    "id": "SAA-171",
    "domainId": "D3",
    "domain": "Design High-Performing Architectures",
    "section": "EBS/EFS",
    "question": "A video rendering farm runs on hundreds of EC2 instances. Each job reads large shared media files and writes per-job output files. The shared input data needs high throughput and must be accessible concurrently by all instances.\nWhich storage approach provides the BEST performance and simplest scaling for the shared input data?",
    "choices": [
      "Attach a single EBS volume to one instance and export it via NFS to all instances",
      "Store all shared media in DynamoDB",
      "Store shared input media in S3 and download needed objects per job (or stream), optionally using CloudFront for edge caching if needed",
      "Use instance store on one instance and share it across the fleet"
    ],
    "answer": 2,
    "explanation": "S3 scales massively for shared object storage and avoids single-instance bottlenecks that occur with self-managed NFS on EBS. For large fleets, object-based distribution from S3 is typically simpler and more scalable for shared read-heavy inputs.",
    "difficulty": "Hard",
    "choiceExplanations": {
      "0": "This creates a single point of failure and a performance bottleneck, as all traffic must flow through one EC2 instance, which cannot scale to support hundreds of concurrent instances requiring high throughput for large media files.",
      "1": "DynamoDB is a key-value and document database designed for structured data with a 400KB item size limit, making it unsuitable for storing large media files that video rendering workloads require.",
      "3": "Instance store provides ephemeral storage that is lost when the instance stops or terminates, and sharing it across a fleet would require the same single-instance bottleneck as the NFS solution, making it unsuitable for high-throughput concurrent access by hundreds of instances."
    }
  },
  {
    "id": "SAA-172",
    "domainId": "D3",
    "domain": "Design High-Performing Architectures",
    "section": "RDS/Aurora",
    "question": "A SaaS application uses Aurora and has a heavy write workload plus a growing number of read-only analytics queries. The team wants to scale reads independently and reduce load on the writer without redesigning the schema.\nWhich solution best meets this requirement?",
    "choices": [
      "Add Aurora reader instances and route read-only queries to the reader endpoint, keeping writes on the writer endpoint",
      "Enable Multi-AZ and route analytics queries to the standby instance",
      "Increase the Aurora storage size to improve read throughput",
      "Move analytics queries to S3 Select against database snapshots"
    ],
    "answer": 0,
    "explanation": "Aurora supports multiple reader instances and provides a reader endpoint to load balance read traffic. This offloads analytics reads from the writer and scales reads independently.",
    "difficulty": "Hard",
    "choiceExplanations": {
      "1": "Aurora Multi-AZ deployments use standby instances for failover purposes only, not for serving read traffic. Unlike Aurora Replicas, Multi-AZ standby instances cannot be used to offload read queries.",
      "2": "Aurora storage automatically scales up to 128 TB and storage size does not directly improve read query performance. Read scaling requires additional compute capacity through reader instances, not additional storage.",
      "3": "S3 Select operates on static snapshot data which would be stale and not reflect current database state. This approach requires schema redesign, doesn't provide real-time analytics, and S3 Select is designed for simple filtering of S3 objects, not complex database queries."
    }
  },
  {
    "id": "SAA-173",
    "domainId": "D3",
    "domain": "Design High-Performing Architectures",
    "section": "S3/Glacier",
    "question": "A media company stores raw video files in S3 and must support occasional reprocessing. Most files are rarely accessed after 30 days, but when they are needed they must be retrievable in minutes, not hours.\nThe team wants to reduce storage cost while maintaining the retrieval requirement.\nWhich lifecycle transition is MOST appropriate?",
    "choices": [
      "Transition objects to S3 Glacier Instant Retrieval (or S3 Glacier Flexible Retrieval with expedited where appropriate) after 30 days, based on the minutes-level access requirement",
      "Transition objects directly to S3 Glacier Deep Archive after 30 days",
      "Keep all objects in S3 Standard forever",
      "Transition objects to S3 One Zone-IA and delete them after 30 days"
    ],
    "answer": 0,
    "explanation": "For minutes-level retrieval, Glacier Instant Retrieval (or Flexible Retrieval with a suitable retrieval tier) fits better than Deep Archive, which typically has hours-level retrieval. Lifecycle transitions reduce cost while meeting access needs.",
    "difficulty": "Hard",
    "choiceExplanations": {
      "1": "S3 Glacier Deep Archive has a minimum retrieval time of 12 hours (standard retrieval), which fails to meet the requirement that files must be retrievable in minutes, not hours.",
      "2": "While this meets the retrieval requirement, it does not reduce storage costs as requested since S3 Standard is the most expensive storage class, and the question states most files are rarely accessed after 30 days.",
      "3": "This solution deletes the files after 30 days, which contradicts the requirement to support occasional reprocessing of files that may be needed beyond the 30-day period."
    }
  },
  {
    "id": "SAA-174",
    "domainId": "D3",
    "domain": "Design High-Performing Architectures",
    "section": "Global Accelerator",
    "question": "A gaming company runs regional game server fleets in three regions. Players should always connect to the closest healthy region with the lowest latency, and fail over quickly when a region becomes unavailable.\nThey also want to keep using UDP and avoid complex client-side logic.\nWhich solution is MOST suitable?",
    "choices": [
      "Use CloudFront to cache UDP game traffic at the edge",
      "Use AWS Global Accelerator with multiple regional endpoints (NLBs) and health checks to route players to the optimal healthy region",
      "Use Route 53 simple routing with a single record",
      "Use an ALB with HTTP routing rules"
    ],
    "answer": 1,
    "explanation": "Global Accelerator provides fast, deterministic routing over the AWS global network and supports health-based failover to the closest healthy endpoint. It’s well suited for latency-sensitive, global applications and can front NLB endpoints for UDP.",
    "difficulty": "Hard",
    "choiceExplanations": {
      "0": "CloudFront is a content delivery network designed for HTTP/HTTPS traffic and does not support UDP protocol, making it unsuitable for game server traffic that requires UDP connectivity.",
      "2": "Simple routing returns all values in random order and does not provide latency-based routing, health checks for automatic failover, or the ability to direct players to the closest healthy region based on network conditions.",
      "3": "Application Load Balancers only support HTTP/HTTPS protocols (Layer 7) and cannot handle UDP traffic, which is required for the gaming workload; additionally, ALBs are regional resources and cannot provide global routing across multiple regions."
    }
  },
  {
    "id": "SAA-175",
    "domainId": "D3",
    "domain": "Design High-Performing Architectures",
    "section": "Kinesis",
    "question": "A company collects clickstream events from millions of users and needs near real-time processing and aggregation. The ingestion layer must handle very high throughput, and multiple consumers (fraud detection, analytics, personalization) must process the same event stream independently.\nWhich solution is MOST appropriate?",
    "choices": [
      "Use Amazon Kinesis Data Streams for ingestion and have multiple consumer applications read from the stream",
      "Use a single SQS queue shared by all consumers",
      "Send events directly to an RDS database table and run triggers",
      "Write all events to S3 and run nightly batch jobs only"
    ],
    "answer": 0,
    "explanation": "Kinesis Data Streams is designed for high-throughput streaming ingestion and supports multiple consumers processing the same stream. SQS does not naturally support multiple independent consumers each receiving all messages without fanout.",
    "difficulty": "Hard",
    "choiceExplanations": {
      "1": "SQS queues deliver each message to only one consumer, so multiple independent consumers cannot each receive all messages from the same queue without implementing SNS fanout; this violates the requirement for multiple consumers to process the same event stream independently.",
      "2": "RDS is not designed for high-throughput streaming ingestion from millions of users and would create a bottleneck; database triggers add latency and complexity, making this unsuitable for near real-time processing at scale.",
      "3": "Nightly batch processing does not meet the near real-time requirement; this approach introduces significant latency (up to 24 hours) which is unacceptable for use cases like fraud detection that require immediate processing."
    }
  },
  {
    "id": "SAA-176",
    "domainId": "D3",
    "domain": "Design High-Performing Architectures",
    "section": "VPC",
    "question": "A private application in a VPC needs low-latency access to Amazon S3 for large object reads. The company wants to avoid NAT bottlenecks and reduce latency jitter.\nWhich network configuration BEST meets this requirement?",
    "choices": [
      "Assign public IPs to instances and access S3 over the internet",
      "Create an S3 Gateway VPC endpoint and route S3 traffic through it",
      "Route S3 traffic through a NAT Gateway in a public subnet",
      "Use VPC peering to an S3 VPC in another account"
    ],
    "answer": 1,
    "explanation": "An S3 gateway endpoint provides private connectivity to S3 without NAT, improving performance and removing NAT as a throughput bottleneck for large S3 transfers.",
    "difficulty": "Hard",
    "choiceExplanations": {
      "0": "This requires instances to be in public subnets and routes traffic over the public internet, introducing variable latency (jitter) and not providing the private, low-latency connectivity required for the application.",
      "2": "This directly contradicts the requirement to avoid NAT bottlenecks, as NAT Gateway has bandwidth limits (up to 100 Gbps with scaling) and introduces additional latency and potential throughput constraints for large object transfers.",
      "3": "This is technically impossible because S3 is a managed service that does not reside in a customer VPC, so you cannot establish VPC peering to access S3; VPC peering only works between customer-owned VPCs."
    }
  },
  {
    "id": "SAA-177",
    "domainId": "D3",
    "domain": "Design High-Performing Architectures",
    "section": "EBS",
    "question": "A transactional database on EC2 requires both high IOPS and high throughput. During peak hours, storage performance becomes the bottleneck.\nWhich combination is MOST likely to improve storage performance?",
    "choices": [
      "Move the database files to S3 and mount it as a file system",
      "Move to io2 (Provisioned IOPS) volumes and ensure the instance type supports sufficient EBS bandwidth; consider EBS-optimized instances",
      "Switch to sc1 (Cold HDD) volumes for higher IOPS",
      "Reduce EBS volume size to increase throughput"
    ],
    "answer": 1,
    "explanation": "Provisioned IOPS SSD volumes provide higher and more consistent IOPS. Instance EBS bandwidth limits can also bottleneck, so choosing an instance type with higher EBS throughput (and EBS-optimized) is important.",
    "difficulty": "Hard",
    "choiceExplanations": {
      "0": "S3 is object storage, not block storage, and cannot be directly mounted as a file system for database operations. Even with solutions like S3 Mountpoint, S3 has high latency and does not support the random read/write IOPS patterns required by transactional databases.",
      "2": "sc1 (Cold HDD) is the lowest-performance EBS volume type, designed for infrequently accessed, throughput-oriented workloads with a maximum of only 250 IOPS. This is completely unsuitable for transactional databases requiring high IOPS.",
      "3": "Reducing EBS volume size does not increase throughput; in fact, for gp2/gp3 volumes, performance scales with volume size. Smaller volumes would likely decrease baseline performance, making this counterproductive for addressing storage bottlenecks."
    }
  },
  {
    "id": "SAA-178",
    "domainId": "D3",
    "domain": "Design High-Performing Architectures",
    "section": "Athena/Glue",
    "question": "A data team runs frequent SQL queries on S3 data using Athena. Query performance is inconsistent because the data is stored as large, uncompressed CSV files with many columns, but most queries read only a few columns.\nThey want faster queries and lower cost.\nWhich approach is MOST suitable?",
    "choices": [
      "Increase Athena concurrency by running queries from more clients",
      "Store the CSV files in EBS instead of S3",
      "Move the data into S3 Glacier Deep Archive",
      "Convert the data to a columnar, compressed format (like Parquet/ORC) and partition it appropriately using AWS Glue/Athena best practices"
    ],
    "answer": 3,
    "explanation": "Columnar, compressed formats and partitioning reduce scanned data and improve Athena query performance and cost. Glue can help catalog and transform data into optimized layouts.",
    "difficulty": "Hard",
    "choiceExplanations": {
      "0": "Running more concurrent queries does not improve individual query performance or reduce the amount of data scanned per query; it only increases parallelism of separate queries and would actually increase costs since Athena charges per data scanned.",
      "1": "Athena is designed to query data stored in Amazon S3, not EBS volumes; EBS is block storage attached to EC2 instances and cannot be directly queried by Athena, making this option technically invalid.",
      "2": "Glacier Deep Archive is designed for long-term archival with retrieval times of 12-48 hours and cannot be directly queried by Athena; this would make queries impossible without first restoring data to S3 Standard, increasing both latency and costs."
    }
  },
  {
    "id": "SAA-179",
    "domainId": "D3",
    "domain": "Design High-Performing Architectures",
    "section": "ECS",
    "question": "A company’s containerized API experiences periodic latency spikes due to noisy neighbors on shared EC2 hosts. They want more predictable performance without managing servers.\nWhich approach is MOST suitable?",
    "choices": [
      "Run the service on AWS Fargate to get serverless containers with more isolation and predictable resource allocation per task",
      "Use a single larger EC2 instance with no scaling",
      "Move the service to S3 static hosting",
      "Run the service on spot instances only"
    ],
    "answer": 0,
    "explanation": "Fargate provides task-level CPU/memory allocation and removes the need to manage the underlying EC2 fleet, often improving predictability compared to a heavily shared EC2 cluster configuration.",
    "difficulty": "Hard",
    "choiceExplanations": {
      "1": "This still requires server management and creates a single point of failure with no fault tolerance; it also doesn't address the noisy neighbor problem since other processes on the same host could still compete for resources, and lacks the ability to handle varying workloads.",
      "2": "S3 static hosting can only serve static content and cannot run containerized APIs or execute dynamic application code, making it completely unsuitable for an API workload.",
      "3": "Spot instances can be interrupted with only 2 minutes notice when AWS needs the capacity back, making them unsuitable for APIs requiring predictable performance; they also still require server management and don't solve the noisy neighbor isolation problem."
    }
  },
  {
    "id": "SAA-180",
    "domainId": "D3",
    "domain": "Design High-Performing Architectures",
    "section": "CloudFront/ALB",
    "question": "A company serves an API through CloudFront in front of an ALB. They want to reduce latency for global users but must ensure that authentication headers are forwarded and that cached responses do not leak between users.\nWhich CloudFront configuration BEST meets these requirements?",
    "choices": [
      "Use S3 as the origin for the API",
      "Cache all API responses for 24 hours to maximize hit ratio",
      "Disable caching (or set very low TTL) for authenticated API paths and forward only required headers/cookies; cache only truly public responses",
      "Remove authentication headers at CloudFront to improve performance"
    ],
    "answer": 2,
    "explanation": "For personalized/authenticated API responses, caching can cause data leakage unless carefully keyed and controlled. The safest approach is to minimize caching for authenticated paths while forwarding only necessary headers/cookies, caching only public endpoints.",
    "difficulty": "Hard",
    "choiceExplanations": {
      "0": "S3 is designed for static content storage, not for serving dynamic API responses that require backend processing through an ALB. The question specifically states the API is served through an ALB, which handles dynamic requests and authentication logic that S3 cannot provide.",
      "1": "Caching authenticated API responses without proper cache key differentiation would cause cached responses from one user to be served to other users, resulting in data leakage and security violations. This directly contradicts the requirement to prevent cached responses from leaking between users.",
      "3": "Removing authentication headers would prevent the ALB and backend application from receiving the credentials needed to authenticate users, breaking the authentication mechanism entirely. The question explicitly requires that authentication headers must be forwarded to the origin."
    }
  },
  {
    "id": "SAA-181",
    "domainId": "D3",
    "domain": "Design High-Performing Architectures",
    "section": "EC2",
    "question": "A compute workload requires very high packet-per-second performance and low network latency. The team also wants to minimize CPU overhead for networking.\nWhich EC2 feature best supports this?",
    "choices": [
      "Using S3 Transfer Acceleration",
      "Enhanced networking (ENA) on supported instance types",
      "Using a smaller instance type to reduce noise",
      "Placing instances in multiple regions"
    ],
    "answer": 1,
    "explanation": "Enhanced networking with ENA provides higher bandwidth, higher PPS, and lower latency by using SR-IOV, reducing CPU overhead for networking on supported instances.",
    "difficulty": "Hard",
    "choiceExplanations": {
      "0": "This feature speeds up transfers to and from S3 buckets over long distances using CloudFront edge locations, but it has no impact on EC2 instance-to-instance network performance, packet-per-second rates, or CPU overhead for networking.",
      "2": "Smaller instance types typically have lower network bandwidth limits and fewer resources, which would actually decrease network performance rather than improve packet-per-second rates or reduce latency; the concept of reducing noise is not relevant to network performance optimization.",
      "3": "Distributing instances across multiple regions increases network latency due to the physical distance between regions, which is the opposite of what is needed for low-latency, high-performance networking between compute resources."
    }
  },
  {
    "id": "SAA-182",
    "domainId": "D3",
    "domain": "Design High-Performing Architectures",
    "section": "S3",
    "question": "A company stores large log files in S3 and frequently needs to retrieve only a subset of fields from the logs (for example, a few columns) without downloading entire objects.\nWhich S3 capability best meets this requirement?",
    "choices": [
      "Use S3 Transfer Acceleration to download the full object faster",
      "Use S3 Select to retrieve only the required data from objects",
      "Use S3 Object Lock to prevent changes",
      "Use S3 Glacier Deep Archive and restore the object"
    ],
    "answer": 1,
    "explanation": "S3 Select allows applications to retrieve a subset of data (using SQL expressions) from an object, reducing data transfer and improving performance when only parts of the object are needed.",
    "difficulty": "Hard",
    "choiceExplanations": {
      "0": "S3 Transfer Acceleration speeds up transfers over long distances using CloudFront edge locations, but it still downloads the entire object rather than allowing selective retrieval of specific fields or columns from within the object.",
      "2": "S3 Object Lock is a data protection feature that prevents objects from being deleted or overwritten using WORM (Write Once Read Many) model, and has nothing to do with selectively retrieving subsets of data from objects.",
      "3": "S3 Glacier Deep Archive is a low-cost storage class for long-term archival with retrieval times of 12-48 hours, and restoring objects still requires downloading the entire object rather than extracting specific fields."
    }
  },
  {
    "id": "SAA-183",
    "domainId": "D3",
    "domain": "Design High-Performing Architectures",
    "section": "Caching",
    "question": "A web application uses an RDS database and experiences spikes in read traffic for a small set of “hot” products. The team wants to reduce database load and keep response times consistently low during spikes.\nThey also want the solution to be simple to operate.\nWhich solution is MOST suitable?",
    "choices": [
      "Store product data only in S3 Glacier to reduce DB load",
      "Enable RDS Multi-AZ and send reads to the standby",
      "Cache hot items in ElastiCache and apply an appropriate cache invalidation/TTL strategy",
      "Increase EBS volume size on the database instance"
    ],
    "answer": 2,
    "explanation": "ElastiCache provides low-latency caching for hot data, reducing repetitive reads to the database and improving performance during spikes. Multi-AZ improves availability but doesn’t offload reads in typical configurations.",
    "difficulty": "Hard",
    "choiceExplanations": {
      "0": "S3 Glacier is designed for archival storage with retrieval times ranging from minutes to hours, making it completely unsuitable for serving hot product data that requires low-latency responses during traffic spikes.",
      "1": "RDS Multi-AZ standby instances are designed solely for failover and high availability purposes; they cannot be used to serve read traffic, as all reads and writes must go through the primary instance.",
      "3": "Increasing EBS volume size adds storage capacity but does not improve read performance or reduce database load; to improve I/O performance you would need to change the volume type or use Provisioned IOPS, but caching is still the better solution for hot data."
    }
  },
  {
    "id": "SAA-184",
    "domainId": "D4",
    "domain": "Design Cost-Optimized Architectures",
    "section": "S3",
    "question": "A company stores confidential build artifacts in S3 and wants to “never worry about capacity.” For the first 30 days, all artifacts are accessed frequently. After 30 days, most artifacts are rarely accessed, and retrieval time is not strict for developers.\nHowever, objects under the prefix /finance-fast/ are used by an automated post-processing pipeline that requires millisecond retrieval at any time.\nWhich lifecycle approach is MOST cost-effective while meeting the access requirements?",
    "choices": [
      "Enable S3 Intelligent-Tiering for the entire bucket and disable any archive tiers",
      "Keep everything in S3 Standard and rely on compression to reduce cost",
      "Transition the entire bucket to S3 Glacier Deep Archive after 30 days",
      "Use lifecycle rules to transition most objects to Glacier Flexible Retrieval after 30 days, but transition /finance-fast/ objects to S3 Standard-IA (or keep in Standard) to maintain millisecond retrieval"
    ],
    "answer": 3,
    "explanation": "Most artifacts can move to an archive tier (like Glacier Flexible Retrieval) after the frequent-access window because developers have no strict retrieval latency requirement. The /finance-fast/ prefix must stay in a millisecond-access class (Standard or Standard-IA). Prefix-based lifecycle rules meet both requirements at lowest cost.",
    "difficulty": "Hard",
    "choiceExplanations": {
      "0": "While Intelligent-Tiering automates cost optimization, disabling archive tiers means objects would only move between Frequent and Infrequent Access tiers, missing the significant cost savings of Glacier Flexible Retrieval for the majority of rarely-accessed artifacts where retrieval time is not strict.",
      "1": "S3 Standard is the most expensive storage class, and compression alone does not provide the same level of cost savings as transitioning infrequently accessed data to lower-cost storage classes like Glacier Flexible Retrieval, making this approach far from cost-optimized.",
      "2": "Glacier Deep Archive has retrieval times of 12-48 hours and does not support millisecond retrieval, which would break the automated post-processing pipeline requirement for /finance-fast/ objects that need instant access at any time."
    }
  },
  {
    "id": "SAA-185",
    "domainId": "D4",
    "domain": "Design Cost-Optimized Architectures",
    "section": "EC2",
    "question": "A company has a mixed compute fleet:\n- A baseline set of instances runs 24/7 year-round\n- Additional instances run only during occasional peak campaigns\nThey want to minimize cost while keeping flexibility for peaks.\nWhich purchasing strategy is MOST cost-effective?",
    "choices": [
      "Use Spot Instances for the baseline steady-state because it is cheapest",
      "Use Savings Plans or Reserved Instances for the baseline, and use On-Demand or Spot (where appropriate) for the variable peak capacity",
      "Use On-Demand for everything to keep flexibility",
      "Use Dedicated Hosts for all instances to reduce cost"
    ],
    "answer": 1,
    "explanation": "A blended strategy is typically optimal: commit discounts (RI/Savings Plans) for steady usage, and use flexible capacity (On-Demand or Spot for fault-tolerant workloads) for peaks. Spot for baseline is risky due to interruptions.",
    "difficulty": "Hard",
    "choiceExplanations": {
      "0": "While Spot Instances offer up to 90% discount, they can be interrupted with only 2 minutes notice when AWS needs the capacity back, making them unsuitable for baseline workloads that must run 24/7 continuously without interruption.",
      "2": "On-Demand pricing is the most expensive option with no discounts, and using it for predictable 24/7 baseline workloads wastes significant cost savings (up to 72%) that could be achieved through Reserved Instances or Savings Plans commitments.",
      "3": "Dedicated Hosts are the most expensive EC2 purchasing option, designed for licensing compliance or regulatory requirements that require dedicated physical servers, not for cost optimization purposes."
    }
  },
  {
    "id": "SAA-186",
    "domainId": "D4",
    "domain": "Design Cost-Optimized Architectures",
    "section": "RDS/Aurora",
    "question": "A startup is building an application with an unpredictable traffic pattern. They need a relational database but want to minimize operational overhead and avoid paying for unused capacity during idle periods.\nWhich option is MOST cost-effective and operationally simple?",
    "choices": [
      "Run MySQL on a large EC2 instance and scale it manually",
      "Use Redshift because it is serverless",
      "Use Aurora Serverless (where supported) to automatically scale capacity based on demand",
      "Use a multi-node self-managed PostgreSQL cluster on EC2 for high availability"
    ],
    "answer": 2,
    "explanation": "Aurora Serverless is designed for variable and unpredictable workloads, automatically scaling capacity and reducing the need to overprovision. Managing databases on EC2 generally increases operational overhead and can be less cost-effective for spiky usage.",
    "difficulty": "Hard",
    "choiceExplanations": {
      "0": "This approach requires significant operational overhead for database management, patching, backups, and scaling decisions, plus a large instance would incur costs even during idle periods, making it neither cost-effective nor operationally simple.",
      "1": "While Redshift Serverless exists, Redshift is a data warehousing solution designed for analytics and OLAP workloads, not a general-purpose relational database for transactional applications, making it unsuitable for typical application database needs.",
      "3": "Self-managed database clusters on EC2 require the highest operational overhead including manual configuration, replication setup, failover management, patching, and backups, while also paying for multiple instances regardless of actual usage."
    }
  },
  {
    "id": "SAA-187",
    "domainId": "D4",
    "domain": "Design Cost-Optimized Architectures",
    "section": "NAT/VPC",
    "question": "A company has workloads in three AZs. Each private subnet routes outbound internet traffic through a single NAT Gateway. Costs are high and throughput is occasionally constrained.\nThey also want to be resilient to an AZ outage.\nWhich design best optimizes BOTH cost and resilience?",
    "choices": [
      "Move all instances to public subnets to avoid NAT cost",
      "Replace NAT Gateway with an Internet Gateway in private subnets",
      "Keep one NAT Gateway and increase its size",
      "Deploy one NAT Gateway per AZ and route each private subnet to the NAT Gateway in the same AZ; add VPC endpoints for high-volume AWS services like S3/DynamoDB to reduce NAT usage"
    ],
    "answer": 3,
    "explanation": "One NAT per AZ avoids a single-AZ dependency, improving resilience. Adding VPC endpoints for high-volume AWS services reduces NAT data processing charges and can improve throughput, optimizing overall cost and performance.",
    "difficulty": "Hard",
    "choiceExplanations": {
      "0": "Moving instances to public subnets exposes them directly to the internet, creating significant security risks by removing the network isolation that private subnets provide, and this approach sacrifices security architecture best practices for cost savings.",
      "1": "An Internet Gateway cannot provide outbound internet access for instances in private subnets because private subnets by definition lack routes to the Internet Gateway; instances need public IP addresses and IGW routes to communicate directly with the internet, which would make them public subnets.",
      "2": "NAT Gateways automatically scale up to 100 Gbps and cannot be manually sized, so this option is technically invalid; additionally, keeping a single NAT Gateway maintains the single point of failure and does not address the AZ resilience requirement."
    }
  },
  {
    "id": "SAA-188",
    "domainId": "D4",
    "domain": "Design Cost-Optimized Architectures",
    "section": "DynamoDB",
    "question": "A company uses DynamoDB for an API with a predictable daily traffic pattern: low at night, very high during business hours. They want to minimize cost while avoiding throttling.\nWhich configuration is MOST suitable?",
    "choices": [
      "Move the API data to S3 Standard to reduce costs",
      "Use provisioned capacity with auto scaling (and scheduled scaling if needed) to match predictable peaks and troughs",
      "Fix provisioned capacity at the peak level 24/7",
      "Use on-demand capacity because it is always cheapest"
    ],
    "answer": 1,
    "explanation": "Provisioned capacity with auto scaling (and optionally scheduled scaling) is well suited for predictable patterns, reducing cost during low periods while scaling up during known peaks. On-demand is simpler but may be more expensive for predictable steady usage.",
    "difficulty": "Hard",
    "choiceExplanations": {
      "0": "S3 is an object storage service not designed for low-latency API data access patterns; DynamoDB provides millisecond response times for key-value lookups that S3 cannot match, and this would fundamentally change the application architecture rather than optimize the existing DynamoDB configuration.",
      "2": "Provisioning at peak capacity continuously wastes money during low-traffic periods (nighttime) since you pay for unused capacity; this approach ignores the predictable traffic pattern that could be leveraged for cost optimization through auto scaling.",
      "3": "On-demand capacity is not always cheapest; for predictable, sustained workloads, provisioned capacity with auto scaling is typically more cost-effective since on-demand pricing is approximately 6x higher per request unit than provisioned capacity."
    }
  },
  {
    "id": "SAA-189",
    "domainId": "D4",
    "domain": "Design Cost-Optimized Architectures",
    "section": "S3",
    "question": "A data lake stores raw data in S3. The analytics team needs frequent queries on recent data (last 7 days) and rarely queries older data, but when they do, queries must still work without manual restores.\nThey want to reduce storage cost without breaking analytics workflows.\nWhich S3 storage strategy is MOST appropriate?",
    "choices": [
      "Store all data in EBS volumes attached to an EC2 instance",
      "Delete all data older than 7 days and rely on backups",
      "Move all older data to Glacier Deep Archive after 7 days",
      "Keep recent data in S3 Standard and transition older data to S3 Intelligent-Tiering (with archive tiers if retrieval latency is acceptable) so access remains transparent"
    ],
    "answer": 3,
    "explanation": "Intelligent-Tiering can automatically move objects between access tiers while keeping access transparent to applications, which helps when older data is occasionally queried without requiring manual restore steps (depending on selected tiers and retrieval expectations).",
    "difficulty": "Hard",
    "choiceExplanations": {
      "0": "EBS is block storage designed for EC2 instances, not for data lake architectures. It is significantly more expensive than S3 for large-scale data storage, lacks S3's native integration with analytics services, and doesn't provide the lifecycle management capabilities needed for cost optimization.",
      "1": "This approach breaks the requirement that older data queries must still work without manual restores. Restoring from backups requires manual intervention and would disrupt analytics workflows when historical data is needed.",
      "2": "Glacier Deep Archive requires manual restore operations before data can be accessed, with retrieval times of 12-48 hours. This violates the requirement that queries on older data must work without manual restores, as objects in archive storage classes cannot be directly queried."
    }
  },
  {
    "id": "SAA-190",
    "domainId": "D4",
    "domain": "Design Cost-Optimized Architectures",
    "section": "CloudFront",
    "question": "A company has a global customer base and serves large downloadable installers from an S3 bucket in one region. They pay high data transfer charges from S3 and users far from the region have slow downloads.\nThey want to improve download performance and reduce origin load, with minimal changes.\nWhich solution is MOST suitable?",
    "choices": [
      "Use an ALB in front of S3 to reduce transfer charges",
      "Move the installers to Glacier Deep Archive to reduce cost",
      "Use CloudFront in front of the S3 bucket and cache the installers at edge locations; set appropriate TTLs and enable compression if applicable",
      "Use a NAT Gateway to speed up downloads"
    ],
    "answer": 2,
    "explanation": "CloudFront caches large files at edge locations, improving download performance globally and reducing repeated origin fetches. This can reduce S3 request load and may lower overall cost depending on traffic patterns.",
    "difficulty": "Hard",
    "choiceExplanations": {
      "0": "ALB cannot directly serve as a target for S3 buckets, and even if it could, it would not reduce data transfer charges or improve global performance since it operates in a single region without edge caching capabilities.",
      "1": "Glacier Deep Archive is designed for long-term archival with retrieval times of 12-48 hours, making it completely unsuitable for serving downloadable content to users who need immediate access.",
      "3": "NAT Gateways are used to allow private subnet resources to access the internet, not to improve download speeds for external users accessing S3; they would actually add latency and additional data processing charges."
    }
  },
  {
    "id": "SAA-191",
    "domainId": "D4",
    "domain": "Design Cost-Optimized Architectures",
    "section": "EFS",
    "question": "A company uses Amazon EFS for shared storage. Most files are read only a few times after creation, but must remain instantly accessible when needed.\nThey want to reduce ongoing storage costs without changing the application.\nWhich EFS feature should they use?",
    "choices": [
      "Transition files to S3 Glacier Deep Archive automatically",
      "Disable encryption on EFS to reduce cost",
      "Mount the EFS file system only during business hours",
      "Enable EFS lifecycle management to transition files to EFS Infrequent Access (EFS IA) after a defined period"
    ],
    "answer": 3,
    "explanation": "EFS lifecycle management can move infrequently accessed files into EFS IA automatically, reducing storage cost while keeping the same file system interface and immediate access when needed.",
    "difficulty": "Hard",
    "choiceExplanations": {
      "0": "EFS does not support automatic transitions to S3 Glacier Deep Archive; EFS lifecycle management only transitions files between EFS Standard and EFS Infrequent Access storage classes within the EFS file system, and Glacier Deep Archive does not provide instant access as required.",
      "1": "Encryption on EFS does not incur additional storage costs; EFS encryption is provided at no extra charge, so disabling it would not reduce costs and would compromise data security.",
      "2": "Unmounting EFS does not reduce storage costs since you are still charged for the data stored regardless of whether the file system is mounted; this approach would also prevent instant access when files are needed outside business hours."
    }
  },
  {
    "id": "SAA-192",
    "domainId": "D4",
    "domain": "Design Cost-Optimized Architectures",
    "section": "RDS",
    "question": "A company’s RDS database storage keeps growing. They store large audit records that are never updated and are queried only a few times per year. The production database must stay fast and cost-effective.\nWhich approach is MOST cost-effective long term?",
    "choices": [
      "Store audit records in EC2 instance store for low cost",
      "Archive historical audit records to S3 (for example, in Parquet) and query them with Athena when needed, keeping only recent/hot data in RDS",
      "Keep all audit records in RDS and increase storage indefinitely",
      "Move the entire database to a larger RDS instance type"
    ],
    "answer": 1,
    "explanation": "Keeping rarely accessed historical data in RDS increases cost and can impact performance. Archiving cold data to S3 and querying with Athena is typically more cost-effective for infrequent access while keeping the production database lean.",
    "difficulty": "Hard",
    "choiceExplanations": {
      "0": "EC2 instance store is ephemeral storage that loses all data when the instance stops, terminates, or fails, making it completely unsuitable for storing audit records that must be retained for compliance and occasional querying.",
      "2": "RDS storage is significantly more expensive than S3, and storing rarely accessed data in RDS wastes resources, increases backup times, and can degrade database performance as the dataset grows larger.",
      "3": "Upgrading to a larger instance type increases compute costs but does not address the storage growth problem, and provides no benefit for data that is rarely queried while adding unnecessary expense."
    }
  },
  {
    "id": "SAA-193",
    "domainId": "D4",
    "domain": "Design Cost-Optimized Architectures",
    "section": "Messaging",
    "question": "A company needs to process images uploaded by users. Processing is bursty: huge spikes during events and almost none at other times.\nThey want to minimize cost while ensuring the system can handle spikes without losing requests.\nWhich architecture is MOST cost-effective?",
    "choices": [
      "Run a fixed fleet of EC2 workers 24/7 sized for peak load",
      "Process images synchronously in the upload request path",
      "Use S3 event notifications to an SQS queue and scale workers (Lambda or ECS) based on queue depth; use DLQ for failures",
      "Write all uploads to EBS and poll the disk every minute"
    ],
    "answer": 2,
    "explanation": "Queue-based buffering decouples ingestion from processing, allowing cost-efficient scale-out during spikes and scale-in when idle. A fixed peak-sized fleet wastes money during idle periods, and synchronous processing increases latency and failure risk.",
    "difficulty": "Hard",
    "choiceExplanations": {
      "0": "This approach is highly cost-inefficient because you pay for peak capacity continuously, even during idle periods when there is almost no processing needed, wasting significant resources during non-event times.",
      "1": "Synchronous processing increases latency for users, cannot handle traffic spikes effectively, and risks losing requests if processing fails or times out, making it unsuitable for bursty workloads.",
      "3": "EBS volumes are attached to single EC2 instances limiting scalability, polling introduces latency up to one minute, and this approach lacks the durability, decoupling, and automatic scaling capabilities that SQS provides for handling bursty workloads."
    }
  },
  {
    "id": "SAA-194",
    "domainId": "D4",
    "domain": "Design Cost-Optimized Architectures",
    "section": "Compute",
    "question": "A company runs CI jobs that compile code for 10–20 minutes and then terminate. Jobs are fault-tolerant and can be retried. The team wants the lowest possible compute cost.\nWhich option is MOST suitable?",
    "choices": [
      "Use On-Demand instances only",
      "Use Spot Instances (or Spot capacity in a managed service) with retry handling",
      "Use Dedicated Hosts to get discounts on short jobs",
      "Use 3-year Reserved Instances for all CI jobs"
    ],
    "answer": 1,
    "explanation": "Short-lived, fault-tolerant workloads are ideal for Spot, which can offer deep discounts. Retries handle interruptions. Reserved Instances and Dedicated Hosts are less suitable for highly variable short jobs.",
    "difficulty": "Hard",
    "choiceExplanations": {
      "0": "While On-Demand provides reliable capacity without interruption, it costs significantly more than Spot Instances (up to 90% more), making it unsuitable when the primary goal is lowest possible compute cost for fault-tolerant workloads.",
      "2": "Dedicated Hosts are designed for licensing compliance and regulatory requirements, not cost optimization; they are billed per host regardless of utilization and are the most expensive option, making them inappropriate for short, variable CI jobs.",
      "3": "Reserved Instances require commitment to consistent, predictable usage and provide savings for steady-state workloads; CI jobs running only 10-20 minutes with variable demand would result in significant waste since you pay for reserved capacity whether used or not."
    }
  },
  {
    "id": "SAA-195",
    "domainId": "D4",
    "domain": "Design Cost-Optimized Architectures",
    "section": "S3",
    "question": "A company must keep a large volume of documents for 7 years for compliance. During the first 90 days, documents are accessed infrequently but must be retrieved in milliseconds. After 90 days, documents are almost never accessed and retrieval can take hours.\nThey want the most cost-effective S3 lifecycle plan.\nWhich option BEST meets the requirements?",
    "choices": [
      "Store in S3 One Zone-IA for 90 days then delete",
      "Store in S3 Intelligent-Tiering only and disable archive tiers",
      "Store in S3 Glacier Deep Archive immediately",
      "Store in S3 Standard initially, transition to S3 Standard-IA shortly after creation, and transition to S3 Glacier Deep Archive after 90 days"
    ],
    "answer": 3,
    "explanation": "Standard-IA provides millisecond retrieval for infrequent access during the first 90 days. After 90 days, Deep Archive minimizes cost when hours-level retrieval is acceptable. This lifecycle aligns storage class to access and latency needs over time.",
    "difficulty": "Hard",
    "choiceExplanations": {
      "0": "This violates the 7-year compliance retention requirement by deleting documents after only 90 days, and One Zone-IA lacks the durability of multi-AZ storage classes which may not meet compliance standards for critical documents.",
      "1": "Disabling archive tiers means objects will never move to the lowest-cost archive storage, resulting in higher costs for the 6+ years when documents are rarely accessed and could tolerate hours-long retrieval times.",
      "2": "This fails the requirement for millisecond retrieval during the first 90 days, as Glacier Deep Archive has a minimum retrieval time of 12 hours, making it unsuitable for the initial infrequent access period."
    }
  },
  {
    "id": "SAA-196",
    "domainId": "D3",
    "domain": "Design High-Performing Architectures",
    "section": "EC2",
    "question": "In the instance name m5.2xlarge, what does the “5” represent?",
    "choices": [
      "Network speed tier",
      "Storage type",
      "Instance size",
      "Generation"
    ],
    "answer": 3,
    "explanation": "In EC2 instance naming, the number indicates the instance generation (e.g., m5 is 5th-generation general purpose).",
    "difficulty": "Easy",
    "choiceExplanations": {
      "0": "Network performance in EC2 is determined by the instance size (like xlarge, 2xlarge) and instance family, not by the generation number; the '5' specifically indicates this is a 5th-generation instance.",
      "1": "Storage type is indicated by additional letters in the instance name (such as 'd' for NVMe SSD storage), not by the generation number; the '5' represents the instance generation.",
      "2": "Instance size is represented by the descriptor after the period (2xlarge in this case), which indicates vCPUs and memory; the '5' before the period represents the generation number."
    }
  },
  {
    "id": "SAA-197",
    "domainId": "D3",
    "domain": "Design High-Performing Architectures",
    "section": "EC2",
    "question": "What is an AMI mainly used for?",
    "choices": [
      "Scaling traffic across instances",
      "Attaching a second ENI",
      "Preconfigured image to launch EC2s with OS/software",
      "Long-term object storage"
    ],
    "answer": 2,
    "explanation": "An AMI (Amazon Machine Image) is a template used to launch EC2 instances with a predefined OS and optional software/configuration.",
    "difficulty": "Easy",
    "choiceExplanations": {
      "0": "This describes the function of Elastic Load Balancing (ELB), which distributes incoming application traffic across multiple EC2 instances, not an AMI which is used as a launch template for instances.",
      "1": "Elastic Network Interfaces (ENIs) are virtual network cards that can be attached to EC2 instances for networking purposes, but this is a separate networking feature unrelated to AMIs which define the instance's operating system and software configuration.",
      "3": "This describes Amazon S3 (Simple Storage Service), which provides durable object storage, not an AMI which is specifically a machine image template used to launch EC2 instances."
    }
  },
  {
    "id": "SAA-198",
    "domainId": "D3",
    "domain": "Design High-Performing Architectures",
    "section": "EBS",
    "question": "What happens to a root EBS volume on instance termination by default?",
    "choices": [
      "Moved to another AZ",
      "Snapshotted automatically",
      "Deleted by default",
      "Always kept"
    ],
    "answer": 2,
    "explanation": "By default, the root EBS volume has DeleteOnTermination=true, so it is deleted when the instance is terminated (unless you change that setting).",
    "difficulty": "Easy",
    "choiceExplanations": {
      "0": "EBS volumes are tied to a specific Availability Zone and cannot be moved to another AZ; they can only be recreated in another AZ by restoring from a snapshot.",
      "1": "AWS does not automatically create a snapshot of the root EBS volume upon instance termination; snapshots must be created manually or through automated backup solutions like AWS Backup or Data Lifecycle Manager.",
      "3": "This is incorrect because the default behavior for root EBS volumes is DeleteOnTermination=true, meaning they are deleted when the instance terminates; only additional (non-root) EBS volumes have DeleteOnTermination=false by default."
    }
  },
  {
    "id": "SAA-199",
    "domainId": "D4",
    "domain": "Design Cost-Optimized Architectures",
    "section": "EC2 Pricing",
    "question": "Which purchase option is best for short, unpredictable workloads?",
    "choices": [
      "Savings Plans",
      "Dedicated Hosts",
      "On-Demand",
      "Reserved Instances"
    ],
    "answer": 2,
    "explanation": "On-Demand is best for short-term, spiky, or unpredictable usage because it requires no commitment and you pay only for what you use.",
    "difficulty": "Easy",
    "choiceExplanations": {
      "0": "Requires a 1 or 3-year commitment to a consistent amount of compute usage (measured in $/hour), making it unsuitable for unpredictable workloads that may not utilize the committed spend.",
      "1": "Provides physical servers dedicated to your use for compliance or licensing requirements, involves higher costs and typically hourly or reservation-based billing, not designed for short unpredictable workloads.",
      "3": "Requires a 1 or 3-year commitment in exchange for discounted pricing, which is not cost-effective for short-term or unpredictable workloads that may not run consistently."
    }
  },
  {
    "id": "SAA-200",
    "domainId": "D1",
    "domain": "Design Secure Architectures",
    "section": "IAM",
    "question": "In which ways can a user access AWS?",
    "choices": [
      "SSH, CLI, SDK",
      "AWS Console, SSH, FTP",
      "AWS Console, CLI, SDK",
      "Console only"
    ],
    "answer": 2,
    "explanation": "Users access AWS via the Management Console, AWS CLI, and AWS SDKs/APIs. SSH/FTP are used to access servers (like EC2), not to access AWS services directly.",
    "difficulty": "Easy",
    "choiceExplanations": {
      "0": "SSH is a protocol used to connect to individual resources like EC2 instances, not to access AWS services directly. The AWS Management Console is a primary access method that is missing from this choice.",
      "1": "SSH and FTP are protocols for connecting to servers and transferring files, not methods for accessing AWS services. The CLI and SDK, which are legitimate AWS access methods, are missing from this choice.",
      "3": "This is incomplete because AWS provides three primary access methods: the Management Console, AWS CLI, and AWS SDKs/APIs. Limiting access to console only ignores programmatic access options that are essential for automation and application integration."
    }
  },
  {
    "id": "SAA-201",
    "domainId": "D1",
    "domain": "Design Secure Architectures",
    "section": "IAM",
    "question": "In IAM, where do you usually attach permissions for many users at once?",
    "choices": [
      "To S3 buckets",
      "To passwords",
      "To groups with policies",
      "To VPCs"
    ],
    "answer": 2,
    "explanation": "Best practice is to attach policies to IAM groups (or roles) and then add users to groups, so you manage permissions at scale.",
    "difficulty": "Easy",
    "choiceExplanations": {
      "0": "S3 bucket policies control access to specific S3 resources, not IAM user permissions; they are resource-based policies attached to buckets, not a mechanism for managing permissions across many IAM users at once.",
      "1": "Passwords are authentication credentials used to verify user identity, not authorization mechanisms; you cannot attach permissions or policies to passwords in IAM.",
      "3": "VPCs are networking constructs that define isolated virtual networks in AWS; they do not have IAM policies attached to them and are not used to manage user permissions."
    }
  },
  {
    "id": "SAA-202",
    "domainId": "D1",
    "domain": "Design Secure Architectures",
    "section": "VPC",
    "question": "By default, a Security Group allows:",
    "choices": [
      "All inbound and all outbound",
      "Blocks all inbound and outbound",
      "Blocks all inbound and allows all outbound",
      "All inbound and blocks all outbound"
    ],
    "answer": 2,
    "explanation": "A new security group starts with no inbound rules (so inbound is blocked) and an allow-all outbound rule (so outbound is allowed).",
    "difficulty": "Easy",
    "choiceExplanations": {
      "0": "This is incorrect because by default, security groups do NOT allow all inbound traffic. A new security group has no inbound rules, meaning all inbound traffic is denied by default following the principle of least privilege.",
      "1": "This is incorrect because while inbound traffic is blocked by default, outbound traffic is NOT blocked. A new security group includes a default outbound rule that allows all outbound traffic to all destinations.",
      "3": "This is the exact opposite of the actual default behavior. Security groups block all inbound traffic by default (no inbound rules) and allow all outbound traffic by default (default outbound rule permits all traffic)."
    }
  },
  {
    "id": "SAA-203",
    "domainId": "D3",
    "domain": "Design High-Performing Architectures",
    "section": "EC2 Networking",
    "question": "Your EC2 public IP keeps changing after stop/start. What’s the simple AWS feature to keep a fixed public IPv4?",
    "choices": [
      "Private IP",
      "Elastic IP",
      "Route 53 Alias",
      "NAT Gateway"
    ],
    "answer": 1,
    "explanation": "An Elastic IP (EIP) is a static public IPv4 address you can allocate and associate to an instance (or other resources). It stays the same across stop/start as long as it remains allocated to you.",
    "difficulty": "Easy",
    "choiceExplanations": {
      "0": "Private IP addresses are internal to the VPC and cannot be used for public internet connectivity; they are not routable over the internet and therefore cannot serve as a fixed public IPv4 address.",
      "2": "Route 53 Alias records are DNS routing mechanisms that point to AWS resources, but they don't provide a static IP address; they would still resolve to the changing public IP unless combined with an Elastic IP.",
      "3": "NAT Gateway enables outbound internet connectivity for instances in private subnets, but it doesn't provide a fixed public IP address directly to an EC2 instance; it's used for private subnet resources to access the internet, not for inbound public access to instances."
    }
  },
  {
    "id": "SAA-204",
    "domainId": "D3",
    "domain": "Design High-Performing Architectures",
    "section": "Storage",
    "question": "EBS vs EFS — which pairing is MOST accurate?",
    "choices": [
      "EBS: single instance / AZ-scoped; EFS: multi-AZ, many instances",
      "Both are multi-AZ, many instances",
      "EBS: multi-AZ, many instances; EFS: single instance only",
      "Both are single-instance only"
    ],
    "answer": 0,
    "explanation": "EBS is block storage that is scoped to a single Availability Zone and typically attached to one instance (with limited exceptions like Multi-Attach within the same AZ). EFS is a regional, multi-AZ file system that can be mounted by many instances concurrently.",
    "difficulty": "Medium",
    "choiceExplanations": {
      "1": "This is incorrect because EBS volumes are scoped to a single Availability Zone and cannot span multiple AZs. While EBS Multi-Attach allows multiple instances to connect, this is limited to instances within the same AZ, unlike EFS which is truly multi-AZ.",
      "2": "This reverses the actual characteristics of both services. EBS is AZ-scoped (not multi-AZ), while EFS is specifically designed as a shared file system that supports thousands of concurrent connections across multiple AZs.",
      "3": "This is incorrect because EFS is designed for concurrent access from multiple EC2 instances across multiple Availability Zones. Additionally, EBS supports Multi-Attach for Provisioned IOPS volumes, allowing attachment to multiple instances within the same AZ."
    }
  },
  {
    "id": "SAA-205",
    "domainId": "D3",
    "domain": "Design High-Performing Architectures",
    "section": "EC2",
    "question": "EC2 User Data scripts run…",
    "choices": [
      "Every hour",
      "Every time the instance reboots",
      "After the instance is terminated",
      "Once, at the first start of the instance"
    ],
    "answer": 3,
    "explanation": "By default, EC2 user data runs only on the first boot/first launch of the instance (unless you build custom logic to run it again).",
    "difficulty": "Easy",
    "choiceExplanations": {
      "0": "EC2 User Data is not a scheduled task or cron job; it is a bootstrap script that executes during the instance launch process, not on a recurring hourly basis.",
      "1": "By default, User Data scripts only run on the initial boot of the instance, not on subsequent reboots or stop/start cycles, unless you explicitly configure the script to run on every boot using cloud-init directives.",
      "2": "Once an instance is terminated, it no longer exists and cannot execute any scripts; User Data runs during the instance launch phase when the instance is starting, not after termination."
    }
  },
  {
    "id": "SAA-206",
    "domainId": "D3",
    "domain": "Design High-Performing Architectures",
    "section": "ELB",
    "question": "Your application runs on EC2 instances in two AZs. You need a managed service to distribute incoming HTTP/HTTPS traffic across all instances. What should you use?",
    "choices": [
      "Application Load Balancer",
      "Amazon Route 53",
      "Classic Load Balancer",
      "Network Load Balancer"
    ],
    "answer": 0,
    "explanation": "An Application Load Balancer (ALB) is designed for HTTP/HTTPS (Layer 7) traffic, supports advanced routing (host/path rules), and can distribute requests across targets in multiple AZs.",
    "difficulty": "Easy",
    "choiceExplanations": {
      "1": "Route 53 is a DNS service that routes users to endpoints based on DNS queries, not a load balancer that distributes traffic across EC2 instances at the application layer.",
      "2": "While Classic Load Balancer can handle HTTP/HTTPS traffic, it is a previous generation load balancer that AWS recommends migrating away from in favor of Application Load Balancer, which offers more advanced Layer 7 features.",
      "3": "Network Load Balancer operates at Layer 4 (TCP/UDP) and is optimized for extreme performance and static IP addresses, but lacks the Layer 7 HTTP/HTTPS-specific features like path-based routing that ALB provides."
    }
  },
  {
    "id": "SAA-207",
    "domainId": "D2",
    "domain": "Design Resilient Architectures",
    "section": "ELB",
    "question": "You have an ALB with targets in multiple AZs. One instance fails its health checks. What will the ALB do?",
    "choices": [
      "Terminate the instance and launch a new one",
      "Continue sending some traffic until all instances are unhealthy",
      "Automatically resize the instance type",
      "Stop sending traffic to the unhealthy instance"
    ],
    "answer": 3,
    "explanation": "An ALB uses health checks to determine target health. If a target becomes unhealthy, the ALB stops routing traffic to it. (Replacing/terminating instances is the job of Auto Scaling, not the ALB.)",
    "difficulty": "Easy",
    "choiceExplanations": {
      "0": "This is incorrect because terminating and replacing instances is the responsibility of Auto Scaling, not the ALB. The ALB only performs health checks and routes traffic; it has no capability to manage EC2 instance lifecycle.",
      "1": "This is incorrect because ALB immediately stops routing new requests to targets that fail health checks. The ALB does not continue sending traffic to unhealthy targets; it only routes to healthy targets in the target group.",
      "2": "This is incorrect because ALB has no capability to modify EC2 instance configurations. Resizing instances would require stopping the instance and changing its type, which is an EC2 management function completely outside the scope of load balancer functionality."
    }
  },
  {
    "id": "SAA-208",
    "domainId": "D2",
    "domain": "Design Resilient Architectures",
    "section": "Auto Scaling",
    "question": "Which option BEST describes how an Auto Scaling Group (ASG) works?",
    "choices": [
      "Manually starts EC2 instances on a fixed schedule only",
      "Is used only with Spot Instances",
      "Only replaces unhealthy instances but never changes capacity",
      "Automatically adds or removes EC2 instances based on policies and health checks"
    ],
    "answer": 3,
    "explanation": "An Auto Scaling Group maintains desired capacity and can scale out/in automatically using scaling policies (for example, CPU-based) and can also replace unhealthy instances based on health checks.",
    "difficulty": "Easy",
    "choiceExplanations": {
      "0": "This is incorrect because Auto Scaling Groups operate automatically, not manually, and while scheduled scaling is one option, ASGs primarily use dynamic scaling policies based on metrics like CPU utilization, not just fixed schedules.",
      "1": "This is incorrect because Auto Scaling Groups can work with On-Demand Instances, Spot Instances, Reserved Instances, or a combination of purchase options through mixed instances policies.",
      "2": "This is incorrect because while ASGs do replace unhealthy instances to maintain desired capacity, they also actively scale capacity up or down based on scaling policies, scheduled actions, or manual adjustments to meet demand."
    }
  },
  {
    "id": "SAA-209",
    "domainId": "D2",
    "domain": "Design Resilient Architectures",
    "section": "Auto Scaling",
    "question": "You configure an ASG with Min=2, Max=6, Desired=3. A scaling policy adds 2 instances when CPU > 70%. What happens on the first scale-out event?",
    "choices": [
      "ASG will have 6 instances",
      "ASG will have 4 instances",
      "ASG will have 5 instances",
      "ASG will have 3 instances"
    ],
    "answer": 2,
    "explanation": "The ASG starts at Desired=3. On the first scale-out event, the policy adds 2 instances, bringing it to 5 total. This is within Max=6, so it scales to 5.",
    "difficulty": "Easy",
    "choiceExplanations": {
      "0": "This is incorrect because the scaling policy adds exactly 2 instances to the current desired capacity of 3, resulting in 5 instances, not the maximum of 6. The Max setting is a ceiling limit, not a target.",
      "1": "This is incorrect because the scaling policy is configured to add 2 instances, not 1. Starting from Desired=3 and adding 2 instances results in 5 instances, not 4.",
      "3": "This is incorrect because when the CPU threshold of 70% is breached, the scaling policy executes and adds 2 instances. The ASG does not remain at 3 instances; it scales out as configured."
    }
  },
  {
    "id": "SAA-210",
    "domainId": "D3",
    "domain": "Design High-Performing Architectures",
    "section": "ELB",
    "question": "You need extremely high performance TCP traffic handling with static IPs per AZ. Which load balancer should you choose?",
    "choices": [
      "Network Load Balancer",
      "Classic Load Balancer",
      "Application Load Balancer",
      "Gateway Load Balancer"
    ],
    "answer": 0,
    "explanation": "A Network Load Balancer (NLB) operates at Layer 4 (TCP/UDP/TLS), supports very high throughput and low latency, and provides static IP addresses per Availability Zone (or you can use Elastic IPs).",
    "difficulty": "Medium",
    "choiceExplanations": {
      "1": "While CLB supports TCP traffic at Layer 4, it does not provide static IP addresses per AZ and offers lower performance compared to NLB, making it unsuitable for extremely high performance requirements.",
      "2": "ALB operates at Layer 7 (HTTP/HTTPS) and does not support raw TCP traffic handling; it also does not provide static IP addresses per AZ, using DNS names instead.",
      "3": "GWLB is designed for deploying and managing third-party virtual network appliances (like firewalls and intrusion detection systems), not for general-purpose high-performance TCP traffic load balancing to applications."
    }
  },
  {
    "id": "SAA-211",
    "domainId": "D2",
    "domain": "Design Resilient Architectures",
    "section": "RDS",
    "question": "Your production MySQL database on RDS must have automatic failover to another AZ with minimal changes to your application endpoint. What should you enable?",
    "choices": [
      "RDS Multi-AZ deployment",
      "RDS Read Replica in the same AZ",
      "Store data only on EBS attached to EC2",
      "RDS snapshot every hour"
    ],
    "answer": 0,
    "explanation": "RDS Multi-AZ provides synchronous replication to a standby in a different AZ and supports automatic failover. The DB endpoint remains the same, so application changes are minimal. Read replicas are mainly for read scaling and are not the primary HA/failover mechanism.",
    "difficulty": "Medium",
    "choiceExplanations": {
      "1": "Read Replicas are designed for read scaling using asynchronous replication, not automatic failover, and placing one in the same AZ provides no protection against AZ failure as required by the question.",
      "2": "This approach requires manual database management without built-in automatic failover capabilities, and EBS volumes are AZ-specific, meaning they cannot automatically failover to another AZ without significant application changes.",
      "3": "Snapshots are point-in-time backups stored in S3 that require manual restoration to recover, which does not provide automatic failover and would result in up to an hour of data loss plus recovery time."
    }
  },
  {
    "id": "SAA-212",
    "domainId": "D2",
    "domain": "Design Resilient Architectures",
    "section": "Aurora",
    "question": "Which statement about Amazon Aurora is MOST accurate?",
    "choices": [
      "Aurora automatically replicates data across multiple AZs",
      "Aurora has no separation between writer and reader",
      "Aurora supports only one AZ",
      "Aurora is only for key-value workloads"
    ],
    "answer": 0,
    "explanation": "Amazon Aurora is a relational database compatible with MySQL/PostgreSQL and is designed for high availability by replicating data across multiple Availability Zones in a region. It supports a writer instance and multiple reader instances for read scaling.",
    "difficulty": "Medium",
    "choiceExplanations": {
      "1": "Aurora clearly separates writer and reader instances, supporting one primary writer instance and up to 15 read replicas that can be used for read scaling and failover purposes.",
      "2": "Aurora automatically replicates data six ways across three Availability Zones within a region, providing high availability and durability by design.",
      "3": "Aurora is a relational database engine compatible with MySQL and PostgreSQL, designed for traditional relational workloads with SQL support, not key-value workloads which are better suited for DynamoDB."
    }
  },
  {
    "id": "SAA-213",
    "domainId": "D3",
    "domain": "Design High-Performing Architectures",
    "section": "ElastiCache",
    "question": "You want to reduce read load on your RDS database by caching frequently accessed session data in memory. Which AWS service is the BEST fit?",
    "choices": [
      "Amazon S3",
      "AWS Lambda",
      "Amazon EFS",
      "Amazon ElastiCache"
    ],
    "answer": 3,
    "explanation": "Amazon ElastiCache (Redis or Memcached) is an in-memory caching service that reduces database load and improves latency for frequently accessed data like sessions, tokens, or hot reads.",
    "difficulty": "Easy",
    "choiceExplanations": {
      "0": "S3 is an object storage service designed for durability and scalability, not for low-latency in-memory caching; it has higher latency compared to in-memory solutions and is not optimized for frequent read/write operations typical of session data.",
      "1": "Lambda is a serverless compute service for running code in response to events, not a caching or data storage service; it cannot store or cache data persistently between invocations.",
      "2": "EFS is a managed file storage service that provides shared file system access across EC2 instances, but it uses disk-based storage rather than in-memory caching, resulting in higher latency than ElastiCache for session data caching."
    }
  },
  {
    "id": "SAA-214",
    "domainId": "D3",
    "domain": "Design High-Performing Architectures",
    "section": "ElastiCache",
    "question": "You need a simple in-memory cache with multiple nodes, no persistence, and easy horizontal scaling. Which ElastiCache engine is MOST suitable?",
    "choices": [
      "Amazon Aurora MySQL",
      "Redis",
      "Amazon DynamoDB",
      "Memcached"
    ],
    "answer": 3,
    "explanation": "Memcached is a simple, distributed in-memory cache designed for ease of horizontal scaling and does not provide persistence. Redis supports more advanced data structures and can provide persistence/replication, but for a simple non-persistent cache, Memcached is the better fit.",
    "difficulty": "Medium",
    "choiceExplanations": {
      "0": "Aurora is a relational database service designed for persistent storage with ACID compliance, not an in-memory caching solution, making it unsuitable for simple caching requirements.",
      "1": "While Redis is an ElastiCache engine, it provides advanced features like persistence, replication, and complex data structures that add unnecessary complexity when only simple, non-persistent caching with horizontal scaling is needed.",
      "2": "DynamoDB is a fully managed NoSQL database service with persistent storage, not an in-memory cache, and while it offers DAX for caching, the base service itself is not designed as a simple in-memory caching solution."
    }
  },
  {
    "id": "SAA-215",
    "domainId": "D2",
    "domain": "Design Resilient Architectures",
    "section": "Architecture",
    "question": "An app runs behind an ALB with an ASG and uses RDS Multi-AZ plus ElastiCache. Which statement BEST describes this architecture?",
    "choices": [
      "It guarantees zero downtime in all failure scenarios",
      "It only improves security, not availability",
      "It removes the need for backups",
      "It is designed for high availability and scalability"
    ],
    "answer": 3,
    "explanation": "ALB + ASG provides scalable and fault-tolerant compute across AZs. RDS Multi-AZ adds database high availability with automatic failover. ElastiCache improves read performance and can reduce DB load. Together this architecture is designed for high availability and scalability, but it doesn’t guarantee zero downtime in every scenario and it does not eliminate the need for backups.",
    "difficulty": "Medium",
    "choiceExplanations": {
      "0": "No architecture can guarantee zero downtime in all scenarios; RDS Multi-AZ failover typically takes 60-120 seconds, and even with ALB and ASG, there can be brief interruptions during instance replacements or AZ failures.",
      "1": "This is incorrect because ALB distributes traffic across multiple targets, ASG maintains desired capacity and replaces unhealthy instances, RDS Multi-AZ provides automatic database failover, and ElastiCache reduces database load - all of which directly improve availability, not just security.",
      "2": "High availability is not a substitute for backups; Multi-AZ provides failover protection but does not protect against data corruption, accidental deletion, or logical errors - automated backups and snapshots are still essential for point-in-time recovery and disaster recovery."
    }
  },
  {
    "id": "SAA-216",
    "domainId": "D2",
    "domain": "Design Resilient Architectures",
    "section": "Route 53",
    "question": "You need to map the root domain example.com to an Application Load Balancer. What should you create in Route 53?",
    "choices": [
      "Alias A record pointing to the ALB",
      "CNAME record pointing to the ALB DNS name",
      "NS record pointing to the ALB",
      "Simple routing policy with the ALB’s IPs"
    ],
    "answer": 0,
    "explanation": "Route 53 does not allow a CNAME at the zone apex (root domain). To point example.com to an ALB, you create an Alias A record to the ALB DNS name. Alias records work at the apex and don’t require hardcoding IPs.",
    "difficulty": "Medium",
    "choiceExplanations": {
      "1": "DNS standards prohibit CNAME records at the zone apex (root domain like example.com) because CNAME records cannot coexist with other record types, and the apex must have SOA and NS records.",
      "2": "NS (Name Server) records are used to delegate DNS authority to name servers, not to point domains to application resources like load balancers.",
      "3": "Simple routing policy with the ALB's IPs: ALB IP addresses are dynamic and can change over time, so hardcoding them in A records would cause failures when AWS changes the underlying infrastructure; Alias records automatically resolve to current ALB IPs."
    }
  },
  {
    "id": "SAA-217",
    "domainId": "D2",
    "domain": "Design Resilient Architectures",
    "section": "Route 53",
    "question": "You want to send 20% of traffic to a new version and 80% to the old one, both behind different target groups. Which policy fits best?",
    "choices": [
      "Geolocation",
      "Simple",
      "Weighted",
      "Latency-based"
    ],
    "answer": 2,
    "explanation": "Weighted routing lets you split traffic across multiple records by percentage using weights (for example, 20/80). This is commonly used for gradual rollouts and A/B testing.",
    "difficulty": "Medium",
    "choiceExplanations": {
      "0": "This routing policy directs traffic based on the geographic location of users (continent, country, or state), not by percentage distribution, so it cannot split traffic 20/80 between versions.",
      "1": "This routing policy returns all values in random order to the client and does not support traffic weighting or percentage-based distribution between multiple endpoints.",
      "3": "This routing policy routes traffic to the AWS region that provides the lowest latency for the user, but it does not allow you to specify percentage-based traffic distribution between different target groups."
    }
  },
  {
    "id": "SAA-218",
    "domainId": "D2",
    "domain": "Design Resilient Architectures",
    "section": "Route 53",
    "question": "You run active–passive across two endpoints. If the primary fails health checks, traffic must move to standby automatically. What should you use?",
    "choices": [
      "Failover routing with health checks",
      "Geoproximity routing",
      "Latency-based routing",
      "Multi-Value Answer"
    ],
    "answer": 0,
    "explanation": "Failover routing is built for active-passive setups. You configure primary and secondary records and associate health checks so Route 53 routes traffic to the secondary endpoint when the primary fails.",
    "difficulty": "Medium",
    "choiceExplanations": {
      "1": "This routing policy directs traffic based on the geographic location of users and resources, with optional bias adjustments, but it is not designed for active-passive failover scenarios between a primary and standby endpoint.",
      "2": "This routing policy directs users to the AWS region with the lowest network latency, which is useful for performance optimization across multiple active endpoints but does not provide automatic failover from a primary to a secondary standby endpoint.",
      "3": "This routing policy returns multiple healthy records randomly selected (up to 8), functioning more like a simple load balancing mechanism across multiple active resources rather than providing the active-passive failover behavior required in this scenario."
    }
  },
  {
    "id": "SAA-219",
    "domainId": "D2",
    "domain": "Design Resilient Architectures",
    "section": "Route 53",
    "question": "You want EU visitors routed to eu-west-1 even if another region is currently lower latency for some users. Which policy?",
    "choices": [
      "Latency-based",
      "Geolocation",
      "Multi-Value Answer",
      "Weighted"
    ],
    "answer": 1,
    "explanation": "Geolocation routing routes users based on the geographic location of their DNS resolvers (for example, Europe to eu-west-1). It is chosen when you want location-based control, not “best latency.”",
    "difficulty": "Medium",
    "choiceExplanations": {
      "0": "This policy routes users to the region with the lowest network latency, which directly contradicts the requirement to always route EU visitors to eu-west-1 regardless of latency measurements.",
      "2": "This policy returns multiple healthy IP addresses in random order for load distribution and health checking, but provides no geographic or location-based routing control to ensure EU users reach eu-west-1.",
      "3": "This policy distributes traffic across resources based on assigned weight ratios, but cannot guarantee that EU visitors are specifically routed to eu-west-1 since it does not consider user location."
    }
  },
  {
    "id": "SAA-220",
    "domainId": "D2",
    "domain": "Design Resilient Architectures",
    "section": "Route 53",
    "question": "Your app runs on several EC2 instances with public IPs. You don’t need L7 features, just simple DNS returning several healthy IPs. Which policy?",
    "choices": [
      "Latency-based",
      "Geoproximity",
      "Failover",
      "Multi-Value Answer"
    ],
    "answer": 3,
    "explanation": "Multi-Value Answer routing returns multiple values (IPs) for a record and can be associated with health checks to return only healthy endpoints. It’s a simple way to do basic DNS-based load distribution without advanced routing logic.",
    "difficulty": "Medium",
    "choiceExplanations": {
      "0": "This routing policy directs traffic to the region with the lowest latency for the user, but it returns only one IP address per query rather than multiple healthy IPs as required by the scenario.",
      "1": "This routing policy routes traffic based on the geographic location of resources and users with optional bias adjustments, but it doesn't return multiple IP addresses in a single DNS response for simple load distribution.",
      "2": "This routing policy is designed for active-passive configurations where traffic goes to a primary resource and fails over to a secondary only when the primary is unhealthy, returning only one IP at a time rather than multiple healthy IPs."
    }
  },
  {
    "id": "SAA-221",
    "domainId": "D3",
    "domain": "Design High-Performing Architectures",
    "section": "Route 53",
    "question": "You’re hosting a static website directly on S3 and want example.com to resolve to it. What Route 53 record do you need?",
    "choices": [
      "AAAA record to the bucket",
      "Alias A record to the ALB",
      "Alias A record to the S3 website endpoint",
      "CNAME to the S3 REST endpoint"
    ],
    "answer": 2,
    "explanation": "For an S3 static website, you use the S3 **website endpoint** (not the REST endpoint). To map the root domain (example.com), create an Alias A record pointing to the S3 website endpoint so it works at the zone apex.",
    "difficulty": "Medium",
    "choiceExplanations": {
      "0": "AAAA records are used for IPv6 addresses, and S3 buckets cannot be directly referenced with standard DNS records; you need an Alias record to point to S3 website endpoints, and this would not resolve the bucket correctly.",
      "1": "This is incorrect because the scenario describes hosting directly on S3, not using an Application Load Balancer; there is no ALB involved in a static S3 website hosting configuration.",
      "3": "CNAME records cannot be used at the zone apex (example.com), and the S3 REST endpoint is used for API access, not for serving static website content which requires the S3 website endpoint."
    }
  },
  {
    "id": "SAA-222",
    "domainId": "D2",
    "domain": "Design Resilient Architectures",
    "section": "S3",
    "question": "Which statement about S3 Versioning is most accurate?",
    "choices": [
      "It automatically replicates objects across regions",
      "It’s required only for Glacier usage",
      "It can be turned on and fully turned off with all old versions deleted automatically",
      "It can be enabled and later suspended; past versions remain, helping recover deletes/overwrites."
    ],
    "answer": 3,
    "explanation": "S3 versioning can be enabled and later suspended, but it cannot be fully “disabled” back to a never-versioned state. Existing versions remain and help recover from accidental deletes/overwrites. Replication across regions is a separate feature (CRR).",
    "difficulty": "Medium",
    "choiceExplanations": {
      "0": "S3 Versioning does not replicate objects across regions; cross-region replication (CRR) is a separate feature that requires versioning to be enabled but must be explicitly configured.",
      "1": "It's required only for Glacier usage: Versioning is not required for S3 Glacier storage class usage; objects can be transitioned to Glacier via lifecycle policies without versioning enabled, though versioning is required for features like Cross-Region Replication.",
      "2": "Once versioning is enabled on a bucket, it cannot be fully disabled back to an unversioned state; it can only be suspended, and existing versions are retained until explicitly deleted."
    }
  },
  {
    "id": "SAA-223",
    "domainId": "D2",
    "domain": "Design Resilient Architectures",
    "section": "S3",
    "question": "You need Cross-Region Replication (CRR) from us-east-1 to eu-west-1. What is a hard prerequisite?",
    "choices": [
      "A lifecycle rule to transition objects to IA",
      "Versioning enabled on both source and destination",
      "Object Lock enabled on both buckets",
      "Default bucket encryption enabled"
    ],
    "answer": 1,
    "explanation": "Cross-Region Replication requires versioning to be enabled on both the source and destination buckets. Without versioning, CRR cannot replicate objects.",
    "difficulty": "Medium",
    "choiceExplanations": {
      "0": "Lifecycle rules are completely independent of Cross-Region Replication and are used to manage object storage class transitions or expiration, not for enabling replication functionality.",
      "2": "Object Lock is an optional feature for WORM (Write Once Read Many) compliance and data protection; it is not a prerequisite for CRR, though if the source bucket has Object Lock enabled, the destination must also have it enabled.",
      "3": "Bucket encryption is an optional security feature that encrypts objects at rest; CRR can replicate objects regardless of whether default encryption is enabled on either bucket."
    }
  },
  {
    "id": "SAA-224",
    "domainId": "D4",
    "domain": "Design Cost-Optimized Architectures",
    "section": "S3",
    "question": "You store objects that are rarely accessed but must be retrieved in milliseconds when needed. You are ok with a single AZ to cut costs. Which storage class?",
    "choices": [
      "S3 Glacier Instant Retrieval",
      "S3 One Zone-IA",
      "S3 Standard",
      "S3 Standard-IA"
    ],
    "answer": 1,
    "explanation": "S3 One Zone-IA is designed for infrequently accessed data with millisecond access, stored in a single Availability Zone at a lower cost than Standard-IA. This matches the requirement for rare access, millisecond retrieval, and cost savings by using one AZ.",
    "difficulty": "Medium",
    "choiceExplanations": {
      "0": "While this class provides millisecond retrieval for rarely accessed data at lower cost than Standard-IA, it stores data across multiple Availability Zones, so it doesn't meet the requirement of accepting single-AZ storage to reduce costs further.",
      "2": "This storage class is designed for frequently accessed data and stores objects across multiple AZs, making it more expensive than necessary for rarely accessed data where single-AZ storage is acceptable.",
      "3": "While this class is designed for infrequently accessed data with millisecond retrieval, it stores data redundantly across multiple Availability Zones, which costs more than One Zone-IA when single-AZ storage is acceptable."
    }
  },
  {
    "id": "SAA-225",
    "domainId": "D4",
    "domain": "Design Cost-Optimized Architectures",
    "section": "S3",
    "question": "You have tens of millions of objects with unpredictable access patterns. You want automatic cost optimization without changing the app, millisecond retrieval when accessed again, and no retrieval fees. Which storage class is best?",
    "choices": [
      "S3 Glacier Instant Retrieval",
      "S3 One Zone-IA",
      "S3 Intelligent-Tiering",
      "S3 Standard-IA"
    ],
    "answer": 2,
    "explanation": "S3 Intelligent-Tiering automatically moves objects between access tiers based on usage, requires no application changes, keeps millisecond retrieval, and does not charge retrieval fees (it charges a small monitoring/automation fee). This matches the requirements for unpredictable access at very large scale.",
    "difficulty": "Hard",
    "choiceExplanations": {
      "0": "While it provides millisecond retrieval, it charges per-GB retrieval fees and requires manual lifecycle policies rather than automatic optimization based on access patterns, making it unsuitable for unpredictable access workloads.",
      "1": "This class charges retrieval fees, does not automatically optimize costs based on access patterns, and stores data in only one Availability Zone reducing durability, requiring manual lifecycle management for cost optimization.",
      "3": "This class charges retrieval fees per GB retrieved and does not automatically move objects between tiers based on access patterns, requiring manual lifecycle policies to optimize costs for unpredictable workloads."
    }
  },
  {
    "id": "SAA-226",
    "domainId": "D4",
    "domain": "Design Cost-Optimized Architectures",
    "section": "S3",
    "question": "You host a public dataset in S3 and want downloaders to pay request and data-transfer costs while you continue paying for storage. What should you enable?",
    "choices": [
      "S3 Transfer Acceleration",
      "S3 Access Points with VPC restriction",
      "Bucket ACLs granting Everyone: READ",
      "Requester Pays"
    ],
    "answer": 3,
    "explanation": "Enable S3 Requester Pays so the requester (downloader) is charged for request and data transfer costs, while the bucket owner continues to pay for storage.",
    "difficulty": "Medium",
    "choiceExplanations": {
      "0": "This feature speeds up data transfers to and from S3 using CloudFront edge locations, but it does not shift costs to the requester - the bucket owner still pays for all request and data transfer charges plus additional acceleration fees.",
      "1": "Access Points simplify managing access to shared datasets and can restrict access to specific VPCs, but they do not change the billing model - the bucket owner still pays for requests and data transfer costs.",
      "2": "This grants public read access to the bucket contents, but it does not shift the cost burden - the bucket owner would still be responsible for paying all request and data transfer costs incurred by downloaders."
    }
  },
  {
    "id": "SAA-227",
    "domainId": "D3",
    "domain": "Design High-Performing Architectures",
    "section": "S3",
    "question": "You must apply a new tag to 50 million existing objects across several buckets, and get a progress report. what is the easiest native option?",
    "choices": [
      "S3 Batch Operations with a manifest",
      "S3 Storage Lens",
      "AWS Glue crawler + Lambda per object",
      "Parallel PutObjectTagging from a custom script"
    ],
    "answer": 0,
    "explanation": "S3 Batch Operations is designed for large-scale object operations (like tagging) across millions or billions of objects. You provide a manifest of objects and get a job progress/completion report. This is the most native and operationally simple option compared to running custom scripts.",
    "difficulty": "Hard",
    "choiceExplanations": {
      "1": "This is an analytics and reporting service that provides visibility into storage usage and activity trends across your S3 buckets, but it cannot modify objects or apply tags - it is read-only for metrics and insights.",
      "2": "While technically possible, this approach is overly complex and not designed for this use case - Glue crawlers are meant for data cataloging, and invoking Lambda per object for 50 million objects would be extremely slow, expensive, and operationally difficult to manage.",
      "3": "While this could work, it requires significant custom development, infrastructure management, error handling, and retry logic - it is not a native AWS managed solution and lacks built-in progress reporting compared to S3 Batch Operations."
    }
  },
  {
    "id": "SAA-228",
    "domainId": "D1",
    "domain": "Design Secure Architectures",
    "section": "S3",
    "question": "Security requires all new objects be encrypted with your KMS CMK. How do you enforce it?",
    "choices": [
      "Turn on default encryption SSE-S3",
      "Use ACLs to deny unencrypted uploads",
      "Enable Object Lock in Compliance mode",
      "Bucket policy that allows s3:PutObject only when s3:x-amz-server-side-encryption = aws:kms and s3:x-amz-server-side-encryption-aws-kms-key-id = your CMK"
    ],
    "answer": 3,
    "explanation": "Default encryption helps, but enforcement is done with a bucket policy. You can require that PutObject requests specify SSE-KMS and the exact KMS key ID (your CMK). If the request doesn't include these headers/values, the upload is denied, guaranteeing all new objects use your CMK.",
    "difficulty": "Hard",
    "choiceExplanations": {
      "0": "This uses Amazon S3-managed keys (SSE-S3), not your KMS CMK as required, and default encryption only applies when no encryption is specified in the request - it does not enforce or prevent uploads with different encryption methods.",
      "1": "S3 ACLs control access permissions (read/write) for accounts and groups, not encryption requirements - they cannot evaluate or enforce encryption headers on upload requests.",
      "2": "Object Lock prevents objects from being deleted or overwritten for a retention period (WORM protection), but it has no relationship to encryption and cannot enforce encryption requirements on uploaded objects."
    }
  },
  {
    "id": "SAA-229",
    "domainId": "D1",
    "domain": "Design Secure Architectures",
    "section": "S3",
    "question": "A web app at https://app.example.com must use JavaScript to PUT/GET objects in https://my-bucket.s3.amazonaws.com. Requests are blocked by the browser. What must you configure?",
    "choices": [
      "CloudTrail data events",
      "Bucket ACLs for Everyone: WRITE",
      "S3 CORS rules allowing the app origin and required methods/headers",
      "Pre-signed URLs only"
    ],
    "answer": 2,
    "explanation": "Browser-based cross-origin requests require the bucket to allow the origin and HTTP methods via CORS. Configure S3 CORS to allow https://app.example.com and the required methods (GET/PUT) and headers so the browser permits the requests.",
    "difficulty": "Medium",
    "choiceExplanations": {
      "0": "CloudTrail data events are used for logging and auditing S3 object-level API activity, not for enabling cross-origin access; they have no effect on browser CORS restrictions.",
      "1": "Bucket ACLs control authorization permissions for who can access the bucket, but they do not address browser-enforced CORS policies; additionally, granting public write access creates a serious security vulnerability.",
      "3": "Pre-signed URLs provide temporary authenticated access to S3 objects but do not solve CORS issues; the browser will still block cross-origin requests unless the S3 bucket has proper CORS configuration to include the required response headers."
    }
  },
  {
    "id": "SAA-230",
    "domainId": "D1",
    "domain": "Design Secure Architectures",
    "section": "S3",
    "question": "Your records must be immutable for 7 years to meet regulatory WORM requirements and prevent privileged users from deletion or alteration. Which feature can handle this requirement?",
    "choices": [
      "S3 Lifecycle with Glacier Deep Archive",
      "S3 Object Lock in Compliance mode",
      "Glacier Vault Lock only",
      "S3 Versioning alone"
    ],
    "answer": 1,
    "explanation": "S3 Object Lock in Compliance mode enforces WORM retention so objects cannot be deleted or overwritten until the retention period expires, even by root or administrators. Versioning alone does not prevent deletion, and lifecycle policies are for transitions/expiration, not enforcement of immutability.",
    "difficulty": "Hard",
    "choiceExplanations": {
      "0": "Lifecycle policies automate transitioning objects to cheaper storage classes and setting expiration dates, but they do not enforce immutability or prevent privileged users from deleting or modifying objects during the retention period.",
      "2": "While Glacier Vault Lock does provide WORM compliance for archives stored in Glacier vaults, the question specifically asks about records that need immutability, and S3 Object Lock provides this capability directly on S3 objects without requiring a separate Glacier vault architecture.",
      "3": "Versioning preserves previous versions of objects when they are overwritten or deleted, but it does not prevent privileged users (including root) from permanently deleting object versions using delete markers or version-specific deletes."
    }
  },
  {
    "id": "SAA-231",
    "domainId": "D1",
    "domain": "Design Secure Architectures",
    "section": "CloudFront",
    "question": "Your streaming service must block viewers from specific countries due to licensing. How can you enforce this at the edge?",
    "choices": [
      "Security groups on the origin",
      "Route 53 geolocation routing",
      "Signed cookies",
      "CloudFront geo restriction"
    ],
    "answer": 3,
    "explanation": "CloudFront geo restriction allows you to whitelist or blacklist specific countries at edge locations. This blocks requests before they reach your origin. Route 53 geolocation influences DNS responses but does not enforce blocking; origin security groups do not filter by country; signed cookies control who can access, not location-based blocking.",
    "difficulty": "Medium",
    "choiceExplanations": {
      "0": "Security groups filter traffic based on IP addresses and ports, not geographic location; they cannot determine or block requests based on the viewer's country of origin.",
      "1": "Geolocation routing directs users to different endpoints based on their location but does not enforce blocking; users could still access content by using DNS resolvers in other regions or through VPNs.",
      "2": "Signed cookies are used to control access based on authentication and authorization (who can access content and for how long), not to restrict access based on geographic location."
    }
  },
  {
    "id": "SAA-232",
    "domainId": "D2",
    "domain": "Design Resilient Architectures",
    "section": "DataSync",
    "question": "You must migrate 300 TB from an on-prem NFS server to Amazon EFS, keeping metadata, with scheduling, verification, and incremental syncs. What is the best service?",
    "choices": [
      "AWS Transfer Family",
      "AWS DataSync",
      "Snowball Edge Storage Optimized",
      "AWS Backup"
    ],
    "answer": 1,
    "explanation": "AWS DataSync is built for large-scale data transfer to AWS storage services (EFS, S3, FSx) and supports metadata preservation, scheduled runs, verification, and incremental syncs after the initial copy.",
    "difficulty": "Hard",
    "choiceExplanations": {
      "0": "This service provides managed SFTP, FTPS, and FTP access to S3 and EFS for file transfers, but it's designed for ongoing file exchange workflows with external parties, not for large-scale data migration with scheduling, verification, and incremental sync capabilities.",
      "2": "While suitable for large offline data transfers, Snowball Edge doesn't support direct transfer to Amazon EFS, lacks built-in scheduling and incremental sync capabilities, and requires physical device shipping which adds complexity compared to DataSync's online transfer approach.",
      "3": "This service is designed for backing up AWS resources (like EFS, RDS, EC2) to protect existing cloud workloads, not for migrating data from on-premises sources to AWS storage services."
    }
  },
  {
    "id": "SAA-233",
    "domainId": "D2",
    "domain": "Design Resilient Architectures",
    "section": "Storage Gateway",
    "question": "Your backup software expects an iSCSI virtual tape library and you want to retire physical tapes while keeping long-term retention in S3/Glacier. Which gateway should you use?",
    "choices": [
      "Volume Gateway – Stored",
      "File Gateway",
      "Tape Gateway",
      "Volume Gateway – Cached"
    ],
    "answer": 2,
    "explanation": "Storage Gateway Tape Gateway provides a virtual tape library (VTL) interface over iSCSI for existing backup software, while storing virtual tapes in S3 and archiving them to Glacier for long-term retention.",
    "difficulty": "Hard",
    "choiceExplanations": {
      "0": "This provides block storage volumes via iSCSI that are stored locally with asynchronous backups to S3 as EBS snapshots, but it does not emulate a virtual tape library interface required by tape-based backup software.",
      "1": "This presents an NFS or SMB file interface for storing files directly in S3 buckets, not an iSCSI virtual tape library interface that tape backup software requires.",
      "3": "This provides block storage volumes via iSCSI with data stored primarily in S3 and frequently accessed data cached locally, but it does not provide the virtual tape library emulation needed for tape-based backup applications."
    }
  },
  {
    "id": "SAA-234",
    "domainId": "D3",
    "domain": "Design High-Performing Architectures",
    "section": "FSx",
    "question": "A Linux HPC workload needs a POSIX file system with sub-millisecond latencies and the ability to link a dataset in S3 so compute nodes can process it as a file system. Which service?",
    "choices": [
      "FSx for Windows File Server",
      "Storage Gateway – File Gateway",
      "FSx for Lustre",
      "S3 + Transfer Acceleration"
    ],
    "answer": 2,
    "explanation": "FSx for Lustre is designed for HPC workloads with very low latencies and high throughput. It integrates with S3 so you can link S3 data to a Lustre file system for high-performance processing by compute nodes.",
    "difficulty": "Hard",
    "choiceExplanations": {
      "0": "This service uses the SMB protocol and is designed for Windows-based workloads, not Linux HPC workloads that require a POSIX-compliant file system. It does not provide native S3 data repository integration like FSx for Lustre.",
      "1": "File Gateway provides NFS/SMB access to S3 storage with local caching, but it does not deliver the sub-millisecond latencies required for HPC workloads and is not optimized for high-performance computing scenarios.",
      "3": "S3 is an object storage service, not a POSIX-compliant file system, so it cannot be directly mounted by compute nodes as a file system. Transfer Acceleration only speeds up data transfers to S3 over long distances and does not address file system requirements."
    }
  },
  {
    "id": "SAA-235",
    "domainId": "D2",
    "domain": "Design Resilient Architectures",
    "section": "Snow Family",
    "question": "Your company must collect and migrate ~300 TB of data from 8 remote plants that have no high-bandwidth network. You also need to run lightweight validation scripts at the edge before shipment, and require KMS encryption and chain-of-custody tracking. Which device should you choose?",
    "choices": [
      "AWS Snowball Edge Storage Optimized",
      "AWS Snowmobile",
      "AWS Snowcone",
      "AWS DataSync"
    ],
    "answer": 0,
    "explanation": "Snowball Edge Storage Optimized is designed for large offline data transfers (hundreds of TB), supports encryption with KMS, includes chain-of-custody tracking, and provides onboard compute capabilities to run lightweight processing/validation at the edge. Snowcone is for much smaller datasets, and Snowmobile is for exabyte-scale transfers.",
    "difficulty": "Hard",
    "choiceExplanations": {
      "1": "This is a 45-foot shipping container designed for exabyte-scale migrations (up to 100 PB), which is vastly oversized and impractical for 300 TB spread across 8 remote locations; it's meant for single massive datacenter migrations, not distributed edge collection scenarios.",
      "2": "With only 8-14 TB of usable storage capacity, Snowcone is designed for small-scale edge computing and data collection, making it insufficient for handling 300 TB across 8 plants without requiring an impractical number of devices.",
      "3": "This is a software-based online data transfer service that requires network connectivity to function; since the remote plants have no high-bandwidth network, DataSync cannot efficiently transfer 300 TB of data from these locations."
    }
  },
  {
    "id": "SAA-236",
    "domainId": "D2",
    "domain": "Design Resilient Architectures",
    "section": "SQS",
    "question": "Your SQS-triggered Lambda sometimes takes 8–10 minutes to process a message. After ~5 minutes, the same message is delivered again to another Lambda instance, causing duplicate work. Which configuration should you use to prevent this duplicate processing?",
    "choices": [
      "Reduce Lambda timeout to 5 minutes",
      "Increase the SQS visibility timeout to be greater than the maximum Lambda processing time",
      "Enable SQS long polling at 20 seconds",
      "Enable FIFO on the queue"
    ],
    "answer": 1,
    "explanation": "If the visibility timeout expires before processing finishes, SQS makes the message visible again and it can be received by another Lambda invocation. Set the visibility timeout longer than the maximum end-to-end processing time (and include buffer). Long polling and FIFO do not solve visibility-timeout re-delivery by themselves.",
    "difficulty": "Medium",
    "choiceExplanations": {
      "0": "This would make the problem worse, not better. Since processing legitimately takes 8-10 minutes, reducing the Lambda timeout to 5 minutes would cause the function to timeout before completing, resulting in failed processing and the message returning to the queue anyway.",
      "2": "Long polling reduces empty responses and API costs by allowing SQS to wait up to 20 seconds for messages to arrive before returning. It has no effect on visibility timeout or message redelivery behavior, so it does not prevent duplicate processing.",
      "3": "FIFO queues ensure exactly-once processing and message ordering, but they still rely on visibility timeout for in-flight messages. If the visibility timeout expires before processing completes, the message will still be redelivered, causing the same duplicate processing issue."
    }
  },
  {
    "id": "SAA-237",
    "domainId": "D3",
    "domain": "Design High-Performing Architectures",
    "section": "SNS",
    "question": "You must fan out each event to multiple consumers while preserving strict ordering and exactly-once semantics. Which architecture should you choose?",
    "choices": [
      "Kinesis Data Firehose with multiple destinations",
      "SNS standard topic → SQS standard queues",
      "SNS FIFO topic → SQS FIFO subscriptions using Message Group IDs",
      "SQS standard queue with multiple consumers"
    ],
    "answer": 2,
    "explanation": "To preserve ordering and get FIFO exactly-once processing semantics, you need FIFO end-to-end. Use an SNS FIFO topic fan-out to multiple SQS FIFO queues, and use Message Group IDs to control ordering per group. Standard SNS/SQS do not provide strict ordering, and Firehose is for delivery to destinations (not ordered fan-out to multiple independent consumers).",
    "difficulty": "Hard",
    "choiceExplanations": {
      "0": "Firehose is designed for streaming data delivery to storage and analytics destinations (S3, Redshift, OpenSearch) rather than fan-out to multiple independent consumers, and it does not provide exactly-once semantics or strict ordering guarantees required by the question.",
      "1": "Standard SNS topics and SQS queues provide best-effort ordering only, meaning messages may be delivered out of order and potentially duplicated, failing to meet the strict ordering and exactly-once semantics requirements.",
      "3": "A single SQS standard queue does not support fan-out (each message is processed by only one consumer), does not guarantee message ordering, and provides at-least-once delivery rather than exactly-once semantics."
    }
  },
  {
    "id": "SAA-238",
    "domainId": "D2",
    "domain": "Design Resilient Architectures",
    "section": "Lambda",
    "question": "An SQS-triggered Lambda scales up quickly and overwhelms RDS during traffic spikes. You want to throttle how many Lambdas run in parallel for this queue. Which configuration should you use?",
    "choices": [
      "Use SNS instead of SQS",
      "Set a Reserved Concurrency on the Lambda function to cap parallel executions",
      "Increase batch size",
      "Increase visibility timeout"
    ],
    "answer": 1,
    "explanation": "Reserved Concurrency caps the maximum number of concurrent Lambda executions, which throttles how fast SQS messages can be processed and protects downstream systems like RDS. Batch size changes how many messages each invocation receives, but it doesn’t directly cap concurrency; visibility timeout doesn’t limit concurrency either.",
    "difficulty": "Medium",
    "choiceExplanations": {
      "0": "SNS is a push-based pub/sub service that would actually make the problem worse, as it invokes Lambda for each message without any built-in throttling mechanism, potentially causing even more concurrent executions during traffic spikes.",
      "2": "While increasing batch size means each Lambda invocation processes more messages, it does not directly limit the number of concurrent Lambda executions; Lambda can still scale up to many parallel invocations, each processing larger batches, still overwhelming RDS.",
      "3": "Visibility timeout controls how long a message is hidden from other consumers while being processed, preventing duplicate processing; it does not limit the number of concurrent Lambda executions and therefore cannot throttle parallel processing to protect RDS."
    }
  },
  {
    "id": "SAA-239",
    "domainId": "D3",
    "domain": "Design High-Performing Architectures",
    "section": "Lambda",
    "question": "You have a Java 11 Lambda that experiences spiky, unpredictable traffic. You must minimize cold-start latency when requests arrive but avoid paying for pre-warmed capacity when idle. Which feature should you choose?",
    "choices": [
      "Lambda Provisioned Concurrency",
      "Increase the function memory size only",
      "Lambda SnapStart for Java",
      "Lambda@Edge"
    ],
    "answer": 2,
    "explanation": "SnapStart reduces cold-start latency for Java functions without needing to keep provisioned instances warm during idle periods. Provisioned Concurrency minimizes cold starts too, but you pay for pre-warmed capacity even when there’s no traffic. Memory can help performance but does not reliably eliminate cold starts.",
    "difficulty": "Hard",
    "choiceExplanations": {
      "0": "While this feature effectively eliminates cold starts by keeping execution environments pre-initialized, it directly violates the requirement to avoid paying for pre-warmed capacity when idle, as you are billed for provisioned instances regardless of whether they receive traffic.",
      "1": "Increasing memory allocates more CPU proportionally and can improve overall execution performance, but it does not address the fundamental cold-start initialization overhead for Java functions, which involves JVM startup and class loading regardless of memory allocation.",
      "3": "This feature runs Lambda functions at CloudFront edge locations for latency-sensitive use cases like request/response manipulation, but it does not support Java runtime and does not address cold-start latency reduction for Java 11 functions."
    }
  },
  {
    "id": "SAA-240",
    "domainId": "D3",
    "domain": "Design High-Performing Architectures",
    "section": "EKS",
    "question": "Your platform team mandates Kubernetes APIs and wants a managed control plane with optional managed node groups and integration with VPC CNI. Which service should you choose?",
    "choices": [
      "Amazon EKS",
      "AWS Lambda",
      "Amazon ECS Fargate",
      "Docker on EC2 with an ALB"
    ],
    "answer": 0,
    "explanation": "Amazon EKS provides a managed Kubernetes control plane and supports managed node groups and AWS VPC CNI integration for pod networking.",
    "difficulty": "Easy",
    "choiceExplanations": {
      "1": "This is a serverless compute service for running functions without managing servers, but it does not provide Kubernetes APIs or a Kubernetes control plane as required by the platform team.",
      "2": "This is a serverless container orchestration service that uses AWS-native APIs, not Kubernetes APIs, so it cannot satisfy the requirement for Kubernetes API compatibility.",
      "3": "This approach requires manual management of the container orchestration layer and does not provide a managed Kubernetes control plane, managed node groups, or native VPC CNI integration as specified in the requirements."
    }
  },
  {
    "id": "SAA-241",
    "domainId": "D3",
    "domain": "Design High-Performing Architectures",
    "section": "ECS",
    "question": "You need to run a long-running, HTTP microservice in containers with no server management, integrate with an ALB, and run in private subnets. Which service should you choose?",
    "choices": [
      "AWS App Runner on Git repo",
      "Amazon ECS on Fargate launch type",
      "Amazon ECS on EC2 launch type",
      "Amazon EKS with self-managed nodes"
    ],
    "answer": 1,
    "explanation": "ECS on Fargate lets you run containers without managing EC2 instances, supports ALB integration, and can run tasks in private subnets. ECS on EC2 requires server management, and EKS with self-managed nodes also increases operational overhead.",
    "difficulty": "Medium",
    "choiceExplanations": {
      "0": "While App Runner provides serverless container hosting with no server management, it does not support running services in private subnets or direct ALB integration - App Runner manages its own endpoint and is designed for public-facing applications with simpler networking requirements.",
      "2": "This option requires you to provision, manage, patch, and scale EC2 instances yourself, which violates the 'no server management' requirement even though it supports ALB integration and private subnet deployment.",
      "3": "Self-managed nodes require you to provision and manage the underlying EC2 instances for the Kubernetes worker nodes, adding significant operational overhead and server management responsibilities that contradict the requirement."
    }
  },
  {
    "id": "SAA-242",
    "domainId": "D4",
    "domain": "Design Cost-Optimized Architectures",
    "section": "DynamoDB",
    "question": "Your DynamoDB workload has unpredictable spikes, and you don’t want to plan read/write capacity or manage auto scaling. Which capacity mode should you choose?",
    "choices": [
      "Global tables with provisioned capacity",
      "On-demand capacity mode",
      "Provisioned with auto scaling",
      "DAX with provisioned capacity"
    ],
    "answer": 1,
    "explanation": "On-demand capacity automatically accommodates unpredictable traffic without you having to plan RCUs/WCUs or configure auto scaling. Provisioned + auto scaling still requires capacity planning and tuning; DAX is a caching layer and doesn’t replace capacity mode.",
    "difficulty": "Medium",
    "choiceExplanations": {
      "0": "Global tables provide multi-region replication for disaster recovery and low-latency access, but provisioned capacity still requires you to plan and specify read/write capacity units, which doesn't address the requirement of avoiding capacity planning for unpredictable workloads.",
      "2": "While auto scaling can adjust capacity based on utilization, it still requires initial capacity planning, setting minimum/maximum limits, and configuring scaling policies, which contradicts the requirement of not wanting to plan capacity or manage auto scaling.",
      "3": "DAX (DynamoDB Accelerator) is an in-memory caching layer that reduces read latency, but it doesn't replace the need to choose a capacity mode; the underlying table would still use provisioned capacity requiring capacity planning and management."
    }
  },
  {
    "id": "SAA-243",
    "domainId": "D1",
    "domain": "Design Secure Architectures",
    "section": "CloudFront",
    "question": "Your distribution must authenticate viewers at the edge by calling an external authorization API, then add/remove headers and possibly return a 302 redirect before the request reaches the origin. Which feature should you choose?",
    "choices": [
      "AWS WAF rate-based rule",
      "CloudFront Functions",
      "ALB listener rules behind CloudFront",
      "Lambda@Edge"
    ],
    "answer": 3,
    "explanation": "Lambda@Edge can run at CloudFront viewer request, call external authorization endpoints, and then modify headers or generate responses (including redirects) before forwarding to the origin. CloudFront Functions are lightweight and fast but cannot make network calls to external APIs. WAF rate rules don’t perform custom auth logic.",
    "difficulty": "Hard",
    "choiceExplanations": {
      "0": "WAF rate-based rules only count and block requests exceeding a threshold rate, they cannot call external authorization APIs, modify headers, or generate custom redirect responses for authentication purposes.",
      "1": "CloudFront Functions are lightweight and designed for simple request/response manipulations, but they cannot make external network calls to authorization APIs, which is a core requirement of this scenario.",
      "2": "ALB listener rules operate at the origin level after CloudFront forwards the request, not at the edge, so they cannot authenticate viewers or modify requests before reaching the origin as required."
    }
  },
  {
    "id": "SAA-244",
    "domainId": "D3",
    "domain": "Design High-Performing Architectures",
    "section": "Kinesis",
    "question": "Your team needs to ingest real-time clickstream events at high throughput, process them with sub-second latency, allow multiple independent consumers (analytics + fraud), and be able to replay data from the last 24–72 hours to reprocess if logic changes. Which service should you choose?",
    "choices": [
      "Amazon Kinesis Data Streams",
      "Amazon SNS",
      "Amazon Kinesis Data Firehose",
      "Amazon SQS"
    ],
    "answer": 0,
    "explanation": "Kinesis Data Streams supports high-throughput streaming ingestion, multiple consumer applications (enhanced fan-out if needed), low-latency processing, and data retention for replay (for example 24–72 hours or longer depending on configuration). Firehose is primarily for delivery to storage/analytics destinations with limited replay semantics.",
    "difficulty": "Hard",
    "choiceExplanations": {
      "1": "SNS is a push-based pub/sub messaging service that does not retain messages after delivery, making it impossible to replay data from the last 24-72 hours for reprocessing when logic changes.",
      "2": "Firehose is designed for near-real-time delivery to destinations like S3, Redshift, or OpenSearch with buffering intervals (minimum 60 seconds), which doesn't meet sub-second latency requirements, and it lacks native data replay capabilities from the stream itself.",
      "3": "SQS is a message queue service where messages are deleted after processing by a single consumer, which doesn't support multiple independent consumers reading the same data or provide the ability to replay historical data for reprocessing."
    }
  },
  {
    "id": "SAA-245",
    "domainId": "D4",
    "domain": "Design Cost-Optimized Architectures",
    "section": "Batch",
    "question": "Your company has a nightly automation script that takes 2–3 hours to complete. They prefer a fully managed, serverless option. Which service should you choose?",
    "choices": [
      "AWS Lambda orchestrated by Step Functions looping for hours",
      "AWS Lambda with Provisioned Concurrency",
      "AWS Batch with a Fargate compute environment",
      "AWS Lambda with the timeout increased to 3 hours"
    ],
    "answer": 2,
    "explanation": "Lambda can’t run for hours (maximum execution time is much lower), so options D and B are not suitable. Provisioned Concurrency doesn’t change Lambda’s max runtime. AWS Batch can run long jobs, and with a Fargate compute environment you avoid managing servers while still running multi-hour workloads reliably on a schedule.",
    "difficulty": "Hard",
    "choiceExplanations": {
      "0": "While Step Functions can orchestrate long-running workflows, using it to loop Lambda functions for hours is an anti-pattern that adds unnecessary complexity, increases costs through multiple invocations and state transitions, and requires breaking the workload into 15-minute chunks rather than running it as a continuous process.",
      "1": "Provisioned Concurrency keeps Lambda functions initialized to reduce cold start latency, but it does not extend the maximum execution timeout of 15 minutes, making it unsuitable for workloads requiring 2-3 hours of continuous execution.",
      "3": "This is not possible because AWS Lambda has a hard maximum execution timeout limit of 15 minutes (900 seconds), which cannot be increased regardless of configuration settings."
    }
  },
  {
    "id": "SAA-246",
    "domainId": "D3",
    "domain": "Design High-Performing Architectures",
    "section": "Neptune",
    "question": "Your company is building a knowledge graph to support features like friend-of-friend, shortest path, and fraud rings. You need a fully managed graph database that supports Gremlin and SPARQL, offers high availability across AZs, and integrates with IAM/KMS for security. Which service should you choose?",
    "choices": [
      "Amazon DocumentDB",
      "Amazon DynamoDB",
      "Amazon Neptune",
      "Amazon RDS for PostgreSQL"
    ],
    "answer": 2,
    "explanation": "Amazon Neptune is a fully managed graph database service that supports Gremlin and SPARQL, provides high availability, and integrates with IAM/KMS for access control and encryption.",
    "difficulty": "Medium",
    "choiceExplanations": {
      "0": "This is a document database compatible with MongoDB, designed for JSON document storage and querying, not a graph database, and does not support Gremlin or SPARQL query languages required for graph traversals like friend-of-friend or shortest path.",
      "1": "This is a key-value and document NoSQL database optimized for high-throughput workloads, but it lacks native graph database capabilities and does not support Gremlin or SPARQL query languages needed for graph traversal operations.",
      "3": "While PostgreSQL has some graph extensions available, RDS for PostgreSQL is primarily a relational database and does not natively support Gremlin or SPARQL, making it unsuitable for purpose-built graph workloads like knowledge graphs and fraud detection."
    }
  },
  {
    "id": "SAA-247",
    "domainId": "D3",
    "domain": "Design High-Performing Architectures",
    "section": "DocumentDB",
    "question": "A legacy microservice uses MongoDB drivers and stores schema-flexible JSON. You want a drop-in managed replacement with automatic backups, VPC isolation, and no manual sharding/patching. Which service should you choose?",
    "choices": [
      "Amazon ElastiCache for Redis",
      "Amazon DocumentDB",
      "Amazon Aurora MySQL",
      "Amazon DynamoDB"
    ],
    "answer": 1,
    "explanation": "Amazon DocumentDB is MongoDB-compatible, fully managed, supports VPC isolation and automated backups, and removes the operational overhead of running MongoDB yourself.",
    "difficulty": "Medium",
    "choiceExplanations": {
      "0": "ElastiCache for Redis is an in-memory caching service designed for high-speed data retrieval, not a document database replacement. It does not provide MongoDB compatibility and is not suitable for persistent primary data storage of JSON documents.",
      "2": "Aurora MySQL is a relational database that requires predefined schemas and uses SQL, making it incompatible with MongoDB drivers and unsuitable for schema-flexible JSON document storage without significant application changes.",
      "3": "While DynamoDB is a fully managed NoSQL database that can store JSON-like documents, it is not MongoDB-compatible and would require rewriting application code since existing MongoDB drivers cannot be used as a drop-in replacement."
    }
  },
  {
    "id": "SAA-248",
    "domainId": "D3",
    "domain": "Design High-Performing Architectures",
    "section": "ElastiCache",
    "question": "Your web tier stores ephemeral session state, needs sub-millisecond latency, TTL eviction, and optional pub/sub. Data must live in memory and offload reads from your primary database. Which service should you choose?",
    "choices": [
      "Amazon S3 Standard",
      "Amazon EFS",
      "Amazon ElastiCache for Redis",
      "Amazon RDS for MySQL"
    ],
    "answer": 2,
    "explanation": "ElastiCache for Redis provides in-memory storage with sub-millisecond latency, supports TTL eviction, and supports pub/sub, making it ideal for session state and offloading reads from databases.",
    "difficulty": "Medium",
    "choiceExplanations": {
      "0": "S3 is an object storage service designed for durability and scalability, not low-latency in-memory caching; it does not provide sub-millisecond latency, TTL eviction, or pub/sub capabilities required for session state management.",
      "1": "EFS is a managed file storage service for EC2 instances that stores data on disk, not in memory; it cannot deliver sub-millisecond latency and lacks native TTL eviction or pub/sub features needed for session caching.",
      "3": "RDS is a relational database service that stores data on disk, not in memory; it cannot achieve sub-millisecond latency consistently and would not offload reads from your primary database since it is itself a database service."
    }
  },
  {
    "id": "SAA-249",
    "domainId": "D4",
    "domain": "Design Cost-Optimized Architectures",
    "section": "Athena",
    "question": "Analysts keep CSV/Parquet in Amazon S3 and need to run one-off SQL and join datasets without provisioning clusters. Results should be billed per query and use the Glue Data Catalog for schemas. Which service should you choose?",
    "choices": [
      "Amazon Athena",
      "Amazon EMR",
      "AWS Glue",
      "Amazon Redshift"
    ],
    "answer": 0,
    "explanation": "Amazon Athena is serverless SQL on S3, billed per query, and integrates with the AWS Glue Data Catalog for table definitions and schemas.",
    "difficulty": "Medium",
    "choiceExplanations": {
      "1": "EMR requires provisioning and managing clusters of EC2 instances, which contradicts the requirement of running queries without provisioning clusters, and it is not billed per query but rather by cluster runtime.",
      "2": "AWS Glue is primarily an ETL (Extract, Transform, Load) service for data preparation and movement, not designed for interactive ad-hoc SQL queries; it is billed based on DPU-hours for ETL jobs rather than per query.",
      "3": "Redshift is a data warehouse that requires provisioning clusters (even Redshift Serverless has different billing model), and while it can query S3 via Redshift Spectrum, it's designed for complex analytics workloads rather than simple one-off queries on S3 data."
    }
  },
  {
    "id": "SAA-250",
    "domainId": "D3",
    "domain": "Design High-Performing Architectures",
    "section": "Redshift",
    "question": "BI teams require a columnar, massively parallel SQL engine with concurrency scaling, materialized views, and integration with QuickSight. Data loads from S3 and operational stores nightly. Which service should you choose?",
    "choices": [
      "AWS Glue",
      "Amazon Redshift",
      "Amazon QuickSight",
      "Amazon Athena"
    ],
    "answer": 1,
    "explanation": "Amazon Redshift is a columnar, MPP data warehouse that supports features like concurrency scaling and materialized views and integrates well with BI tools like QuickSight.",
    "difficulty": "Medium",
    "choiceExplanations": {
      "0": "AWS Glue is a serverless ETL (Extract, Transform, Load) service for data preparation and cataloging, not a columnar MPP SQL engine designed for data warehousing and BI analytics workloads.",
      "2": "QuickSight is a business intelligence visualization and reporting tool, not a data warehouse engine; it consumes data from sources like Redshift but does not provide columnar storage, MPP processing, or concurrency scaling features.",
      "3": "While Athena is a serverless SQL query service that can query S3 data, it lacks native concurrency scaling, materialized views support, and the MPP data warehouse architecture that Redshift provides for sustained BI workloads."
    }
  },
  {
    "id": "SAA-251",
    "domainId": "D3",
    "domain": "Design High-Performing Architectures",
    "section": "Glue",
    "question": "Nightly jobs must crawl S3, infer/update table schemas, run Spark transformations from CSV → Parquet, and load curated data to Redshift with minimal ops. Which service should you choose?",
    "choices": [
      "AWS Data Pipeline",
      "Amazon EMR with long-running clusters",
      "Amazon Athena CTAS queries only",
      "AWS Glue"
    ],
    "answer": 3,
    "explanation": "AWS Glue provides crawlers to infer schemas and update the Data Catalog, and managed Spark ETL jobs to transform data (CSV to Parquet) and load curated outputs to targets like Redshift with low operational overhead.",
    "difficulty": "Medium",
    "choiceExplanations": {
      "0": "While it can orchestrate data workflows and move data between AWS services, it lacks built-in schema crawling/inference capabilities and requires more operational overhead to configure and manage compared to AWS Glue's serverless, integrated approach.",
      "1": "EMR can run Spark transformations but requires significant operational overhead to manage clusters, configure infrastructure, and handle scaling; it also lacks built-in crawlers for automatic schema discovery and Data Catalog integration.",
      "2": "Athena CTAS can convert CSV to Parquet format, but it cannot crawl and infer schemas automatically, does not maintain a Data Catalog, and cannot directly load data into Redshift, making it insufficient for the complete ETL pipeline requirements."
    }
  },
  {
    "id": "SAA-252",
    "domainId": "D3",
    "domain": "Design High-Performing Architectures",
    "section": "Rekognition",
    "question": "Your app must detect objects and faces in images and return labels with confidence scores through a managed API. Which service should you choose?",
    "choices": [
      "Transcribe",
      "Comprehend",
      "Polly",
      "Rekognition"
    ],
    "answer": 3,
    "explanation": "Amazon Rekognition provides managed image/video analysis APIs to detect objects, scenes, and faces and returns labels with confidence scores.",
    "difficulty": "Easy",
    "choiceExplanations": {
      "0": "Amazon Transcribe is a speech-to-text service that converts audio to text, not an image analysis service for detecting objects or faces.",
      "1": "Amazon Comprehend is a natural language processing (NLP) service that analyzes text for sentiment, entities, and key phrases, not images or visual content.",
      "2": "Amazon Polly is a text-to-speech service that converts text into lifelike speech audio, not a service for analyzing images or detecting objects and faces."
    }
  },
  {
    "id": "SAA-253",
    "domainId": "D3",
    "domain": "Design High-Performing Architectures",
    "section": "Polly",
    "question": "Marketing needs to turn blog posts into audio using lifelike voices via an API. Which service should you choose?",
    "choices": [
      "Polly",
      "Lex",
      "Transcribe",
      "Comprehend"
    ],
    "answer": 0,
    "explanation": "Amazon Polly converts text to lifelike speech using a managed API (text-to-speech).",
    "difficulty": "Easy",
    "choiceExplanations": {
      "1": "Amazon Lex is a service for building conversational interfaces (chatbots) using voice and text, not for converting written content into audio speech.",
      "2": "Amazon Transcribe performs the opposite function—it converts speech (audio) into text, rather than converting text into speech as required for turning blog posts into audio.",
      "3": "Amazon Comprehend is a natural language processing (NLP) service that analyzes text to extract insights, sentiment, and entities, but it does not generate audio output from text."
    }
  },
  {
    "id": "SAA-254",
    "domainId": "D1",
    "domain": "Design Secure Architectures",
    "section": "CloudTrail",
    "question": "Yesterday a production outage was traced to a security group rule change. You need to answer, “Which principal made the API call, from which IP, and at what exact time?” Which service should you choose?",
    "choices": [
      "Amazon CloudWatch Metrics",
      "AWS Systems Manager",
      "AWS Config conformance packs",
      "AWS CloudTrail"
    ],
    "answer": 3,
    "explanation": "AWS CloudTrail records API activity and includes who made the call (principal), source IP, request details, and timestamps—ideal for auditing and forensics.",
    "difficulty": "Medium",
    "choiceExplanations": {
      "0": "CloudWatch Metrics collects and tracks numerical performance data like CPU utilization and network throughput, but does not record API call details such as who made the call, source IP addresses, or timestamps of configuration changes.",
      "1": "Systems Manager provides operational management capabilities like patch management, configuration management, and remote access to instances, but does not track or log API calls or record which principal made specific AWS API requests.",
      "2": "AWS Config conformance packs evaluate resource configurations against compliance rules and track configuration history, but they do not capture API call details like the principal identity, source IP address, or exact timestamp of who made the change."
    }
  },
  {
    "id": "SAA-255",
    "domainId": "D1",
    "domain": "Design Secure Architectures",
    "section": "Organizations",
    "question": "Your company uses AWS Organizations with Control Tower. At the Root, an SCP is attached that denies ec2:TerminateInstances on all resources. An admin in a member account (with AdministratorAccess) tries to terminate an EC2 instance in any region. What does this SCP mean for the attached accounts?",
    "choices": [
      "The action is allowed only if the instance has a certain tag",
      "The action is denied for all principals in all attached accounts in all regions, regardless of IAM permissions",
      "The action is denied only when called from the console, not the CLI",
      "The action is allowed because AdministratorAccess overrides the SCP at the account level"
    ],
    "answer": 1,
    "explanation": "SCPs set the maximum permissions for accounts/OUs. An explicit Deny in an SCP cannot be overridden by IAM permissions, so ec2:TerminateInstances is denied for all principals in all attached accounts in all regions.",
    "difficulty": "Hard",
    "choiceExplanations": {
      "0": "This is incorrect because the SCP explicitly denies ec2:TerminateInstances on all resources without any conditions. Tag-based exceptions would only apply if the SCP included a condition element specifying tag requirements, which this scenario does not describe.",
      "2": "This is incorrect because SCPs apply uniformly to all API calls regardless of the access method used. Whether the request comes from the AWS Console, CLI, SDK, or any other method, the SCP deny applies equally to all.",
      "3": "This is incorrect because SCPs define the maximum permissions boundary for member accounts and cannot be overridden by any IAM policy, including AdministratorAccess. SCPs take precedence over IAM permissions, meaning even full admin rights cannot bypass an SCP deny."
    }
  },
  {
    "id": "SAA-256",
    "domainId": "D1",
    "domain": "Design Secure Architectures",
    "section": "KMS",
    "question": "Your app writes data in us-east-1 and replicates the ciphertext to eu-west-1. You need to decrypt in both Regions without re-encrypting and keep keys cryptographically equivalent across Regions. Which KMS feature should you choose?",
    "choices": [
      "Customer-managed alias pointing to different keys per Region",
      "A single-Region KMS key shared to eu-west-1",
      "KMS multi-Region keys",
      "SSE-S3 without KMS"
    ],
    "answer": 2,
    "explanation": "KMS multi-Region keys create linked, cryptographically equivalent keys in multiple Regions so ciphertext encrypted in one Region can be decrypted in another without re-encrypting.",
    "difficulty": "Hard",
    "choiceExplanations": {
      "0": "Different KMS keys in each Region are not cryptographically equivalent, meaning ciphertext encrypted with one key cannot be decrypted by another key, requiring re-encryption when moving data between Regions.",
      "1": "Single-Region KMS keys cannot be shared or used outside their Region of creation; KMS keys are Regional resources and cannot be exported or replicated to other Regions.",
      "3": "SSE-S3 uses Amazon-managed keys that are Region-specific and do not provide cryptographically equivalent keys across Regions, plus you lose the key management control that KMS provides."
    }
  },
  {
    "id": "SAA-257",
    "domainId": "D1",
    "domain": "Design Secure Architectures",
    "section": "S3",
    "question": "You enable S3 Cross-Region Replication for a bucket using SSE-KMS. Replication fails with an access error on the destination key. Which change should you implement so the replicas are encrypted at the destination?",
    "choices": [
      "Create a VPC endpoint for S3",
      "Turn off KMS on the source bucket",
      "Use SSE-S3 on the destination only",
      "Update the destination KMS key policy to allow the source bucket’s replication role to use kms:Encrypt"
    ],
    "answer": 3,
    "explanation": "For CRR with SSE-KMS, the replication IAM role must be permitted by the destination KMS key policy to encrypt (and typically generate data keys). Grant the replication role the required KMS permissions on the destination key.",
    "difficulty": "Hard",
    "choiceExplanations": {
      "0": "VPC endpoints are used for private connectivity between VPCs and S3, but S3 Cross-Region Replication operates over the AWS backbone network and does not require VPC endpoints; the error is specifically about KMS key access permissions, not network connectivity.",
      "1": "Disabling KMS encryption on the source bucket would change your security posture and is not necessary; CRR fully supports SSE-KMS encrypted objects when proper permissions are configured, and the issue is specifically with destination key permissions.",
      "2": "While this might work as a workaround, it changes the encryption method and may not meet security requirements that mandate KMS encryption; the proper solution is to fix the KMS key policy permissions rather than downgrade to SSE-S3 encryption."
    }
  },
  {
    "id": "SAA-258",
    "domainId": "D1",
    "domain": "Design Secure Architectures",
    "section": "EC2",
    "question": "You must share an EBS-backed AMI encrypted with your CMK so another AWS account can launch it. Which steps should you choose?",
    "choices": [
      "Share only the AMI",
      "Share the AMI and its encrypted snapshot, and grant the other account kms:Decrypt on the CMK (or let them copy the snapshot to their CMK)",
      "Copy the AMI to S3 and send a link",
      "Share just the snapshot"
    ],
    "answer": 1,
    "explanation": "For an encrypted EBS-backed AMI, you must share the AMI and the underlying encrypted snapshot and also allow the target account to use the KMS key (or have them copy the snapshot/AMI using their own CMK). Sharing only the AMI is not sufficient.",
    "difficulty": "Hard",
    "choiceExplanations": {
      "0": "Sharing only the AMI is insufficient because the other account also needs access to the underlying encrypted EBS snapshot and permissions to use the KMS key (kms:Decrypt) to decrypt the snapshot data when launching instances from the AMI.",
      "2": "AMIs cannot be copied to S3 and shared via a link; AMIs are registered EC2 resources that must be shared through the EC2 AMI sharing mechanism, and their underlying snapshots are stored in S3 but managed by AWS, not directly accessible.",
      "3": "Sharing only the snapshot is insufficient because the other account needs the AMI itself (which contains the instance configuration metadata like architecture, kernel, and block device mappings) in addition to the snapshot and KMS key permissions to successfully launch instances."
    }
  },
  {
    "id": "SAA-259",
    "domainId": "D1",
    "domain": "Design Secure Architectures",
    "section": "Secrets Manager",
    "question": "You store database credentials and must rotate them automatically every 30 days, with built-in rotation workflows and audit. Which service should you choose?",
    "choices": [
      "SSM Parameter Store",
      "IAM Roles Anywhere",
      "AWS Secrets Manager",
      "S3 with SSE-KMS"
    ],
    "answer": 2,
    "explanation": "AWS Secrets Manager provides managed secret storage with built-in rotation workflows (via Lambda), scheduled rotation, and auditing/integration with IAM and CloudTrail.",
    "difficulty": "Medium",
    "choiceExplanations": {
      "0": "While it can store secrets as SecureString parameters, it does not provide built-in automatic rotation workflows for database credentials; rotation must be implemented manually using custom Lambda functions without native scheduling support.",
      "1": "This service enables workloads outside AWS to obtain temporary IAM credentials using X.509 certificates, but it is not designed for storing or rotating database credentials.",
      "3": "While S3 can store encrypted files using KMS, it is not designed for secrets management and does not provide built-in rotation workflows, scheduling, or native integration for credential rotation."
    }
  },
  {
    "id": "SAA-260",
    "domainId": "D1",
    "domain": "Design Secure Architectures",
    "section": "ACM",
    "question": "You will expose a web app through an Application Load Balancer at app.example.com. You want a public TLS certificate managed by AWS with easy renewals. Which approach should you choose?",
    "choices": [
      "Issue a private ACM cert from a Private CA",
      "Upload a self-signed cert to the ALB",
      "Use CloudFront to auto-create a cert",
      "Request a public certificate in AWS Certificate Manager and validate via DNS in Route 53"
    ],
    "answer": 3,
    "explanation": "ACM public certificates are AWS-managed and renew automatically (when DNS validation remains in place). You then attach the ACM cert to the ALB HTTPS listener.",
    "difficulty": "Medium",
    "choiceExplanations": {
      "0": "Private CA certificates are intended for internal resources and are not publicly trusted by browsers, making them unsuitable for a public-facing web application that external users will access.",
      "1": "Self-signed certificates are not trusted by browsers and will display security warnings to users, plus they require manual renewal and management rather than being automatically managed by AWS.",
      "2": "CloudFront does not auto-create certificates; you must still request a certificate through ACM (specifically in us-east-1 for CloudFront), and this adds unnecessary complexity when the ALB can directly use an ACM certificate."
    }
  },
  {
    "id": "SAA-261",
    "domainId": "D1",
    "domain": "Design Secure Architectures",
    "section": "Firewall Manager",
    "question": "Your org needs to enforce WAF rules and Shield protections across dozens of accounts and ALBs/CloudFront from a central place using AWS Organizations. Which service should you choose?",
    "choices": [
      "Amazon GuardDuty",
      "AWS Shield Advanced alone",
      "AWS Firewall Manager",
      "AWS Network Firewall"
    ],
    "answer": 2,
    "explanation": "AWS Firewall Manager is the AWS Organizations-integrated service for centrally configuring and enforcing AWS WAF rules and Shield Advanced protections across multiple accounts and resources.",
    "difficulty": "Hard",
    "choiceExplanations": {
      "0": "GuardDuty is a threat detection service that analyzes logs for malicious activity and security threats, but it does not enforce WAF rules or Shield protections across accounts.",
      "1": "While Shield Advanced provides DDoS protection, it does not natively integrate with AWS Organizations for centralized policy management across multiple accounts; Firewall Manager is required to deploy and manage Shield Advanced protections at scale across an organization.",
      "3": "Network Firewall provides stateful inspection and filtering for VPC traffic at the network layer, but it is not designed for managing WAF rules or Shield protections for ALBs and CloudFront distributions."
    }
  },
  {
    "id": "SAA-262",
    "domainId": "D1",
    "domain": "Design Secure Architectures",
    "section": "GuardDuty",
    "question": "Security wants managed threat detection that analyzes CloudTrail, VPC Flow Logs, and DNS logs to alert on anomalous IAM activity and known malicious IPs. Which service should you choose?",
    "choices": [
      "Amazon Inspector",
      "Amazon GuardDuty",
      "AWS CloudTrail",
      "AWS Config"
    ],
    "answer": 1,
    "explanation": "Amazon GuardDuty is a managed threat detection service that analyzes CloudTrail events, VPC Flow Logs, and DNS logs to generate security findings.",
    "difficulty": "Medium",
    "choiceExplanations": {
      "0": "This service assesses applications for vulnerabilities and security exposures within EC2 instances and container images, but it does not analyze CloudTrail, VPC Flow Logs, or DNS logs for threat detection or malicious IP identification.",
      "2": "This service records API calls and account activity for auditing purposes, but it only logs events and does not provide threat detection, anomaly analysis, or alerting on malicious activity.",
      "3": "This service tracks resource configuration changes and evaluates compliance against rules, but it does not analyze logs for threats, detect anomalous IAM activity, or identify malicious IPs."
    }
  },
  {
    "id": "SAA-263",
    "domainId": "D1",
    "domain": "Design Secure Architectures",
    "section": "VPC",
    "question": "You place workloads in IPv6-only private subnets and they must reach public Internet services while remaining non-routable from the Internet. Which gateway should you choose?",
    "choices": [
      "Transit Gateway",
      "Egress-Only Internet Gateway",
      "NAT Gateway",
      "Internet Gateway"
    ],
    "answer": 1,
    "explanation": "An Egress-Only Internet Gateway allows outbound-only IPv6 access to the internet while preventing inbound connections initiated from the internet.",
    "difficulty": "Medium",
    "choiceExplanations": {
      "0": "Transit Gateway is used to connect multiple VPCs and on-premises networks together, not to provide internet access for IPv6 workloads; it does not provide the outbound-only internet connectivity required for this scenario.",
      "2": "NAT Gateway only supports IPv4 traffic for translating private IP addresses to public addresses; it does not support IPv6, which makes it unsuitable for IPv6-only subnets.",
      "3": "Internet Gateway allows both inbound and outbound IPv6 traffic, making instances directly routable from the internet; this violates the requirement that workloads remain non-routable from the internet."
    }
  },
  {
    "id": "SAA-264",
    "domainId": "D4",
    "domain": "Design Cost-Optimized Architectures",
    "section": "VPC Endpoints",
    "question": "Instances in private subnets must access S3 without using a NAT Gateway to minimize cost and keep traffic off the Internet. Which integration should you choose?",
    "choices": [
      "Gateway VPC endpoint for S3",
      "Interface VPC endpoint for S3",
      "Public S3 with bucket policy Allow *",
      "VPC peering to the S3 VPC"
    ],
    "answer": 0,
    "explanation": "A Gateway VPC endpoint for S3 routes S3 traffic privately over the AWS network without a NAT Gateway, reducing cost and keeping traffic off the public internet.",
    "difficulty": "Medium",
    "choiceExplanations": {
      "1": "While Interface endpoints do work for S3 and keep traffic private, they incur hourly charges and data processing fees, making them more expensive than Gateway endpoints which are free to use.",
      "2": "This approach still requires a NAT Gateway for private subnet instances to reach the public S3 endpoint, which contradicts the cost-minimization requirement and creates a security risk by allowing unrestricted access.",
      "3": "S3 is a managed service that does not reside in a customer-accessible VPC, so VPC peering cannot be established to reach S3; this option is technically not possible."
    }
  },
  {
    "id": "SAA-265",
    "domainId": "D2",
    "domain": "Design Resilient Architectures",
    "section": "Transit Gateway",
    "question": "You need to connect dozens of VPCs and on-prem networks in a hub-and-spoke topology with route propagation and centralized control, avoiding complex peering meshes. Which service should you choose?",
    "choices": [
      "AWS Transit Gateway",
      "VPC Peering",
      "Site-to-Site VPN per VPC",
      "AWS Direct Connect only"
    ],
    "answer": 0,
    "explanation": "AWS Transit Gateway provides hub-and-spoke connectivity for many VPCs and on-prem networks with centralized routing and route propagation, avoiding a complex full mesh of VPC peering connections.",
    "difficulty": "Medium",
    "choiceExplanations": {
      "1": "VPC peering creates one-to-one connections between VPCs and does not support transitive routing, meaning connecting dozens of VPCs would require a complex full mesh of individual peering connections (n*(n-1)/2 connections), which is exactly what the question wants to avoid.",
      "2": "Creating individual VPN connections to each VPC would result in management complexity with dozens of separate VPN tunnels, lacks centralized routing control, and does not provide the hub-and-spoke topology with route propagation that Transit Gateway offers.",
      "3": "Direct Connect provides dedicated private connectivity between on-premises and AWS but does not by itself enable VPC-to-VPC connectivity or provide the hub-and-spoke topology with centralized routing; it would need to be combined with Transit Gateway to achieve the required architecture."
    }
  },
  {
    "id": "SAA-266",
    "domainId": "D2",
    "domain": "Design Resilient Architectures",
    "section": "Disaster Recovery",
    "question": "A payments platform needs minutes-level RTO and low data loss across two Regions but wants to avoid the full cost of active/active. It will keep a scaled-down copy of the app and database warm in the secondary Region and scale up on failover. Which DR strategy should you choose?",
    "choices": [
      "Multi-Region Active/Active",
      "Pilot Light",
      "Backup & Restore",
      "Warm Standby"
    ],
    "answer": 3,
    "explanation": "Warm Standby keeps a scaled-down but fully functional environment running in the secondary Region (app + database) and scales up on failover, providing minutes-level RTO with lower cost than active/active.",
    "difficulty": "Medium",
    "choiceExplanations": {
      "0": "While this provides the lowest RTO, it requires running full capacity in both Regions simultaneously, which the question explicitly states the company wants to avoid due to cost concerns.",
      "1": "This strategy keeps only core infrastructure running (like database replication) but requires provisioning and deploying application servers during failover, resulting in longer RTO (typically tens of minutes to hours) rather than the minutes-level RTO required.",
      "2": "This is the lowest-cost DR strategy but has the longest RTO (hours to days) because it requires restoring data from backups and provisioning all infrastructure from scratch, which does not meet the minutes-level RTO requirement."
    }
  },
  {
    "id": "SAA-267",
    "domainId": "D2",
    "domain": "Design Resilient Architectures",
    "section": "DMS",
    "question": "You must move an on-prem Oracle OLTP database to Amazon Aurora PostgreSQL with minutes of cutover downtime. The target schema needs conversion, and you want ongoing change data capture (CDC) until the cutover. Which approach should you choose?",
    "choices": [
      "AWS Schema Conversion Tool (SCT) + AWS DMS replication task with CDC",
      "Export/import with Data Pump only",
      "Snapshot/restore to Aurora",
      "Glue ETL jobs into Aurora"
    ],
    "answer": 0,
    "explanation": "SCT handles heterogeneous schema conversion (Oracle → Aurora PostgreSQL). DMS can do full load plus CDC replication so you keep the target nearly in sync and perform a short cutover window.",
    "difficulty": "Hard",
    "choiceExplanations": {
      "1": "Oracle Data Pump is an Oracle-native tool that cannot directly export to PostgreSQL format, does not handle schema conversion between heterogeneous databases, and requires significant downtime during the export/import process without CDC capability for ongoing replication.",
      "2": "Snapshots are used for restoring within the same database engine family; you cannot restore an Oracle database snapshot to Aurora PostgreSQL as they are completely different database engines with incompatible storage formats.",
      "3": "AWS Glue is designed for batch ETL workloads and data transformation, not real-time database replication; it lacks native CDC capabilities and cannot maintain continuous synchronization needed for minimal cutover downtime in OLTP migrations."
    }
  },
  {
    "id": "SAA-268",
    "domainId": "D2",
    "domain": "Design Resilient Architectures",
    "section": "RDS",
    "question": "You’re upgrading RDS MySQL to a new major version and need a very short, controlled cutover with automatic replica synchronization and quick rollback if needed. Which feature should you choose?",
    "choices": [
      "Cross-Region read replica and manual promotion",
      "DMS full load only",
      "RDS Blue/Green Deployments",
      "Multi-AZ failover"
    ],
    "answer": 2,
    "explanation": "RDS Blue/Green Deployments lets you create a synchronized staging (green) environment, perform the upgrade there, and then switch over with a controlled cutover. It also supports rolling back by switching back if needed (depending on the situation).",
    "difficulty": "Hard",
    "choiceExplanations": {
      "0": "This approach requires manual intervention for promotion, does not provide automatic replica synchronization during major version upgrades, and lacks the built-in quick rollback capability that Blue/Green Deployments offer.",
      "1": "DMS full load performs a one-time data migration without ongoing replication, meaning any changes during the migration window would be lost, and it doesn't provide the automatic synchronization or quick rollback capabilities needed for a controlled cutover.",
      "3": "Multi-AZ is designed for high availability and automatic failover during infrastructure failures, not for major version upgrades; the standby instance must run the same engine version as the primary and cannot be used for version upgrades or rollback scenarios."
    }
  },
  {
    "id": "SAA-269",
    "domainId": "D2",
    "domain": "Design Resilient Architectures",
    "section": "Outposts",
    "question": "A factory site requires local, single-digit-ms latency and wants to run native AWS services (EC2, EBS, EKS, RDS) on-prem with AWS-managed hardware and the same APIs/console. Which service should you choose?",
    "choices": [
      "AWS Snowball Edge",
      "AWS Outposts",
      "VMware Cloud on AWS",
      "AWS Local Zones"
    ],
    "answer": 1,
    "explanation": "AWS Outposts brings AWS-managed hardware and many AWS services into your on-prem site, using the same AWS APIs/console and providing very low-latency local access.",
    "difficulty": "Medium",
    "choiceExplanations": {
      "0": "This is a portable edge computing and data transfer device designed for temporary deployments, data migration, or disconnected environments, not for running persistent AWS-managed infrastructure on-premises with the full range of services like RDS and EKS.",
      "2": "This service runs VMware workloads on AWS infrastructure in AWS data centers, not on-premises at customer sites, and is designed for VMware-based workloads rather than native AWS services.",
      "3": "These are AWS-managed infrastructure extensions located in metropolitan areas near population centers, not deployed on-premises at customer facilities like a factory site."
    }
  },
  {
    "id": "SAA-270",
    "domainId": "D2",
    "domain": "Design Resilient Architectures",
    "section": "AWS Backup",
    "question": "You need central policy-based backups for RDS, EFS, DynamoDB, EC2/EBS across multiple accounts and Regions with cross-account copy and backup vaults. Which service should you choose?",
    "choices": [
      "CloudFormation custom resources",
      "EBS snapshots with custom scripts",
      "Systems Manager Automation documents",
      "AWS Backup with Backup Policies via AWS Organizations"
    ],
    "answer": 3,
    "explanation": "AWS Backup provides a centralized managed backup service for multiple AWS data sources and supports backup vaults, cross-account copy, and policy-based backup management via AWS Organizations.",
    "difficulty": "Medium",
    "choiceExplanations": {
      "0": "While CloudFormation can trigger Lambda functions for custom backup logic, it is not designed as a backup management service and lacks native support for centralized backup policies, cross-account copy, backup vaults, and multi-service backup coordination across AWS Organizations.",
      "1": "EBS snapshots only cover EBS volumes and EC2 instances, not RDS, EFS, or DynamoDB, and custom scripts require significant operational overhead to manage cross-account, cross-Region backups without the centralized policy management and backup vault features that AWS Backup provides.",
      "2": "While SSM Automation can orchestrate backup-related tasks, it is not a dedicated backup service and lacks native backup vault functionality, built-in cross-account copy capabilities, and centralized backup policy management through AWS Organizations that the question requires."
    }
  },
  {
    "id": "SAA-271",
    "domainId": "D1",
    "domain": "Design Secure Architectures",
    "section": "CloudFormation",
    "question": "Security wants to ensure a stack can only create certain resources (for example, EC2 within specific subnets) even if the template is modified. Which configuration should you use?",
    "choices": [
      "Give CloudFormation full AdministratorAccess",
      "Use stack termination protection only",
      "Attach a dedicated CloudFormation service role with a least-privilege IAM policy",
      "Rely on drift detection"
    ],
    "answer": 2,
    "explanation": "A CloudFormation service role with least-privilege permissions enforces what the stack can create/update, even if someone modifies the template. Termination protection and drift detection don’t restrict what resources can be created.",
    "difficulty": "Medium",
    "choiceExplanations": {
      "0": "This grants CloudFormation unrestricted permissions to create any AWS resource, which directly contradicts the security requirement to limit stack operations to only specific resources like EC2 instances in certain subnets.",
      "1": "Termination protection only prevents accidental deletion of the entire stack; it does not restrict or control which resources can be created or modified within the stack.",
      "3": "Drift detection only identifies when stack resources have been modified outside of CloudFormation after deployment; it does not prevent or restrict the creation of specific resource types during stack operations."
    }
  },
  {
    "id": "SAA-272",
    "domainId": "D3",
    "domain": "Design High-Performing Architectures",
    "section": "Pinpoint",
    "question": "Product needs to send bulk marketing campaigns with segmentation, A/B testing, and analytics dashboards across email and SMS, while engineering will keep transactional emails simple. Which service should you choose for the marketing use case?",
    "choices": [
      "Amazon SES only",
      "SQS",
      "Amazon Pinpoint",
      "SNS"
    ],
    "answer": 2,
    "explanation": "Amazon Pinpoint is designed for marketing engagement at scale (segmentation, campaigns, A/B testing, analytics) across channels like email and SMS. SES alone is better suited for transactional email sending without the marketing campaign features.",
    "difficulty": "Medium",
    "choiceExplanations": {
      "0": "While SES is excellent for sending transactional and bulk emails, it lacks built-in marketing features like customer segmentation, A/B testing, campaign management, and analytics dashboards that are essential for marketing campaigns.",
      "1": "Amazon Simple Queue Service is a message queuing service for decoupling application components, not a communication service for sending emails or SMS to end users, and has no marketing campaign capabilities.",
      "3": "Amazon Simple Notification Service is designed for application-to-application and application-to-person messaging with pub/sub patterns, but lacks marketing-specific features like segmentation, A/B testing, campaign orchestration, and engagement analytics."
    }
  },
  {
    "id": "SAA-273",
    "domainId": "D1",
    "domain": "Design Secure Architectures",
    "section": "Systems Manager",
    "question": "Your EC2 instances are in private subnets with no inbound rules. Ops needs interactive shell and port-forwarding for troubleshooting with full audit logs and no bastion hosts. Which service should you choose?",
    "choices": [
      "A public bastion with SSH keys",
      "AWS Systems Manager Session Manager",
      "Direct Connect",
      "EC2 Instance Connect"
    ],
    "answer": 1,
    "explanation": "SSM Session Manager provides interactive shell access and port forwarding without opening inbound SSH/RDP, and it can log sessions for auditing. This removes the need for bastion hosts.",
    "difficulty": "Medium",
    "choiceExplanations": {
      "0": "This directly contradicts the requirement of 'no bastion hosts' and requires managing SSH keys, opening inbound ports, and maintaining additional infrastructure, while also lacking native audit logging capabilities.",
      "2": "This establishes a dedicated private network connection between on-premises data centers and AWS, but does not provide interactive shell access, port forwarding, or session audit logging capabilities for EC2 instances.",
      "3": "This service requires inbound SSH access (port 22) to be open in security groups, which violates the requirement of 'no inbound rules' and does not natively support port forwarding or comprehensive session audit logging."
    }
  },
  {
    "id": "SAA-274",
    "domainId": "D4",
    "domain": "Design Cost-Optimized Architectures",
    "section": "Billing",
    "question": "Finance wants automatic detection of unusual daily spend and alerts without maintaining per-service thresholds. Which service should you choose?",
    "choices": [
      "AWS Cost Anomaly Detection with monitors and SNS notifications",
      "AWS Budgets with fixed thresholds",
      "Trusted Advisor",
      "Cost Explorer saved reports"
    ],
    "answer": 0,
    "explanation": "AWS Cost Anomaly Detection uses machine learning to detect unusual spend patterns and can alert via monitors (often routed through SNS) without you defining manual per-service thresholds.",
    "difficulty": "Medium",
    "choiceExplanations": {
      "1": "Requires manually setting and maintaining specific dollar amount thresholds for each budget, which contradicts the requirement of not maintaining per-service thresholds and cannot automatically adapt to detect unusual spending patterns.",
      "2": "Provides best practice recommendations across cost optimization, security, performance, and fault tolerance categories, but does not offer automatic anomaly detection or alerting for unusual daily spending patterns.",
      "3": "Enables viewing and analyzing historical cost data through saved queries and visualizations, but does not provide automatic anomaly detection or real-time alerting capabilities for unusual spend."
    }
  },
  {
    "id": "SAA-275",
    "domainId": "D2",
    "domain": "Design Resilient Architectures",
    "section": "MGN",
    "question": "You must migrate hundreds of on-prem VMs to AWS with block-level continuous replication, test cutovers, and a short final cutover window to EC2. Which service should you choose?",
    "choices": [
      "AWS Application Migration Service (MGN)",
      "AWS Database Migration Service",
      "AWS DataSync",
      "VMware Cloud on AWS"
    ],
    "answer": 0,
    "explanation": "AWS Application Migration Service (MGN) performs block-level continuous replication of servers to AWS, supports test cutovers, and enables a short final cutover to EC2. DMS is for databases, and DataSync is file/object transfer (not VM lift-and-shift).",
    "difficulty": "Hard",
    "choiceExplanations": {
      "1": "DMS is specifically designed for migrating databases between different database engines or to AWS database services, not for migrating entire virtual machines with their operating systems and applications to EC2 instances.",
      "2": "DataSync is a data transfer service for moving files and objects between on-premises storage and AWS storage services (S3, EFS, FSx), not for replicating and migrating entire VM workloads with block-level replication to EC2.",
      "3": "This service runs VMware vSphere-based workloads on dedicated AWS infrastructure and maintains the VMware environment, rather than converting and migrating VMs to native EC2 instances as required by the question."
    }
  },
  {
    "id": "SAA-276",
    "domainId": "D1",
    "domain": "Design Secure Architectures",
    "section": "ACM",
    "question": "You are exposing https://app.example.com through an Application Load Balancer (ALB). You want a publicly trusted TLS certificate with automatic renewal and the least operational overhead. Which TWO actions should you take? (Choose TWO.)",
    "choices": [
      "Create a self-signed certificate and upload it to the ALB listener",
      "Create a private certificate using ACM Private CA and attach it to the public ALB",
      "Store the certificate in S3 and configure the ALB to fetch it on startup",
      "Request a public certificate in AWS Certificate Manager (ACM)",
      "Validate the ACM certificate using DNS validation in Route 53"
    ],
    "answer": [
      3,
      4
    ],
    "explanation": "Use ACM public certificates for publicly trusted TLS with managed renewals, and validate via Route 53 DNS. Self-signed and private CA certs are not publicly trusted by default, and ALB does not pull certs from S3.",
    "difficulty": "Easy",
    "choiceExplanations": {
      "0": "Self-signed certificates are not publicly trusted by browsers and will generate security warnings for users, failing the requirement for a publicly trusted TLS certificate. Additionally, manually uploaded certificates do not benefit from ACM's automatic renewal feature, increasing operational overhead.",
      "1": "ACM Private CA certificates are designed for internal resources and are not publicly trusted by browsers or external clients. Using a private certificate for a public-facing application would cause trust errors for users accessing the site.",
      "2": "ALB does not support fetching certificates from S3; certificates must be stored in AWS Certificate Manager (ACM) or AWS Identity and Access Management (IAM). This approach is not a valid configuration option and would require manual certificate management."
    }
  },
  {
    "id": "SAA-277",
    "domainId": "D1",
    "domain": "Design Secure Architectures",
    "section": "IAM",
    "question": "A security team wants to reduce risk by ensuring engineers do not attach permissions directly to individual IAM users, and instead manage permissions at scale. Which TWO practices best meet this goal? (Choose TWO.)",
    "choices": [
      "Store access keys in Parameter Store and share them across users",
      "Use IAM roles for applications and workloads instead of long-term user keys",
      "Enable S3 versioning on all buckets",
      "Use IAM groups with managed policies and add users to groups",
      "Attach policies directly to each IAM user for better visibility"
    ],
    "answer": [
      1,
      3
    ],
    "explanation": "Groups + policies scale permission management for many users. Roles reduce long-term credentials for workloads. The other options do not address scalable user permission management.",
    "difficulty": "Easy",
    "choiceExplanations": {
      "0": "Sharing access keys across users is a security anti-pattern that violates the principle of individual accountability, makes auditing impossible, and increases risk rather than reducing it. AWS best practices recommend unique credentials per user or using IAM roles instead.",
      "2": "S3 versioning is a data protection feature that preserves multiple versions of objects to protect against accidental deletion or overwrites. It has no relationship to IAM permission management or reducing the risk of directly attached user policies.",
      "4": "This approach directly contradicts the goal of the question. Attaching policies to individual users does not scale well, increases management overhead, and is exactly the practice the security team wants to eliminate in favor of group-based permission management."
    }
  },
  {
    "id": "SAA-278",
    "domainId": "D2",
    "domain": "Design Resilient Architectures",
    "section": "Route 53",
    "question": "You run two endpoints in an active-passive setup. If the primary endpoint fails, traffic must automatically shift to the standby. Which TWO Route 53 components do you configure? (Choose TWO.)",
    "choices": [
      "Weighted routing policy",
      "Latency-based routing policy",
      "Geoproximity routing policy",
      "Failover routing policy",
      "A Route 53 health check for the primary endpoint"
    ],
    "answer": [
      3,
      4
    ],
    "explanation": "Failover routing + health checks provide automated primary/secondary DNS failover. Weighted/latency/geoproximity are for different routing goals.",
    "difficulty": "Easy",
    "choiceExplanations": {
      "0": "This distributes traffic across multiple endpoints based on assigned weights (percentages), which is designed for load balancing or gradual migrations, not for automatic failover from a primary to a standby endpoint.",
      "1": "This routes traffic to the endpoint that provides the lowest latency for the user, which optimizes performance across multiple regions but does not provide automatic failover when a primary endpoint becomes unhealthy.",
      "2": "This routes traffic based on the geographic location of users and resources, allowing you to shift traffic by adjusting bias values, but it is designed for geographic traffic distribution rather than active-passive failover scenarios."
    }
  },
  {
    "id": "SAA-279",
    "domainId": "D3",
    "domain": "Design High-Performing Architectures",
    "section": "ELB",
    "question": "A gaming service uses UDP for client-to-server communication and needs a load balancer that supports UDP and can scale to very high throughput. Which TWO AWS services together form the best front-door solution? (Choose TWO.)",
    "choices": [
      "Amazon Route 53",
      "Network Load Balancer",
      "Gateway Load Balancer",
      "Application Load Balancer",
      "AWS Global Accelerator"
    ],
    "answer": [
      1,
      4
    ],
    "explanation": "NLB supports UDP at Layer 4. Global Accelerator can improve global performance and provides static anycast IPs in front of the NLB for worldwide users.",
    "difficulty": "Easy",
    "choiceExplanations": {
      "0": "While Route 53 provides DNS-based routing and health checks, it is not a load balancer and cannot distribute UDP traffic across multiple targets or provide the static anycast IPs and performance optimization that Global Accelerator offers for gaming workloads.",
      "2": "Gateway Load Balancer is designed for deploying, scaling, and managing third-party virtual appliances like firewalls and intrusion detection systems, not for load balancing client-to-server gaming traffic.",
      "3": "ALB operates at Layer 7 (HTTP/HTTPS) and does not support UDP protocol, making it unsuitable for gaming services that require UDP-based communication."
    }
  },
  {
    "id": "SAA-280",
    "domainId": "D4",
    "domain": "Design Cost-Optimized Architectures",
    "section": "S3",
    "question": "You store data that is frequently accessed for 30 days, then rarely accessed but still needs millisecond retrieval afterward. Which TWO storage classes best match this requirement over time? (Choose TWO.)",
    "choices": [
      "S3 Glacier Flexible Retrieval",
      "S3 One Zone-IA",
      "S3 Standard",
      "S3 Standard-IA",
      "S3 Glacier Deep Archive"
    ],
    "answer": [
      2,
      3
    ],
    "explanation": "S3 Standard fits frequent access; S3 Standard-IA fits infrequent access with millisecond retrieval. Glacier classes have longer retrieval times; One Zone-IA is single-AZ and only fits if you accept reduced resilience.",
    "difficulty": "Easy",
    "choiceExplanations": {
      "0": "This storage class does not provide millisecond retrieval times; standard retrieval takes 3-5 hours, expedited retrieval takes 1-5 minutes, making it unsuitable for the millisecond access requirement.",
      "1": "While this class does offer millisecond retrieval for infrequently accessed data, it stores data in only a single Availability Zone, providing reduced durability and availability compared to S3 Standard-IA, which is not ideal when the question implies standard resilience requirements.",
      "4": "This is the lowest-cost storage class designed for long-term archival with retrieval times of 12-48 hours, making it completely unsuitable for the millisecond retrieval requirement."
    }
  },
  {
    "id": "SAA-281",
    "domainId": "D2",
    "domain": "Design Resilient Architectures",
    "section": "Auto Scaling",
    "question": "A web application must remain available during an AZ failure and automatically replace unhealthy instances. Which TWO AWS components should you implement? (Choose TWO.)",
    "choices": [
      "Run instances in a single AZ with a larger instance type",
      "A local database on instance store",
      "An Application Load Balancer across multiple AZs",
      "An Auto Scaling Group spanning at least two AZs",
      "A single EC2 instance with an Elastic IP"
    ],
    "answer": [
      2,
      3
    ],
    "explanation": "ASG across multiple AZs replaces unhealthy instances and maintains capacity. An ALB across AZs distributes traffic and stops routing to unhealthy targets.",
    "difficulty": "Easy",
    "choiceExplanations": {
      "0": "Running instances in a single AZ provides no protection against AZ failure since all instances would be affected if that AZ becomes unavailable, regardless of instance size.",
      "1": "Instance store data is ephemeral and lost when the instance stops or terminates, making it unsuitable for database storage that requires durability; it also doesn't address the AZ failure or automatic instance replacement requirements.",
      "4": "A single instance creates a single point of failure with no redundancy across AZs and no automatic replacement capability when the instance becomes unhealthy."
    }
  },
  {
    "id": "SAA-282",
    "domainId": "D1",
    "domain": "Design Secure Architectures",
    "section": "VPC Endpoints",
    "question": "Instances in private subnets must access Amazon S3 without traversing the public internet and without using a NAT Gateway. Which TWO configuration elements are required? (Choose TWO.)",
    "choices": [
      "A Site-to-Site VPN",
      "An Internet Gateway attached to the VPC",
      "A public Elastic IP on each instance",
      "A Gateway VPC endpoint for S3",
      "A route table entry targeting the S3 Gateway endpoint"
    ],
    "answer": [
      3,
      4
    ],
    "explanation": "Use an S3 Gateway VPC endpoint and add the endpoint route to the private subnet route tables. Internet gateways/EIPs are not needed for private S3 access through the endpoint.",
    "difficulty": "Easy",
    "choiceExplanations": {
      "0": "This establishes a secure connection between an on-premises network and AWS VPC, but does not provide private connectivity to S3 from within AWS; it's used for hybrid connectivity scenarios, not for accessing AWS services privately.",
      "1": "This enables communication between the VPC and the public internet, which directly contradicts the requirement to access S3 without traversing the public internet; Gateway VPC endpoints provide private connectivity without requiring an IGW.",
      "2": "Assigning public IPs to instances in private subnets would require routing through an Internet Gateway and would expose traffic to the public internet, violating the requirement for private S3 access without internet traversal."
    }
  },
  {
    "id": "SAA-283",
    "domainId": "D1",
    "domain": "Design Secure Architectures",
    "section": "CloudTrail",
    "question": "After an incident, you must identify who changed a security group rule, from which IP, and the exact time. Which TWO AWS services/features should be used to capture and retain this information? (Choose TWO.)",
    "choices": [
      "CloudTrail log file delivery to an S3 bucket",
      "AWS CloudTrail management events",
      "AWS WAF logs",
      "Amazon CloudWatch Metrics only",
      "Amazon S3 access logs"
    ],
    "answer": [
      0,
      1
    ],
    "explanation": "CloudTrail management events record the API caller, source IP, and timestamp. Delivering CloudTrail logs to S3 retains the audit history.",
    "difficulty": "Easy",
    "choiceExplanations": {
      "2": "AWS WAF logs capture web request data for applications protected by WAF rules, such as HTTP headers and request patterns, but they do not record AWS API calls or security group changes made through the EC2 service.",
      "3": "CloudWatch Metrics collect numerical performance data like CPU utilization and network throughput, but they do not capture audit information such as who made API calls, source IP addresses, or timestamps of configuration changes.",
      "4": "S3 access logs record requests made to S3 buckets, including object-level operations and requester information, but they do not capture EC2 security group modifications or other AWS service API calls outside of S3."
    }
  },
  {
    "id": "SAA-284",
    "domainId": "D3",
    "domain": "Design High-Performing Architectures",
    "section": "ElastiCache",
    "question": "A web tier needs an in-memory cache for session data with sub-millisecond latency and TTL eviction. Which TWO options are valid managed caching solutions on AWS? (Choose TWO.)",
    "choices": [
      "Amazon S3 Glacier Instant Retrieval",
      "Amazon RDS Multi-AZ",
      "Amazon ElastiCache for Redis",
      "Amazon EFS",
      "Amazon ElastiCache for Memcached"
    ],
    "answer": [
      2,
      4
    ],
    "explanation": "ElastiCache Redis and Memcached are managed in-memory caches. The other services are storage or databases, not in-memory cache engines.",
    "difficulty": "Easy",
    "choiceExplanations": {
      "0": "This is an archival storage class designed for rarely accessed data with millisecond retrieval, not an in-memory caching solution; it lacks TTL eviction features and is optimized for long-term storage rather than session data caching.",
      "1": "This is a managed relational database service with high availability, not an in-memory cache; it stores data on disk and cannot provide the sub-millisecond latency required for session caching workloads.",
      "3": "This is a managed network file system (NFS) for shared file storage across EC2 instances; it is not an in-memory caching solution and does not provide sub-millisecond latency or native TTL eviction capabilities for session data."
    }
  },
  {
    "id": "SAA-285",
    "domainId": "D4",
    "domain": "Design Cost-Optimized Architectures",
    "section": "EC2 Pricing",
    "question": "A team runs a steady baseline of EC2 usage 24/7 but also has unpredictable spikes. Which TWO purchasing models best minimize cost while handling both patterns? (Choose TWO.)",
    "choices": [
      "Dedicated Hosts for spikes",
      "Spot Instances for the baseline with no interruptions",
      "On-Demand Instances for the baseline",
      "Reserved Instances or Savings Plans for the baseline",
      "On-Demand Instances for spikes"
    ],
    "answer": [
      3,
      4
    ],
    "explanation": "Commitments (RI/Savings Plans) reduce baseline cost. On-Demand handles unpredictable spikes without commitment. Spot for baseline risks interruption; Dedicated Hosts increase cost.",
    "difficulty": "Easy",
    "choiceExplanations": {
      "0": "Dedicated Hosts are the most expensive EC2 purchasing option, designed for licensing compliance or regulatory requirements, not cost optimization; using them for unpredictable spikes would significantly increase costs rather than minimize them.",
      "1": "Spot Instances can be interrupted by AWS with a 2-minute warning when capacity is needed, making them unsuitable for baseline workloads that require consistent 24/7 availability without interruptions.",
      "2": "While On-Demand provides flexibility, using it for predictable 24/7 baseline usage is significantly more expensive than Reserved Instances or Savings Plans, which offer up to 72% discount for committed usage."
    }
  },
  {
    "id": "SAA-286",
    "domainId": "D1",
    "domain": "Design Secure Architectures",
    "section": "S3",
    "question": "A bucket must enforce encryption using a specific customer-managed KMS key (CMK). Developers sometimes upload objects without specifying encryption headers. Which TWO controls best enforce the requirement? (Choose TWO.)",
    "choices": [
      "Add a bucket policy condition that requires the specific KMS key ID",
      "Enable default encryption with SSE-S3 only",
      "Enable S3 Transfer Acceleration",
      "Enable default encryption with SSE-KMS using the CMK",
      "Add a bucket policy that denies PutObject unless s3:x-amz-server-side-encryption is aws:kms"
    ],
    "answer": [
      0,
      4
    ],
    "explanation": "Default encryption helps, but enforcement is best done by denying uploads that don’t use SSE-KMS and the required key ID via bucket policy conditions.",
    "difficulty": "Medium",
    "choiceExplanations": {
      "1": "SSE-S3 uses Amazon S3-managed keys, not customer-managed KMS keys (CMKs), so this fails to meet the requirement of enforcing encryption with a specific CMK.",
      "2": "Transfer Acceleration improves upload speeds by routing data through CloudFront edge locations, but has no relation to encryption enforcement or KMS key requirements.",
      "3": "While this applies the CMK to objects uploaded without encryption headers, it does not enforce the requirement because users can still override the default by specifying a different key or encryption method; bucket policies are needed to truly enforce the specific CMK."
    }
  },
  {
    "id": "SAA-287",
    "domainId": "D2",
    "domain": "Design Resilient Architectures",
    "section": "RDS",
    "question": "An OLTP application uses Amazon RDS MySQL. Analytics users need to run heavy read queries without impacting production performance. Which TWO options meet the requirement with the best fit? (Choose TWO.)",
    "choices": [
      "Offload analytics to an Amazon Redshift cluster (ETL/ELT pipeline)",
      "Enable RDS Multi-AZ and route analytics reads to the standby",
      "Use Amazon ElastiCache to cache all analytics queries",
      "Increase the production DB instance size only",
      "Create an RDS Read Replica and route analytics reads to it"
    ],
    "answer": [
      0,
      4
    ],
    "explanation": "Read replicas offload read traffic from the primary. Redshift is purpose-built for analytics and can be a better long-term warehouse. Multi-AZ standby isn’t for reads, and resizing alone doesn’t prevent contention.",
    "difficulty": "Medium",
    "choiceExplanations": {
      "1": "The Multi-AZ standby instance is designed solely for failover purposes and cannot serve read traffic; it remains passive and inaccessible for queries until a failover event occurs.",
      "2": "ElastiCache is designed for caching frequently accessed data with low latency, but analytics queries are typically complex, ad-hoc queries against large datasets that are not suitable for caching and would not benefit from this approach.",
      "3": "Simply scaling up the instance provides more resources but does not isolate analytics workloads from production OLTP traffic, meaning heavy analytics queries would still compete for resources and potentially impact production performance."
    }
  },
  {
    "id": "SAA-288",
    "domainId": "D2",
    "domain": "Design Resilient Architectures",
    "section": "SQS",
    "question": "Your SQS-triggered Lambda sometimes processes messages for up to 12 minutes. You want to prevent duplicate processing and also control concurrency so downstream RDS is not overwhelmed. Which TWO configurations should you apply? (Choose TWO.)",
    "choices": [
      "Set SQS visibility timeout greater than the maximum processing time",
      "Switch to an SNS topic instead of SQS",
      "Increase Lambda memory to maximum",
      "Enable SQS long polling at 20 seconds",
      "Set a Reserved Concurrency limit on the Lambda function"
    ],
    "answer": [
      0,
      4
    ],
    "explanation": "Visibility timeout prevents re-delivery during processing. Reserved Concurrency caps parallel executions and protects RDS. Long polling reduces empty receives but doesn’t stop duplicates or throttle concurrency.",
    "difficulty": "Medium",
    "choiceExplanations": {
      "1": "SNS is a push-based pub/sub service that does not provide message persistence, visibility timeout, or built-in retry mechanisms like SQS, making it unsuitable for preventing duplicate processing of long-running tasks and would not address the concurrency control requirement.",
      "2": "While increasing Lambda memory also increases CPU allocation and may speed up processing, it does not prevent duplicate message processing (which requires proper visibility timeout) nor does it control concurrency to protect downstream RDS from being overwhelmed.",
      "3": "Long polling reduces the number of empty responses and API costs by waiting for messages to arrive, but it does not prevent duplicate processing (that requires visibility timeout) and does not control Lambda concurrency to protect downstream resources."
    }
  },
  {
    "id": "SAA-289",
    "domainId": "D3",
    "domain": "Design High-Performing Architectures",
    "section": "CloudFront",
    "question": "A global website serves mostly cacheable content. The company wants lower latency worldwide and reduced origin load. Which TWO services should be used together to meet this goal? (Choose TWO.)",
    "choices": [
      "Amazon CloudFront",
      "AWS Storage Gateway",
      "Amazon Route 53 Resolver inbound endpoints",
      "An Application Load Balancer as the origin",
      "AWS Global Accelerator only (no CDN)"
    ],
    "answer": [
      0,
      3
    ],
    "explanation": "CloudFront caches content at edge locations. ALB can serve as a scalable origin (routing to multiple targets) for dynamic and cacheable content.",
    "difficulty": "Medium",
    "choiceExplanations": {
      "1": "This service is designed for hybrid cloud storage integration between on-premises environments and AWS storage services (S3, EBS, Glacier), not for content delivery or reducing latency for global website users.",
      "2": "These endpoints allow DNS queries from on-premises networks to resolve AWS-hosted domain names, which is unrelated to content caching, latency reduction, or origin load reduction for web content delivery.",
      "4": "While Global Accelerator improves performance by routing traffic through AWS's global network, it does not cache content at edge locations, so it cannot reduce origin load for cacheable content like CloudFront does."
    }
  },
  {
    "id": "SAA-290",
    "domainId": "D4",
    "domain": "Design Cost-Optimized Architectures",
    "section": "S3",
    "question": "You have tens of millions of objects with unpredictable access patterns. You want automatic tiering without app changes and millisecond access when requested. Which TWO S3 options can satisfy this pattern? (Choose TWO.)",
    "choices": [
      "S3 Intelligent-Tiering",
      "S3 Standard-IA only",
      "S3 Glacier Deep Archive",
      "S3 One Zone-IA only",
      "S3 Lifecycle rules transitioning between Standard and Standard-IA"
    ],
    "answer": [
      0,
      4
    ],
    "explanation": "Intelligent-Tiering automatically optimizes based on access. Lifecycle transitions (Standard ↔ IA patterns) can reduce cost without app changes, though they’re rule-based rather than automatic learning. Deep Archive won’t meet millisecond access.",
    "difficulty": "Medium",
    "choiceExplanations": {
      "1": "This is a static storage class that does not provide automatic tiering capabilities; it requires manual or lifecycle-based transitions and charges retrieval fees, making it unsuitable for unpredictable access patterns without additional configuration.",
      "2": "This storage class is designed for long-term archival with retrieval times of 12-48 hours, which does not meet the millisecond access requirement specified in the question.",
      "3": "This is a static storage class without automatic tiering capabilities; it stores data in a single Availability Zone and requires manual management or lifecycle rules to transition objects, not providing the automatic optimization needed for unpredictable access patterns."
    }
  },
  {
    "id": "SAA-291",
    "domainId": "D1",
    "domain": "Design Secure Architectures",
    "section": "Organizations",
    "question": "A company wants to centrally enforce that no account in an OU can disable CloudTrail or stop log delivery. Which TWO mechanisms are most appropriate? (Choose TWO.)",
    "choices": [
      "Service Control Policies (SCPs) denying cloudtrail:StopLogging and s3:PutBucketPolicy changes",
      "Security groups denying outbound HTTPS",
      "CloudFront Functions",
      "IAM inline policies on each developer user",
      "AWS Control Tower guardrails (detective/preventive) where applicable"
    ],
    "answer": [
      0,
      4
    ],
    "explanation": "SCPs set maximum permissions for accounts and can prevent disabling CloudTrail. Control Tower guardrails help enforce and monitor required configurations at scale.",
    "difficulty": "Medium",
    "choiceExplanations": {
      "1": "Security groups control network traffic at the instance level and have no capability to restrict AWS API actions like stopping CloudTrail logging, which is an IAM/policy-level control requirement.",
      "2": "CloudFront Functions are used to customize content delivery at edge locations for HTTP request/response manipulation and have no relationship to enforcing CloudTrail logging policies or account-level governance controls.",
      "3": "IAM policies only apply to the specific principals they are attached to and can be modified or removed by account administrators, making them unsuitable for centralized enforcement across an entire OU since they lack the hierarchical control that SCPs provide from the management account."
    }
  },
  {
    "id": "SAA-292",
    "domainId": "D2",
    "domain": "Design Resilient Architectures",
    "section": "DataSync",
    "question": "You need to migrate 150 TB from an on-prem NFS server to Amazon EFS with metadata preservation, scheduling, and incremental sync. Which TWO components are required? (Choose TWO.)",
    "choices": [
      "AWS DataSync agent deployed on-prem",
      "Amazon EBS snapshots of the NFS server",
      "AWS Transfer Family SFTP server in AWS",
      "Amazon CloudFront distribution",
      "An AWS DataSync task configured from NFS to EFS"
    ],
    "answer": [
      0,
      4
    ],
    "explanation": "DataSync uses an on-prem agent plus a configured DataSync task to move data from NFS to EFS with scheduling and verification.",
    "difficulty": "Medium",
    "choiceExplanations": {
      "1": "EBS snapshots are point-in-time backups of EBS volumes attached to EC2 instances, not a mechanism for migrating data from on-premises NFS servers. They cannot capture or transfer data from external NFS sources and do not support incremental sync or scheduling for migrations.",
      "2": "AWS Transfer Family provides managed SFTP, FTPS, and FTP services for transferring files into and out of Amazon S3 or EFS, but it is designed for interactive file transfers rather than large-scale data migrations with scheduling, metadata preservation, and incremental synchronization capabilities.",
      "3": "CloudFront is a content delivery network (CDN) service that caches and delivers content to end users with low latency. It has no capability for data migration, metadata preservation, or synchronization between on-premises storage and AWS storage services."
    }
  },
  {
    "id": "SAA-293",
    "domainId": "D3",
    "domain": "Design High-Performing Architectures",
    "section": "Kinesis",
    "question": "A team needs near real-time ingestion of clickstream events with multiple independent consumers and replay capability for 48 hours. Which TWO statements about the correct service are true? (Choose TWO.)",
    "choices": [
      "Amazon SNS provides ordered replay for 48 hours by default",
      "Amazon Kinesis Data Streams is suited for low-latency stream processing",
      "Amazon Kinesis Data Streams supports multiple consumers and configurable retention for replay",
      "Amazon Kinesis Data Firehose is best for sub-second consumer processing with replay",
      "Amazon SQS Standard guarantees strict ordering for all messages"
    ],
    "answer": [
      1,
      2
    ],
    "explanation": "Kinesis Data Streams supports low-latency processing, multiple consumers, and retention for replay. Firehose is optimized for delivery to destinations, not multi-consumer replay-first patterns.",
    "difficulty": "Medium",
    "choiceExplanations": {
      "0": "Amazon SNS is a pub/sub messaging service that does not store messages for replay; once a message is delivered to subscribers, it is not retained, so SNS has no replay capability at all.",
      "3": "Kinesis Data Firehose is designed for near real-time delivery to destinations like S3, Redshift, or OpenSearch with minimum buffering of 60 seconds; it does not support multiple independent consumers or native replay functionality.",
      "4": "SQS Standard queues provide best-effort ordering only and do not guarantee strict message ordering; only SQS FIFO queues guarantee strict ordering, and neither provides replay capability since messages are deleted after processing."
    }
  },
  {
    "id": "SAA-294",
    "domainId": "D1",
    "domain": "Design Secure Architectures",
    "section": "VPC",
    "question": "Workloads are IPv6-only in private subnets and must reach the internet outbound, but must not be reachable inbound from the internet. Which TWO items are part of the correct solution? (Choose TWO.)",
    "choices": [
      "VPC peering to a public VPC",
      "Routes in private subnet route tables to the egress-only internet gateway for ::/0",
      "Internet Gateway with inbound security group rules opened",
      "Egress-only Internet Gateway",
      "NAT Gateway"
    ],
    "answer": [
      1,
      3
    ],
    "explanation": "For IPv6 outbound-only internet, use an egress-only IGW and add ::/0 routes to it from private subnets. NAT Gateway is for IPv4.",
    "difficulty": "Medium",
    "choiceExplanations": {
      "0": "VPC peering connects two VPCs for private communication between them but does not provide internet access; traffic cannot transit through a peered VPC to reach the internet, making this irrelevant for outbound internet connectivity.",
      "2": "A standard Internet Gateway allows bidirectional traffic (both inbound and outbound) for IPv6, which violates the requirement that workloads must not be reachable inbound from the internet; security groups alone cannot prevent all inbound internet-initiated traffic to IPv6 resources.",
      "4": "NAT Gateway only supports IPv4 traffic and cannot be used for IPv6 workloads; for IPv6 outbound-only internet access, an Egress-only Internet Gateway is the required component."
    }
  },
  {
    "id": "SAA-295",
    "domainId": "D4",
    "domain": "Design Cost-Optimized Architectures",
    "section": "Compute",
    "question": "A containerized batch job runs nightly for 2 hours and is not time-sensitive. The team wants to minimize cost and avoid managing servers. Which TWO compute options are the best fit? (Choose TWO.)",
    "choices": [
      "AWS Lambda with a 3-hour timeout",
      "Amazon EC2 Dedicated Hosts",
      "AWS Batch with a Fargate compute environment",
      "Amazon ECS on Fargate with scheduled tasks",
      "Amazon EKS with self-managed nodes kept running 24/7"
    ],
    "answer": [
      2,
      3
    ],
    "explanation": "Batch on Fargate or ECS Fargate scheduled tasks meet serverless container execution and reduce idle costs. Lambda cannot run for hours, and always-on node fleets increase cost.",
    "difficulty": "Medium",
    "choiceExplanations": {
      "0": "Lambda has a maximum execution timeout of 15 minutes, making a 3-hour timeout impossible and unsuitable for a 2-hour batch job.",
      "1": "Dedicated Hosts are the most expensive EC2 option, designed for licensing compliance and hardware isolation, and require server management which contradicts the requirement to avoid managing servers.",
      "4": "Running nodes continuously for a job that only runs 2 hours nightly wastes 22 hours of compute costs daily, and self-managed nodes require server management which the team wants to avoid."
    }
  },
  {
    "id": "SAA-296",
    "domainId": "D1",
    "domain": "Design Secure Architectures",
    "section": "KMS",
    "question": "A company replicates encrypted objects from us-east-1 to eu-west-1. They must decrypt in both Regions without re-encrypting and ensure keys remain cryptographically equivalent. Which TWO KMS actions/features should be used? (Choose TWO.)",
    "choices": [
      "Use a single-region key and share it directly into eu-west-1",
      "Create a replica key in eu-west-1 for the multi-Region key",
      "Use unrelated CMKs in each Region but keep the same alias name",
      "Create a KMS multi-Region primary key in us-east-1",
      "Use SSE-S3 because it decrypts cross-Region automatically"
    ],
    "answer": [
      1,
      3
    ],
    "explanation": "Multi-Region keys are designed for cross-Region encrypt/decrypt without re-encryption by using linked primary + replica keys that are cryptographically equivalent.",
    "difficulty": "Hard",
    "choiceExplanations": {
      "0": "Single-region KMS keys cannot be shared or used directly in another Region; they are confined to the Region where they were created and cannot decrypt data in a different Region without re-encryption.",
      "2": "Using separate unrelated CMKs means they have different key material and are not cryptographically equivalent; data encrypted with one key cannot be decrypted by the other, requiring re-encryption during replication.",
      "4": "SSE-S3 uses Amazon-managed keys that are Region-specific; when objects are replicated cross-Region, they are re-encrypted with the destination Region's key, which does not meet the requirement of keys being cryptographically equivalent without re-encryption."
    }
  },
  {
    "id": "SAA-297",
    "domainId": "D1",
    "domain": "Design Secure Architectures",
    "section": "S3",
    "question": "S3 Cross-Region Replication is enabled for a source bucket using SSE-KMS. Replication fails due to access errors on the destination KMS key. Which TWO changes are most likely required to fix it while keeping destination objects SSE-KMS encrypted? (Choose TWO.)",
    "choices": [
      "Ensure the replication IAM role has permissions to replicate objects to the destination bucket (s3:ReplicateObject, s3:ReplicateDelete, etc.)",
      "Turn off SSE-KMS on the source bucket",
      "Disable versioning on the destination bucket to reduce complexity",
      "Create an S3 Transfer Acceleration endpoint",
      "Update the destination KMS key policy to allow the replication IAM role to use kms:Encrypt and kms:GenerateDataKey"
    ],
    "answer": [
      0,
      4
    ],
    "explanation": "CRR with SSE-KMS needs (1) S3 permissions for replication and (2) KMS key policy permissions on the destination CMK so the replication role can encrypt (and generate data keys).",
    "difficulty": "Hard",
    "choiceExplanations": {
      "1": "This would not fix the replication issue and contradicts the requirement to keep destination objects SSE-KMS encrypted; the problem is permissions on the destination KMS key, not the source encryption configuration.",
      "2": "Versioning is a mandatory prerequisite for S3 Cross-Region Replication on both source and destination buckets; disabling it would completely break replication rather than fix it.",
      "3": "Transfer Acceleration is used to speed up uploads to S3 over long distances using CloudFront edge locations; it has no relationship to Cross-Region Replication or KMS key access permissions."
    }
  },
  {
    "id": "SAA-298",
    "domainId": "D1",
    "domain": "Design Secure Architectures",
    "section": "Organizations",
    "question": "A security team wants to ensure that even admins in member accounts cannot create internet-facing load balancers and cannot disable GuardDuty. The company uses AWS Organizations. Which TWO controls best enforce these requirements at scale? (Choose TWO.)",
    "choices": [
      "IAM policies on each admin user, manually maintained per account",
      "Security groups that block 0.0.0.0/0",
      "Permission boundaries attached to every IAM role in every account",
      "AWS Config rules only, with email notifications",
      "SCPs that explicitly deny elasticloadbalancing:CreateLoadBalancer with scheme=internet-facing and guardduty:DeleteDetector/StopMonitoringMembers"
    ],
    "answer": [
      2,
      4
    ],
    "explanation": "SCPs enforce maximum permissions across accounts. Permission boundaries further constrain what IAM roles/users can do even when admins try to expand permissions. Config alone is detective, not preventive.",
    "difficulty": "Hard",
    "choiceExplanations": {
      "0": "This approach does not scale across an organization with multiple accounts, requires manual maintenance that is error-prone, and admin users with sufficient privileges could potentially modify or remove these policies themselves, defeating the security control.",
      "1": "Security groups control network traffic to resources, not the creation of resources; they cannot prevent the creation of internet-facing load balancers or stop GuardDuty from being disabled, as these are API-level actions that require IAM-based controls.",
      "3": "AWS Config rules are detective controls that identify non-compliant resources after they are created and can send notifications, but they do not preventively block the creation of internet-facing load balancers or the disabling of GuardDuty."
    }
  },
  {
    "id": "SAA-299",
    "domainId": "D2",
    "domain": "Design Resilient Architectures",
    "section": "Disaster Recovery",
    "question": "A critical payments platform requires minutes-level RTO and low RPO across two Regions, but cannot justify active/active cost. The secondary Region should run a scaled-down environment that can rapidly scale during failover. Which TWO elements best describe the correct approach? (Choose TWO.)",
    "choices": [
      "Backup and restore strategy",
      "Keep only backups in S3 Glacier Deep Archive and restore during disaster",
      "Warm Standby strategy",
      "Keep a minimal but running copy of the application stack in the secondary Region",
      "Multi-Region active/active with continuous traffic splitting"
    ],
    "answer": [
      2,
      3
    ],
    "explanation": "Warm standby keeps a reduced-capacity but running environment in the secondary Region and scales up on failover, providing minutes-level RTO with lower cost than active/active.",
    "difficulty": "Hard",
    "choiceExplanations": {
      "0": "This approach has the longest RTO (hours to days) among DR strategies because it requires restoring infrastructure and data from backups during a disaster, which cannot meet the minutes-level RTO requirement for a critical payments platform.",
      "1": "S3 Glacier Deep Archive has retrieval times of 12-48 hours, making it completely unsuitable for minutes-level RTO requirements; this is the slowest and lowest-cost DR approach designed for rarely accessed archival data.",
      "4": "While this provides the lowest RTO/RPO, the question explicitly states the organization cannot justify active/active costs; this approach requires running full capacity in both Regions simultaneously, making it the most expensive DR option."
    }
  },
  {
    "id": "SAA-300",
    "domainId": "D3",
    "domain": "Design High-Performing Architectures",
    "section": "CloudFront",
    "question": "A CloudFront distribution must run lightweight JavaScript code to modify requests and responses at the edge with sub-millisecond latency. What is the BEST solution?",
    "choices": [
      "Lambda@Edge functions",
      "CloudFront Functions",
      "API Gateway with Lambda",
      "AWS AppSync"
    ],
    "answer": 1,
    "explanation": "CloudFront Functions are designed for lightweight, sub-millisecond latency JavaScript execution at the edge. They are ideal for simple request/response transformations like header manipulation, URL rewrites, and authorization. Lambda@Edge is better for more complex operations but has higher latency.",
    "difficulty": "Hard",
    "choiceExplanations": {
      "0": "While Lambda@Edge can modify requests and responses at edge locations, it has higher latency (typically milliseconds to seconds) compared to CloudFront Functions' sub-millisecond execution, making it better suited for complex operations rather than lightweight, latency-sensitive transformations.",
      "2": "This solution runs at AWS regional endpoints rather than at CloudFront edge locations, introducing significant network latency and not meeting the sub-millisecond requirement for edge-based request/response modifications.",
      "3": "This is a managed GraphQL service for building APIs and is not designed for modifying CloudFront requests and responses at the edge; it serves a completely different purpose than edge-based request manipulation."
    }
  },
  {
    "id": "SAA-301",
    "domainId": "D2",
    "domain": "Design Resilient Architectures",
    "section": "Networking",
    "question": "A company needs to connect dozens of VPCs across accounts plus on-prem networks in a hub-and-spoke topology, with centralized routing, route propagation, and minimal operational overhead. Which TWO statements describe the best solution? (Choose TWO.)",
    "choices": [
      "A separate Site-to-Site VPN per VPC is the simplest at large scale",
      "VPC Peering is preferred because it automatically provides transitive routing",
      "AWS Transit Gateway provides hub-and-spoke connectivity and centralized route tables",
      "Transit Gateway attachments simplify connecting many VPCs without a full mesh",
      "Direct Connect alone automatically connects VPC-to-VPC routing without a hub"
    ],
    "answer": [
      2,
      3
    ],
    "explanation": "Transit Gateway is built for centralized connectivity and avoids complex peering meshes. VPC peering is non-transitive and becomes operationally complex at scale.",
    "difficulty": "Hard",
    "choiceExplanations": {
      "0": "Managing dozens of individual VPN connections creates significant operational overhead and complexity, whereas Transit Gateway allows you to terminate a single VPN connection that can route to all attached VPCs.",
      "1": "VPC Peering explicitly does NOT support transitive routing - traffic cannot pass through one VPC to reach another peered VPC, requiring a full mesh of peering connections at scale which becomes operationally complex.",
      "4": "Direct Connect provides connectivity between on-premises and AWS but does not enable VPC-to-VPC routing by itself; you need Transit Gateway or another mechanism to route traffic between VPCs over Direct Connect."
    }
  },
  {
    "id": "SAA-302",
    "domainId": "D1",
    "domain": "Design Secure Architectures",
    "section": "EKS",
    "question": "An EKS cluster runs workloads that must access DynamoDB securely without storing long-term AWS keys in pods. The solution must use IAM policies and be least privilege. Which TWO actions should you take? (Choose TWO.)",
    "choices": [
      "Store AWS access keys in a ConfigMap and mount it into pods",
      "Enable IAM Roles for Service Accounts (IRSA) and map a Kubernetes service account to an IAM role",
      "Expose DynamoDB through a public ALB and use basic auth",
      "Assign AdministratorAccess to the node instance role so pods inherit it",
      "Attach a least-privilege IAM policy to the IRSA IAM role allowing required DynamoDB actions"
    ],
    "answer": [
      1,
      4
    ],
    "explanation": "IRSA provides short-lived credentials to pods via an IAM role bound to a service account. Attach only the required DynamoDB permissions to that role for least privilege.",
    "difficulty": "Hard",
    "choiceExplanations": {
      "0": "This violates the requirement to avoid storing long-term AWS keys, as ConfigMaps store data in plain text and access keys are static credentials that pose security risks if exposed or compromised.",
      "2": "DynamoDB is a managed service accessed via AWS APIs, not through ALBs, and basic authentication does not integrate with IAM policies, making this approach both architecturally incorrect and insecure.",
      "3": "This violates the least privilege principle by granting excessive permissions to all pods on the node, and AWS recommends using IRSA instead of node instance roles to provide granular, pod-level IAM permissions."
    }
  },
  {
    "id": "SAA-303",
    "domainId": "D2",
    "domain": "Design Resilient Architectures",
    "section": "RDS",
    "question": "A company needs a very short, controlled database upgrade cutover and the ability to quickly roll back if issues occur. They are using Amazon RDS for MySQL and upgrading a major version. Which TWO steps/features best match this requirement? (Choose TWO.)",
    "choices": [
      "Switch over to the green environment during a controlled maintenance window",
      "Rely on Multi-AZ failover to downgrade automatically",
      "Use RDS Blue/Green Deployments to create a synchronized green environment",
      "Use S3 Lifecycle policies to archive old database logs",
      "Perform the major upgrade directly on the production instance during business hours"
    ],
    "answer": [
      0,
      2
    ],
    "explanation": "Blue/Green provides a synchronized staging environment to upgrade safely, then switch over with a short cutover. Multi-AZ is HA, not version rollback.",
    "difficulty": "Hard",
    "choiceExplanations": {
      "1": "Multi-AZ failover is designed for high availability during infrastructure failures, not for version rollback. When a major version upgrade occurs, both primary and standby instances are upgraded together, so Multi-AZ cannot automatically downgrade to a previous database version.",
      "3": "S3 Lifecycle policies manage object storage transitions and expiration for cost optimization, not database version management. Archiving logs has no relevance to database upgrade cutover or rollback capabilities.",
      "4": "Performing a major upgrade directly on production is risky and does not provide quick rollback capability. This approach causes extended downtime during the upgrade process and would require restoring from a backup to roll back, which is neither short nor controlled."
    }
  },
  {
    "id": "SAA-304",
    "domainId": "D4",
    "domain": "Design Cost-Optimized Architectures",
    "section": "S3",
    "question": "You must update tags on 50 million objects across multiple S3 buckets and you need progress reporting with minimal custom code. Which TWO items form the most native, operationally simple solution? (Choose TWO.)",
    "choices": [
      "Provide an S3 Batch Operations manifest listing objects to update",
      "Use S3 Transfer Acceleration to speed up tagging API calls",
      "Use S3 Batch Operations to run a PutObjectTagging job",
      "Use S3 Storage Lens to apply tags",
      "Write a custom script with thousands of parallel threads and no job tracking"
    ],
    "answer": [
      0,
      2
    ],
    "explanation": "S3 Batch Operations is built for massive-scale object actions and provides job tracking/reporting. A manifest is the standard way to define the object set for the batch job.",
    "difficulty": "Hard",
    "choiceExplanations": {
      "1": "S3 Transfer Acceleration is designed to speed up data transfers over long distances by routing through CloudFront edge locations, but it only applies to PUT and GET operations for object content, not metadata operations like tagging API calls.",
      "3": "S3 Storage Lens is an analytics feature that provides organization-wide visibility into object storage usage and activity trends, but it is a read-only reporting tool and cannot modify objects or apply tags.",
      "4": "This approach contradicts the requirement for minimal custom code and progress reporting, as it requires significant development effort, lacks built-in job tracking, and increases operational complexity compared to the native S3 Batch Operations service."
    }
  },
  {
    "id": "SAA-305",
    "domainId": "D2",
    "domain": "Design Resilient Architectures",
    "section": "Migration",
    "question": "You must migrate hundreds of on-prem VMs to AWS with block-level continuous replication, support test cutovers, and keep the final cutover window short. Which TWO statements describe the correct service/approach? (Choose TWO.)",
    "choices": [
      "S3 Batch Operations is used to replicate running VM disks",
      "AWS DMS is the primary service for lift-and-shift VM replication to EC2",
      "AWS Application Migration Service (MGN) performs block-level replication for server migrations",
      "AWS DataSync is designed for VM block-level replication and cutover orchestration",
      "MGN supports launching test instances in AWS before final cutover"
    ],
    "answer": [
      2,
      4
    ],
    "explanation": "MGN is purpose-built for lift-and-shift server migrations with continuous block-level replication and test cutovers. DataSync is for file transfers; DMS is for databases.",
    "difficulty": "Hard",
    "choiceExplanations": {
      "0": "S3 Batch Operations is designed to perform large-scale batch operations on S3 objects (like copying, tagging, or invoking Lambda functions), not for replicating running VM disks or block-level data from on-premises servers.",
      "1": "AWS Database Migration Service (DMS) is specifically designed for migrating databases between different database engines or to AWS database services, not for replicating entire virtual machines or server workloads to EC2 instances.",
      "3": "AWS DataSync is a data transfer service designed for moving large amounts of file-based data between on-premises storage and AWS storage services (S3, EFS, FSx), not for block-level VM replication or migration cutover orchestration."
    }
  },
  {
    "id": "SAA-306",
    "domainId": "D1",
    "domain": "Design Secure Architectures",
    "section": "IAM",
    "question": "A new AWS account was created for production. Which TWO best practices should be applied to the root user right away? (Choose TWO.)",
    "choices": [
      "Enable MFA on the root user",
      "Share the root password with the DevOps team for emergencies",
      "Use the root user only for tasks that specifically require it",
      "Attach AdministratorAccess to all IAM users instead of using the root user",
      "Create access keys for the root user for daily CLI use"
    ],
    "answer": [
      0,
      2
    ],
    "explanation": "Enable MFA on the root user and avoid using it for day-to-day operations; use it only when required.",
    "difficulty": "Easy",
    "choiceExplanations": {
      "1": "Sharing root credentials violates AWS security best practices as it eliminates accountability, increases exposure risk, and makes it impossible to track who performed actions; instead, create individual IAM users with appropriate permissions.",
      "3": "Granting AdministratorAccess to all IAM users violates the principle of least privilege; users should only receive the minimum permissions necessary to perform their specific job functions.",
      "4": "AWS strongly recommends against creating access keys for the root user as this increases security risk; if compromised, attackers would have unrestricted access to all resources and billing in the account."
    }
  },
  {
    "id": "SAA-308",
    "domainId": "D1",
    "domain": "Design Secure Architectures",
    "section": "Networking",
    "question": "Your EC2 instances are in private subnets and must download patches from the internet without being directly reachable from the internet. Which TWO components are typically required? (Choose TWO.)",
    "choices": [
      "Route table in the private subnet pointing 0.0.0.0/0 to the NAT Gateway",
      "VPC peering to a public VPC owned by AWS",
      "Internet Gateway attached to the VPC",
      "NAT Gateway in a public subnet",
      "An ALB in front of the instances to provide outbound internet"
    ],
    "answer": [
      0,
      3
    ],
    "explanation": "Private subnets use a NAT Gateway for outbound internet access, plus a route to the NAT in the private route table.",
    "difficulty": "Easy",
    "choiceExplanations": {
      "1": "AWS does not provide a public VPC for customers to peer with for internet access; VPC peering connects two VPCs for private communication and does not provide internet connectivity.",
      "2": "While an Internet Gateway is required for the NAT Gateway to reach the internet, the question asks for components typically required and this choice alone doesn't enable private subnet instances to access the internet without the NAT Gateway and route table configuration.",
      "4": "Application Load Balancers handle inbound traffic distribution to targets and do not provide outbound internet access for instances; ALBs are Layer 7 load balancers for incoming HTTP/HTTPS requests."
    }
  },
  {
    "id": "SAA-309",
    "domainId": "D2",
    "domain": "Design Resilient Architectures",
    "section": "EC2",
    "question": "By default, what happens to an EC2 instance’s root EBS volume when the instance is terminated?",
    "choices": [
      "It is deleted by default",
      "It is automatically snapshotted",
      "It is moved to another AZ",
      "It is always kept"
    ],
    "answer": 0,
    "explanation": "The default behavior is to delete the root EBS volume on termination (unless you change the DeleteOnTermination flag).",
    "difficulty": "Easy",
    "choiceExplanations": {
      "1": "AWS does not automatically create snapshots of root EBS volumes upon instance termination; snapshots must be created manually or through automated backup solutions like AWS Backup or custom scripts before termination.",
      "2": "EBS volumes cannot be moved between Availability Zones; they are bound to a single AZ, and the root volume is simply deleted upon termination by default, not relocated.",
      "3": "This is incorrect because the default DeleteOnTermination attribute for root EBS volumes is set to true, meaning the volume is deleted when the instance terminates unless this setting is explicitly changed to false."
    }
  },
  {
    "id": "SAA-310",
    "domainId": "D3",
    "domain": "Design High-Performing Architectures",
    "section": "Access",
    "question": "Which TWO are valid ways to access AWS services programmatically? (Choose TWO.)",
    "choices": [
      "AWS SDKs",
      "Remote Desktop Protocol (RDP) to the AWS Console",
      "FTP client",
      "AWS CLI",
      "Telnet"
    ],
    "answer": [
      0,
      3
    ],
    "explanation": "Programmatic access is typically done using the AWS CLI or AWS SDKs (which call AWS APIs).",
    "difficulty": "Easy",
    "choiceExplanations": {
      "1": "RDP is a graphical remote access protocol used to connect to Windows instances, not for programmatic API access to AWS services; additionally, the AWS Console is a web-based interface accessed via HTTPS, not RDP.",
      "2": "FTP is a file transfer protocol and is not a method for programmatic access to AWS services; AWS APIs use HTTPS-based REST/Query protocols, not FTP.",
      "4": "Telnet is an insecure text-based remote terminal protocol and is not supported for accessing AWS services programmatically; AWS requires secure HTTPS connections for API calls."
    }
  },
  {
    "id": "SAA-311",
    "domainId": "D3",
    "domain": "Design High-Performing Architectures",
    "section": "ELB",
    "question": "Which load balancer is best suited for HTTP/HTTPS traffic with features like host-based and path-based routing?",
    "choices": [
      "Application Load Balancer (ALB)",
      "Network Load Balancer (NLB)",
      "Gateway Load Balancer (GWLB)",
      "Classic Load Balancer (CLB) only"
    ],
    "answer": 0,
    "explanation": "ALB is Layer 7 and supports routing features like host-based and path-based rules.",
    "difficulty": "Easy",
    "choiceExplanations": {
      "1": "NLB operates at Layer 4 (TCP/UDP) and is designed for ultra-low latency and high throughput, but it does not support Layer 7 features like host-based or path-based routing since it cannot inspect HTTP headers or URL paths.",
      "2": "GWLB operates at Layer 3 and is designed for deploying, scaling, and managing third-party virtual appliances like firewalls and intrusion detection systems, not for HTTP/HTTPS application routing features.",
      "3": "CLB is a legacy load balancer that provides basic Layer 4 and Layer 7 load balancing but does not support advanced routing features like host-based or path-based routing that ALB provides."
    }
  },
  {
    "id": "SAA-312",
    "domainId": "D2",
    "domain": "Design Resilient Architectures",
    "section": "Auto Scaling",
    "question": "You want your application to automatically add EC2 instances during high load and replace unhealthy instances. Which TWO AWS components are the standard solution? (Choose TWO.)",
    "choices": [
      "Auto Scaling Group (ASG)",
      "AWS Snowball Edge",
      "Amazon Route 53 private hosted zone only",
      "Application Load Balancer (ALB)",
      "Amazon S3 lifecycle policies"
    ],
    "answer": [
      0,
      3
    ],
    "explanation": "An ASG handles scaling and health-based replacement, while an ALB distributes traffic and removes unhealthy targets.",
    "difficulty": "Easy",
    "choiceExplanations": {
      "1": "This is a physical data transfer and edge computing device used for migrating large amounts of data to AWS or running workloads in disconnected environments, not for scaling or managing EC2 instances.",
      "2": "Route 53 private hosted zones provide DNS resolution within VPCs for internal resources, but they do not provide automatic scaling, health-based instance replacement, or traffic distribution for EC2 instances.",
      "4": "These are rules that automatically transition S3 objects between storage classes or delete objects after specified time periods, and have no relation to EC2 instance scaling or health management."
    }
  },
  {
    "id": "SAA-313",
    "domainId": "D4",
    "domain": "Design Cost-Optimized Architectures",
    "section": "EC2 Pricing",
    "question": "Which EC2 purchase option is typically best for short, unpredictable workloads with no long-term commitment?",
    "choices": [
      "Reserved Instances (3-year)",
      "Dedicated Hosts",
      "Savings Plans (3-year)",
      "On-Demand Instances"
    ],
    "answer": 3,
    "explanation": "On-Demand is best for short, unpredictable workloads because it has no long-term commitment.",
    "difficulty": "Easy",
    "choiceExplanations": {
      "0": "Reserved Instances require a 1-year or 3-year commitment in exchange for significant discounts, making them unsuitable for short, unpredictable workloads that need flexibility without long-term obligations.",
      "1": "Dedicated Hosts provide physical servers dedicated to your use for compliance or licensing requirements, but they are expensive and typically require reservations, making them inappropriate for short, unpredictable workloads.",
      "2": "Savings Plans require a commitment to a consistent amount of compute usage (measured in $/hour) for 1 or 3 years, which contradicts the requirement for no long-term commitment with unpredictable workloads."
    }
  },
  {
    "id": "SAA-314",
    "domainId": "D3",
    "domain": "Design High-Performing Architectures",
    "section": "Storage",
    "question": "Which TWO statements accurately describe Amazon EBS vs Amazon EFS? (Choose TWO.)",
    "choices": [
      "EFS is a managed NFS file system that can be mounted by many instances across AZs",
      "EFS is object storage for static websites",
      "EBS automatically replicates across Regions by default",
      "EBS can be mounted by unlimited instances across multiple AZs by default",
      "EBS is block storage attached to a single EC2 instance (AZ-scoped)"
    ],
    "answer": [
      0,
      4
    ],
    "explanation": "EBS is AZ-scoped block storage for a single instance (typical use). EFS is shared file storage (NFS) across multiple instances and AZs.",
    "difficulty": "Easy",
    "choiceExplanations": {
      "1": "EFS is a file storage service using the NFS protocol, not object storage. Amazon S3 is the AWS object storage service used for static website hosting, while EFS provides a POSIX-compliant file system for shared access.",
      "2": "EBS volumes are automatically replicated within a single Availability Zone for durability, not across Regions. Cross-Region replication requires manually creating and copying EBS snapshots to other Regions.",
      "3": "Standard EBS volumes are AZ-scoped and can only be attached to instances within the same AZ. While EBS Multi-Attach exists for io1/io2 volumes, it only supports up to 16 Nitro-based instances within the same AZ, not unlimited instances across AZs."
    }
  },
  {
    "id": "SAA-316",
    "domainId": "D1",
    "domain": "Design Secure Architectures",
    "section": "Security Groups",
    "question": "By default, which TWO statements about a new Security Group are correct? (Choose TWO.)",
    "choices": [
      "It blocks all outbound traffic by default",
      "It is stateless like a Network ACL",
      "It allows all inbound traffic by default",
      "It allows all outbound traffic by default",
      "It blocks all inbound traffic until you add inbound rules"
    ],
    "answer": [
      3,
      4
    ],
    "explanation": "Default security group behavior is: inbound denied (no inbound rules) and outbound allowed (allow all outbound).",
    "difficulty": "Easy",
    "choiceExplanations": {
      "0": "This is incorrect because a newly created security group includes a default outbound rule that allows all outbound traffic to all destinations (0.0.0.0/0), not blocks it.",
      "1": "This is incorrect because security groups are stateful, meaning return traffic is automatically allowed regardless of outbound rules. Network ACLs are stateless and require explicit rules for both inbound and outbound traffic.",
      "2": "This is incorrect because a newly created security group has no inbound rules by default, which means all inbound traffic is implicitly denied until you explicitly add rules to allow specific traffic."
    }
  },
  {
    "id": "SAA-317",
    "domainId": "D2",
    "domain": "Design Resilient Architectures",
    "section": "RDS",
    "question": "Which RDS feature provides automatic failover to another AZ with minimal application changes (same endpoint)?",
    "choices": [
      "RDS snapshot",
      "RDS Multi-AZ deployment",
      "RDS Read Replica",
      "RDS Performance Insights"
    ],
    "answer": 1,
    "explanation": "Multi-AZ provides a standby in another AZ and automatic failover with the same endpoint.",
    "difficulty": "Easy",
    "choiceExplanations": {
      "0": "Snapshots are point-in-time backups of your database stored in S3, used for manual recovery or creating new instances, but they do not provide automatic failover capability.",
      "2": "Read Replicas are designed for read scaling and offloading read traffic, not automatic failover; they have separate endpoints and require manual promotion to become a primary instance.",
      "3": "Performance Insights is a database monitoring feature that helps analyze and troubleshoot database performance issues, but it has no failover or high availability functionality."
    }
  },
  {
    "id": "SAA-318",
    "domainId": "D4",
    "domain": "Design Cost-Optimized Architectures",
    "section": "S3",
    "question": "You need to host a public dataset in S3 and want downloaders to pay request and data-transfer costs while you keep paying for storage. Which TWO statements are true? (Choose TWO.)",
    "choices": [
      "Enable Requester Pays on the bucket",
      "You must enable S3 Transfer Acceleration for Requester Pays to work",
      "Requester Pays prevents public access automatically",
      "Requesters are charged for requests and data transfer when Requester Pays is enabled",
      "Requester Pays makes the bucket owner pay for all requests"
    ],
    "answer": [
      0,
      3
    ],
    "explanation": "Requester Pays shifts request and transfer charges to the requester; the bucket owner still pays for storage.",
    "difficulty": "Easy",
    "choiceExplanations": {
      "1": "S3 Transfer Acceleration and Requester Pays are completely independent features. Transfer Acceleration speeds up uploads/downloads using CloudFront edge locations, while Requester Pays shifts costs to requesters - neither requires the other to function.",
      "2": "Requester Pays does not automatically block public access, but anonymous requests are not allowed because AWS needs to identify and bill the requester. Requesters must authenticate and include x-amz-request-payer in their requests to be charged.",
      "4": "This is the opposite of what Requester Pays does. When enabled, requesters pay for requests and data transfer costs, while the bucket owner only pays for storage costs."
    }
  },
  {
    "id": "SAA-319",
    "domainId": "D1",
    "domain": "Design Secure Architectures",
    "section": "S3",
    "question": "A browser-based web app at https://app.example.com needs to call GET/PUT on an S3 bucket. Requests are blocked by the browser. What must be configured?",
    "choices": [
      "S3 Transfer Acceleration",
      "CloudTrail data events only",
      "S3 CORS configuration allowing the origin and required methods/headers",
      "S3 Object Lock"
    ],
    "answer": 2,
    "explanation": "Cross-origin browser requests require S3 CORS rules allowing the web app origin and the needed HTTP methods/headers.",
    "difficulty": "Easy",
    "choiceExplanations": {
      "0": "This feature speeds up data transfers to S3 by routing traffic through CloudFront edge locations, but it does not address browser security restrictions that block cross-origin requests.",
      "1": "CloudTrail data events provide logging and auditing of S3 object-level API activity, but they do not configure permissions or resolve browser-enforced cross-origin request blocking.",
      "3": "This feature prevents objects from being deleted or overwritten for a specified retention period (WORM model), but it has no relation to browser cross-origin security policies."
    }
  },
  {
    "id": "SAA-320",
    "domainId": "D2",
    "domain": "Design Resilient Architectures",
    "section": "Route 53",
    "question": "You want to split traffic between two endpoints: 80% to the old version and 20% to the new version. Which TWO Route 53 concepts are used? (Choose TWO.)",
    "choices": [
      "Geolocation routing policy",
      "Failover routing policy",
      "Two records (one per endpoint) with different weights",
      "Multi-Value Answer routing policy",
      "Weighted routing policy"
    ],
    "answer": [
      2,
      4
    ],
    "explanation": "Weighted routing uses multiple records with weights to control traffic percentage between endpoints.",
    "difficulty": "Easy",
    "choiceExplanations": {
      "0": "This routes traffic based on the geographic location of users (continent, country, or state), not by percentage distribution, so it cannot split traffic 80/20 between endpoints.",
      "1": "This is designed for active-passive failover scenarios where traffic routes to a secondary resource only when the primary is unhealthy, not for distributing traffic by percentage.",
      "3": "This returns multiple healthy records randomly to clients for simple load distribution and health checking, but does not allow you to specify exact traffic percentages like 80/20."
    }
  },
  {
    "id": "SAA-321",
    "domainId": "D2",
    "domain": "Design Resilient Architectures",
    "section": "Route 53",
    "question": "You need to map the zone apex (example.com) to an Application Load Balancer. Which Route 53 record type should you use?",
    "choices": [
      "CNAME record to the ALB DNS name",
      "Alias A record to the ALB",
      "NS record to the ALB",
      "TXT record containing the ALB name"
    ],
    "answer": 1,
    "explanation": "At the zone apex you use an Alias A record (CNAME isn’t allowed at the root in Route 53).",
    "difficulty": "Easy",
    "choiceExplanations": {
      "0": "CNAME records cannot be created at the zone apex (root domain) according to DNS RFC standards, as they would conflict with other required records like SOA and NS records that must exist at the apex.",
      "2": "NS (Name Server) records are used to delegate DNS authority to name servers, not to point domain names to load balancers or other AWS resources.",
      "3": "TXT records are used to store text information for purposes like domain verification or SPF records, not for routing traffic to load balancers or resolving domain names to IP addresses."
    }
  },
  {
    "id": "SAA-322",
    "domainId": "D1",
    "domain": "Design Secure Architectures",
    "section": "CloudTrail",
    "question": "A security team needs to know who made AWS API calls, from which IP, and when. Which TWO steps/services provide this auditing capability? (Choose TWO.)",
    "choices": [
      "Deliver CloudTrail logs to an S3 bucket",
      "Enable Amazon GuardDuty only",
      "Enable S3 Transfer Acceleration",
      "Enable AWS Budgets",
      "Enable AWS CloudTrail management events"
    ],
    "answer": [
      0,
      4
    ],
    "explanation": "CloudTrail records API calls (identity, source IP, time), and delivering logs to S3 retains them for auditing.",
    "difficulty": "Easy",
    "choiceExplanations": {
      "1": "GuardDuty is a threat detection service that analyzes CloudTrail logs, VPC Flow Logs, and DNS logs to identify security threats, but it does not provide direct auditing of who made API calls, from which IP, and when - it relies on CloudTrail for that underlying data.",
      "2": "S3 Transfer Acceleration is a feature that speeds up data transfers to S3 buckets over long distances using CloudFront edge locations, and has no relation to API call auditing or security logging.",
      "3": "AWS Budgets is a cost management service that allows you to set custom budgets and receive alerts when costs or usage exceed thresholds, and provides no capability for tracking API calls or security auditing."
    }
  },
  {
    "id": "SAA-323",
    "domainId": "D3",
    "domain": "Design High-Performing Architectures",
    "section": "Lambda",
    "question": "What is the maximum duration a single AWS Lambda invocation can run before it times out (assuming you set it to the maximum)?",
    "choices": [
      "5 minutes",
      "15 minutes",
      "30 seconds",
      "1 hour"
    ],
    "answer": 1,
    "explanation": "Lambda has a maximum timeout of 15 minutes per invocation.",
    "difficulty": "Easy",
    "choiceExplanations": {
      "0": "This was the original maximum timeout limit when Lambda was first launched, but AWS increased the maximum timeout to 15 minutes in October 2018 to support longer-running workloads.",
      "2": "This is far below the maximum allowed timeout; 30 seconds is actually the default timeout value for new Lambda functions, not the maximum configurable limit.",
      "3": "This exceeds Lambda's maximum timeout limit of 15 minutes; for workloads requiring execution times longer than 15 minutes, you should consider using AWS Step Functions, AWS Batch, or Amazon ECS instead."
    }
  },
  {
    "id": "SAA-324",
    "domainId": "D2",
    "domain": "Design Resilient Architectures",
    "section": "SQS",
    "question": "An SQS-triggered Lambda is processing a message and you don’t want SQS to deliver the same message again while processing is still in progress. Which TWO settings should be aligned? (Choose TWO.)",
    "choices": [
      "SQS visibility timeout should be greater than the maximum processing time",
      "SQS long polling must be set to 20 seconds",
      "Enable S3 Versioning",
      "Lambda function timeout should be less than or equal to the SQS visibility timeout",
      "Enable FIFO to automatically prevent all duplicates"
    ],
    "answer": [
      0,
      3
    ],
    "explanation": "Visibility timeout must cover processing time, and Lambda timeout should fit within that window to reduce duplicate deliveries.",
    "difficulty": "Easy",
    "choiceExplanations": {
      "1": "Long polling is a technique to reduce empty responses and API costs by waiting for messages to arrive, but it has no effect on preventing duplicate message delivery during processing; it only affects how the queue is polled for new messages.",
      "2": "S3 Versioning is a feature for maintaining multiple versions of objects in S3 buckets and is completely unrelated to SQS message processing or preventing duplicate message delivery.",
      "4": "While FIFO queues provide exactly-once processing through message deduplication, this only prevents duplicate messages from being sent within a 5-minute deduplication interval; it does not prevent the same message from being redelivered if processing exceeds the visibility timeout."
    }
  },
  {
    "id": "SAA-325",
    "domainId": "D3",
    "domain": "Design High-Performing Architectures",
    "section": "DynamoDB",
    "question": "Your DynamoDB table has unpredictable traffic patterns and you want to automatically scale capacity without manual intervention. What capacity mode should you use?",
    "choices": [
      "Provisioned capacity with Auto Scaling",
      "On-Demand capacity mode",
      "Reserved capacity",
      "Provisioned capacity without Auto Scaling"
    ],
    "answer": 1,
    "explanation": "On-Demand capacity mode automatically scales to accommodate workload demands without capacity planning. It is ideal for unpredictable traffic patterns as it instantly accommodates workloads as they ramp up or down, charging only for the read and write requests consumed.",
    "difficulty": "Easy",
    "choiceExplanations": {
      "0": "While this can automatically adjust capacity, it requires initial capacity planning, has scaling delays during sudden traffic spikes, and may not react quickly enough for truly unpredictable workloads compared to On-Demand mode's instant scaling.",
      "2": "Reserved capacity is a pricing option for provisioned capacity mode that provides discounted rates in exchange for a commitment, not a capacity mode itself, and still requires capacity planning and management.",
      "3": "This requires manual intervention to adjust read and write capacity units, making it unsuitable for unpredictable traffic patterns as it cannot automatically scale to meet changing demands."
    }
  },
  {
    "id": "SAA-326",
    "domainId": "D1",
    "domain": "Design Secure Architectures",
    "section": "Secrets Manager",
    "question": "You store database credentials and need automatic rotation every 30 days with managed workflows. Which TWO capabilities/services should you use? (Choose TWO.)",
    "choices": [
      "AWS Secrets Manager",
      "Route 53 health checks",
      "Secrets Manager rotation (uses a Lambda rotation function)",
      "S3 bucket policies",
      "EBS snapshots"
    ],
    "answer": [
      0,
      2
    ],
    "explanation": "Secrets Manager stores secrets and supports automatic rotation via a rotation Lambda function on a schedule.",
    "difficulty": "Easy",
    "choiceExplanations": {
      "1": "These monitor the health and availability of endpoints and resources for DNS failover purposes, not for managing or rotating database credentials.",
      "3": "These are resource-based policies that control access to S3 buckets and objects, not for storing or rotating database credentials.",
      "4": "These are point-in-time backups of EBS volumes used for data recovery and replication, not for credential management or secret rotation."
    }
  },
  {
    "id": "SAA-327",
    "domainId": "D1",
    "domain": "Design Secure Architectures",
    "section": "KMS",
    "question": "Which AWS service is used to create and manage encryption keys for services like S3, EBS, and RDS (SSE-KMS)?",
    "choices": [
      "AWS Secrets Manager",
      "AWS Key Management Service (KMS)",
      "Amazon Cognito",
      "AWS Certificate Manager (ACM)"
    ],
    "answer": 1,
    "explanation": "KMS manages encryption keys used by many AWS services for server-side encryption and cryptographic operations.",
    "difficulty": "Easy",
    "choiceExplanations": {
      "0": "This service is designed to store, rotate, and manage secrets such as database credentials, API keys, and passwords, not to create and manage encryption keys for server-side encryption of AWS services.",
      "2": "This service provides user authentication, authorization, and user management for web and mobile applications, not encryption key management for AWS storage and database services.",
      "3": "This service provisions, manages, and deploys SSL/TLS certificates for securing network communications, not encryption keys used for server-side encryption of data at rest in services like S3, EBS, and RDS."
    }
  },
  {
    "id": "SAA-328",
    "domainId": "D3",
    "domain": "Design High-Performing Architectures",
    "section": "CloudFront",
    "question": "You want to block viewers from specific countries from accessing your content at the edge. Which TWO CloudFront features can directly help? (Choose TWO.)",
    "choices": [
      "Security groups on the origin only",
      "CloudFront geo restriction",
      "Route 53 weighted routing",
      "S3 Object Lock",
      "CloudFront signed URLs or signed cookies"
    ],
    "answer": [
      1,
      4
    ],
    "explanation": "Geo restriction blocks by country at the edge, and signed URLs/cookies restrict access to authorized viewers.",
    "difficulty": "Easy",
    "choiceExplanations": {
      "0": "Security groups operate at the origin server level (EC2 instances) and filter traffic by IP address/port, not by geographic location, and they cannot block traffic at the CloudFront edge locations where content is served.",
      "2": "Weighted routing distributes traffic across multiple resources based on assigned weights for load balancing purposes, not for blocking access based on geographic location of viewers.",
      "3": "S3 Object Lock is a data protection feature that prevents objects from being deleted or overwritten for a specified retention period using WORM (Write Once Read Many) model, and has no capability to restrict access based on viewer geography."
    }
  },
  {
    "id": "SAA-329",
    "domainId": "D3",
    "domain": "Design High-Performing Architectures",
    "section": "ECS",
    "question": "You want to run containers without managing EC2 instances. Which ECS launch type should you use?",
    "choices": [
      "EC2 launch type",
      "Fargate launch type",
      "On-premises launch type",
      "Dedicated Host launch type"
    ],
    "answer": 1,
    "explanation": "ECS on Fargate removes the need to manage EC2 instances for container workloads.",
    "difficulty": "Easy",
    "choiceExplanations": {
      "0": "This launch type requires you to provision, configure, and manage EC2 instances yourself to run your containers, which directly contradicts the requirement of not managing EC2 instances.",
      "2": "This is not a valid ECS launch type; ECS Anywhere allows running containers on-premises but still requires you to manage the underlying infrastructure.",
      "3": "This is not a valid ECS launch type; Dedicated Hosts are a feature of EC2 for compliance requirements and would still require managing the underlying infrastructure."
    }
  },
  {
    "id": "SAA-330",
    "domainId": "D1",
    "domain": "Design Secure Architectures",
    "section": "VPC Endpoints",
    "question": "You want private subnets to reach Amazon S3 without using a NAT Gateway and without sending traffic over the public internet. Which TWO actions achieve this? (Choose TWO.)",
    "choices": [
      "Update the private subnet route table to target the S3 Gateway endpoint",
      "Create an Interface VPC endpoint for S3 and disable private DNS",
      "Assign Elastic IPs to the instances",
      "Attach an Internet Gateway to the private subnet",
      "Create a Gateway VPC endpoint for S3"
    ],
    "answer": [
      0,
      4
    ],
    "explanation": "Use an S3 Gateway VPC endpoint and add the endpoint route to the private route table.",
    "difficulty": "Easy",
    "choiceExplanations": {
      "1": "While Interface endpoints can work for S3, disabling private DNS would require applications to use endpoint-specific DNS names rather than standard S3 URLs, making this configuration incomplete and impractical; additionally, Gateway endpoints are the preferred and cost-free option for S3 access.",
      "2": "Elastic IPs provide public IP addresses to instances, which would require an Internet Gateway and route traffic over the public internet, directly contradicting the requirement to avoid public internet traffic.",
      "3": "Internet Gateways attach to VPCs (not subnets), and adding a route to an IGW would make the subnet public and send S3 traffic over the public internet, which violates the stated requirements."
    }
  },
  {
    "id": "SAA-331",
    "domainId": "D2",
    "domain": "Design Resilient Architectures",
    "section": "S3",
    "question": "What is a hard prerequisite for enabling S3 Cross-Region Replication (CRR) between two buckets?",
    "choices": [
      "S3 Object Lock enabled on both buckets",
      "S3 Transfer Acceleration enabled on both buckets",
      "The buckets must be in the same Region",
      "Versioning enabled on both source and destination buckets"
    ],
    "answer": 3,
    "explanation": "CRR requires versioning enabled on both buckets.",
    "difficulty": "Easy",
    "choiceExplanations": {
      "0": "S3 Object Lock is an optional feature for WORM (Write Once Read Many) compliance and data retention, not a prerequisite for CRR; replication works without Object Lock enabled.",
      "1": "Transfer Acceleration is an optional feature that speeds up uploads to S3 using CloudFront edge locations, but it is not required for CRR; replication uses AWS's internal network infrastructure.",
      "2": "This is the opposite of what CRR requires; Cross-Region Replication specifically requires buckets to be in different AWS Regions, while Same-Region Replication (SRR) is used for buckets in the same Region."
    }
  },
  {
    "id": "SAA-332",
    "domainId": "D3",
    "domain": "Design High-Performing Architectures",
    "section": "CloudWatch",
    "question": "You want to be alerted when an EC2 instance’s CPU utilization stays above 80% for 5 minutes. Which TWO services/features do you use? (Choose TWO.)",
    "choices": [
      "Amazon CloudWatch alarm",
      "Amazon Athena",
      "Amazon CloudWatch metric (CPUUtilization)",
      "AWS Config",
      "AWS CloudTrail"
    ],
    "answer": [
      0,
      2
    ],
    "explanation": "CloudWatch metrics provide CPUUtilization and CloudWatch alarms evaluate the threshold and trigger notifications/actions.",
    "difficulty": "Easy",
    "choiceExplanations": {
      "1": "Athena is an interactive query service used to analyze data in Amazon S3 using standard SQL, not for monitoring EC2 instance metrics or creating performance-based alerts.",
      "3": "AWS Config is used to assess, audit, and evaluate the configurations of AWS resources for compliance purposes, not for monitoring real-time performance metrics like CPU utilization.",
      "4": "CloudTrail records API calls and user activity for auditing and governance purposes, but it does not monitor EC2 performance metrics or provide alerting capabilities for resource utilization thresholds."
    }
  },
  {
    "id": "SAA-333",
    "domainId": "D2",
    "domain": "Design Resilient Architectures",
    "section": "EBS",
    "question": "What is the primary purpose of an EBS snapshot?",
    "choices": [
      "To create a point-in-time backup of an EBS volume",
      "To encrypt a KMS key",
      "To store objects for static website hosting",
      "To distribute HTTP traffic across instances"
    ],
    "answer": 0,
    "explanation": "An EBS snapshot is a point-in-time backup of an EBS volume.",
    "difficulty": "Easy",
    "choiceExplanations": {
      "1": "EBS snapshots do not encrypt KMS keys. KMS keys are used to encrypt EBS volumes and snapshots, not the other way around. KMS is a separate service for managing encryption keys.",
      "2": "Static website hosting is a feature of Amazon S3, which stores objects in buckets. EBS snapshots are block-level backups stored in S3 but are specifically for backing up EBS volumes, not for hosting websites.",
      "3": "Distributing HTTP traffic across instances is the function of Elastic Load Balancing (ELB), not EBS snapshots. EBS snapshots are solely for creating backups of EBS volumes."
    }
  },
  {
    "id": "SAA-334",
    "domainId": "D1",
    "domain": "Design Secure Architectures",
    "section": "ACM",
    "question": "You need a publicly trusted TLS certificate for an ALB and want AWS-managed renewals. What should you do?",
    "choices": [
      "Request a public certificate in ACM and validate it (DNS or email)",
      "Use S3 to host the certificate and reference it from the ALB",
      "Use a self-signed certificate and import it into ACM",
      "Create a certificate in Secrets Manager"
    ],
    "answer": 0,
    "explanation": "ACM public certificates are managed by AWS and support automatic renewal when validation remains in place.",
    "difficulty": "Easy",
    "choiceExplanations": {
      "1": "ALB does not support referencing certificates directly from S3; certificates must be stored in ACM or IAM Certificate Store, and S3 is not designed for certificate management or automatic renewals.",
      "2": "Self-signed certificates are not publicly trusted by browsers and clients, and imported certificates in ACM do not receive AWS-managed automatic renewals - you must manually renew and re-import them.",
      "3": "Secrets Manager is designed for storing secrets like database credentials and API keys, not for creating or managing TLS certificates; ALB cannot use Secrets Manager as a certificate source."
    }
  },
  {
    "id": "SAA-335",
    "domainId": "D4",
    "domain": "Design Cost-Optimized Architectures",
    "section": "S3",
    "question": "You store compliance archives that are rarely accessed but must be retained for 10 years with retrieval times of up to 12 hours acceptable. What is the MOST cost-effective S3 storage class?",
    "choices": [
      "S3 Standard",
      "S3 Standard-IA",
      "S3 Glacier Flexible Retrieval",
      "S3 Glacier Deep Archive"
    ],
    "answer": 3,
    "explanation": "S3 Glacier Deep Archive is the most cost-effective storage class for long-term archives that are rarely accessed. It offers the lowest storage costs and supports retrieval times of up to 12 hours, making it ideal for compliance archives with 7-10 year retention requirements.",
    "difficulty": "Easy",
    "choiceExplanations": {
      "0": "This is the most expensive storage class designed for frequently accessed data with millisecond retrieval, making it unnecessarily costly for rarely accessed compliance archives that can tolerate 12-hour retrieval times.",
      "1": "While cheaper than S3 Standard, this class is designed for infrequently accessed data requiring immediate retrieval and costs significantly more than Glacier classes, making it not the most cost-effective option for rarely accessed archives.",
      "2": "Although suitable for archival data with retrieval times ranging from minutes to hours, it costs more than Glacier Deep Archive and is not the most cost-effective option when 12-hour retrieval times are acceptable."
    }
  },
  {
    "id": "SAA-336",
    "domainId": "D3",
    "domain": "Design High-Performing Architectures",
    "section": "Athena",
    "question": "You want to run ad-hoc SQL queries directly against files in S3 without provisioning servers. Which service should you use?",
    "choices": [
      "Amazon Athena",
      "Amazon RDS",
      "Amazon ElastiCache",
      "Amazon EC2"
    ],
    "answer": 0,
    "explanation": "Athena is serverless SQL for querying data in S3.",
    "difficulty": "Easy",
    "choiceExplanations": {
      "1": "RDS is a managed relational database service that requires provisioning database instances and stores data in its own managed storage, not directly querying files in S3.",
      "2": "ElastiCache is an in-memory caching service for Redis or Memcached, designed to improve application performance through caching, not for running SQL queries against S3 data.",
      "3": "EC2 provides virtual servers that require provisioning and management, which contradicts the serverless requirement of the question for running ad-hoc queries."
    }
  },
  {
    "id": "SAA-337",
    "domainId": "D2",
    "domain": "Design Resilient Architectures",
    "section": "Disaster Recovery",
    "question": "Which disaster recovery strategy has the lowest cost but typically the highest RTO/RPO among common DR patterns?",
    "choices": [
      "Pilot Light",
      "Backup & Restore",
      "Warm Standby",
      "Multi-Region Active/Active"
    ],
    "answer": 1,
    "explanation": "Backup & Restore is usually the lowest cost, but it has longer recovery time and potentially more data loss compared to warm standby or active/active.",
    "difficulty": "Easy",
    "choiceExplanations": {
      "0": "This strategy maintains a minimal version of the environment always running (core components like databases), which incurs ongoing compute costs and provides faster recovery than Backup & Restore, resulting in lower RTO/RPO but higher costs.",
      "2": "This approach keeps a scaled-down but fully functional version of the production environment running at all times, which costs more than Backup & Restore but provides significantly faster recovery times and lower RTO/RPO.",
      "3": "This is the most expensive DR strategy as it runs full production capacity across multiple regions simultaneously, but it provides near-zero RTO/RPO since traffic can immediately failover to healthy regions."
    }
  },
  {
    "id": "SAA-338",
    "domainId": "D1",
    "domain": "Design Secure Architectures",
    "section": "Organizations",
    "question": "What is the main purpose of an AWS Organizations Service Control Policy (SCP)?",
    "choices": [
      "Set the maximum permissions for member accounts/OUs (guardrails)",
      "Encrypt data at rest for all services",
      "Grant permissions to IAM users in an account",
      "Provide DDoS protection for CloudFront"
    ],
    "answer": 0,
    "explanation": "SCPs define the permission boundaries (maximum allowed) for accounts in an organization; they do not grant permissions by themselves.",
    "difficulty": "Easy",
    "choiceExplanations": {
      "1": "Encryption at rest is managed through service-specific settings like AWS KMS, S3 bucket policies, or EBS encryption settings, not through Service Control Policies which only control permission boundaries.",
      "2": "SCPs do not grant permissions; they only set the maximum available permissions (guardrails) that can be granted. Actual permissions must still be granted through IAM policies within each account.",
      "3": "DDoS protection is provided by AWS Shield (Standard and Advanced), not by Service Control Policies which are used for managing permission boundaries across AWS Organizations."
    }
  },
  {
    "id": "SAA-339",
    "domainId": "D2",
    "domain": "Design Resilient Architectures",
    "section": "AWS Backup",
    "question": "You want a centralized managed service to back up resources like EBS, RDS, DynamoDB, and EFS using policies. Which service should you use?",
    "choices": [
      "Amazon CloudFront",
      "AWS Glue",
      "AWS Backup",
      "AWS DataSync"
    ],
    "answer": 2,
    "explanation": "AWS Backup is the managed centralized service for policy-based backups across multiple AWS services.",
    "difficulty": "Easy",
    "choiceExplanations": {
      "0": "This is a content delivery network (CDN) service that caches and delivers content from edge locations to reduce latency, not a backup service for AWS resources.",
      "1": "This is a serverless data integration service used for ETL (Extract, Transform, Load) operations and data cataloging, not for backing up AWS resources.",
      "3": "This is a data transfer service designed to move large amounts of data between on-premises storage and AWS or between AWS storage services, not a centralized backup management service with policy-based controls."
    }
  },
  {
    "id": "SAA-340",
    "domainId": "D1",
    "domain": "Design Secure Architectures",
    "section": "WAF",
    "question": "A company uses CloudFront in front of multiple ALBs across several AWS accounts. Security wants to centrally enforce a baseline set of WAF rules across all accounts using AWS Organizations. Which service should be used?",
    "choices": [
      "AWS Shield Standard",
      "AWS Firewall Manager",
      "Amazon GuardDuty",
      "AWS Network Firewall"
    ],
    "answer": 1,
    "explanation": "AWS Firewall Manager integrates with AWS Organizations to centrally manage and enforce AWS WAF (and Shield Advanced) policies across multiple accounts and resources.",
    "difficulty": "Medium",
    "choiceExplanations": {
      "0": "This service provides automatic protection against DDoS attacks for all AWS customers at no additional cost, but it does not provide WAF rule management or centralized policy enforcement across accounts.",
      "2": "This is a threat detection service that continuously monitors for malicious activity and unauthorized behavior using machine learning, but it does not enforce WAF rules or provide centralized security policy management.",
      "3": "This is a managed firewall service for VPCs that provides network-level traffic filtering, but it does not manage AWS WAF rules for CloudFront or ALBs, nor does it provide centralized cross-account WAF policy management."
    }
  },
  {
    "id": "SAA-341",
    "domainId": "D2",
    "domain": "Design Resilient Architectures",
    "section": "RDS",
    "question": "A production MySQL database runs on Amazon RDS. The analytics team must run heavy read queries without impacting the application’s performance. Which solution is the MOST suitable and cost-effective?",
    "choices": [
      "Export data nightly to S3 and query with Athena only",
      "Create an RDS Read Replica and direct analytics queries to the replica",
      "Increase the DB instance size and keep analytics on the primary",
      "Enable RDS Multi-AZ and direct analytics queries to the standby instance"
    ],
    "answer": 1,
    "explanation": "Read replicas offload read traffic from the primary DB, preventing analytics queries from impacting the production workload. Multi-AZ standby is not used for reads.",
    "difficulty": "Medium",
    "choiceExplanations": {
      "0": "While this approach works for analytics, it only provides data up to 24 hours old, making it unsuitable for real-time or near-real-time analytics needs, and adds complexity with ETL processes compared to using a read replica.",
      "2": "This approach is not cost-effective as it requires paying for a larger instance continuously, and heavy analytics queries would still compete for resources with production workloads on the same instance, potentially impacting application performance.",
      "3": "The Multi-AZ standby instance is designed solely for failover purposes and cannot serve read traffic; it remains in a passive state and is not accessible for queries until a failover event promotes it to primary."
    }
  },
  {
    "id": "SAA-342",
    "domainId": "D4",
    "domain": "Design Cost-Optimized Architectures",
    "section": "S3",
    "question": "A team stores large objects in S3. Objects are heavily accessed for the first 14 days, then rarely accessed for the next 60 days but must still be retrieved immediately (milliseconds). After that, the data is kept for compliance and can take hours to retrieve. Which lifecycle approach best meets the requirements at the lowest cost?",
    "choices": [
      "S3 Standard (14 days) → S3 Glacier Deep Archive (after day 14)",
      "S3 One Zone-IA (14 days) → S3 Standard-IA (day 14–74) → S3 Glacier Deep Archive (after day 74)",
      "S3 Intelligent-Tiering (14 days) → S3 One Zone-IA (day 14–74) → S3 Glacier Instant Retrieval (after day 74)",
      "S3 Standard (14 days) → S3 Standard-IA (day 14–74) → S3 Glacier Flexible Retrieval (after day 74)"
    ],
    "answer": 3,
    "explanation": "Standard fits frequent access, Standard-IA supports infrequent access with millisecond retrieval, and Glacier Flexible Retrieval supports long-term archiving with hour-level retrieval time.",
    "difficulty": "Medium",
    "choiceExplanations": {
      "0": "This skips the 60-day period where objects must be retrieved immediately (milliseconds). Glacier Deep Archive has retrieval times of 12-48 hours, which fails the requirement for millisecond access during days 14-74.",
      "1": "One Zone-IA is inappropriate for the first 14 days when objects are heavily accessed, as it's designed for infrequent access and has higher retrieval costs. Additionally, Glacier Deep Archive has 12-48 hour retrieval times, which exceeds the 'hours' requirement for the compliance phase.",
      "2": "One Zone-IA stores data in only one Availability Zone, reducing durability and availability compared to Standard-IA. Glacier Instant Retrieval provides millisecond access, which is more expensive than necessary when the requirement only needs hour-level retrieval for compliance data."
    }
  },
  {
    "id": "SAA-343",
    "domainId": "D1",
    "domain": "Design Secure Architectures",
    "section": "KMS",
    "question": "An S3 bucket uses SSE-KMS. A replication job to another Region fails with an error related to the destination KMS key. Which change is most likely required to allow replication to encrypt objects in the destination bucket?",
    "choices": [
      "Add permissions to the destination KMS key policy for the replication role to use kms:Encrypt and kms:GenerateDataKey",
      "Disable bucket versioning on the source bucket",
      "Enable MFA delete on the destination bucket",
      "Enable S3 Transfer Acceleration on the destination bucket"
    ],
    "answer": 0,
    "explanation": "For SSE-KMS replication, the replication IAM role must be allowed by the destination KMS key policy to perform encryption-related KMS actions (such as Encrypt and GenerateDataKey).",
    "difficulty": "Medium",
    "choiceExplanations": {
      "1": "This would actually break replication entirely, as S3 Cross-Region Replication requires versioning to be enabled on both source and destination buckets; it does not address KMS key permission issues.",
      "2": "MFA delete is a security feature that requires multi-factor authentication to permanently delete object versions; it has no relationship to KMS encryption permissions needed for replication.",
      "3": "Transfer Acceleration is a feature that speeds up data transfers to S3 using CloudFront edge locations; it does not address KMS key policy permissions required for encrypting replicated objects."
    }
  },
  {
    "id": "SAA-344",
    "domainId": "D2",
    "domain": "Design Resilient Architectures",
    "section": "Disaster Recovery",
    "question": "A web platform must meet an RTO of under 30 minutes and an RPO of near zero for a regional disaster. The company can’t afford full active/active but can keep the secondary environment running at reduced capacity and scale it on failover. Which DR strategy is the best fit?",
    "choices": [
      "Pilot Light",
      "Multi-Region Active/Active",
      "Backup and Restore",
      "Warm Standby"
    ],
    "answer": 3,
    "explanation": "Warm standby keeps a scaled-down, fully functional environment running in the secondary Region and scales up during failover, meeting moderate RTO/RPO without active/active cost.",
    "difficulty": "Medium",
    "choiceExplanations": {
      "0": "This strategy keeps only core critical components running (like databases) with other resources stopped, requiring more time to provision and start application servers during failover, typically resulting in RTOs of hours rather than the required under 30 minutes.",
      "1": "While this provides the lowest RTO/RPO by running full capacity in multiple regions simultaneously, the question explicitly states the company cannot afford this approach due to its high cost of maintaining duplicate full-capacity infrastructure.",
      "2": "This strategy relies on restoring systems from backups stored in another region, resulting in RTOs of hours to days and RPOs dependent on backup frequency, which cannot meet the requirements of under 30 minutes RTO and near-zero RPO."
    }
  },
  {
    "id": "SAA-345",
    "domainId": "D3",
    "domain": "Design High-Performing Architectures",
    "section": "Kinesis",
    "question": "A company needs to ingest clickstream events at high throughput with multiple consumer applications (analytics, fraud detection). Consumers must be able to replay events from the last 48 hours if processing logic changes. Which service best meets these requirements?",
    "choices": [
      "Amazon Kinesis Data Firehose",
      "Amazon SQS Standard",
      "Amazon SNS",
      "Amazon Kinesis Data Streams"
    ],
    "answer": 3,
    "explanation": "Kinesis Data Streams supports multiple consumers, low-latency processing, and configurable retention for replaying data (e.g., 48 hours).",
    "difficulty": "Medium",
    "choiceExplanations": {
      "0": "Firehose is a delivery service that loads streaming data into destinations like S3, Redshift, or OpenSearch, but it does not support multiple independent consumers reading the same data or provide replay capabilities from the stream itself.",
      "1": "SQS is a message queue where messages are deleted after being processed by a consumer, making it unsuitable for multiple consumers reading the same messages or replaying events from the past 48 hours.",
      "2": "SNS is a pub/sub notification service that delivers messages in real-time but does not retain messages for replay; once a message is delivered to subscribers, it cannot be retrieved again for reprocessing."
    }
  },
  {
    "id": "SAA-346",
    "domainId": "D1",
    "domain": "Design Secure Architectures",
    "section": "VPC Endpoints",
    "question": "EC2 instances in private subnets must access S3 without routing traffic through a NAT Gateway to reduce costs. What solution should you use?",
    "choices": [
      "VPC endpoint for S3",
      "Internet Gateway",
      "AWS PrivateLink",
      "VPN connection"
    ],
    "answer": 0,
    "explanation": "A VPC endpoint for S3 (Gateway endpoint) allows instances in private subnets to access S3 directly without requiring a NAT Gateway, Internet Gateway, or VPN connection. This eliminates NAT Gateway data transfer costs and provides better performance.",
    "difficulty": "Medium",
    "choiceExplanations": {
      "1": "An Internet Gateway allows communication between a VPC and the internet, but instances in private subnets cannot directly use it without a NAT Gateway, which defeats the cost-reduction goal and exposes traffic to the public internet.",
      "2": "While AWS PrivateLink provides private connectivity to AWS services using Interface VPC endpoints, S3 access is optimally achieved through Gateway endpoints which are free, whereas Interface endpoints incur hourly and data processing charges.",
      "3": "A VPN connection establishes encrypted connectivity between on-premises networks and AWS VPCs, not between EC2 instances and S3; it would add complexity and cost rather than providing direct private S3 access."
    }
  },
  {
    "id": "SAA-347",
    "domainId": "D2",
    "domain": "Design Resilient Architectures",
    "section": "Outposts",
    "question": "A manufacturing site needs to run AWS services (EC2, EBS, EKS) on-premises with the same AWS APIs and console while achieving very low local latency. Which service is the BEST choice?",
    "choices": [
      "VMware Cloud on AWS",
      "AWS Local Zones",
      "AWS Outposts",
      "AWS Snowball Edge"
    ],
    "answer": 2,
    "explanation": "AWS Outposts brings AWS-managed infrastructure on-prem and supports native AWS services with consistent APIs and console experience.",
    "difficulty": "Medium",
    "choiceExplanations": {
      "0": "This service runs VMware workloads in AWS cloud data centers, not on-premises at customer locations, so it cannot provide local low-latency processing at the manufacturing site.",
      "1": "These are AWS-managed infrastructure extensions located in metropolitan areas near population centers, not deployed on-premises at customer facilities, so they cannot be installed at the manufacturing site.",
      "3": "While it can run EC2 instances locally, it is primarily designed for edge computing and data transfer scenarios with limited service support, not for running the full range of AWS services (EC2, EBS, EKS) with consistent AWS management console integration on-premises."
    }
  },
  {
    "id": "SAA-348",
    "domainId": "D4",
    "domain": "Design Cost-Optimized Architectures",
    "section": "Compute",
    "question": "A batch workload runs in containers for about 90 minutes each night. It is not time-sensitive and the team wants a serverless option without managing EC2 instances. Which solution is the MOST cost-effective?",
    "choices": [
      "Amazon EC2 On-Demand instances running 24/7",
      "Amazon ECS on Fargate with a scheduled task",
      "Amazon EKS with always-on managed node groups",
      "AWS Lambda with the timeout increased to 2 hours"
    ],
    "answer": 1,
    "explanation": "ECS Fargate supports serverless containers and can run scheduled tasks without managing servers. Lambda can’t run that long, and always-on nodes increase cost.",
    "difficulty": "Medium",
    "choiceExplanations": {
      "0": "Running EC2 instances continuously for a workload that only runs 90 minutes per night wastes approximately 93% of compute costs, and requires managing EC2 instances which contradicts the serverless requirement.",
      "2": "Always-on managed node groups run EC2 instances continuously, incurring costs 24/7 for a 90-minute workload, and managed node groups still require EC2 instance management rather than being truly serverless.",
      "3": "AWS Lambda has a maximum execution timeout of 15 minutes, making it technically impossible to run a 90-minute batch workload regardless of configuration settings."
    }
  },
  {
    "id": "SAA-349",
    "domainId": "D3",
    "domain": "Design High-Performing Architectures",
    "section": "ElastiCache",
    "question": "A web app is experiencing high read pressure on its RDS database due to frequently accessed session and user profile data. The data must be served with sub-millisecond latency and expire automatically. Which service is the BEST fit?",
    "choices": [
      "Amazon ElastiCache for Redis",
      "Amazon Athena",
      "Amazon EFS",
      "Amazon S3 Standard"
    ],
    "answer": 0,
    "explanation": "ElastiCache for Redis provides in-memory caching with very low latency and TTL expiration, reducing read load on RDS.",
    "difficulty": "Medium",
    "choiceExplanations": {
      "1": "Athena is a serverless query service designed for analyzing data in S3 using SQL, not for caching frequently accessed data with sub-millisecond latency or automatic expiration capabilities.",
      "2": "EFS is a managed file storage service for EC2 instances that provides file system access, not in-memory caching; it cannot deliver sub-millisecond latency or built-in TTL expiration for cached data.",
      "3": "S3 is an object storage service with typical latencies in the tens to hundreds of milliseconds range, which does not meet the sub-millisecond latency requirement, and while it supports lifecycle policies, it lacks native TTL expiration for caching use cases."
    }
  },
  {
    "id": "SAA-350",
    "domainId": "D1",
    "domain": "Design Secure Architectures",
    "section": "Systems Manager",
    "question": "EC2 instances are in private subnets with no inbound access allowed. The operations team needs interactive shell access and port forwarding for troubleshooting without using bastion hosts, and all activity must be logged. Which service should be used?",
    "choices": [
      "AWS Systems Manager Session Manager",
      "Amazon Inspector",
      "Direct Connect",
      "EC2 Instance Connect"
    ],
    "answer": 0,
    "explanation": "SSM Session Manager provides interactive access without inbound SSH and supports logging/auditing to CloudWatch Logs/S3.",
    "difficulty": "Medium",
    "choiceExplanations": {
      "1": "This is a vulnerability assessment service that scans EC2 instances and container images for security vulnerabilities and unintended network exposure, but it does not provide any interactive shell access or port forwarding capabilities for troubleshooting.",
      "2": "This service establishes a dedicated private network connection between on-premises data centers and AWS, but it does not provide interactive shell access to EC2 instances or session logging capabilities.",
      "3": "This service provides SSH access to EC2 instances using temporary keys, but it requires inbound SSH connectivity (port 22) to the instance, which is not available in private subnets with no inbound access allowed."
    }
  },
  {
    "id": "SAA-351",
    "domainId": "D2",
    "domain": "Design Resilient Architectures",
    "section": "Networking",
    "question": "You need to connect dozens of VPCs and multiple on-premises networks in a hub-and-spoke design with centralized routing and route propagation. Which TWO services could be used to meet this requirement? (Choose TWO.)",
    "choices": [
      "AWS Site-to-Site VPN",
      "AWS Transit Gateway",
      "AWS Direct Connect",
      "VPC Peering",
      "Amazon Route 53 Resolver endpoints"
    ],
    "answer": [
      1,
      2
    ],
    "explanation": "Transit Gateway provides the hub for many VPCs and on-prem connections. Direct Connect can connect on-prem to AWS and can attach to Transit Gateway for centralized routing. (Site-to-Site VPN can also attach, but the question asks for TWO.)",
    "difficulty": "Medium",
    "choiceExplanations": {
      "0": "While Site-to-Site VPN can connect on-premises networks to AWS and attach to Transit Gateway, it is a connectivity method rather than a hub-and-spoke architecture component itself; it doesn't provide the centralized routing and route propagation capabilities that Transit Gateway offers as the hub.",
      "3": "VPC Peering creates point-to-point connections between VPCs and does not support transitive routing, making it unsuitable for hub-and-spoke designs with dozens of VPCs as it would require a full mesh of individual peering connections without centralized routing.",
      "4": "Route 53 Resolver endpoints are used for DNS query resolution between on-premises networks and VPCs, not for network connectivity or routing between VPCs and on-premises networks in a hub-and-spoke topology."
    }
  },
  {
    "id": "SAA-352",
    "domainId": "D3",
    "domain": "Design High-Performing Architectures",
    "section": "Global Accelerator",
    "question": "A global gaming app uses UDP and needs static anycast IPs and improved latency for worldwide users while balancing traffic to AWS endpoints. Which TWO AWS services should be used together? (Choose TWO.)",
    "choices": [
      "Network Load Balancer",
      "AWS Global Accelerator",
      "AWS WAF",
      "Application Load Balancer",
      "Amazon CloudFront"
    ],
    "answer": [
      0,
      1
    ],
    "explanation": "Global Accelerator provides static anycast IPs and optimized network paths for global users. Network Load Balancer supports UDP at Layer 4 and can serve as the regional endpoint.",
    "difficulty": "Medium",
    "choiceExplanations": {
      "2": "AWS WAF is a web application firewall that protects against common web exploits at Layer 7 (HTTP/HTTPS), but it does not provide static anycast IPs, latency optimization, or UDP protocol support needed for this gaming application.",
      "3": "ALB operates at Layer 7 (HTTP/HTTPS) and does not support UDP protocol, which is explicitly required for this gaming application that needs Layer 4 UDP traffic handling.",
      "4": "CloudFront is a CDN optimized for HTTP/HTTPS content delivery and does not support UDP protocol or provide the static anycast IP addresses required for this gaming application's real-time UDP traffic."
    }
  },
  {
    "id": "SAA-353",
    "domainId": "D1",
    "domain": "Design Secure Architectures",
    "section": "CloudFront",
    "question": "A company serves a global web app through Amazon CloudFront with an ALB origin. Security requires an authorization step at the edge: before any request reaches the origin, CloudFront must call an external authorization API, then either add/remove headers or return a redirect when access is denied. Which solution will meet these requirements with the LEAST operational overhead?",
    "choices": [
      "Move authorization to the origin and enforce it only in the application code",
      "Use CloudFront Functions to call the external authorization API before forwarding to the origin",
      "Use Lambda@Edge on viewer request to call the authorization API and rewrite headers or return redirects",
      "Attach AWS WAF to CloudFront and configure WAF to call the external authorization API"
    ],
    "answer": 2,
    "explanation": "Lambda@Edge can run on viewer request, perform external network calls (within limits), modify headers, and return custom responses. CloudFront Functions cannot call external services, and WAF cannot call arbitrary external authorization APIs.",
    "difficulty": "Hard",
    "choiceExplanations": {
      "0": "This approach does not meet the requirement to perform authorization at the edge before requests reach the origin, as it allows all requests to pass through CloudFront to the ALB, increasing origin load and latency while failing to block unauthorized traffic at the edge.",
      "1": "CloudFront Functions cannot make external network calls or access external APIs; they are limited to lightweight request/response manipulation using a restricted JavaScript runtime without network access capabilities.",
      "3": "AWS WAF cannot call arbitrary external authorization APIs; it only supports predefined rule types such as IP matching, rate limiting, SQL injection detection, and managed rule groups, not custom external API integrations for authorization decisions."
    }
  },
  {
    "id": "SAA-354",
    "domainId": "D2",
    "domain": "Design Resilient Architectures",
    "section": "RDS",
    "question": "A retail company runs a mission-critical RDS for MySQL database. They must upgrade to a new major version with a very short, controlled cutover and want an easy rollback if issues are found after the change. Which approach can be used to fulfill this requirement?",
    "choices": [
      "Export to S3, restore into a new DB, and repoint clients",
      "Use RDS Blue/Green Deployments and switch over when validation is complete",
      "Perform an in-place major version upgrade and rely on Multi-AZ failover for rollback",
      "Create a read replica, upgrade it, and promote it during cutover"
    ],
    "answer": 1,
    "explanation": "RDS Blue/Green Deployments supports safer, controlled upgrades with minimal downtime by keeping a synchronized staging environment and performing a switch-over when ready, with a practical rollback path.",
    "difficulty": "Hard",
    "choiceExplanations": {
      "0": "This approach involves significant downtime during the export/restore process and does not maintain data synchronization between old and new databases, making cutover lengthy and rollback complex since any new data written to the upgraded database would need to be migrated back.",
      "2": "Multi-AZ failover cannot be used for rollback because the standby instance is also upgraded during an in-place upgrade, leaving no previous version to fail back to, and in-place upgrades are irreversible without restoring from a snapshot.",
      "3": "When a read replica is promoted, it becomes a standalone database and replication from the source stops permanently, meaning there is no automatic synchronization or easy rollback path since the original database will have continued receiving writes that the promoted replica missed."
    }
  },
  {
    "id": "SAA-355",
    "domainId": "D1",
    "domain": "Design Secure Architectures",
    "section": "S3",
    "question": "A finance team stores monthly statements in Amazon S3. Regulations require WORM immutability for 7 years and protection against deletion by privileged users. Which combination of actions best satisfies the requirements while being the most cost-effective? (Choose TWO.)",
    "choices": [
      "Enable CloudTrail Insights",
      "Enable S3 Object Lock in Compliance mode with a 7-year retention",
      "Enable S3 Transfer Acceleration",
      "Enable default encryption with SSE-S3",
      "Enable S3 Versioning"
    ],
    "answer": [
      1,
      4
    ],
    "explanation": "Object Lock (Compliance) provides WORM enforcement that cannot be bypassed and requires versioning. Together they satisfy immutability and retention requirements.",
    "difficulty": "Hard",
    "choiceExplanations": {
      "0": "CloudTrail Insights analyzes CloudTrail events to detect unusual API activity patterns, but it does not provide WORM immutability or prevent deletion of objects, making it irrelevant to the compliance requirements.",
      "2": "S3 Transfer Acceleration speeds up data transfers to S3 by using CloudFront edge locations, but it has no relationship to data immutability, retention policies, or protection against deletion.",
      "3": "SSE-S3 provides server-side encryption to protect data at rest, but encryption addresses data confidentiality, not immutability or protection against deletion by privileged users as required by WORM compliance."
    }
  },
  {
    "id": "SAA-356",
    "domainId": "D3",
    "domain": "Design High-Performing Architectures",
    "section": "DynamoDB",
    "question": "A SaaS platform serves users in North America and Europe. The app needs single-digit-millisecond reads in both Regions and must continue operating through a full regional outage. Writes must be accepted in either Region. Which solution will meet these requirements with the LEAST operational overhead?",
    "choices": [
      "ElastiCache Global Datastore only",
      "DynamoDB Global Tables",
      "S3 Cross-Region Replication plus Athena queries",
      "Aurora read replicas in each Region with manual failover"
    ],
    "answer": 1,
    "explanation": "DynamoDB Global Tables provide active-active, multi-Region replication with local low-latency reads and multi-Region writes, minimizing operational overhead for this pattern.",
    "difficulty": "Hard",
    "choiceExplanations": {
      "0": "ElastiCache Global Datastore is a caching layer, not a primary database, and operates in active-passive mode where writes are only accepted in the primary Region, failing the requirement to accept writes in either Region.",
      "2": "Athena is designed for analytical queries on data in S3 and cannot provide single-digit-millisecond read latency; it typically has query response times measured in seconds, making it unsuitable for low-latency operational workloads.",
      "3": "Aurora read replicas are read-only and cannot accept writes, so writes would only be possible in the primary Region; additionally, manual failover increases operational overhead and does not meet the requirement for accepting writes in either Region."
    }
  },
  {
    "id": "SAA-357",
    "domainId": "D4",
    "domain": "Design Cost-Optimized Architectures",
    "section": "S3",
    "question": "A company stores project artifacts in S3. For 30 days objects are frequently accessed. After day 30, most objects are rarely accessed and can tolerate minutes-to-hours retrieval. However, objects under s3://bucket/hotfix/ must still be retrievable in milliseconds after day 30. Which solution is MOST cost-effective?",
    "choices": [
      "Keep all objects in S3 Standard indefinitely",
      "Enable Intelligent-Tiering and disable lifecycle rules",
      "Use lifecycle rules: hotfix/ to S3 Standard-IA after 30 days, and the rest to S3 Glacier Flexible Retrieval",
      "Move the entire bucket to S3 One Zone-IA after 30 days"
    ],
    "answer": 2,
    "explanation": "Standard-IA provides millisecond retrieval for infrequently accessed objects at lower cost than Standard, while Glacier Flexible Retrieval lowers cost for the rest with acceptable retrieval latency.",
    "difficulty": "Hard",
    "choiceExplanations": {
      "0": "This is not cost-effective because S3 Standard has the highest storage cost, and the question states that most objects are rarely accessed after 30 days, making cheaper storage classes more appropriate for those objects.",
      "1": "While Intelligent-Tiering automatically moves objects between tiers, it does not transition objects to Glacier storage classes, so it cannot achieve the lowest cost for objects that can tolerate minutes-to-hours retrieval times as specified in the requirements.",
      "3": "This approach does not differentiate between the hotfix/ prefix and other objects, and One Zone-IA still costs more than Glacier Flexible Retrieval for the majority of objects that can tolerate longer retrieval times; additionally, One Zone-IA reduces durability by storing data in only one Availability Zone."
    }
  },
  {
    "id": "SAA-358",
    "domainId": "D1",
    "domain": "Design Secure Architectures",
    "section": "Organizations",
    "question": "An OU has an SCP that denies s3:PutBucketPolicy. A developer in a member account has AdministratorAccess but cannot update a bucket policy for a valid business use case. How will the Architect fix this issue while keeping strong guardrails?",
    "choices": [
      "Remove the SCP and rely on IAM permissions in each account",
      "Enable ACLs and stop using bucket policies for cross-account access",
      "Use a separate AWS account with no SCPs and migrate the bucket there",
      "Refine the SCP to allow s3:PutBucketPolicy only under controlled conditions (for example, using tags/conditions)"
    ],
    "answer": 3,
    "explanation": "SCPs apply regardless of IAM AdministratorAccess. The correct approach is to adjust the guardrail to allow the action only when it meets defined constraints.",
    "difficulty": "Hard",
    "choiceExplanations": {
      "0": "This eliminates the organizational guardrails entirely, which contradicts the requirement to maintain strong guardrails and removes centralized security controls that SCPs provide across the organization.",
      "1": "ACLs are a legacy access control mechanism that AWS recommends disabling for most use cases, and this approach doesn't address the underlying need to manage bucket policies while circumventing proper security controls.",
      "2": "Creating accounts outside of SCP governance defeats the purpose of organizational security controls, increases management complexity, and represents a workaround rather than a proper solution that maintains guardrails."
    }
  },
  {
    "id": "SAA-359",
    "domainId": "D2",
    "domain": "Design Resilient Architectures",
    "section": "Disaster Recovery",
    "question": "A payments platform needs minutes-level RTO and low data loss across two Regions, but wants to avoid full active/active cost. It will keep a reduced-capacity environment running in the secondary Region and scale up on failover. Which DR strategy should you choose?",
    "choices": [
      "Cold Standby",
      "Pilot Light",
      "Warm Standby",
      "Backup & Restore"
    ],
    "answer": 2,
    "explanation": "Warm Standby keeps a scaled-down but running environment in the secondary Region and can scale quickly during failover, meeting tighter RTO/RPO than backup/restore or pilot light.",
    "difficulty": "Hard",
    "choiceExplanations": {
      "0": "This is not a recognized AWS DR strategy; it conflates concepts from Cold Site (no running infrastructure) with Warm Standby, and would not meet minutes-level RTO requirements as it would require provisioning infrastructure from scratch.",
      "1": "This strategy keeps only core critical components running (like databases) with minimal infrastructure, requiring more time to provision and scale application servers during failover, resulting in longer RTO (typically hours) than the minutes-level requirement.",
      "3": "This strategy involves restoring from backups stored in another Region with no running infrastructure, resulting in the longest RTO (hours to days) and highest potential data loss, which fails to meet the minutes-level RTO and low data loss requirements."
    }
  },
  {
    "id": "SAA-360",
    "domainId": "D1",
    "domain": "Design Secure Architectures",
    "section": "EKS",
    "question": "A platform team runs workloads on Amazon EKS. Pods must call DynamoDB without storing long-term keys. Access must be least privilege per workload. Which combination of actions best satisfies the requirement while being the most cost-effective? (Choose TWO.)",
    "choices": [
      "Use CloudFront signed URLs to DynamoDB",
      "Store access keys in Kubernetes Secrets and rotate monthly",
      "Give the node instance role AdministratorAccess",
      "Attach least-privilege DynamoDB permissions to the IAM role used by IRSA",
      "Enable IAM Roles for Service Accounts (IRSA)"
    ],
    "answer": [
      3,
      4
    ],
    "explanation": "IRSA provides short-lived credentials to pods, and attaching a least-privilege policy to the mapped IAM role ensures per-workload access without long-term keys.",
    "difficulty": "Hard",
    "choiceExplanations": {
      "0": "CloudFront signed URLs are used for controlling access to content distributed through CloudFront, not for authenticating API calls to DynamoDB; DynamoDB requires IAM-based authentication and does not support CloudFront signed URL access.",
      "1": "This approach uses long-term access keys which directly violates the requirement of not storing long-term keys, and manual monthly rotation is operationally burdensome compared to IRSA's automatic short-lived credential rotation.",
      "2": "This violates the least-privilege principle by granting excessive permissions to all pods on the node, and node-level IAM roles cannot provide per-workload access control as required."
    }
  },
  {
    "id": "SAA-361",
    "domainId": "D3",
    "domain": "Design High-Performing Architectures",
    "section": "FSx",
    "question": "A research team runs HPC jobs that need a POSIX file system with very low latency and high throughput. The dataset is stored in S3 and must be processed as a mounted file system without manual copy steps. Which solution will meet these requirements with the LEAST operational overhead?",
    "choices": [
      "AWS Storage Gateway File Gateway",
      "Amazon FSx for Lustre linked to the S3 dataset",
      "S3 Glacier Instant Retrieval mounted via NFS",
      "Amazon EFS with lifecycle policies"
    ],
    "answer": 1,
    "explanation": "FSx for Lustre is optimized for HPC and can link to S3, presenting data as a high-performance file system with minimal operational effort.",
    "difficulty": "Hard",
    "choiceExplanations": {
      "0": "While it provides NFS/SMB access to S3 data, it is designed for hybrid cloud storage and on-premises access, not for the high-throughput, low-latency performance required by HPC workloads.",
      "2": "S3 Glacier Instant Retrieval is an archive storage class that cannot be mounted as a file system via NFS; S3 storage classes are object storage and do not natively support POSIX file system mounting.",
      "3": "EFS provides a POSIX-compliant file system but does not offer native S3 integration for automatic data linking, and its throughput and latency characteristics are not optimized for HPC workloads like FSx for Lustre."
    }
  },
  {
    "id": "SAA-362",
    "domainId": "D4",
    "domain": "Design Cost-Optimized Architectures",
    "section": "Compute",
    "question": "A containerized microservice requires a steady compute baseline 24/7, but also has unpredictable spikes. The company wants to lower cost while avoiding capacity risk during spikes. Which combination best satisfies the requirements?",
    "choices": [
      "Spot for baseline usage and Spot for spikes",
      "Dedicated Hosts for baseline and On-Demand for spikes",
      "Savings Plans for baseline usage and On-Demand for spikes",
      "Only On-Demand so scaling is always flexible"
    ],
    "answer": 2,
    "explanation": "Savings Plans reduce cost for steady usage. On-Demand covers spikes without interruption risk or capacity constraints typical of Spot.",
    "difficulty": "Hard",
    "choiceExplanations": {
      "0": "Spot Instances can be interrupted with 2-minute notice when AWS needs capacity back, making them unsuitable for baseline workloads requiring 24/7 steady compute and creating capacity risk during spikes when Spot availability may be limited.",
      "1": "Dedicated Hosts are designed for licensing compliance or regulatory requirements, not cost optimization, and are significantly more expensive than Savings Plans for baseline compute needs.",
      "3": "While On-Demand provides flexibility and avoids capacity risk, using it exclusively for predictable baseline usage is not cost-optimized since Savings Plans can provide up to 72% savings compared to On-Demand pricing for committed usage."
    }
  },
  {
    "id": "SAA-363",
    "domainId": "D2",
    "domain": "Design Resilient Architectures",
    "section": "SQS",
    "question": "An order-processing system uses SQS with a Lambda consumer. During spikes, Lambda scales too aggressively and overwhelms the downstream database. How will the Architect fix this issue?",
    "choices": [
      "Increase SQS long polling to 20 seconds",
      "Enable FIFO so Lambda cannot scale out",
      "Decrease visibility timeout to reduce retries",
      "Set Reserved Concurrency on the Lambda function and tune batch size"
    ],
    "answer": 3,
    "explanation": "Reserved Concurrency caps parallel executions, throttling throughput. Batch size tuning further controls processing rate without changing producers.",
    "difficulty": "Hard",
    "choiceExplanations": {
      "0": "Long polling reduces empty responses and API costs by waiting for messages to arrive, but it does not control Lambda concurrency or scaling behavior, so it cannot prevent the database from being overwhelmed during traffic spikes.",
      "1": "While FIFO queues do have lower throughput limits and process messages in order by message group, Lambda can still scale to multiple concurrent executions based on the number of message groups, so FIFO alone does not effectively cap Lambda concurrency to protect downstream resources.",
      "2": "Decreasing visibility timeout would actually cause more retries because messages would become visible again sooner if processing takes longer than the timeout, potentially worsening the database load rather than reducing it."
    }
  },
  {
    "id": "SAA-364",
    "domainId": "D1",
    "domain": "Design Secure Architectures",
    "section": "VPC Endpoints",
    "question": "Instances in private subnets must access S3 without using NAT and the security team wants to allow access only to a single bucket from those subnets. Which solution will meet these requirements with the LEAST operational overhead?",
    "choices": [
      "Use an Internet Gateway and Network ACLs to block inbound traffic",
      "Use VPC peering to an S3 VPC and restrict routes",
      "Create an S3 Gateway VPC endpoint and restrict the bucket policy to the endpoint",
      "Use a NAT Gateway and restrict the bucket policy to the NAT public IP"
    ],
    "answer": 2,
    "explanation": "Gateway endpoints keep traffic on the AWS network without NAT. Bucket policy conditions can restrict access to requests coming via a specific VPC endpoint.",
    "difficulty": "Hard",
    "choiceExplanations": {
      "0": "An Internet Gateway alone cannot provide internet access to instances in private subnets (they lack public IPs and routes), and NACLs cannot restrict access to a specific S3 bucket since S3 uses many dynamic IP addresses that change frequently.",
      "1": "S3 is a managed service that does not reside in a customer-accessible VPC, so you cannot establish VPC peering with S3. VPC peering is only for connecting two customer VPCs.",
      "3": "This solution explicitly violates the requirement to access S3 without using NAT, and NAT Gateways incur additional costs and operational overhead compared to the free Gateway VPC endpoint solution."
    }
  },
  {
    "id": "SAA-365",
    "domainId": "D1",
    "domain": "Design Secure Architectures",
    "section": "Secrets Manager",
    "question": "A company stores database credentials in AWS Secrets Manager. Auditors require proof of which IAM principal retrieved secret values and from which IP address. Which approach best meets the requirement?",
    "choices": [
      "Enable CloudWatch metrics for Secrets Manager and export them",
      "Enable CloudTrail and review Secrets Manager API events",
      "Enable VPC Flow Logs and search for AWS endpoint connections",
      "Enable AWS Config to record changes to secret rotation schedule"
    ],
    "answer": 1,
    "explanation": "CloudTrail logs Secrets Manager API calls (including GetSecretValue), capturing identity and source IP, which is what auditors need.",
    "difficulty": "Hard",
    "choiceExplanations": {
      "0": "CloudWatch metrics provide aggregate numerical data about Secrets Manager operations (such as API call counts) but do not capture the identity of the IAM principal or the source IP address of who accessed the secrets.",
      "2": "VPC Flow Logs capture network traffic metadata (source/destination IPs, ports, protocols) but do not identify which IAM principal made the API call or which specific secret was accessed, lacking the application-level detail auditors require.",
      "3": "AWS Config tracks configuration changes to AWS resources over time, such as rotation schedule modifications, but does not log data plane operations like GetSecretValue API calls or capture who retrieved secret values."
    }
  },
  {
    "id": "SAA-366",
    "domainId": "D1",
    "domain": "Design Secure Architectures",
    "section": "KMS",
    "question": "You enable S3 Cross-Region Replication on a bucket that uses SSE-KMS. Replication fails due to an access error on the destination KMS key. Which of the following must be implemented in the current architecture to satisfy the new requirement?",
    "choices": [
      "Update the destination KMS key policy to allow the replication role to use KMS encryption actions",
      "Disable versioning on the destination bucket",
      "Enable S3 Transfer Acceleration on both buckets",
      "Disable SSE-KMS on the source bucket and switch to SSE-S3"
    ],
    "answer": 0,
    "explanation": "For SSE-KMS replication, the replication role must be allowed by the destination key policy to perform encrypt/data key actions so replicas can be encrypted at the destination.",
    "difficulty": "Hard",
    "choiceExplanations": {
      "1": "This is incorrect because versioning is actually required on both source and destination buckets for S3 Cross-Region Replication to work; disabling it would break replication entirely rather than fix the KMS access error.",
      "2": "This is incorrect because S3 Transfer Acceleration is a feature for faster data transfers over long distances using CloudFront edge locations, and has no relationship to KMS key permissions or encryption access errors during replication.",
      "3": "This is incorrect because it unnecessarily removes the customer-managed key encryption capability; the proper solution is to grant the replication role appropriate permissions on the destination KMS key rather than downgrading the encryption method."
    }
  },
  {
    "id": "SAA-367",
    "domainId": "D3",
    "domain": "Design High-Performing Architectures",
    "section": "Kinesis",
    "question": "A company ingests telemetry at high throughput. Multiple consumers need sub-second processing and the ability to replay 72 hours of events after code changes. Which service should you choose?",
    "choices": [
      "Amazon Kinesis Data Streams",
      "Amazon SQS standard queue",
      "Amazon Kinesis Data Firehose only",
      "Amazon SNS standard topic"
    ],
    "answer": 0,
    "explanation": "Kinesis Data Streams supports multiple consumers and configurable retention for replay. SNS/SQS don’t provide the same stream replay pattern, and Firehose is delivery-focused without consumer replay semantics.",
    "difficulty": "Hard",
    "choiceExplanations": {
      "1": "SQS messages are deleted after being processed by a consumer, making replay impossible, and it follows a point-to-point model where each message is typically processed by only one consumer rather than supporting multiple concurrent consumers reading the same data.",
      "2": "Firehose is designed for near-real-time delivery to destinations like S3, Redshift, or OpenSearch, but it does not support multiple consumers reading from the stream or provide replay capabilities since it automatically delivers and removes data.",
      "3": "SNS is a push-based pub/sub service that delivers messages immediately to subscribers without storing them, so it cannot provide message replay functionality or retain 72 hours of historical events for reprocessing."
    }
  },
  {
    "id": "SAA-368",
    "domainId": "D3",
    "domain": "Design High-Performing Architectures",
    "section": "Global Accelerator",
    "question": "A multiplayer game uses UDP and needs static anycast IPs and improved performance for global users to AWS endpoints. Which combination of actions best satisfies the requirements while being the most cost-effective? (Choose TWO.)",
    "choices": [
      "Use CloudFront as the entrypoint for UDP",
      "Use Application Load Balancer as the regional endpoint",
      "Use AWS Global Accelerator for the entrypoint",
      "Use S3 Transfer Acceleration for game packets",
      "Use Network Load Balancer as the regional endpoint"
    ],
    "answer": [
      2,
      4
    ],
    "explanation": "Global Accelerator provides static anycast IPs and optimized routing. NLB supports UDP and high throughput as a regional endpoint.",
    "difficulty": "Hard",
    "choiceExplanations": {
      "0": "CloudFront is a content delivery network that only supports HTTP, HTTPS, and WebSocket protocols, and does not support UDP traffic, making it unsuitable for this multiplayer game requirement.",
      "1": "Application Load Balancer operates at Layer 7 and only supports HTTP, HTTPS, and WebSocket protocols, not UDP, which is required for this multiplayer game's network traffic.",
      "3": "S3 Transfer Acceleration is designed specifically for accelerating uploads to and downloads from S3 buckets, not for routing real-time game traffic or UDP packets to application endpoints."
    }
  },
  {
    "id": "SAA-369",
    "domainId": "D3",
    "domain": "Design High-Performing Architectures",
    "section": "Aurora",
    "question": "A read-heavy application uses Aurora MySQL. The team wants to scale read capacity with minimal changes and ensure fast writer failover. Which solution best meets these requirements?",
    "choices": [
      "Use periodic snapshots to improve read performance",
      "Move reads into S3 Select",
      "Add Aurora Replicas and use the reader endpoint for reads",
      "Increase the writer instance size only"
    ],
    "answer": 2,
    "explanation": "Aurora Replicas increase read capacity, and the reader endpoint distributes read traffic. Aurora managed failover improves resilience without complex application changes.",
    "difficulty": "Hard",
    "choiceExplanations": {
      "0": "Snapshots are point-in-time backups used for disaster recovery and data restoration, not for improving read performance or scaling read capacity; they do not serve live read traffic.",
      "1": "S3 Select is designed to retrieve subsets of data from objects stored in S3, not for querying relational database data; this would require significant application changes and data architecture redesign, not meeting the 'minimal changes' requirement.",
      "3": "Vertical scaling of the writer instance does not effectively scale read capacity for read-heavy workloads, and it does not improve failover speed since Aurora Replicas are required for fast automated failover promotion."
    }
  },
  {
    "id": "SAA-370",
    "domainId": "D1",
    "domain": "Design Secure Architectures",
    "section": "KMS",
    "question": "A company encrypts data in us-east-1 and replicates ciphertext to eu-west-1. They must decrypt in both Regions without re-encrypting and want AWS-managed equivalent keys. Which approach should you choose?",
    "choices": [
      "Use one single-Region key and share it to the other Region",
      "Use SSE-S3 so decryption works anywhere",
      "Use KMS multi-Region keys with a replica key in the second Region",
      "Use two unrelated CMKs and keep the alias name identical"
    ],
    "answer": 2,
    "explanation": "KMS multi-Region keys are designed to provide cryptographically related keys across Regions so ciphertext can be decrypted in either Region without re-encryption.",
    "difficulty": "Hard",
    "choiceExplanations": {
      "0": "Single-Region KMS keys cannot be shared or used across AWS Regions; they are bound to the Region where they were created and cannot decrypt ciphertext in another Region.",
      "1": "SSE-S3 uses AWS-managed keys that are specific to each Region, and while S3 handles encryption/decryption transparently, this approach requires re-encryption when data is replicated to another Region and does not provide equivalent customer-managed keys.",
      "3": "Two separate unrelated CMKs are cryptographically independent, meaning ciphertext encrypted with one key cannot be decrypted by the other regardless of alias naming; this would require re-encryption when moving data between Regions."
    }
  },
  {
    "id": "SAA-371",
    "domainId": "D2",
    "domain": "Design Resilient Architectures",
    "section": "Migration",
    "question": "A company must migrate hundreds of on-prem VMs to AWS. They require continuous block-level replication, the ability to launch test cutovers, and a short final cutover window. Which combination of actions best satisfies the given set of requirements while being the most cost-effective? (Choose TWO.)",
    "choices": [
      "Use AWS Application Migration Service (MGN) for replication",
      "Use AWS DMS to replicate VM blocks",
      "Use AWS DataSync for continuous block replication",
      "Perform test cutovers by launching test instances from replicated data",
      "Use S3 Batch Operations to import VM images"
    ],
    "answer": [
      0,
      3
    ],
    "explanation": "MGN provides continuous block-level replication and supports test cutovers by launching test instances, enabling a short final cutover window.",
    "difficulty": "Hard",
    "choiceExplanations": {
      "1": "AWS Database Migration Service (DMS) is designed specifically for database migrations, not for replicating entire VM block-level storage or operating systems, making it unsuitable for full VM migrations.",
      "2": "AWS DataSync is designed for transferring file-based data between on-premises storage and AWS storage services (like S3, EFS, FSx), not for continuous block-level replication of virtual machines required for lift-and-shift migrations.",
      "4": "S3 Batch Operations is used for performing bulk operations on existing S3 objects, not for importing or migrating VM images; it does not provide continuous replication or support test cutovers needed for VM migrations."
    }
  },
  {
    "id": "SAA-372",
    "domainId": "D4",
    "domain": "Design Cost-Optimized Architectures",
    "section": "EFS",
    "question": "A pipeline stores temporary processing files on Amazon EFS. Files are heavily used for 7 days, then rarely accessed but must remain available for 90 days. The team wants to reduce storage cost without changing the app. Which solution should you implement?",
    "choices": [
      "Enable EFS lifecycle management to transition to EFS Infrequent Access after 7 days",
      "Move files to EBS gp3 after 7 days via cron jobs",
      "Replicate EFS to another Region and delete the primary copy",
      "Replace EFS with instance store to reduce cost"
    ],
    "answer": 0,
    "explanation": "EFS lifecycle management automatically transitions infrequently accessed files to EFS IA, lowering cost while keeping the same file system interface.",
    "difficulty": "Hard",
    "choiceExplanations": {
      "1": "This requires application changes to access files from a different storage type (EBS vs EFS), violates the requirement of not changing the app, and adds operational complexity with custom cron job management.",
      "2": "This would require application changes to access files in a different region, increases latency, adds cross-region data transfer costs, and does not reduce storage costs since you're still storing the same amount of data.",
      "3": "Instance store is ephemeral storage that loses data when the instance stops or terminates, making it unsuitable for files that must remain available for 90 days, and this would require application changes to use a different storage type."
    }
  },
  {
    "id": "SAA-373",
    "domainId": "D1",
    "domain": "Design Secure Architectures",
    "section": "IAM",
    "question": "A company must allow a third-party auditor to review CloudWatch logs and CloudTrail events in a dedicated audit account without giving write permissions. The auditor should not need long-term access keys. Which solution will meet these requirements with the LEAST operational overhead?",
    "choices": [
      "Attach AdministratorAccess to an auditor IAM user to avoid missing permissions",
      "Create an IAM user in the audit account and email the access keys to the auditor",
      "Create a root user in the audit account and enable MFA, then share the credentials",
      "Create an IAM role in the audit account and allow the auditor’s AWS account to assume it with read-only permissions"
    ],
    "answer": 3,
    "explanation": "Cross-account role assumption is the standard pattern for third-party access without distributing long-term keys. You can scope the role to read-only access.",
    "difficulty": "Hard",
    "choiceExplanations": {
      "0": "This violates the principle of least privilege by granting full administrative access including write permissions, when only read-only access to CloudWatch logs and CloudTrail is required. Additionally, IAM users require long-term access keys, which the question explicitly states should be avoided.",
      "1": "IAM users require long-term access keys, which directly contradicts the requirement that the auditor should not need long-term credentials. Emailing access keys is also an insecure practice and creates operational overhead for key rotation and management.",
      "2": "You cannot create additional root users in an AWS account as each account has exactly one root user created at account inception. Sharing root credentials is a severe security violation of AWS best practices, and root users have full unrestricted access far exceeding the read-only requirement."
    }
  },
  {
    "id": "SAA-374",
    "domainId": "D2",
    "domain": "Design Resilient Architectures",
    "section": "Route 53",
    "question": "A company runs active-passive endpoints in two Regions. If the primary endpoint fails health checks, traffic must move to standby automatically, then return to primary when healthy. Which solution should be used?",
    "choices": [
      "CloudFront geo restriction",
      "Route 53 failover routing with health checks",
      "Route 53 weighted routing without health checks",
      "An ALB spanning both Regions"
    ],
    "answer": 1,
    "explanation": "Route 53 failover routing uses health checks to shift traffic to a secondary endpoint when the primary is unhealthy and can restore traffic when it becomes healthy again.",
    "difficulty": "Hard",
    "choiceExplanations": {
      "0": "This feature is used to block or allow content access based on geographic location of users, not for health-based failover between endpoints in different regions.",
      "2": "Without health checks, Route 53 cannot detect when the primary endpoint fails and would continue sending traffic to unhealthy endpoints based on configured weights rather than automatically failing over.",
      "3": "Application Load Balancers are regional resources and cannot span multiple AWS Regions; cross-region failover requires a global DNS service like Route 53."
    }
  },
  {
    "id": "SAA-375",
    "domainId": "D1",
    "domain": "Design Secure Architectures",
    "section": "ACM",
    "question": "A company has dozens of internet-facing ALBs in multiple accounts. Each ALB requires a publicly trusted TLS certificate with automatic renewal, and operations wants minimal per-application work. Which approach can be used to fulfill this requirement?",
    "choices": [
      "Use AWS Certificate Manager public certificates and validate using DNS in Route 53 hosted zones",
      "Use ACM Private CA so browsers trust certificates automatically",
      "Use OpenSSL on EC2 and copy certificates to each ALB manually",
      "Use self-signed certificates and rotate them quarterly"
    ],
    "answer": 0,
    "explanation": "ACM public certificates are publicly trusted and support managed renewal when DNS validation is kept in place, minimizing operational overhead compared with manual certificate creation and rotation.",
    "difficulty": "Hard",
    "choiceExplanations": {
      "1": "ACM Private CA issues private certificates that are NOT automatically trusted by public browsers since they are signed by a private certificate authority, not a publicly trusted root CA. Private CA certificates are intended for internal resources, not internet-facing applications.",
      "2": "This approach requires significant manual operational effort to generate, distribute, and renew certificates across dozens of ALBs in multiple accounts, directly contradicting the requirement for minimal per-application work. Additionally, certificates generated this way would need to be obtained from a public CA to be publicly trusted.",
      "3": "Self-signed certificates are not trusted by browsers and will display security warnings to users, making them unsuitable for internet-facing applications. Manual quarterly rotation also increases operational overhead rather than minimizing it."
    }
  },
  {
    "id": "SAA-376",
    "domainId": "D3",
    "domain": "Design High-Performing Architectures",
    "section": "S3",
    "question": "A data lake stores tens of millions of objects in S3 with highly unpredictable access. The team wants automatic cost optimization with millisecond retrieval when accessed and no retrieval fees. Which storage class should be used?",
    "choices": [
      "S3 Standard-IA",
      "S3 Intelligent-Tiering",
      "S3 One Zone-IA",
      "S3 Glacier Instant Retrieval"
    ],
    "answer": 1,
    "explanation": "S3 Intelligent-Tiering automatically moves objects between access tiers based on usage patterns while maintaining millisecond retrieval and avoiding retrieval fees for access tiers.",
    "difficulty": "Hard",
    "choiceExplanations": {
      "0": "While it provides millisecond retrieval, it charges retrieval fees per GB retrieved and requires manual lifecycle management rather than automatic cost optimization based on access patterns.",
      "2": "This class charges retrieval fees per GB retrieved, requires manual lifecycle policies for cost optimization, and stores data in only one Availability Zone which reduces durability compared to other options.",
      "3": "Although it provides millisecond retrieval, it charges retrieval fees per GB accessed and is designed for data accessed once per quarter, not for automatic optimization of unpredictable access patterns."
    }
  },
  {
    "id": "SAA-377",
    "domainId": "D4",
    "domain": "Design Cost-Optimized Architectures",
    "section": "Cost Management",
    "question": "Finance wants to categorize AWS costs by project and department for detailed cost tracking. What is the BEST approach?",
    "choices": [
      "Use AWS Budgets to set spending limits per project",
      "Create separate AWS accounts for each project",
      "Use cost allocation tags and enable them in the Billing console",
      "Export billing data to S3 and use Athena for analysis"
    ],
    "answer": 2,
    "explanation": "Cost allocation tags allow you to categorize and track AWS costs by project, department, or any custom dimension. After applying tags to resources and enabling them in the Billing console, you can view costs broken down by tag in Cost Explorer and billing reports.",
    "difficulty": "Hard",
    "choiceExplanations": {
      "0": "AWS Budgets is designed for setting cost thresholds and alerts, not for categorizing or tracking costs by project and department. It monitors spending against defined limits but does not provide the detailed cost categorization and breakdown capabilities that the question requires.",
      "1": "While this approach can separate costs by project, it introduces significant operational overhead and complexity in managing multiple accounts. Cost allocation tags provide the same categorization capability within a single account without the administrative burden of maintaining separate accounts, making this approach unnecessarily complex.",
      "3": "While this method can analyze billing data, it requires additional setup, manual data processing, and technical expertise to query the data. Cost allocation tags with Cost Explorer provide built-in, native cost categorization and visualization without the complexity of setting up a custom analytics solution."
    }
  },
  {
    "id": "SAA-378",
    "domainId": "D1",
    "domain": "Design Secure Architectures",
    "section": "Networking",
    "question": "A global company has two VPCs in different AWS Regions: one for HR and one for Finance. The departments must be able to access each other’s resources. Security also mandates in-line inspection to actively block malicious traffic patterns between the VPCs. Which network architecture design should the Solutions Architect set up to satisfy these requirements?",
    "choices": [
      "Create Amazon Route 53 traffic policies between the VPCs and enable Route 53 Resolver DNS Firewall to inspect and block inter-VPC traffic",
      "Connect the VPCs using VPC peering across Regions, then use security groups to inspect and block vulnerability exploits in transit",
      "Deploy an AWS Transit Gateway with inter-Region peering, attach both VPCs, and use AWS Network Firewall in a dedicated inspection VPC to enforce in-line traffic inspection and blocking",
      "Build an AWS Direct Connect Gateway with VPC associations, then enable AWS Security Hub to inspect and block traffic between the VPCs"
    ],
    "answer": 2,
    "explanation": "Transit Gateway supports scalable hub-and-spoke connectivity, including inter-Region TGW peering. AWS Network Firewall provides stateful, in-line inspection and blocking. Route 53/DNS Firewall is DNS-focused, Security Hub is posture management, and security groups are not an IPS for in-line inspection.",
    "difficulty": "Hard",
    "choiceExplanations": {
      "0": "Route 53 traffic policies manage DNS-based routing and do not provide network connectivity between VPCs, while Route 53 Resolver DNS Firewall only filters DNS queries (domain name lookups) and cannot inspect or block actual network traffic flowing between VPCs.",
      "1": "Security groups are stateful firewalls that filter traffic based on IP addresses, ports, and protocols at the instance level, but they cannot perform deep packet inspection or detect and block malicious traffic patterns like an IPS/IDS would.",
      "3": "AWS Direct Connect Gateway is designed to connect on-premises networks to multiple VPCs and does not provide VPC-to-VPC connectivity without an on-premises path, and AWS Security Hub is a security posture management service that aggregates findings but does not inspect or block network traffic."
    }
  },
  {
    "id": "SAA-379",
    "domainId": "D2",
    "domain": "Design Resilient Architectures",
    "section": "S3",
    "question": "A company stores critical documents in Amazon S3 in us-east-1. The compliance team requires that the same data exist in eu-west-1 for disaster recovery. Only objects under the prefix legal/ should replicate, and replicated objects must remain encrypted using SSE-KMS with a destination KMS key. Which solution best meets these requirements with the LEAST operational overhead?",
    "choices": [
      "Enable S3 Transfer Acceleration on both buckets and configure a bucket policy to copy new objects to the destination bucket automatically",
      "Enable S3 Cross-Region Replication with a replication rule filtered to legal/, keep versioning enabled, and update the destination KMS key policy to allow the replication role to encrypt with the destination key",
      "Create a Lambda function triggered by S3 events to copy objects across Regions and use KMS decrypt/encrypt calls inside the function for each object",
      "Run a nightly AWS DataSync task to move objects from the source bucket to the destination bucket and enable default encryption on the destination"
    ],
    "answer": 1,
    "explanation": "CRR supports prefix filters, requires versioning, and works with SSE-KMS when the destination key policy allows the replication role to encrypt. It is the lowest-ops native solution compared with custom Lambda or scheduled copy jobs.",
    "difficulty": "Hard",
    "choiceExplanations": {
      "0": "S3 Transfer Acceleration only speeds up uploads to a single bucket using CloudFront edge locations; it does not provide replication functionality, and bucket policies cannot automatically copy objects between buckets.",
      "2": "While this approach would work functionally, it introduces significant operational overhead requiring custom code development, maintenance, error handling, and monitoring compared to the native CRR feature that handles all this automatically.",
      "3": "DataSync runs on a schedule (nightly) rather than continuously, which does not meet disaster recovery requirements for near-real-time replication, and introduces operational overhead of managing scheduled tasks compared to native CRR."
    }
  },
  {
    "id": "SAA-380",
    "domainId": "D3",
    "domain": "Design High-Performing Architectures",
    "section": "ECS",
    "question": "A company runs an internal API on Amazon ECS using the Fargate launch type behind an ALB. During deployments, traffic spikes and some containers are terminated while still handling requests, causing a burst of 5xx errors. The team wants a solution that reduces deployment errors without changing application code. Which approach should the Solutions Architect recommend?",
    "choices": [
      "Configure ECS service deployment to use a higher desired count and enable deployment circuit breaker with automatic rollback, ensuring tasks are drained properly before termination",
      "Switch from ALB to NLB so that connections are preserved and tasks are never terminated during deployments",
      "Enable S3 static website hosting for the API endpoints and route traffic through CloudFront to avoid container termination issues",
      "Move the API to Lambda@Edge so scaling is global and deployments never cause any 5xx responses"
    ],
    "answer": 0,
    "explanation": "ECS deployment settings (including deployment configuration and circuit breaker) help reduce failed deployments and roll back automatically. Proper draining/health checks and controlled deployment behavior mitigate 5xx spikes without changing code.",
    "difficulty": "Hard",
    "choiceExplanations": {
      "1": "NLB does not prevent task termination during deployments, and while NLB supports connection draining, ALB also supports connection draining through deregistration delay settings. The core issue of tasks being terminated while handling requests is an ECS deployment configuration problem, not a load balancer type issue.",
      "2": "S3 static website hosting can only serve static content and cannot host dynamic API endpoints that require server-side processing. This fundamentally changes the architecture and would not work for an internal API running on ECS containers.",
      "3": "Lambda@Edge is designed for lightweight request/response manipulation at CloudFront edge locations with strict limitations (execution time, package size), not for hosting full APIs. Additionally, Lambda deployments can still cause errors, and this would require significant code changes contrary to the requirement."
    }
  },
  {
    "id": "SAA-381",
    "domainId": "D4",
    "domain": "Design Cost-Optimized Architectures",
    "section": "EC2 Pricing",
    "question": "A data processing workload runs 24/7 on EC2 and is expected to remain steady for at least 2 years. The company wants to reduce compute cost but must be able to change instance families if needed later. Which purchasing option provides the best balance of savings and flexibility?",
    "choices": [
      "Purchase Standard Reserved Instances for a specific instance family and size for 2 years to maximize discount",
      "Use Spot Instances for the entire workload and rely on instance interruption handling for cost savings",
      "Use Compute Savings Plans to cover the baseline usage while retaining flexibility across instance families and Regions",
      "Use Dedicated Hosts so the workload qualifies for the biggest discount while keeping full flexibility"
    ],
    "answer": 2,
    "explanation": "Compute Savings Plans provide discounts for steady usage while remaining flexible across instance families, sizes, and Regions compared with Standard RIs. Spot is risky for 24/7 steady workloads, and Dedicated Hosts are for compliance/licensing needs, not general cost optimization.",
    "difficulty": "Hard",
    "choiceExplanations": {
      "0": "Standard Reserved Instances lock you into a specific instance type, size, and Availability Zone, which does not meet the requirement to change instance families if needed later. While they offer significant discounts, they lack the flexibility that Compute Savings Plans provide across instance families and Regions.",
      "1": "Spot Instances can be interrupted by AWS with only 2 minutes notice when capacity is needed, making them unsuitable for workloads that must run 24/7 continuously. While they offer up to 90% savings, the interruption risk is unacceptable for steady, always-on production workloads.",
      "3": "Dedicated Hosts are designed for licensing compliance and regulatory requirements, not general cost optimization, and are actually more expensive than shared tenancy options. They do not provide the biggest discount and are the wrong tool for simply reducing compute costs on standard workloads."
    }
  },
  {
    "id": "SAA-382",
    "domainId": "D2",
    "domain": "Design Resilient Architectures",
    "section": "Route 53",
    "question": "A company has an application deployed in two Regions. Users should normally go to the closest Region, but if one Region becomes unhealthy, all traffic must fail over to the healthy Region automatically. Which Route 53 configuration best meets the requirements?",
    "choices": [
      "Geolocation routing so users are forced to specific Regions based on country and never fail over automatically",
      "Weighted routing set to 50/50 so both Regions receive traffic equally, and remove health checks to avoid DNS flapping",
      "Latency-based routing combined with health checks on both endpoints to route to the lowest-latency healthy Region",
      "Multi-Value Answer routing with a long TTL so clients cache answers and reduce Route 53 query costs"
    ],
    "answer": 2,
    "explanation": "Latency-based routing directs users to the lowest-latency endpoint and, with health checks, removes unhealthy endpoints from DNS responses for automatic failover behavior.",
    "difficulty": "Hard",
    "choiceExplanations": {
      "0": "Geolocation routing directs users based on their geographic location (country/continent), not latency, and while it can support failover when combined with health checks, this answer explicitly states it never fails over automatically, which fails the automatic failover requirement.",
      "1": "Weighted routing distributes traffic based on assigned weights rather than proximity/latency, and removing health checks eliminates the ability to detect unhealthy endpoints, making automatic failover impossible when a Region becomes unhealthy.",
      "3": "Multi-Value Answer routing returns multiple IP addresses and lets clients choose, but it does not route users to the closest or lowest-latency Region, and long TTLs delay failover response times when health status changes, working against the automatic failover requirement."
    }
  },
  {
    "id": "SAA-383",
    "domainId": "D1",
    "domain": "Design Secure Architectures",
    "section": "IAM",
    "question": "A company wants developers to access production resources only through federated SSO and must avoid long-term IAM user access keys. Access should be granted temporarily and audited. Which approach best satisfies these requirements with the LEAST operational overhead?",
    "choices": [
      "Create IAM users for each developer and rotate access keys every 30 days using an internal script",
      "Use IAM roles with AWS IAM Identity Center (AWS SSO) so developers obtain short-lived credentials through federation",
      "Store AWS access keys in AWS Secrets Manager and issue them to developers only when needed",
      "Share a single IAM user among all developers and enforce MFA to prevent misuse"
    ],
    "answer": 1,
    "explanation": "Identity Center (SSO) with IAM roles provides federated access with temporary credentials and centralized auditing. It eliminates long-term keys and reduces operational burden compared with rotating user keys.",
    "difficulty": "Hard",
    "choiceExplanations": {
      "0": "This approach uses long-term IAM access keys which the requirements explicitly prohibit, and maintaining rotation scripts adds significant operational overhead compared to federated SSO with automatic temporary credentials.",
      "2": "This still relies on long-term IAM access keys rather than federated SSO, and manually issuing keys adds operational overhead while not providing the temporary credential model that IAM roles with federation automatically deliver.",
      "3": "Sharing credentials violates AWS security best practices, uses long-term access keys instead of federated SSO, and makes individual auditing impossible since all actions appear under the same identity."
    }
  },
  {
    "id": "SAA-384",
    "domainId": "D3",
    "domain": "Design High-Performing Architectures",
    "section": "CloudFront",
    "question": "A company serves large downloadable files globally from an S3 origin behind CloudFront. Security requires that only paid subscribers can download files, and the access mechanism must work even if the S3 bucket is private. Which solution will meet these requirements?",
    "choices": [
      "Use Route 53 weighted routing to send subscribers to a different S3 bucket",
      "Enable S3 Transfer Acceleration and require users to authenticate with IAM user access keys",
      "Use CloudFront signed URLs or signed cookies and restrict S3 access to CloudFront using an origin access control (OAC) or similar mechanism",
      "Make the S3 bucket public-read and rely on application-side authentication only"
    ],
    "answer": 2,
    "explanation": "Signed URLs/cookies enforce viewer authorization at CloudFront, and OAC/OAI-style access ensures the S3 bucket remains private and only CloudFront can fetch objects.",
    "difficulty": "Hard",
    "choiceExplanations": {
      "0": "Route 53 weighted routing distributes traffic based on assigned weights for load balancing purposes, not for authentication or authorization. This approach does not provide any mechanism to verify subscriber status or restrict access to paid users only.",
      "1": "S3 Transfer Acceleration speeds up uploads to S3 using CloudFront edge locations but does not address content delivery or access control. Distributing IAM user access keys to subscribers is a security anti-pattern, as it exposes AWS credentials and is not scalable for managing customer access.",
      "3": "Making the bucket public-read violates the requirement that the S3 bucket must remain private. Anyone who discovers the S3 URL could bypass the application authentication entirely and download files directly without being a paid subscriber."
    }
  },
  {
    "id": "SAA-385",
    "domainId": "D2",
    "domain": "Design Resilient Architectures",
    "section": "SQS",
    "question": "A payment pipeline uses standard SQS and a Lambda consumer. The business now requires strict ordering for events per customer and exactly-once processing semantics to avoid double-charging. Which solution best meets the requirement with minimal redesign?",
    "choices": [
      "Keep the standard queue and increase the visibility timeout so messages are processed only once",
      "Migrate to an SQS FIFO queue and use Message Group IDs per customer along with deduplication",
      "Use Kinesis Data Firehose to deliver data into S3 and process it from there in order",
      "Use an SNS standard topic to broadcast messages and rely on retries for ordering"
    ],
    "answer": 1,
    "explanation": "SQS FIFO supports ordering and deduplication features (exactly-once processing semantics within FIFO constraints), and Message Group IDs maintain ordering per customer.",
    "difficulty": "Hard",
    "choiceExplanations": {
      "0": "Standard SQS queues provide at-least-once delivery and best-effort ordering, meaning they cannot guarantee strict ordering or exactly-once processing regardless of visibility timeout settings. Visibility timeout only prevents other consumers from receiving a message temporarily but does not prevent duplicate deliveries.",
      "2": "Kinesis Data Firehose is designed for near-real-time data delivery to destinations like S3, not for maintaining strict message ordering or exactly-once processing semantics. This approach would require significant redesign and adds complexity without providing the ordering guarantees needed for payment processing.",
      "3": "SNS standard topics do not guarantee message ordering and use at-least-once delivery, which could result in duplicate messages and out-of-order processing. Retries cannot establish ordering and would actually increase the risk of duplicate deliveries and double-charging."
    }
  },
  {
    "id": "SAA-386",
    "domainId": "D1",
    "domain": "Design Secure Architectures",
    "section": "Network Firewall",
    "question": "A company centralizes outbound internet access from multiple VPCs using a shared egress VPC. Security now requires stateful inspection, domain-based allow/deny controls, and centralized logging for all egress traffic. Which solution should be implemented?",
    "choices": [
      "Enable VPC Flow Logs and block domains by adding route table blackhole entries",
      "Deploy AWS Network Firewall in the egress VPC and route traffic through firewall endpoints with centralized logging",
      "Attach AWS WAF to the NAT Gateway so it can inspect and block outbound requests",
      "Use security groups with outbound rules to inspect and block domain names at Layer 7"
    ],
    "answer": 1,
    "explanation": "AWS Network Firewall provides stateful inspection and filtering with centralized logging for VPC traffic. Security groups and WAF don’t provide the required in-line egress inspection for arbitrary outbound traffic.",
    "difficulty": "Hard",
    "choiceExplanations": {
      "0": "VPC Flow Logs only capture metadata about network traffic (source/destination IPs, ports, protocol) for monitoring purposes and cannot perform stateful inspection or domain-based filtering. Route table blackhole entries can only block traffic to specific IP ranges, not domain names, and provide no inspection capabilities.",
      "2": "AWS WAF cannot be attached to NAT Gateways; WAF can only be associated with CloudFront distributions, Application Load Balancers, API Gateway, and AppSync. Additionally, WAF is designed for inbound web application protection, not outbound traffic inspection.",
      "3": "Security groups operate at Layer 3/4 and can only filter based on IP addresses, ports, and protocols. They cannot perform domain name filtering, Layer 7 inspection, or stateful deep packet inspection required for domain-based allow/deny controls."
    }
  },
  {
    "id": "SAA-388",
    "domainId": "D3",
    "domain": "Design High-Performing Architectures",
    "section": "S3",
    "question": "Which S3 feature allows uploading large objects by splitting them into parts that can be retried independently?",
    "choices": [
      "S3 Inventory",
      "S3 Multipart Upload",
      "S3 Event Notifications",
      "S3 Object Lock"
    ],
    "answer": 1,
    "explanation": "Multipart Upload breaks an object into parts, enabling parallel upload and independent retries.",
    "difficulty": "Easy",
    "choiceExplanations": {
      "0": "This feature provides scheduled reports listing objects and their metadata in a bucket for auditing and compliance purposes, not for uploading large objects in parts.",
      "2": "This feature triggers notifications to SNS, SQS, or Lambda when specific events occur in a bucket (like object creation or deletion), but does not handle object uploads or splitting files into parts.",
      "3": "This feature prevents objects from being deleted or overwritten for a specified retention period using WORM (Write Once Read Many) protection, and has no relation to uploading objects in parts."
    }
  },
  {
    "id": "SAA-389",
    "domainId": "D2",
    "domain": "Design Resilient Architectures",
    "section": "ELB",
    "question": "Which AWS service distributes incoming HTTP/HTTPS traffic across targets and supports path-based routing?",
    "choices": [
      "Gateway Load Balancer",
      "AWS Direct Connect",
      "Network Load Balancer",
      "Application Load Balancer"
    ],
    "answer": 3,
    "explanation": "An Application Load Balancer operates at Layer 7 and supports routing features like path-based rules.",
    "difficulty": "Easy",
    "choiceExplanations": {
      "0": "Operates at Layer 3 (network layer) and is designed for deploying, scaling, and managing third-party virtual appliances like firewalls and intrusion detection systems, not for HTTP/HTTPS traffic distribution or path-based routing.",
      "1": "This is a dedicated network connection service that establishes a private link between your on-premises data center and AWS, not a load balancing service that distributes traffic or supports routing rules.",
      "2": "Operates at Layer 4 (transport layer) handling TCP/UDP traffic with ultra-low latency, but does not support Layer 7 features like path-based routing since it cannot inspect HTTP/HTTPS content."
    }
  },
  {
    "id": "SAA-390",
    "domainId": "D4",
    "domain": "Design Cost-Optimized Architectures",
    "section": "EC2 Pricing",
    "question": "Which EC2 pricing model provides the biggest discounts but can be interrupted with little notice?",
    "choices": [
      "Spot Instances",
      "On-Demand Instances",
      "Dedicated Hosts",
      "Reserved Instances"
    ],
    "answer": 0,
    "explanation": "Spot Instances offer deep discounts but can be interrupted when AWS needs the capacity back.",
    "difficulty": "Easy",
    "choiceExplanations": {
      "1": "These provide no discount as you pay full price per hour or second with no commitment, and they cannot be interrupted by AWS, making them the opposite of what the question describes.",
      "2": "These are physical servers dedicated to your use and typically cost more than standard instances rather than providing discounts, and they are not subject to interruption by AWS.",
      "3": "While these offer significant discounts (up to 72%) compared to On-Demand pricing, they require a 1 or 3-year commitment and are not subject to interruption, unlike Spot Instances which offer even deeper discounts but can be reclaimed."
    }
  },
  {
    "id": "SAA-391",
    "domainId": "D1",
    "domain": "Design Secure Architectures",
    "section": "IAM",
    "question": "A company wants to ensure that IAM users cannot accidentally expose their AWS credentials in application code. What is the AWS best practice for granting applications running on EC2 instances access to AWS services?",
    "choices": [
      "Store IAM user access keys in environment variables on the EC2 instance",
      "Attach an IAM role to the EC2 instance",
      "Embed access keys directly in the application code",
      "Share a single set of IAM user credentials across all EC2 instances"
    ],
    "answer": 1,
    "explanation": "IAM roles provide temporary credentials to EC2 instances without requiring long-term access keys, following AWS security best practices.",
    "difficulty": "Easy",
    "choiceExplanations": {
      "0": "While environment variables are better than hardcoding, this still uses long-term IAM user credentials that can be exposed, require manual rotation, and persist on the instance, violating AWS best practices for EC2 applications.",
      "2": "This is the worst practice as credentials can be accidentally committed to version control, exposed in logs, or discovered through code inspection, creating significant security vulnerabilities.",
      "3": "Sharing credentials violates the principle of least privilege, makes credential rotation difficult, prevents individual instance auditing, and if compromised affects all instances using those credentials."
    }
  },
  {
    "id": "SAA-392",
    "domainId": "D1",
    "domain": "Design Secure Architectures",
    "section": "KMS",
    "question": "A company needs to encrypt data at rest in an Amazon S3 bucket. Which AWS service should they use to manage the encryption keys?",
    "choices": [
      "AWS Systems Manager",
      "AWS Secrets Manager",
      "AWS Certificate Manager",
      "AWS Key Management Service (KMS)"
    ],
    "answer": 3,
    "explanation": "AWS KMS is specifically designed for creating and managing cryptographic keys for encryption, including S3 server-side encryption.",
    "difficulty": "Easy",
    "choiceExplanations": {
      "0": "This service is used for operational management of AWS resources, including configuration management, patching, and parameter storage, but it is not designed to create or manage cryptographic encryption keys for data at rest.",
      "1": "This service is designed to store, rotate, and manage secrets like database credentials and API keys, not to create and manage cryptographic keys for encrypting data at rest in S3.",
      "2": "This service manages SSL/TLS certificates for securing data in transit and enabling HTTPS connections, not for managing encryption keys used to encrypt data at rest."
    }
  },
  {
    "id": "SAA-393",
    "domainId": "D1",
    "domain": "Design Secure Architectures",
    "section": "Security Groups",
    "question": "A developer needs to allow inbound SSH access to an EC2 instance only from their company's office IP address. Which AWS feature should they configure?",
    "choices": [
      "Network ACL with a deny rule for all other IPs",
      "Security group with an inbound rule allowing port 22 from the office IP",
      "IAM policy restricting SSH access",
      "VPC route table entry"
    ],
    "answer": 1,
    "explanation": "Security groups act as virtual firewalls and can restrict inbound SSH (port 22) access to specific IP addresses.",
    "difficulty": "Easy",
    "choiceExplanations": {
      "0": "While NACLs can filter traffic, this approach is overly complex and would require maintaining explicit deny rules for all non-office IPs, whereas security groups are stateful and deny all traffic by default, making them the simpler and recommended solution for instance-level access control.",
      "2": "IAM policies control access to AWS API operations and resources, not network-level traffic like SSH connections to EC2 instances; SSH access is controlled at the network layer through security groups or NACLs.",
      "3": "Route tables determine where network traffic is directed within a VPC and to external destinations, but they do not filter or restrict traffic based on source IP addresses or ports; they are for routing decisions, not access control."
    }
  },
  {
    "id": "SAA-394",
    "domainId": "D2",
    "domain": "Design Resilient Architectures",
    "section": "Multi-AZ",
    "question": "A company wants to ensure their RDS database remains available if an Availability Zone fails. What feature should they enable?",
    "choices": [
      "RDS Read Replicas",
      "Multi-AZ deployment",
      "RDS snapshots",
      "Enhanced monitoring"
    ],
    "answer": 1,
    "explanation": "Multi-AZ deployment automatically provisions and maintains a synchronous standby replica in a different AZ for high availability and automatic failover.",
    "difficulty": "Easy",
    "choiceExplanations": {
      "0": "Read Replicas are designed for read scalability and offloading read traffic, not for high availability; they use asynchronous replication and do not provide automatic failover when an AZ fails.",
      "2": "Snapshots are point-in-time backups stored in S3 used for data recovery and restoration, but they do not provide automatic failover or continuous availability during an AZ failure.",
      "3": "Enhanced monitoring provides detailed metrics about the database instance's operating system and processes, but it is an observability feature that does not provide any failover or high availability capabilities."
    }
  },
  {
    "id": "SAA-395",
    "domainId": "D2",
    "domain": "Design Resilient Architectures",
    "section": "ELB",
    "question": "An application running on multiple EC2 instances needs to distribute incoming traffic evenly across all healthy instances. Which AWS service should be used?",
    "choices": [
      "Amazon Route 53",
      "AWS Auto Scaling",
      "Elastic Load Balancer",
      "Amazon CloudFront"
    ],
    "answer": 2,
    "explanation": "Elastic Load Balancer automatically distributes incoming application traffic across multiple targets and performs health checks.",
    "difficulty": "Easy",
    "choiceExplanations": {
      "0": "While Route 53 is a DNS service that can route traffic to multiple endpoints using routing policies, it operates at the DNS level and cannot perform real-time health checks and traffic distribution across EC2 instances within a single application tier like a load balancer can.",
      "1": "Auto Scaling automatically adjusts the number of EC2 instances based on demand or schedules, but it does not distribute incoming traffic across instances—it manages capacity, not traffic routing.",
      "3": "CloudFront is a content delivery network (CDN) that caches and delivers content from edge locations to reduce latency, but it is not designed to distribute traffic evenly across multiple EC2 instances in an origin server group."
    }
  },
  {
    "id": "SAA-396",
    "domainId": "D3",
    "domain": "Design High-Performing Architectures",
    "section": "CloudFront",
    "question": "A company serves static content to users worldwide and wants to reduce latency for global users. Which AWS service should they use?",
    "choices": [
      "AWS Global Accelerator",
      "Amazon Route 53",
      "Amazon CloudFront",
      "Amazon S3 Transfer Acceleration"
    ],
    "answer": 2,
    "explanation": "CloudFront is a CDN that caches content at edge locations worldwide, reducing latency for global users accessing static content.",
    "difficulty": "Easy",
    "choiceExplanations": {
      "0": "While it improves performance by routing traffic through AWS's global network, it does not cache content at edge locations like CloudFront does, making it better suited for dynamic applications rather than static content delivery.",
      "1": "This is a DNS service that can route users to the nearest endpoint, but it does not cache or serve content itself, so it cannot reduce latency for delivering static content to global users.",
      "3": "This service accelerates uploads to S3 buckets using edge locations, but it is designed for data transfers into S3, not for serving static content to end users with reduced latency."
    }
  },
  {
    "id": "SAA-397",
    "domainId": "D3",
    "domain": "Design High-Performing Architectures",
    "section": "ElastiCache",
    "question": "An application frequently reads the same data from a relational database, causing high database load. Which service can help reduce database read load by caching frequently accessed data?",
    "choices": [
      "Amazon ElastiCache",
      "Amazon DynamoDB",
      "AWS Lambda",
      "Amazon SQS"
    ],
    "answer": 0,
    "explanation": "ElastiCache provides in-memory caching (Redis or Memcached) to store frequently accessed data, reducing database read operations.",
    "difficulty": "Easy",
    "choiceExplanations": {
      "1": "While DynamoDB is a high-performance NoSQL database that can handle high read loads, it is a separate database service rather than a caching layer, and migrating from a relational database to DynamoDB would require significant application changes rather than simply reducing load on the existing database.",
      "2": "Lambda is a serverless compute service for running code in response to events, not a caching service; it cannot store and serve frequently accessed data to reduce database read operations.",
      "3": "SQS is a message queuing service used for decoupling application components and handling asynchronous communication, not for caching data to reduce database read load."
    }
  },
  {
    "id": "SAA-398",
    "domainId": "D3",
    "domain": "Design High-Performing Architectures",
    "section": "EBS",
    "question": "A database application requires consistent low-latency disk performance with high IOPS. Which EBS volume type is best suited for this workload?",
    "choices": [
      "EBS Provisioned IOPS SSD (io2)",
      "EBS Throughput Optimized HDD (st1)",
      "EBS Cold HDD (sc1)",
      "EBS General Purpose SSD (gp3)"
    ],
    "answer": 0,
    "explanation": "Provisioned IOPS SSD volumes are designed for I/O intensive workloads requiring sustained high IOPS and consistent low-latency performance.",
    "difficulty": "Easy",
    "choiceExplanations": {
      "1": "This HDD-based volume type is optimized for throughput-intensive workloads like big data and log processing, not for high IOPS; it delivers a maximum of only 500 IOPS and cannot provide the consistent low-latency performance required for database applications.",
      "2": "This is the lowest-cost HDD option designed for infrequently accessed data, offering only 250 maximum IOPS with higher latency, making it completely unsuitable for database workloads requiring consistent low-latency and high IOPS performance.",
      "3": "While gp3 provides good baseline performance (3,000 IOPS baseline, up to 16,000 IOPS), it is designed for general-purpose workloads and does not guarantee the same level of consistent, sustained low-latency performance that io2 provides for mission-critical database applications requiring up to 64,000 IOPS."
    }
  },
  {
    "id": "SAA-399",
    "domainId": "D4",
    "domain": "Design Cost-Optimized Architectures",
    "section": "S3",
    "question": "A company has log files in S3 that are frequently accessed for 30 days, then rarely accessed but must be retained for compliance. Which approach optimizes storage costs?",
    "choices": [
      "Keep all logs in S3 Standard indefinitely",
      "Use S3 Lifecycle policies to transition logs to S3 Glacier after 30 days",
      "Delete logs after 30 days and recreate them if needed",
      "Move logs to EBS volumes after 30 days"
    ],
    "answer": 1,
    "explanation": "S3 Lifecycle policies can automatically transition objects to lower-cost storage classes like Glacier for long-term archival, reducing costs while maintaining compliance.",
    "difficulty": "Easy",
    "choiceExplanations": {
      "0": "S3 Standard is the most expensive storage class and is designed for frequently accessed data; keeping rarely accessed logs in Standard storage wastes money when lower-cost archival options like Glacier exist.",
      "2": "This violates the compliance requirement to retain logs, and log files typically cannot be recreated once deleted since they capture historical events and activities.",
      "3": "EBS volumes are block storage designed for EC2 instances and are significantly more expensive than S3 Glacier for archival storage; this approach increases costs rather than optimizing them."
    }
  },
  {
    "id": "SAA-400",
    "domainId": "D4",
    "domain": "Design Cost-Optimized Architectures",
    "section": "EC2 Pricing",
    "question": "A company runs batch processing jobs that can be interrupted and resumed without issues. Which EC2 pricing model would be most cost-effective?",
    "choices": [
      "On-Demand Instances",
      "Reserved Instances",
      "Spot Instances",
      "Dedicated Hosts"
    ],
    "answer": 2,
    "explanation": "Spot Instances offer up to 90% discount compared to On-Demand pricing and are ideal for fault-tolerant, flexible workloads that can handle interruptions.",
    "difficulty": "Easy",
    "choiceExplanations": {
      "0": "While On-Demand provides flexibility with no commitment, it offers no discount and is significantly more expensive than Spot Instances, making it not the most cost-effective option for interruptible batch workloads.",
      "1": "Reserved Instances require a 1 or 3-year commitment and provide up to 72% savings, but they are designed for steady-state workloads with predictable usage, not for interruptible batch jobs that can leverage deeper Spot discounts.",
      "3": "Dedicated Hosts provide physical servers dedicated to your use for compliance or licensing requirements, but they are the most expensive option and are not designed for cost optimization of interruptible workloads."
    }
  },
  {
    "id": "SAA-401",
    "domainId": "D1",
    "domain": "Design Secure Architectures",
    "section": "IAM",
    "question": "A company needs to grant a third-party vendor temporary access to specific S3 buckets in their AWS account for auditing purposes. The vendor has their own AWS account and should not require long-term credentials. The solution must follow the principle of least privilege and allow the company to revoke access at any time.\nWhat is the MOST secure approach?",
    "choices": [
      "Create an IAM user with programmatic access in the company's account and share the access keys with the vendor via encrypted email",
      "Configure an IAM role with a trust policy allowing the vendor's AWS account to assume it, with permissions scoped to only the required S3 buckets",
      "Enable public access on the S3 buckets and provide the vendor with pre-signed URLs that expire after 24 hours",
      "Create an IAM group with the necessary S3 permissions and add the vendor's IAM users to the group using cross-account IAM group membership"
    ],
    "answer": 1,
    "explanation": "Cross-account IAM roles with trust policies allow secure temporary access without sharing long-term credentials. The company maintains control and can modify or revoke the role at any time. Pre-signed URLs are time-limited but don't provide the same level of control, and sharing access keys violates security best practices. Cross-account IAM group membership is not supported in AWS.",
    "difficulty": "Medium",
    "choiceExplanations": {
      "0": "This violates security best practices by creating long-term credentials that the question explicitly states should be avoided, and sharing access keys (even encrypted) creates security risks as they can be compromised, are difficult to rotate, and don't provide the same auditability as role assumption.",
      "2": "Enabling public access on S3 buckets is a severe security violation that exposes data to anyone on the internet, and while pre-signed URLs provide temporary access, they don't offer the granular IAM-based access control, CloudTrail logging of who accessed what, or the ability to immediately revoke access that cross-account roles provide.",
      "3": "This approach is technically impossible because AWS IAM does not support cross-account group membership; IAM users can only belong to groups within the same AWS account where they were created."
    }
  },
  {
    "id": "SAA-402",
    "domainId": "D1",
    "domain": "Design Secure Architectures",
    "section": "VPC",
    "question": "An application running in a private subnet needs to access Amazon S3 and DynamoDB without traversing the public internet, while also preventing any internet-bound traffic from the instances. The security team requires that all network traffic remain within the AWS network.\nWhich combination of VPC components achieves this requirement with the LEAST operational overhead?",
    "choices": [
      "Deploy NAT Gateway in a public subnet and configure route tables to route S3 and DynamoDB traffic through the NAT Gateway",
      "Create VPC endpoints for S3 (Gateway endpoint) and DynamoDB (Gateway endpoint) and update route tables accordingly",
      "Establish AWS Direct Connect to route all traffic through the corporate data center firewall before reaching AWS services",
      "Deploy AWS PrivateLink endpoints for both S3 and DynamoDB in each private subnet"
    ],
    "answer": 1,
    "explanation": "Gateway VPC endpoints for S3 and DynamoDB allow private connectivity without internet access and incur no additional charges. NAT Gateway would route traffic through the internet and incurs costs. Direct Connect is unnecessary for AWS service access and adds complexity. While PrivateLink works for many services, S3 and DynamoDB use Gateway endpoints which are simpler and more cost-effective.",
    "difficulty": "Medium",
    "choiceExplanations": {
      "0": "NAT Gateway routes traffic through the public internet to reach AWS services, which violates the requirement to keep all traffic within the AWS network and prevent internet-bound traffic. Additionally, NAT Gateway incurs hourly charges and data processing costs, increasing operational overhead.",
      "2": "Direct Connect is designed for hybrid connectivity between on-premises data centers and AWS, not for VPC-to-AWS-service communication. This approach adds significant complexity, cost, and operational overhead while introducing unnecessary network hops through the corporate data center.",
      "3": "While S3 does support Interface endpoints (PrivateLink), DynamoDB only supports Gateway endpoints, not Interface endpoints. Gateway endpoints are also simpler, free of charge, and require only route table updates rather than deploying ENIs in each subnet, making them the lower operational overhead option."
    }
  },
  {
    "id": "SAA-403",
    "domainId": "D1",
    "domain": "Design Secure Architectures",
    "section": "KMS",
    "question": "A financial services company must encrypt all data at rest in their RDS database and S3 buckets using customer-managed keys. They need to implement automatic key rotation annually and maintain an audit trail of all key usage. Compliance requirements mandate that the company must be able to immediately revoke access to encrypted data if a security breach is detected.\nWhich solution meets all these requirements?",
    "choices": [
      "Use AWS KMS customer managed keys (CMK) with automatic key rotation enabled, CloudTrail logging, and key policies that allow immediate key disablement",
      "Use S3 and RDS default encryption with AWS managed keys and rely on service-level access controls",
      "Implement client-side encryption using keys stored in AWS Secrets Manager with custom rotation Lambda functions",
      "Use AWS KMS with imported key material and manually rotate keys annually using custom scripts"
    ],
    "answer": 0,
    "explanation": "AWS KMS customer managed keys support automatic annual rotation, integrate with CloudTrail for audit logging, and can be immediately disabled via key policies to revoke access. AWS managed keys don't allow immediate disabling by customers. Client-side encryption adds complexity and doesn't integrate as seamlessly. Imported key material requires manual rotation and doesn't support automatic rotation.",
    "difficulty": "Medium",
    "choiceExplanations": {
      "1": "AWS managed keys do not allow customers to disable or delete them, making it impossible to immediately revoke access to encrypted data during a security breach. Additionally, AWS managed keys cannot be managed or controlled by customers as required for customer-managed key compliance.",
      "2": "This approach adds unnecessary complexity and does not integrate seamlessly with RDS and S3 server-side encryption. Secrets Manager is designed for storing secrets like database credentials, not encryption keys, and lacks the cryptographic key management capabilities and CloudTrail integration that KMS provides natively.",
      "3": "KMS keys with imported key material do not support automatic key rotation, requiring manual rotation processes. Manual rotation using custom scripts increases operational overhead and risk of human error, failing to meet the automatic annual rotation requirement."
    }
  },
  {
    "id": "SAA-404",
    "domainId": "D2",
    "domain": "Design Resilient Architectures",
    "section": "Route 53",
    "question": "A global e-commerce application is deployed in both us-east-1 and eu-west-1 regions. The company needs to implement automatic failover to the secondary region if the primary region becomes unavailable, with a Recovery Time Objective (RTO) of less than 1 minute. Health checks must validate application functionality, not just endpoint availability.\nWhat is the MOST appropriate Route 53 configuration?",
    "choices": [
      "Configure Route 53 geolocation routing policy to route users to the nearest region based on their geographic location",
      "Use Route 53 weighted routing policy with 100% traffic to the primary region and 0% to secondary, manually updating weights during failover",
      "Implement Route 53 failover routing policy with health checks configured to monitor application-specific endpoints in each region",
      "Deploy Route 53 latency-based routing to automatically direct users to the lowest latency region"
    ],
    "answer": 2,
    "explanation": "Failover routing with application-level health checks provides automatic failover based on application health, not just network latency or geography. Health checks can be configured to test application functionality (HTTP status, response time) to ensure true availability. Geolocation and latency-based routing don't provide automatic failover. Weighted routing requires manual intervention, failing to meet the RTO requirement.",
    "difficulty": "Medium",
    "choiceExplanations": {
      "0": "Geolocation routing directs traffic based on user location, not application health, so it does not provide automatic failover when a region becomes unavailable and cannot meet the RTO requirement without additional failover configuration.",
      "1": "Manual intervention to update weights during failover cannot meet the sub-1-minute RTO requirement, as it depends on human response time rather than automatic health-based failover.",
      "3": "Latency-based routing optimizes for network performance by directing users to the lowest-latency endpoint, but it does not automatically failover based on application health and would continue routing to an unhealthy region if it has lower latency."
    }
  },
  {
    "id": "SAA-405",
    "domainId": "D2",
    "domain": "Design Resilient Architectures",
    "section": "Backup",
    "question": "A company runs critical databases on Amazon RDS and EC2 instances with attached EBS volumes across multiple Availability Zones. They need a backup strategy that provides cross-region disaster recovery with a Recovery Point Objective (RPO) of 15 minutes and centralized backup management and compliance reporting.\nWhich solution best meets these requirements?",
    "choices": [
      "Create manual EBS snapshots and RDS snapshots every 15 minutes using CloudWatch Events and Lambda, then copy snapshots to a secondary region",
      "Use AWS Backup to create backup plans with 15-minute backup frequency, enable cross-region copy, and use AWS Backup Vault Lock for compliance",
      "Configure RDS automated backups with 15-minute backup windows and use custom scripts to replicate EBS volumes to another region",
      "Implement third-party backup software on EC2 instances to manage all backups and replicate data to S3 in another region"
    ],
    "answer": 1,
    "explanation": "AWS Backup provides centralized backup management across RDS and EBS with policy-based backup plans, automated cross-region copy, and compliance reporting through Backup Vault Lock. It supports the 15-minute RPO requirement and reduces operational overhead. Manual snapshots with Lambda require custom development and lack centralized management. RDS automated backups don't support 15-minute RPO. Third-party solutions add cost and complexity.",
    "difficulty": "Medium",
    "choiceExplanations": {
      "0": "While this approach could technically achieve the 15-minute RPO, it requires significant custom development, lacks centralized backup management capabilities, and does not provide built-in compliance reporting features that AWS Backup offers natively.",
      "2": "RDS automated backups occur once daily during the backup window (not every 15 minutes), so this cannot meet the 15-minute RPO requirement; additionally, custom scripts lack centralized management and compliance reporting capabilities.",
      "3": "Third-party solutions add unnecessary cost, complexity, and operational overhead compared to AWS Backup, and may not integrate natively with RDS for backup management or provide the same level of centralized compliance reporting."
    }
  },
  {
    "id": "SAA-406",
    "domainId": "D3",
    "domain": "Design High-Performing Architectures",
    "section": "RDS/Aurora",
    "question": "An online analytics platform experiences read-heavy database workloads with millions of queries per day. The application requires sub-10ms read latency for frequently accessed data and can tolerate slightly stale data (up to 30 seconds old) for read queries. The database is currently running on RDS MySQL and experiencing performance bottlenecks during peak hours.\nWhat combination of services would BEST improve read performance while minimizing infrastructure changes?",
    "choices": [
      "Migrate to Amazon Aurora and add up to 15 Aurora read replicas to distribute read traffic",
      "Implement Amazon ElastiCache for Redis in front of the RDS database to cache frequent queries, with a TTL of 30 seconds",
      "Vertically scale the RDS instance to a larger instance type with more CPU and memory resources",
      "Create multiple RDS read replicas and use Route 53 weighted routing to distribute queries across replicas"
    ],
    "answer": 1,
    "explanation": "ElastiCache for Redis provides sub-millisecond read latency for cached data and is ideal for read-heavy workloads with tolerable data staleness. The 30-second TTL matches the application's tolerance. While Aurora read replicas improve scalability, they still involve database queries with higher latency than cache. Vertical scaling has limits and doesn't address the read-heavy pattern. RDS read replicas help but don't provide the sub-10ms latency that cache delivers.",
    "difficulty": "Medium",
    "choiceExplanations": {
      "0": "While Aurora provides improved performance and scalability over RDS MySQL, read replicas still involve database queries with typical latencies of several milliseconds, which may not consistently achieve sub-10ms latency for all queries. Additionally, migrating to Aurora requires significant infrastructure changes compared to simply adding a caching layer.",
      "2": "Vertical scaling has inherent limits, requires downtime during the resize operation, and doesn't fundamentally address the read-heavy workload pattern. It also doesn't provide the sub-millisecond latency that caching offers for frequently accessed data.",
      "3": "Using Route 53 for database query distribution is not an appropriate architectural pattern since Route 53 is designed for DNS-based routing, not database connection management. Read replicas also cannot guarantee sub-10ms latency as consistently as an in-memory cache, and this approach adds unnecessary complexity."
    }
  },
  {
    "id": "SAA-407",
    "domainId": "D3",
    "domain": "Design High-Performing Architectures",
    "section": "CloudFront",
    "question": "A media streaming company serves video content to users globally from an S3 bucket in us-east-1. Users in Asia and Europe experience high latency and buffering issues. The company needs to reduce latency for global users while minimizing data transfer costs from S3. Video files are large (500MB-2GB) and content is updated weekly.\nWhat is the MOST cost-effective solution to improve performance?",
    "choices": [
      "Enable S3 Transfer Acceleration to speed up uploads and downloads for global users accessing the S3 bucket directly",
      "Create additional S3 buckets in ap-southeast-1 and eu-west-1 regions and use Route 53 geolocation routing to direct users to the nearest bucket",
      "Configure Amazon CloudFront distribution with the S3 bucket as the origin, enabling caching at edge locations worldwide",
      "Deploy an Application Load Balancer in each region with EC2 instances that stream content from the S3 bucket"
    ],
    "answer": 2,
    "explanation": "CloudFront caches content at edge locations globally, providing low-latency access for users worldwide and reducing S3 data transfer costs since cached content is served from edge locations. Transfer Acceleration helps with uploads but not the primary use case of downloads. Multiple S3 buckets require replication costs and complexity. ALB with EC2 adds unnecessary infrastructure costs and complexity compared to CloudFront's managed CDN.",
    "difficulty": "Medium",
    "choiceExplanations": {
      "0": "S3 Transfer Acceleration is primarily designed to speed up uploads to S3 over long distances, not optimize content delivery for downloads. It also does not provide caching capabilities, meaning every request still retrieves data from the origin S3 bucket, resulting in higher data transfer costs compared to CloudFront's edge caching.",
      "1": "This approach requires S3 Cross-Region Replication which incurs additional storage costs in multiple regions and data transfer costs for replication. It also adds operational complexity for managing content synchronization across buckets, making it less cost-effective than CloudFront which automatically caches content at edge locations without requiring data replication.",
      "3": "This solution introduces unnecessary infrastructure costs including EC2 instances, ALBs, and cross-region data transfer fees from S3 to EC2. It also requires managing and scaling EC2 instances across multiple regions, adding significant operational overhead compared to CloudFront's fully managed CDN service."
    }
  },
  {
    "id": "SAA-408",
    "domainId": "D3",
    "domain": "Design High-Performing Architectures",
    "section": "DynamoDB",
    "question": "An IoT application writes sensor data from 100,000 devices every second to a DynamoDB table. Each write is approximately 1KB in size. The application experiences throttling errors during peak traffic periods. The data has a time-series pattern where recent data (last 7 days) is frequently queried, while older data is rarely accessed but must be retained for 2 years for compliance.\nWhich solution provides the MOST cost-effective performance improvement?",
    "choices": [
      "Increase provisioned write capacity units (WCUs) to handle peak load and enable DynamoDB auto scaling",
      "Switch to DynamoDB on-demand pricing mode to automatically handle variable workload patterns",
      "Implement DynamoDB write sharding using multiple partition keys and use DynamoDB Time to Live (TTL) to archive old data to S3",
      "Partition data by time range into separate tables (daily tables) and use DynamoDB global tables for replication"
    ],
    "answer": 2,
    "explanation": "Write sharding distributes writes across multiple partitions to avoid hot partition throttling, while TTL automatically archives old data to reduce storage costs. This addresses both performance and cost optimization. On-demand mode is more expensive for predictable high-volume workloads. Simply increasing WCUs is costly and doesn't optimize for the time-series access pattern. Daily tables add operational complexity and don't address the core throttling issue.",
    "difficulty": "Medium",
    "choiceExplanations": {
      "0": "While this can handle throughput, it doesn't address hot partition throttling which occurs when traffic concentrates on specific partition keys, and it's more expensive because it doesn't optimize for the time-series access pattern where older data is rarely accessed.",
      "1": "On-demand mode is significantly more expensive for predictable, sustained high-volume workloads like 100,000 writes per second, and it still doesn't solve hot partition throttling issues or optimize storage costs for the time-series data pattern.",
      "3": "This adds significant operational complexity managing multiple tables, global tables are designed for multi-region replication rather than solving write throttling, and this approach doesn't address the core hot partition issue causing throttling errors."
    }
  },
  {
    "id": "SAA-409",
    "domainId": "D4",
    "domain": "Design Cost-Optimized Architectures",
    "section": "S3",
    "question": "A data analytics company stores 500TB of raw log data in S3 Standard. Analysis shows that 80% of the data is accessed only during the first 30 days after upload, 15% is accessed occasionally between 30-90 days, and 5% is rarely accessed after 90 days but must be retained for 7 years for compliance. Objects vary in size from 1KB to 100MB.\nWhich S3 storage strategy provides the GREATEST cost savings while meeting access requirements?",
    "choices": [
      "Use S3 Intelligent-Tiering for all objects to automatically move data between access tiers based on usage patterns",
      "Implement S3 Lifecycle policies to transition objects to S3 Standard-IA after 30 days, S3 Glacier Flexible Retrieval after 90 days, and S3 Glacier Deep Archive after 1 year",
      "Store all data in S3 One Zone-IA to reduce costs with acceptable availability for log data",
      "Migrate all data to S3 Glacier Flexible Retrieval immediately and use expedited retrieval when access is needed"
    ],
    "answer": 1,
    "explanation": "Lifecycle policies with tiered transitions match the described access patterns precisely, maximizing cost savings. Standard for 30 days handles frequent access, Standard-IA for occasional access (30-90 days), and Glacier tiers for long-term archival provide the lowest cost. Intelligent-Tiering has monitoring fees that may not be cost-effective for predictable patterns. One Zone-IA doesn't optimize for the multi-phase access pattern. Immediate Glacier storage prevents efficient access during the first 30 days when data is frequently used.",
    "difficulty": "Medium",
    "choiceExplanations": {
      "0": "While Intelligent-Tiering automates tier transitions, it charges a monthly monitoring fee per object which becomes costly with 500TB of varied-size objects (especially small 1KB files), and since access patterns are already well-known and predictable, manual lifecycle policies provide greater cost savings without monitoring overhead.",
      "2": "One Zone-IA is a single storage class that doesn't address the multi-phase access pattern, charges retrieval fees for the 80% of data accessed frequently in the first 30 days, has a 128KB minimum object size charge (inefficient for 1KB objects), and provides no path to Glacier for the 7-year retention requirement.",
      "3": "This approach is extremely cost-inefficient because 80% of data is frequently accessed during the first 30 days, and Glacier retrieval times (minutes to hours) plus expedited retrieval fees would significantly increase costs and degrade performance compared to keeping active data in S3 Standard."
    }
  },
  {
    "id": "SAA-410",
    "domainId": "D4",
    "domain": "Design Cost-Optimized Architectures",
    "section": "EC2 Pricing",
    "question": "A company runs a web application on EC2 instances that experiences predictable traffic patterns: baseline load requires 10 instances 24/7, with peak periods (4 hours daily during business hours) requiring 50 additional instances. The application has been running for over a year with consistent patterns and will continue for at least 2 more years. The company wants to minimize compute costs.\nWhat EC2 purchasing strategy provides the LOWEST cost?",
    "choices": [
      "Purchase 60 Reserved Instances with 1-year all upfront payment to cover maximum load",
      "Use 10 Reserved Instances for baseline load with 3-year all upfront payment, and On-Demand Instances for peak load",
      "Purchase 10 Reserved Instances for baseline with 3-year all upfront payment, and use Spot Instances with On-Demand as fallback for peak load",
      "Use 60 Spot Instances for all workload with On-Demand instances as fallback when Spot is unavailable"
    ],
    "answer": 2,
    "explanation": "Combining Reserved Instances for predictable baseline load (maximum discount with 3-year all upfront) with Spot Instances for flexible peak load provides optimal cost savings. Spot Instances can save up to 90% for interruptible workloads, with On-Demand as fallback ensures availability. Reserving 60 instances wastes money on idle capacity. Using only RIs with On-Demand for peaks misses Spot savings. Full Spot usage risks availability for baseline workload that requires 24/7 operation.",
    "difficulty": "Medium",
    "choiceExplanations": {
      "0": "This wastes significant money because 50 of the 60 Reserved Instances would sit idle for 20 hours daily (83% of the time), and 1-year terms provide smaller discounts than 3-year terms, making this approach highly cost-inefficient.",
      "1": "While this correctly reserves baseline capacity, using On-Demand for peak load misses the opportunity to save up to 90% with Spot Instances, which are ideal for the flexible, interruptible peak workload that only runs 4 hours daily.",
      "3": "This approach risks availability for the baseline workload that requires 24/7 operation, as Spot Instances can be interrupted with 2-minute notice; Reserved Instances provide guaranteed capacity and better cost optimization for predictable, always-on workloads."
    }
  },
  {
    "id": "SAA-411",
    "domainId": "D1",
    "domain": "Design Secure Architectures",
    "section": "Organizations",
    "question": "A large financial services corporation operates over 200 AWS accounts across multiple business units. The company must enforce strict compliance requirements including: mandatory encryption for all S3 buckets and RDS instances, prevent any account from disabling CloudTrail logging, restrict deployment to only approved AWS regions (us-east-1, us-west-2, eu-west-1), and maintain centralized audit logging. The security team needs to implement these controls with minimal ongoing operational overhead while allowing individual teams autonomy for their application deployments.\nWhich solution BEST meets all these requirements?",
    "choices": [
      "Implement AWS Config rules in each account with AWS Lambda remediation functions, use CloudFormation StackSets to deploy the rules across all accounts, and configure Amazon EventBridge to centralize audit logs in a master account.",
      "Use AWS Organizations with Service Control Policies (SCPs) to enforce encryption, CloudTrail, and region restrictions at the organizational unit level, enable AWS Control Tower for governance, and configure AWS CloudTrail Organization Trail for centralized logging.",
      "Deploy AWS Systems Manager State Manager across all accounts to enforce compliance configurations, use AWS Config Conformance Packs to validate requirements, and replicate CloudTrail logs to a central S3 bucket using cross-account replication.",
      "Create IAM policies in each account restricting user permissions, implement AWS Security Hub to monitor compliance, use Amazon GuardDuty for threat detection, and manually audit CloudTrail logs quarterly."
    ],
    "answer": 1,
    "explanation": "AWS Organizations with SCPs provides centralized, preventive controls that cannot be overridden by individual accounts, making them ideal for mandatory compliance requirements. Control Tower automates best practice guardrails and account provisioning. Organization Trail automatically aggregates CloudTrail logs from all accounts with minimal overhead. Config rules are detective controls requiring remediation rather than prevention. Systems Manager requires agents and ongoing management. Manual IAM policies in each account lack centralization and are prone to configuration drift.",
    "difficulty": "Hard",
    "choiceExplanations": {
      "0": "AWS Config rules are detective controls that identify non-compliance after resources are created, requiring remediation rather than preventing violations upfront. This approach also introduces significant operational overhead with Lambda functions across 200+ accounts and does not provide the preventive, unoverridable controls that SCPs offer for requirements like preventing CloudTrail disabling.",
      "2": "Systems Manager State Manager requires SSM agents on instances and ongoing management overhead, and cannot enforce account-level restrictions like region limitations or prevent CloudTrail disabling. Cross-account S3 replication for CloudTrail logs requires manual configuration per account, whereas Organization Trail provides automatic centralized logging with minimal effort.",
      "3": "IAM policies in individual accounts lack centralized enforcement, can be modified by account administrators, and are prone to configuration drift across 200+ accounts. Manual quarterly audits do not meet continuous compliance requirements and introduce significant operational overhead, while GuardDuty is for threat detection rather than compliance enforcement."
    }
  },
  {
    "id": "SAA-412",
    "domainId": "D1",
    "domain": "Design Secure Architectures",
    "section": "VPC",
    "question": "A healthcare technology company runs HIPAA-compliant applications across three VPCs in the same region: a shared services VPC with Active Directory and monitoring tools, a production VPC with patient data processing applications, and a development VPC. The company needs to enable private connectivity between all VPCs while ensuring: traffic between development and production VPCs is completely blocked, all inter-VPC traffic must be inspected by a centralized firewall for compliance logging, the solution must support adding 20 more VPCs over the next year without re-architecting, and minimize data transfer costs between VPCs.\nWhich architecture would BEST satisfy these requirements?",
    "choices": [
      "Create VPC peering connections between each VPC pair, configure route tables to prevent development-production routing, deploy AWS Network Firewall in each VPC, and use VPC Flow Logs for compliance logging.",
      "Implement AWS Transit Gateway with separate route tables for production and development environments, deploy AWS Network Firewall in an inspection VPC, configure Transit Gateway route tables to route all inter-VPC traffic through the firewall, and enable VPC Flow Logs.",
      "Use AWS PrivateLink to create endpoint services in each VPC, implement Network Load Balancers for routing, deploy third-party firewall appliances in each VPC, and centralize logs using CloudWatch Logs.",
      "Deploy a hub-and-spoke architecture with VPN connections, place firewall appliances in the hub VPC, use static routing to control traffic flow, and configure Security Groups to block development-production traffic."
    ],
    "answer": 1,
    "explanation": "Transit Gateway with separate route tables provides scalable VPC connectivity with centralized routing control, easily accommodating future VPC additions. The inspection VPC architecture allows all inter-VPC traffic to be routed through AWS Network Firewall for centralized inspection and logging while maintaining network segmentation. Transit Gateway supports thousands of VPCs and reduces data transfer costs compared to VPC peering. VPC peering doesn't scale well and can't provide centralized traffic inspection without complex routing. PrivateLink is designed for service exposure, not general VPC connectivity. VPN connections add latency and complexity for intra-region communication.",
    "difficulty": "Hard",
    "choiceExplanations": {
      "0": "VPC peering does not support transitive routing, making centralized firewall inspection impossible since traffic cannot pass through an intermediate VPC. Additionally, deploying Network Firewall in each VPC contradicts the requirement for centralized inspection, and scaling to 20+ VPCs would require managing hundreds of peering connections (n*(n-1)/2), making this architecture unmanageable.",
      "2": "AWS PrivateLink is designed for exposing specific services privately, not for general VPC-to-VPC connectivity, and requires creating endpoint services for each application. Deploying firewall appliances in each VPC fails the centralized inspection requirement, increases operational complexity, and significantly increases costs compared to a single centralized firewall solution.",
      "3": "VPN connections for intra-region VPC connectivity add unnecessary latency, complexity, and are limited to 1.25 Gbps per tunnel, making them unsuitable for high-throughput requirements. Security Groups operate at the instance level and cannot block VPC-to-VPC traffic at the network layer, and static routing does not scale well for adding 20+ VPCs."
    }
  },
  {
    "id": "SAA-413",
    "domainId": "D1",
    "domain": "Design Secure Architectures",
    "section": "KMS",
    "question": "A multinational corporation processes sensitive financial data in AWS across multiple regions (us-east-1, eu-west-1, ap-southeast-1). Regulatory requirements mandate that: encryption keys must be managed by the customer with the ability to immediately revoke access, all cryptographic operations must be performed in FIPS 140-2 Level 3 validated hardware security modules, encryption keys for EU data must never leave the EU region due to GDPR, the company must maintain complete audit trails of all key usage, and the solution must support automatic key rotation. The company is currently using AWS managed keys and needs to migrate to a compliant solution.\nWhich solution would NOT be suitable for meeting these requirements?",
    "choices": [
      "Implement AWS KMS with customer managed keys in each region, enable automatic key rotation, use CloudTrail for audit logging, create key policies allowing immediate disablement, and configure cross-region encrypted snapshots using regional KMS keys.",
      "Deploy AWS CloudHSM clusters in each region with FIPS 140-2 Level 3 validated HSMs, implement custom key management using CloudHSM client SDK, configure CloudTrail for audit logging, and build custom key rotation logic using Lambda functions.",
      "Use AWS KMS with imported key material from an on-premises HSM, configure regional KMS keys for each geography, enable CloudTrail logging, manually rotate keys by importing new key material periodically, and use key policies for access control.",
      "Continue using AWS managed keys but enable CloudTrail logging, implement AWS Config rules to monitor key usage, use Service Control Policies to restrict key access, and configure AWS Backup to ensure keys are replicated across regions."
    ],
    "answer": 3,
    "explanation": "AWS managed keys do not provide customer control over key management, cannot be immediately disabled by customers, do not support FIPS 140-2 Level 3 (AWS KMS uses Level 2), and cannot meet the requirement for customer-managed keys. Cross-region key replication would violate GDPR data residency requirements. KMS customer managed keys with CloudTrail meet most requirements and support automatic rotation. CloudHSM provides FIPS 140-2 Level 3 compliance and full customer control. Imported key material allows external key management with regional isolation, though rotation is manual.",
    "difficulty": "Hard",
    "choiceExplanations": {
      "0": "This choice IS suitable because customer managed keys provide customer control with immediate revocation via key policies, automatic rotation is supported, CloudTrail provides audit trails, and using regional KMS keys for cross-region snapshots maintains data residency compliance. However, it only meets FIPS 140-2 Level 2 (not Level 3), which may be acceptable depending on interpretation of requirements.",
      "1": "This choice IS suitable because CloudHSM provides FIPS 140-2 Level 3 validated HSMs, offers complete customer control over keys with immediate revocation capability, regional deployment keeps EU keys in EU, and CloudTrail integration provides audit logging. Custom rotation logic via Lambda addresses the rotation requirement.",
      "2": "This choice IS suitable because imported key material allows customer-managed keys from on-premises HSMs, regional KMS keys maintain data residency, CloudTrail provides audit trails, key policies enable immediate access revocation, and manual rotation through new key material imports satisfies the rotation requirement, though not automatically."
    }
  },
  {
    "id": "SAA-414",
    "domainId": "D2",
    "domain": "Design Resilient Architectures",
    "section": "DR",
    "question": "A SaaS platform provider hosts a business-critical application processing real-time financial transactions in us-east-1. The application uses a three-tier architecture with Application Load Balancer, Amazon ECS on EC2 for compute, and Amazon Aurora PostgreSQL for the database. The company's disaster recovery requirements specify: Recovery Time Objective (RTO) of 5 minutes, Recovery Point Objective (RPO) of 30 seconds, the DR solution must be in a different AWS region (us-west-2), the solution must support automated failover without manual intervention, and minimize infrastructure costs during normal operations while maintaining DR readiness.\nWhich disaster recovery strategy would BEST meet these requirements?",
    "choices": [
      "Configure Aurora Global Database with us-east-1 as primary and us-west-2 as secondary region, use AWS Global Accelerator for automatic traffic routing during failover, maintain warm standby ECS cluster in us-west-2 with 25% capacity, and use Auto Scaling to scale up during failover.",
      "Implement Aurora read replicas in us-west-2, use Route 53 health checks with failover routing policy, deploy full production capacity ECS cluster in us-west-2 as hot standby, and configure automated database promotion scripts using Lambda.",
      "Deploy pilot light architecture with Aurora snapshots replicated to us-west-2 every 30 minutes, use CloudFormation templates to rebuild infrastructure during disaster, implement Route 53 failover routing, and maintain AMIs of application servers in both regions.",
      "Use AWS Backup to copy Aurora backups to us-west-2 daily, maintain infrastructure-as-code templates for quick deployment, implement manual failover procedures documented in runbooks, and use Route 53 to manually redirect traffic during disaster."
    ],
    "answer": 0,
    "explanation": "Aurora Global Database provides sub-second data replication to meet the 30-second RPO and supports automated failover capabilities. Global Accelerator provides automatic traffic redirection based on health checks. The warm standby approach with 25% capacity balances cost optimization with the ability to meet 5-minute RTO through auto-scaling. Full hot standby exceeds requirements and doubles infrastructure costs unnecessarily. Pilot light with 30-minute snapshots cannot meet the 30-second RPO, and infrastructure rebuild would exceed 5-minute RTO. Daily backups and manual procedures fail both RTO and RPO requirements and lack automation.",
    "difficulty": "Hard",
    "choiceExplanations": {
      "1": "While this solution could meet RTO/RPO requirements, Aurora cross-region read replicas require manual promotion (even with Lambda scripts) which is less reliable than Aurora Global Database's managed failover, and maintaining full production capacity as hot standby unnecessarily doubles infrastructure costs when the requirement specifies minimizing costs during normal operations.",
      "2": "This solution fails both requirements - 30-minute snapshot intervals cannot meet the 30-second RPO, and rebuilding infrastructure from CloudFormation templates during a disaster would take significantly longer than the 5-minute RTO allows.",
      "3": "Daily backups result in up to 24 hours of potential data loss which grossly exceeds the 30-second RPO, manual failover procedures violate the automated failover requirement, and restoring from backups plus deploying infrastructure would far exceed the 5-minute RTO."
    }
  },
  {
    "id": "SAA-415",
    "domainId": "D2",
    "domain": "Design Resilient Architectures",
    "section": "Auto Scaling",
    "question": "An e-learning platform experiences highly variable traffic patterns: baseline load of 100 concurrent users growing to 10,000 users during scheduled class sessions (known 24 hours in advance), plus unpredictable traffic spikes of up to 5,000 users when popular courses launch. The application runs on EC2 instances behind an Application Load Balancer. The company needs a scaling solution that: responds within 60 seconds to unpredictable spikes, minimizes costs during low-usage periods, pre-warms capacity for scheduled sessions to ensure performance, maintains exactly 2 instances minimum for high availability, and avoids over-provisioning during predictable events.\nWhich combination of Auto Scaling configurations would MOST effectively meet these requirements?",
    "choices": [
      "Use target tracking scaling policy based on ALB request count per target with 60-second evaluation periods, configure scheduled scaling actions for known class sessions, set minimum capacity to 2 instances, and enable predictive scaling with 24-hour forecasting.",
      "Implement step scaling policies with CloudWatch alarms on CPU utilization at 60-second intervals, use scheduled scaling for class sessions, configure warm pool with pre-initialized instances, set minimum capacity to 2, and enable instance protection on baseline instances.",
      "Deploy simple scaling policy based on ALB target response time, create scheduled scaling actions for class sessions with 15-minute warmup, maintain minimum 2 instances, enable mixed instances policy with Spot and On-Demand, and use lifecycle hooks for health checks.",
      "Use AWS Application Auto Scaling with custom CloudWatch metrics measuring concurrent users, implement scheduled scaling with predictive scaling override, configure minimum 2 instances, enable capacity rebalancing for mixed instance types, and use cooldown periods of 120 seconds."
    ],
    "answer": 0,
    "explanation": "Target tracking scaling policy provides fast, responsive scaling based on ALB request count per target, which directly correlates with user load and can respond within 60 seconds. Scheduled scaling handles known class sessions efficiently without over-provisioning. Predictive scaling with 24-hour forecasting learns traffic patterns to optimize capacity for scheduled events. The minimum capacity of 2 ensures high availability. Step scaling with CPU may not respond fast enough to rapid user growth. Simple scaling based on response time is reactive rather than proactive. Custom metrics add complexity and may have delayed responses compared to ALB metrics.",
    "difficulty": "Hard",
    "choiceExplanations": {
      "1": "Step scaling with CPU utilization is less responsive than target tracking for user load patterns because CPU is a lagging indicator that may not correlate directly with concurrent users, and step scaling requires multiple alarm thresholds to be configured manually rather than automatically adjusting like target tracking.",
      "2": "Simple scaling policies have mandatory cooldown periods between scaling activities, making them too slow to respond within 60 seconds to unpredictable spikes, and response time is a reactive metric that only triggers after performance has already degraded.",
      "3": "AWS Application Auto Scaling is designed for non-EC2 resources like ECS, DynamoDB, and Lambda, not EC2 instances which use EC2 Auto Scaling; additionally, 120-second cooldown periods would prevent the required 60-second response time to unpredictable spikes."
    }
  },
  {
    "id": "SAA-416",
    "domainId": "D3",
    "domain": "Design High-Performing Architectures",
    "section": "FSx",
    "question": "A visual effects studio is migrating their render farm to AWS for processing high-resolution video content. The workload requires a parallel file system that can: deliver sustained throughput of 10 GB/s for reading source video files, support concurrent access from 500 EC2 instances running rendering software, provide sub-millisecond latencies for metadata operations, persist data long-term (multi-year retention) for completed projects, integrate with their existing on-premises NFS storage for active project files during migration, and minimize storage costs for archived completed projects.\nWhich storage solution would BEST meet all these requirements?",
    "choices": [
      "Deploy Amazon FSx for Lustre with Persistent file system deployment type, configure data repository association with S3 for long-term storage, enable automatic export of completed renders to S3 Glacier Deep Archive using lifecycle policies, and use AWS DataSync for on-premises integration.",
      "Implement Amazon EFS with Max I/O performance mode and Elastic throughput, configure EFS-to-EFS replication for disaster recovery, use EFS Lifecycle Management to transition infrequently accessed files to Infrequent Access storage class, and connect on-premises storage via AWS Direct Connect with NFS mounts.",
      "Use Amazon FSx for NetApp ONTAP with Multi-AZ deployment, configure FlexCache for performance optimization, implement SnapMirror for on-premises replication, use cloud tiering to S3 for archive storage, and enable NFS protocol for compatibility.",
      "Deploy Amazon File Cache with on-premises NFS as the data source, use Amazon S3 with S3 Glacier for archival, configure multiple cache instances for scale, and access cache via NFS from EC2 rendering instances."
    ],
    "answer": 0,
    "explanation": "FSx for Lustre is purpose-built for high-performance computing workloads and can easily deliver 10+ GB/s throughput with sub-millisecond latencies. Persistent deployment type ensures data durability for long-term storage. Data repository association with S3 enables seamless archiving to Glacier for cost optimization. AWS DataSync provides efficient data transfer from on-premises NFS during migration. EFS Max I/O doesn't provide the extreme performance levels required for HPC rendering workloads. FSx for NetApp ONTAP is designed for enterprise file shares, not HPC parallel file systems. Amazon File Cache is designed for temporary caching scenarios, not long-term data persistence and retention.",
    "difficulty": "Hard",
    "choiceExplanations": {
      "1": "Amazon EFS, even with Max I/O mode and Elastic throughput, cannot deliver the sustained 10 GB/s throughput and sub-millisecond metadata latencies required for HPC rendering workloads. EFS is designed for general-purpose file storage, not parallel file system performance needed for render farms.",
      "2": "FSx for NetApp ONTAP is designed for enterprise file sharing and data management workloads, not high-performance computing parallel file systems. It cannot match the extreme throughput (10 GB/s) and sub-millisecond metadata latencies that FSx for Lustre provides for HPC rendering workloads.",
      "3": "Amazon File Cache is designed for temporary, high-speed caching of data from on-premises or S3 sources, not for long-term data persistence. It does not meet the multi-year retention requirement for completed projects as it is a transient caching layer, not a durable storage solution."
    }
  },
  {
    "id": "SAA-417",
    "domainId": "D3",
    "domain": "Design High-Performing Architectures",
    "section": "DynamoDB",
    "question": "A global gaming company operates a leaderboard system that must handle: 50,000 writes per second during peak gaming hours (4 hours daily), 500,000 reads per second for real-time leaderboard queries globally, single-digit millisecond read latencies in all geographic regions, the ability to perform complex queries ranking players by multiple attributes (score, level, region), strong consistency for write operations to prevent score manipulation, and minimize database costs during off-peak hours (20 hours daily with 10% of peak traffic).\nWhich database architecture would MOST cost-effectively meet these performance requirements?",
    "choices": [
      "Use Amazon DynamoDB with on-demand capacity mode, implement DynamoDB Global Tables for multi-region deployment, create Global Secondary Indexes for ranking queries, enable DynamoDB Accelerator (DAX) for read caching in each region, and use strongly consistent reads.",
      "Deploy Amazon Aurora Global Database with write forwarding enabled, implement read replicas in five regions, use Aurora's auto-scaling for capacity management, create indexes for ranking queries, and enable Aurora's query cache for frequently accessed leaderboards.",
      "Implement DynamoDB with provisioned capacity mode and auto-scaling, deploy Global Tables across regions, use ElastiCache for Redis in front of DynamoDB for read caching, implement sorted sets in Redis for ranking operations, and use DynamoDB Streams for cache invalidation.",
      "Use Amazon DocumentDB with global clusters, implement custom sharding logic for write distribution, deploy read replicas globally, create compound indexes for ranking, and use Amazon ElastiCache for Memcached for read optimization."
    ],
    "answer": 2,
    "explanation": "DynamoDB provisioned capacity with auto-scaling is more cost-effective than on-demand for predictable traffic patterns with 20 hours of low usage. Global Tables provide multi-region replication with strong consistency. ElastiCache for Redis with sorted sets is specifically designed for leaderboard use cases and can handle complex ranking queries efficiently while reducing DynamoDB read load. DynamoDB Streams enables real-time cache updates. On-demand mode would be more expensive given the predictable traffic pattern. Aurora cannot match DynamoDB's write scalability of 50K writes/second without significant over-provisioning. DocumentDB lacks the extreme scalability and global distribution capabilities required for this use case.",
    "difficulty": "Hard",
    "choiceExplanations": {
      "0": "On-demand capacity mode is significantly more expensive than provisioned capacity with auto-scaling when traffic patterns are predictable (4 hours peak, 20 hours low). Additionally, DAX does not support strongly consistent reads, and GSIs are inefficient for complex ranking queries compared to Redis sorted sets which are purpose-built for leaderboard operations.",
      "1": "Aurora cannot scale to handle 50,000 writes per second without significant over-provisioning, as it has single-writer architecture limitations. Write forwarding adds latency for cross-region writes, and Aurora's maximum capacity cannot match DynamoDB's virtually unlimited write throughput for this extreme workload.",
      "3": "DocumentDB lacks native global distribution capabilities and requires custom sharding logic which adds operational complexity and potential failure points. It cannot match DynamoDB's extreme scalability requirements, and Memcached lacks sorted set data structures needed for efficient leaderboard ranking operations unlike Redis."
    }
  },
  {
    "id": "SAA-418",
    "domainId": "D3",
    "domain": "Design High-Performing Architectures",
    "section": "ECS",
    "question": "A fintech startup is building a microservices-based trading platform that must meet the following requirements: deploy 50+ containerized microservices with independent scaling policies, support blue/green deployments with automated rollback on failures, maintain service mesh capabilities for inter-service communication and observability, ensure developers can deploy supplemental infrastructure components (caches, queues) alongside their services, auto-scale container tasks based on custom business metrics (trades per second), and minimize operational overhead for infrastructure management while maintaining control over service configurations.\nWhich solution would BEST address these requirements?",
    "choices": [
      "Deploy containers using Amazon ECS on AWS Fargate with Application Load Balancer, implement AWS App Mesh for service mesh, use AWS CodeDeploy for blue/green deployments, configure Auto Scaling using CloudWatch custom metrics for trades per second, and enable ECS Service Discovery.",
      "Use Amazon Elastic Kubernetes Service (EKS) with managed node groups, implement Istio service mesh, configure Argo Rollouts for progressive delivery, use Horizontal Pod Autoscaler with custom metrics from CloudWatch Container Insights, and deploy Helm charts for infrastructure components.",
      "Implement AWS Proton for standardized service templates, deploy containers on ECS with EC2 launch type, use AWS App Mesh for service communication, configure CodeDeploy for deployment automation, enable ECS Auto Scaling with target tracking policies, and allow developers to add components through Proton.",
      "Deploy Amazon EKS Anywhere on EC2 instances for full control, use Linkerd for service mesh, implement Flux for GitOps-based deployments, configure custom autoscaling with KEDA using trading metrics, and use Kubernetes operators for infrastructure provisioning."
    ],
    "answer": 2,
    "explanation": "AWS Proton is specifically designed to enable standardized infrastructure templates while allowing developers to add supplemental components, directly addressing the requirement for infrastructure flexibility. ECS with App Mesh provides service mesh capabilities with less operational overhead than Kubernetes. CodeDeploy supports blue/green deployments with automatic rollback. ECS Auto Scaling integrates well with CloudWatch custom metrics. While EKS with Istio is powerful, it adds significant operational complexity compared to the managed Proton approach. ECS on Fargate lacks the component extensibility that Proton provides. EKS Anywhere on EC2 maximizes operational overhead rather than minimizing it.",
    "difficulty": "Hard",
    "choiceExplanations": {
      "0": "While this solution minimizes operational overhead with Fargate, it lacks a mechanism for developers to deploy supplemental infrastructure components (caches, queues) alongside their services in a standardized way, which is a key requirement that AWS Proton specifically addresses.",
      "1": "This solution adds significant operational complexity through managing Istio service mesh, Argo Rollouts, and Helm charts, which contradicts the requirement to minimize operational overhead; Istio alone requires substantial expertise to configure and maintain compared to AWS-managed alternatives.",
      "3": "EKS Anywhere on EC2 maximizes rather than minimizes operational overhead, as it requires managing the Kubernetes control plane, EC2 instances, and multiple third-party tools (Linkerd, Flux, KEDA), directly contradicting the requirement to minimize infrastructure management burden."
    }
  },
  {
    "id": "SAA-419",
    "domainId": "D4",
    "domain": "Design Cost-Optimized Architectures",
    "section": "Compute",
    "question": "A data analytics company runs three distinct compute workloads on AWS: batch data processing jobs that run nightly for 6 hours (interruptible, can restart from checkpoints), a web application requiring 20 instances continuously (24/7 with consistent load), and machine learning training jobs that run unpredictably 2-3 times per week for 12-hour periods (stateful, cannot be interrupted). The company has committed to AWS for the next 3 years and wants to minimize total compute costs while ensuring workload reliability. Current spend is $150,000 annually using all On-Demand instances.\nWhich EC2 purchasing strategy would provide the GREATEST cost savings while meeting workload requirements?",
    "choices": [
      "Purchase 20 Standard 3-year Reserved Instances with all-upfront payment for web application, use Spot Instances with Spot Fleet for batch processing with automatic fallback to On-Demand, and use On-Demand Instances for ML training jobs to ensure completion.",
      "Buy 20 Convertible 3-year Reserved Instances for web servers, use Spot Instances with maximum price limit for batch jobs, purchase 3-year Compute Savings Plans to cover ML training at any instance type, and use Spot block instances for predictable 12-hour ML sessions.",
      "Implement 20 Standard 3-year Reserved Instances with all-upfront for web tier, use EC2 Spot Instances with checkpointing for batch processing, use On-Demand Instances for ML training, and purchase EC2 Instance Savings Plans (3-year) to cover unexpected ML compute needs.",
      "Use Compute Savings Plans (3-year) to cover baseline web application instances, supplement with On-Demand during any unexpected growth, use Spot Fleet with diversified instance types for batch processing, and use Reserved Instances for ML training workloads based on historical usage patterns."
    ],
    "answer": 0,
    "explanation": "Standard 3-year RIs with all-upfront provide maximum discount (up to 72%) for the predictable 24/7 web workload. Spot Instances are ideal for interruptible batch jobs and offer up to 90% savings with checkpoint recovery. ML training's unpredictable schedule and stateful nature makes On-Demand most reliable despite higher cost, but represents small portion of total compute. Convertible RIs are more expensive than Standard for known stable workloads. Spot blocks are deprecated. Compute Savings Plans are less optimal than Standard RIs when instance requirements are well-defined. Reserved Instances for unpredictable ML workloads risk underutilization and waste.",
    "difficulty": "Hard",
    "choiceExplanations": {
      "1": "Convertible RIs provide lower discounts (up to 66%) compared to Standard RIs (up to 72%) for a stable, well-defined workload. Spot block instances have been deprecated by AWS and are no longer available. Using Compute Savings Plans for unpredictable ML workloads risks paying for committed compute that goes unused, and Spot cannot be used for stateful ML jobs that cannot be interrupted.",
      "2": "EC2 Instance Savings Plans are locked to a specific instance family in a specific region, making them less flexible than Compute Savings Plans. Purchasing Instance Savings Plans for unpredictable ML workloads that run only 2-3 times per week would result in significant waste during periods when the commitment is unused, reducing overall cost savings.",
      "3": "Compute Savings Plans provide less discount than Standard RIs for well-defined, stable workloads where instance type is known. Purchasing Reserved Instances for ML training that runs unpredictably 2-3 times per week for only 12 hours would result in significant underutilization and wasted commitment, as RIs charge continuously regardless of actual usage."
    }
  },
  {
    "id": "SAA-420",
    "domainId": "D4",
    "domain": "Design Cost-Optimized Architectures",
    "section": "S3",
    "question": "A media company stores 5 PB of video content in Amazon S3 with the following access patterns: new uploads are frequently accessed for transcoding and initial editing (first 7 days), videos are occasionally accessed for re-editing between 7-90 days, content older than 90 days is rarely accessed but must be available within 12 hours when needed, videos must be retained for 10 years for licensing compliance, object sizes range from 100 MB to 50 GB, and the company receives frequent requests to retrieve videos uploaded 2-3 years ago. Monthly storage costs are currently $120,000 using S3 Standard for all content.\nWhich storage optimization strategy would provide the GREATEST cost reduction while meeting access requirements?",
    "choices": [
      "Implement S3 Intelligent-Tiering for all objects to automatically optimize storage costs based on access patterns, configure Archive Instant Access tier for objects not accessed in 90 days, and use S3 Lifecycle policies to delete objects after 10 years.",
      "Use S3 Lifecycle policies to transition objects to S3 Standard-IA after 7 days, transition to S3 Glacier Flexible Retrieval after 90 days, transition to S3 Glacier Deep Archive after 1 year, and configure retrieval expedited mode for urgent access needs.",
      "Store new uploads in S3 Standard, use lifecycle policies to move to S3 One Zone-IA after 7 days, transition to S3 Intelligent-Tiering after 90 days, move to S3 Glacier Deep Archive after 2 years, and restore to S3 Standard when accessed.",
      "Keep objects in S3 Standard for 7 days, transition to S3 Standard-IA for 7-90 days, move to S3 Glacier Instant Retrieval after 90 days for frequently requested archived content, transition to S3 Glacier Deep Archive after 3 years for final long-term archival."
    ],
    "answer": 3,
    "explanation": "This strategy optimizes for the specific access patterns: S3 Standard for active use (7 days), Standard-IA for occasional access (7-90 days at lower cost), Glacier Instant Retrieval for archived content with frequent retrieval needs (provides millisecond access matching the 2-3 year retrieval pattern), and Deep Archive for truly cold data (lowest cost at $1/TB/month). Intelligent-Tiering has monitoring fees that may exceed savings for predictable patterns, and Archive Instant Access doesn't provide the immediate retrieval needed. Glacier Flexible Retrieval's 12-hour retrieval meets requirements but costs more than Instant Retrieval given frequent access to 2-3 year old content. One Zone-IA lacks durability guarantees needed for 10-year retention requirements.",
    "difficulty": "Hard",
    "choiceExplanations": {
      "0": "S3 Intelligent-Tiering incurs per-object monitoring fees that add unnecessary costs when access patterns are predictable and well-defined, and the Archive Instant Access tier within Intelligent-Tiering doesn't provide the same cost optimization as using Glacier Instant Retrieval directly for the known frequent retrieval pattern of 2-3 year old content.",
      "1": "Glacier Flexible Retrieval requires 1-5 minutes for expedited retrieval (or 3-5 hours for standard), which is more expensive than Glacier Instant Retrieval when content is frequently accessed, and expedited retrievals incur additional per-GB and per-request charges that significantly increase costs for the frequent 2-3 year old content retrieval pattern.",
      "2": "S3 One Zone-IA stores data in only one Availability Zone with 99.5% availability, lacking the durability guarantees required for 10-year retention of licensing-critical video content, and this approach adds unnecessary complexity by mixing Intelligent-Tiering with lifecycle transitions."
    }
  },
  {
    "id": "SAA-421",
    "domainId": "D1",
    "domain": "Design Secure Architectures",
    "section": "IAM",
    "question": "Which AWS service allows you to create and manage user permissions and access to AWS resources?",
    "choices": [
      "AWS Organizations",
      "AWS IAM",
      "AWS Directory Service",
      "AWS Single Sign-On"
    ],
    "answer": 1,
    "explanation": "AWS IAM (Identity and Access Management) is the service used to create and manage user permissions and access control for AWS resources.",
    "difficulty": "Easy",
    "choiceExplanations": {
      "0": "This service is used for centrally managing and governing multiple AWS accounts, including consolidated billing and applying service control policies across accounts, but it does not create or manage individual user permissions and access to AWS resources.",
      "2": "This service provides managed Microsoft Active Directory or directory connectors for integrating on-premises directories with AWS, but it does not directly create and manage AWS resource permissions like IAM does.",
      "3": "This service (now called AWS IAM Identity Center) enables centralized access management across multiple AWS accounts and business applications using single sign-on, but the core creation and management of user permissions and access policies is handled by IAM."
    }
  },
  {
    "id": "SAA-422",
    "domainId": "D1",
    "domain": "Design Secure Architectures",
    "section": "S3",
    "question": "Which S3 feature should be enabled to prevent accidental deletion of objects?",
    "choices": [
      "S3 Versioning",
      "S3 Replication",
      "S3 Transfer Acceleration",
      "S3 Inventory"
    ],
    "answer": 0,
    "explanation": "S3 Versioning preserves multiple versions of an object, allowing recovery from accidental deletions or overwrites.",
    "difficulty": "Easy",
    "choiceExplanations": {
      "1": "This feature copies objects to another bucket (same or different region) for redundancy or compliance purposes, but if an object is deleted from the source, the deletion can also be replicated, so it does not inherently prevent accidental deletion.",
      "2": "This feature speeds up uploads to S3 by using Amazon CloudFront edge locations to transfer data more quickly over long distances, but it has no functionality related to protecting objects from deletion.",
      "3": "This feature provides scheduled reports listing objects and their metadata in a bucket for auditing and compliance purposes, but it only reports on existing objects and does not prevent or recover from accidental deletions."
    }
  },
  {
    "id": "SAA-423",
    "domainId": "D1",
    "domain": "Design Secure Architectures",
    "section": "VPC",
    "question": "What AWS service provides a logically isolated section of the AWS Cloud where you can launch resources in a virtual network?",
    "choices": [
      "AWS Direct Connect",
      "Amazon VPC",
      "AWS Transit Gateway",
      "AWS PrivateLink"
    ],
    "answer": 1,
    "explanation": "Amazon VPC (Virtual Private Cloud) provides an isolated virtual network environment within AWS where you can launch and manage resources.",
    "difficulty": "Easy",
    "choiceExplanations": {
      "0": "This service establishes a dedicated private network connection from your on-premises data center to AWS, but it does not create the isolated virtual network environment itself where you launch resources.",
      "2": "This service acts as a central hub to connect multiple VPCs and on-premises networks together, but it is a connectivity service rather than the isolated virtual network environment where resources are launched.",
      "3": "This service enables private connectivity between VPCs and AWS services or your own services without exposing traffic to the public internet, but it does not provide the isolated virtual network section itself."
    }
  },
  {
    "id": "SAA-424",
    "domainId": "D1",
    "domain": "Design Secure Architectures",
    "section": "CloudTrail",
    "question": "Which AWS service records API calls made in your AWS account for auditing and compliance?",
    "choices": [
      "AWS Config",
      "Amazon CloudWatch",
      "AWS CloudTrail",
      "AWS X-Ray"
    ],
    "answer": 2,
    "explanation": "AWS CloudTrail records all API calls and actions in your AWS account, providing an audit trail for security analysis and compliance.",
    "difficulty": "Easy",
    "choiceExplanations": {
      "0": "This service tracks resource configuration changes and evaluates compliance against desired configurations, but it does not record API calls made in your account.",
      "1": "This service collects and monitors metrics, logs, and events for AWS resources and applications, but it does not specifically record API calls for auditing purposes.",
      "3": "This service is used for analyzing and debugging distributed applications by tracing requests, not for recording API calls made in your AWS account for compliance and auditing."
    }
  },
  {
    "id": "SAA-425",
    "domainId": "D1",
    "domain": "Design Secure Architectures",
    "section": "KMS",
    "question": "What is the purpose of AWS KMS?",
    "choices": [
      "To monitor application performance",
      "To create and manage encryption keys",
      "To manage user identities",
      "To distribute content globally"
    ],
    "answer": 1,
    "explanation": "AWS KMS (Key Management Service) is used to create and control encryption keys for securing data.",
    "difficulty": "Easy",
    "choiceExplanations": {
      "0": "This describes Amazon CloudWatch, which monitors AWS resources and applications, not AWS KMS which is specifically designed for cryptographic key management.",
      "2": "This describes AWS IAM (Identity and Access Management) or AWS IAM Identity Center, which handle user authentication and authorization, not AWS KMS which focuses on encryption key management.",
      "3": "This describes Amazon CloudFront, AWS's content delivery network (CDN) service that caches and delivers content worldwide, not AWS KMS which manages cryptographic keys for data encryption."
    }
  },
  {
    "id": "SAA-426",
    "domainId": "D1",
    "domain": "Design Secure Architectures",
    "section": "Secrets Manager",
    "question": "Which service helps you rotate, manage, and retrieve database credentials, API keys, and other secrets?",
    "choices": [
      "AWS Secrets Manager",
      "AWS Systems Manager Parameter Store",
      "AWS KMS",
      "AWS Certificate Manager"
    ],
    "answer": 0,
    "explanation": "AWS Secrets Manager helps manage, rotate, and retrieve secrets like database credentials and API keys with automatic rotation capabilities.",
    "difficulty": "Easy",
    "choiceExplanations": {
      "1": "While Parameter Store can store secrets and configuration data, it does not provide built-in automatic rotation capabilities for secrets like database credentials, which is a key feature specifically offered by Secrets Manager.",
      "2": "AWS Key Management Service is used to create and manage cryptographic keys for encryption, not to store, manage, or rotate secrets like database credentials and API keys.",
      "3": "AWS Certificate Manager is used to provision, manage, and deploy SSL/TLS certificates for AWS services and connected resources, not to manage database credentials, API keys, or other application secrets."
    }
  },
  {
    "id": "SAA-427",
    "domainId": "D1",
    "domain": "Design Secure Architectures",
    "section": "WAF",
    "question": "Which AWS service protects web applications from common web exploits like SQL injection and cross-site scripting?",
    "choices": [
      "AWS Shield",
      "AWS WAF",
      "AWS GuardDuty",
      "Amazon Inspector"
    ],
    "answer": 1,
    "explanation": "AWS WAF (Web Application Firewall) protects web applications from common web exploits and attacks at the application layer.",
    "difficulty": "Easy",
    "choiceExplanations": {
      "0": "This service provides protection against DDoS (Distributed Denial of Service) attacks at the network and transport layers, not application-layer exploits like SQL injection or cross-site scripting.",
      "2": "This is a threat detection service that monitors for malicious activity and unauthorized behavior by analyzing AWS account logs and network activity, but it does not actively block or filter web application traffic.",
      "3": "This service automatically assesses applications for vulnerabilities and deviations from best practices by scanning EC2 instances and container images, but it does not provide real-time protection against web exploits."
    }
  },
  {
    "id": "SAA-428",
    "domainId": "D1",
    "domain": "Design Secure Architectures",
    "section": "Security Groups",
    "question": "What type of firewall is a security group in AWS?",
    "choices": [
      "Network-level firewall",
      "Stateful firewall at the instance level",
      "Stateless firewall at the subnet level",
      "Application-level firewall"
    ],
    "answer": 1,
    "explanation": "Security groups act as stateful firewalls at the EC2 instance level, controlling inbound and outbound traffic.",
    "difficulty": "Easy",
    "choiceExplanations": {
      "0": "This is incorrect because security groups operate at the instance level (attached to ENIs), not at the network level. Network ACLs are the network-level firewalls in AWS that operate at the subnet boundary.",
      "2": "This describes Network ACLs (NACLs), not security groups. Security groups are stateful (return traffic is automatically allowed) and operate at the instance level, while NACLs are stateless and operate at the subnet level.",
      "3": "This describes AWS WAF (Web Application Firewall), which inspects HTTP/HTTPS traffic at Layer 7. Security groups operate at the transport layer (Layer 4), filtering traffic based on IP addresses, ports, and protocols, not application-layer content."
    }
  },
  {
    "id": "SAA-429",
    "domainId": "D1",
    "domain": "Design Secure Architectures",
    "section": "IAM",
    "question": "What is an IAM policy?",
    "choices": [
      "A JSON document that defines permissions",
      "A user authentication mechanism",
      "A network access control list",
      "An encryption key"
    ],
    "answer": 0,
    "explanation": "An IAM policy is a JSON document that explicitly defines permissions for users, groups, or roles to access AWS resources.",
    "difficulty": "Easy",
    "choiceExplanations": {
      "1": "IAM policies handle authorization (what actions are allowed), not authentication (verifying identity). Authentication in IAM is handled separately through credentials like passwords, access keys, or MFA devices.",
      "2": "Network ACLs are VPC components that control inbound and outbound traffic at the subnet level using rules based on IP addresses and ports. IAM policies control access to AWS services and resources, not network traffic.",
      "3": "Encryption keys are managed by AWS Key Management Service (KMS) and are used to encrypt and decrypt data. IAM policies are permission documents that define what actions principals can perform on AWS resources."
    }
  },
  {
    "id": "SAA-430",
    "domainId": "D1",
    "domain": "Design Secure Architectures",
    "section": "S3",
    "question": "Which S3 feature encrypts data at rest using server-side encryption?",
    "choices": [
      "S3 SSE (Server-Side Encryption)",
      "S3 CRR (Cross-Region Replication)",
      "S3 Transfer Acceleration",
      "S3 Intelligent-Tiering"
    ],
    "answer": 0,
    "explanation": "S3 Server-Side Encryption (SSE) automatically encrypts objects at rest in S3 buckets using various key management options.",
    "difficulty": "Easy",
    "choiceExplanations": {
      "1": "This feature automatically replicates objects across S3 buckets in different AWS Regions for disaster recovery and compliance purposes, but it does not provide encryption functionality itself.",
      "2": "This feature speeds up data transfers to and from S3 by using Amazon CloudFront's globally distributed edge locations, but it addresses data transfer performance rather than encryption at rest.",
      "3": "This storage class automatically moves objects between access tiers based on changing access patterns to optimize storage costs, but it is a cost optimization feature rather than an encryption mechanism."
    }
  },
  {
    "id": "SAA-431",
    "domainId": "D1",
    "domain": "Design Secure Architectures",
    "section": "VPC",
    "question": "What component allows private subnet instances to access the internet without exposing their private IP addresses?",
    "choices": [
      "Internet Gateway",
      "NAT Gateway",
      "VPC Peering",
      "VPN Connection"
    ],
    "answer": 1,
    "explanation": "A NAT Gateway enables instances in private subnets to initiate outbound internet traffic while preventing inbound connections from the internet.",
    "difficulty": "Easy",
    "choiceExplanations": {
      "0": "While an Internet Gateway enables internet connectivity for a VPC, instances using it directly must have public IP addresses, which exposes them to the internet rather than hiding their private IP addresses as the question requires.",
      "2": "VPC Peering establishes private connectivity between two VPCs for resource communication, but it does not provide internet access and cannot route traffic to the internet.",
      "3": "A VPN Connection creates an encrypted tunnel between a VPC and an on-premises network or another remote network, but it does not provide internet access for private subnet instances."
    }
  },
  {
    "id": "SAA-432",
    "domainId": "D1",
    "domain": "Design Secure Architectures",
    "section": "IAM",
    "question": "What is the AWS best practice for granting permissions to applications running on EC2 instances?",
    "choices": [
      "Embed access keys in the application code",
      "Use IAM roles attached to the EC2 instance",
      "Store credentials in a configuration file on the instance",
      "Use root account credentials"
    ],
    "answer": 1,
    "explanation": "IAM roles provide temporary security credentials to EC2 instances without requiring long-term access keys, following security best practices.",
    "difficulty": "Easy",
    "choiceExplanations": {
      "0": "This is a security anti-pattern because access keys are long-term credentials that can be exposed through source code repositories, are difficult to rotate, and cannot be automatically managed like IAM role credentials.",
      "2": "This approach uses long-term credentials that must be manually managed and rotated, creates security risks if the instance is compromised or AMIs are shared, and lacks the automatic credential rotation provided by IAM roles.",
      "3": "AWS strongly advises never using root account credentials for application access as they provide unrestricted access to all AWS services and resources, cannot be limited by IAM policies, and should only be used for initial account setup and billing tasks."
    }
  },
  {
    "id": "SAA-433",
    "domainId": "D1",
    "domain": "Design Secure Architectures",
    "section": "GuardDuty",
    "question": "Which AWS service provides intelligent threat detection by analyzing VPC Flow Logs, CloudTrail logs, and DNS logs?",
    "choices": [
      "Amazon Inspector",
      "AWS GuardDuty",
      "AWS Security Hub",
      "AWS Macie"
    ],
    "answer": 1,
    "explanation": "AWS GuardDuty is a threat detection service that continuously monitors and analyzes AWS account activity and network traffic for malicious behavior.",
    "difficulty": "Easy",
    "choiceExplanations": {
      "0": "This service is designed for automated vulnerability assessment of EC2 instances and container images, scanning for software vulnerabilities and unintended network exposure, not for analyzing VPC Flow Logs, CloudTrail, or DNS logs for threat detection.",
      "2": "This service aggregates and prioritizes security findings from multiple AWS services (including GuardDuty) and third-party tools, but it does not directly analyze VPC Flow Logs, CloudTrail logs, or DNS logs for threat detection itself.",
      "3": "This service uses machine learning to discover, classify, and protect sensitive data stored in Amazon S3, focusing on data privacy and PII detection rather than analyzing network and account activity logs for threat detection."
    }
  },
  {
    "id": "SAA-434",
    "domainId": "D1",
    "domain": "Design Secure Architectures",
    "section": "IAM",
    "question": "A company needs to grant temporary access to AWS resources for users from a corporate directory. They also want to ensure users can access multiple AWS services with a single set of credentials. Which TWO AWS services should they use together? (Choose TWO.)",
    "choices": [
      "AWS IAM Identity Center (formerly AWS SSO)",
      "AWS Directory Service",
      "AWS Cognito",
      "AWS Organizations",
      "AWS KMS"
    ],
    "answer": [
      0,
      1
    ],
    "explanation": "AWS IAM Identity Center provides single sign-on access to multiple AWS accounts and applications. AWS Directory Service integrates with corporate directories like Active Directory to enable centralized user management and authentication.",
    "difficulty": "Easy",
    "choiceExplanations": {
      "2": "While Cognito provides identity management and temporary credentials, it is designed primarily for web and mobile application users (customer-facing), not for corporate workforce users accessing AWS management resources from an enterprise directory.",
      "3": "This service is used for centrally managing and governing multiple AWS accounts, including consolidated billing and policy-based management, but it does not provide authentication, identity federation, or single sign-on capabilities.",
      "4": "AWS Key Management Service is used for creating and managing cryptographic keys for data encryption, not for user authentication, identity management, or granting access to AWS resources."
    }
  },
  {
    "id": "SAA-435",
    "domainId": "D2",
    "domain": "Design Resilient Architectures",
    "section": "ELB",
    "question": "Which type of load balancer operates at the application layer (Layer 7) and can route requests based on content?",
    "choices": [
      "Network Load Balancer",
      "Application Load Balancer",
      "Classic Load Balancer",
      "Gateway Load Balancer"
    ],
    "answer": 1,
    "explanation": "Application Load Balancer operates at Layer 7 and can route HTTP/HTTPS traffic based on URL paths, hostnames, and other request content.",
    "difficulty": "Easy",
    "choiceExplanations": {
      "0": "Operates at Layer 4 (transport layer) and routes traffic based on IP protocol data such as TCP/UDP ports, not application-level content like URLs or headers.",
      "2": "While it can operate at both Layer 4 and Layer 7, it provides only basic routing capabilities and cannot perform advanced content-based routing like path-based or host-based routing that Application Load Balancer offers.",
      "3": "Operates at Layer 3 (network layer) and is designed to deploy, scale, and manage third-party virtual appliances like firewalls and intrusion detection systems, not for content-based application routing."
    }
  },
  {
    "id": "SAA-436",
    "domainId": "D2",
    "domain": "Design Resilient Architectures",
    "section": "RDS",
    "question": "What RDS feature automatically replicates your database to a standby instance in a different Availability Zone?",
    "choices": [
      "Read Replicas",
      "Multi-AZ deployment",
      "Automated backups",
      "Database snapshots"
    ],
    "answer": 1,
    "explanation": "Multi-AZ deployment automatically maintains a synchronous standby replica in another AZ, providing high availability and automatic failover.",
    "difficulty": "Easy",
    "choiceExplanations": {
      "0": "These are designed for read scalability and offloading read traffic, not for high availability failover; they use asynchronous replication and can be in the same or different AZ, but do not provide automatic failover like Multi-AZ.",
      "2": "This feature creates daily backups and transaction logs stored in S3 for point-in-time recovery, but does not maintain a standby database instance in another Availability Zone for failover purposes.",
      "3": "These are user-initiated or scheduled point-in-time backups stored in S3, but they do not provide a running standby instance in another AZ for automatic failover."
    }
  },
  {
    "id": "SAA-437",
    "domainId": "D2",
    "domain": "Design Resilient Architectures",
    "section": "S3",
    "question": "Which S3 storage class is designed for long-term archival with retrieval times of hours?",
    "choices": [
      "S3 Standard",
      "S3 Standard-IA",
      "S3 Glacier Flexible Retrieval",
      "S3 One Zone-IA"
    ],
    "answer": 2,
    "explanation": "S3 Glacier Flexible Retrieval (formerly S3 Glacier) is designed for long-term archive storage with retrieval times ranging from minutes to hours.",
    "difficulty": "Easy",
    "choiceExplanations": {
      "0": "This storage class is designed for frequently accessed data with millisecond retrieval times, not for long-term archival purposes, and has higher storage costs compared to archive classes.",
      "1": "This storage class is designed for infrequently accessed data that still requires immediate millisecond retrieval, not for long-term archival with hour-long retrieval times.",
      "3": "This storage class stores data in a single Availability Zone for infrequently accessed data with immediate millisecond retrieval, not for long-term archival with hour-long retrieval times."
    }
  },
  {
    "id": "SAA-438",
    "domainId": "D2",
    "domain": "Design Resilient Architectures",
    "section": "Route 53",
    "question": "Which Route 53 routing policy routes traffic to multiple resources and returns all healthy resource records?",
    "choices": [
      "Simple routing",
      "Weighted routing",
      "Multivalue answer routing",
      "Failover routing"
    ],
    "answer": 2,
    "explanation": "Multivalue answer routing returns multiple healthy IP addresses for a query, allowing Route 53 to perform basic load distribution and health checking.",
    "difficulty": "Easy",
    "choiceExplanations": {
      "0": "Returns a single record with one or more values but does not support health checks, so it cannot filter out unhealthy resources and returns all configured values regardless of health status.",
      "1": "Routes traffic to multiple resources based on assigned weights/proportions, but returns only one record at a time based on the weight distribution rather than returning all healthy records simultaneously.",
      "3": "Designed for active-passive failover scenarios where traffic is routed to a primary resource and only fails over to a secondary resource when the primary is unhealthy, not for returning multiple healthy records."
    }
  },
  {
    "id": "SAA-439",
    "domainId": "D2",
    "domain": "Design Resilient Architectures",
    "section": "Auto Scaling",
    "question": "What is the primary benefit of using Auto Scaling groups?",
    "choices": [
      "Reduces costs by using smaller instances",
      "Automatically adjusts capacity to maintain performance and availability",
      "Provides faster network connectivity",
      "Encrypts data at rest"
    ],
    "answer": 1,
    "explanation": "Auto Scaling automatically adjusts the number of EC2 instances based on demand, maintaining application performance and availability while optimizing costs.",
    "difficulty": "Easy",
    "choiceExplanations": {
      "0": "Auto Scaling does not reduce costs by using smaller instances; it optimizes costs by adjusting the number of instances based on demand, scaling out when needed and scaling in when demand decreases, regardless of instance size.",
      "2": "Auto Scaling does not affect network connectivity speed; network performance is determined by instance types, placement groups, and networking features like Enhanced Networking or Elastic Fabric Adapter, not by Auto Scaling groups.",
      "3": "Auto Scaling does not provide encryption capabilities; data encryption at rest is handled by other AWS services such as EBS encryption, S3 encryption, or AWS KMS, which are separate from Auto Scaling functionality."
    }
  },
  {
    "id": "SAA-440",
    "domainId": "D2",
    "domain": "Design Resilient Architectures",
    "section": "SQS",
    "question": "Which AWS service provides a fully managed message queuing service for decoupling application components?",
    "choices": [
      "Amazon SNS",
      "Amazon SQS",
      "Amazon Kinesis",
      "AWS Step Functions"
    ],
    "answer": 1,
    "explanation": "Amazon SQS (Simple Queue Service) is a fully managed message queue service that enables decoupling and scaling of distributed systems.",
    "difficulty": "Easy",
    "choiceExplanations": {
      "0": "Amazon SNS (Simple Notification Service) is a pub/sub messaging service for sending notifications to multiple subscribers, not a message queuing service for decoupling components through point-to-point communication.",
      "2": "Amazon Kinesis is a real-time streaming data service designed for collecting, processing, and analyzing streaming data at scale, not a message queuing service for decoupling application components.",
      "3": "AWS Step Functions is a serverless orchestration service that coordinates multiple AWS services into workflows using state machines, not a message queuing service for decoupling components."
    }
  },
  {
    "id": "SAA-441",
    "domainId": "D2",
    "domain": "Design Resilient Architectures",
    "section": "CloudFront",
    "question": "What is the primary purpose of Amazon CloudFront?",
    "choices": [
      "Database replication",
      "Content delivery network (CDN)",
      "Server monitoring",
      "Identity management"
    ],
    "answer": 1,
    "explanation": "Amazon CloudFront is a CDN service that delivers content to users with low latency by caching at edge locations worldwide.",
    "difficulty": "Easy",
    "choiceExplanations": {
      "0": "This is incorrect because database replication is handled by services like Amazon RDS Multi-AZ, Aurora Global Database, or DynamoDB Global Tables, not CloudFront which focuses on content delivery at edge locations.",
      "2": "This is incorrect because server monitoring is the function of Amazon CloudWatch, which collects metrics, logs, and events from AWS resources, whereas CloudFront is designed to accelerate content delivery to end users.",
      "3": "This is incorrect because identity management is handled by AWS IAM (Identity and Access Management) and AWS IAM Identity Center, not CloudFront which serves as a content delivery network for distributing web content globally."
    }
  },
  {
    "id": "SAA-442",
    "domainId": "D2",
    "domain": "Design Resilient Architectures",
    "section": "ELB",
    "question": "Which load balancer type is best suited for routing TCP traffic with ultra-high performance and low latency?",
    "choices": [
      "Application Load Balancer",
      "Classic Load Balancer",
      "Network Load Balancer",
      "Gateway Load Balancer"
    ],
    "answer": 2,
    "explanation": "Network Load Balancer operates at Layer 4 (TCP) and can handle millions of requests per second with ultra-low latency.",
    "difficulty": "Easy",
    "choiceExplanations": {
      "0": "Operates at Layer 7 (HTTP/HTTPS) and is designed for content-based routing of web traffic, not raw TCP traffic, and has higher latency compared to Network Load Balancer due to application-layer processing.",
      "1": "While it supports TCP traffic at Layer 4, it is a legacy load balancer with lower performance capabilities and higher latency compared to Network Load Balancer, and AWS recommends migrating to newer load balancer types.",
      "3": "Operates at Layer 3 (IP packets) and is designed for deploying, scaling, and managing third-party virtual appliances like firewalls and intrusion detection systems, not for general TCP traffic routing."
    }
  },
  {
    "id": "SAA-443",
    "domainId": "D2",
    "domain": "Design Resilient Architectures",
    "section": "RDS",
    "question": "What is the primary technical benefit of using RDS Read Replicas?",
    "choices": [
      "Automatic failover for high availability",
      "Offload read traffic from the primary database to improve performance",
      "Enable cross-region disaster recovery",
      "Reduce storage costs by sharing data"
    ],
    "answer": 1,
    "explanation": "RDS Read Replicas offload read traffic from the primary database, improving overall performance for read-heavy workloads. They use asynchronous replication and are primarily used for scaling read operations, not for automatic failover (which requires Multi-AZ).",
    "difficulty": "Easy",
    "choiceExplanations": {
      "0": "Read Replicas do not provide automatic failover; this is the function of RDS Multi-AZ deployments, which use synchronous replication and automatic failover to a standby instance in a different Availability Zone.",
      "2": "While Read Replicas can be created in different regions and manually promoted to standalone databases during a disaster, this is a secondary use case, not the primary technical benefit; the primary purpose is to scale read operations and improve performance.",
      "3": "Read Replicas do not share storage with the primary database; each replica maintains its own complete copy of the data, which actually increases storage costs rather than reducing them."
    }
  },
  {
    "id": "SAA-444",
    "domainId": "D2",
    "domain": "Design Resilient Architectures",
    "section": "S3",
    "question": "Which feature automatically replicates S3 objects to a different AWS region?",
    "choices": [
      "S3 Versioning",
      "S3 Cross-Region Replication (CRR)",
      "S3 Lifecycle policies",
      "S3 Transfer Acceleration"
    ],
    "answer": 1,
    "explanation": "S3 Cross-Region Replication automatically copies objects across S3 buckets in different AWS regions for disaster recovery and compliance.",
    "difficulty": "Easy",
    "choiceExplanations": {
      "0": "This feature preserves multiple versions of an object within the same bucket to protect against accidental deletions or overwrites, but it does not replicate objects to different regions.",
      "2": "These automate transitioning objects between storage classes or expiring objects based on age, but they manage object lifecycle within or across storage tiers, not replication to different regions.",
      "3": "This feature speeds up uploads to S3 by routing data through CloudFront edge locations, but it optimizes transfer speed rather than automatically replicating objects to different regions."
    }
  },
  {
    "id": "SAA-445",
    "domainId": "D2",
    "domain": "Design Resilient Architectures",
    "section": "SNS",
    "question": "What type of messaging pattern does Amazon SNS provide?",
    "choices": [
      "Point-to-point",
      "Publish-subscribe",
      "Request-response",
      "Peer-to-peer"
    ],
    "answer": 1,
    "explanation": "Amazon SNS (Simple Notification Service) follows a publish-subscribe pattern, allowing messages to be sent to multiple subscribers.",
    "difficulty": "Easy",
    "choiceExplanations": {
      "0": "This messaging pattern delivers messages to a single receiver, which describes Amazon SQS (Simple Queue Service), not SNS. SNS is designed to fan out messages to multiple subscribers simultaneously.",
      "2": "This is a synchronous communication pattern where a sender waits for a reply from the receiver, which is not how SNS operates. SNS uses asynchronous one-way message delivery to subscribers without expecting responses.",
      "3": "This pattern involves direct communication between equal nodes without a central broker, which does not describe SNS. SNS acts as a managed message broker that coordinates message delivery from publishers to multiple subscribers through topics."
    }
  },
  {
    "id": "SAA-446",
    "domainId": "D2",
    "domain": "Design Resilient Architectures",
    "section": "Lambda",
    "question": "What is AWS Lambda primarily used for?",
    "choices": [
      "Running containerized applications",
      "Running serverless code in response to events",
      "Managing virtual machines",
      "Creating VPN connections"
    ],
    "answer": 1,
    "explanation": "AWS Lambda is a serverless compute service that runs code in response to events without provisioning or managing servers.",
    "difficulty": "Easy",
    "choiceExplanations": {
      "0": "While Lambda does support container images as a deployment package format, its primary purpose is running serverless code in response to events, not managing containerized applications. Amazon ECS and Amazon EKS are the primary services for running containerized applications.",
      "2": "AWS Lambda is a serverless service that abstracts away all infrastructure management. Amazon EC2 is the service used for provisioning and managing virtual machines, where users have direct control over the underlying compute instances.",
      "3": "VPN connections in AWS are created and managed using AWS VPN (Site-to-Site VPN or Client VPN) services, not Lambda. Lambda is a compute service for running code, not a networking service for establishing secure connections."
    }
  },
  {
    "id": "SAA-447",
    "domainId": "D2",
    "domain": "Design Resilient Architectures",
    "section": "EBS",
    "question": "What happens to data on an instance store volume when an EC2 instance is stopped or terminated?",
    "choices": [
      "Data persists and can be reattached",
      "Data is lost",
      "Data is automatically backed up to S3",
      "Data is moved to EBS"
    ],
    "answer": 1,
    "explanation": "Instance store volumes provide temporary block-level storage that is lost when the instance is stopped or terminated.",
    "difficulty": "Easy",
    "choiceExplanations": {
      "0": "Instance store volumes are ephemeral storage physically attached to the host computer, and unlike EBS volumes, they cannot be detached and reattached to other instances, nor does data persist after the instance stops or terminates.",
      "2": "AWS does not automatically back up instance store data to S3 or any other storage service; users must manually copy any important data to persistent storage like S3 or EBS before stopping or terminating the instance.",
      "3": "There is no automatic migration of instance store data to EBS volumes; instance store and EBS are separate storage types, and AWS does not transfer data between them automatically when an instance stops or terminates."
    }
  },
  {
    "id": "SAA-448",
    "domainId": "D2",
    "domain": "Design Resilient Architectures",
    "section": "Route 53",
    "question": "A web application needs high availability across multiple regions. The application should automatically route traffic to healthy endpoints and minimize downtime during failures. Which TWO Route 53 features should be used? (Choose TWO.)",
    "choices": [
      "Health checks",
      "Failover routing policy",
      "Private hosted zones",
      "DNSSEC",
      "Alias records for S3 buckets"
    ],
    "answer": [
      0,
      1
    ],
    "explanation": "Route 53 health checks monitor endpoint health, and failover routing automatically redirects traffic to healthy resources when primary endpoints fail, ensuring high availability.",
    "difficulty": "Easy",
    "choiceExplanations": {
      "2": "These are used to route traffic within Amazon VPCs using private DNS names and do not provide health checking or failover capabilities for multi-region high availability across public endpoints.",
      "3": "This feature provides DNS response authentication and data integrity protection against DNS spoofing attacks, but it does not monitor endpoint health or provide automatic traffic routing during failures.",
      "4": "While alias records eliminate the need for additional DNS queries and can point to S3 buckets, they are a record type feature rather than a health monitoring or failover mechanism for multi-region high availability."
    }
  },
  {
    "id": "SAA-449",
    "domainId": "D3",
    "domain": "Design High-Performing Architectures",
    "section": "ElastiCache",
    "question": "Which AWS service provides in-memory caching to improve application performance?",
    "choices": [
      "Amazon RDS",
      "Amazon ElastiCache",
      "Amazon DynamoDB",
      "Amazon Aurora"
    ],
    "answer": 1,
    "explanation": "Amazon ElastiCache provides in-memory caching using Redis or Memcached to improve application performance by reducing database load.",
    "difficulty": "Easy",
    "choiceExplanations": {
      "0": "This is a managed relational database service that provides persistent disk-based storage, not in-memory caching; it stores data on disk and is designed for durable database workloads rather than caching.",
      "2": "This is a fully managed NoSQL database service that stores data persistently on disk; while it offers DAX (DynamoDB Accelerator) as an optional in-memory cache, DynamoDB itself is not an in-memory caching service.",
      "3": "This is a MySQL and PostgreSQL-compatible relational database that stores data persistently on disk; it is designed for high-performance database workloads but is not an in-memory caching solution."
    }
  },
  {
    "id": "SAA-450",
    "domainId": "D3",
    "domain": "Design High-Performing Architectures",
    "section": "EBS",
    "question": "Which EBS volume type provides the highest IOPS performance for mission-critical applications?",
    "choices": [
      "General Purpose SSD (gp3)",
      "Provisioned IOPS SSD (io2)",
      "Throughput Optimized HDD (st1)",
      "Cold HDD (sc1)"
    ],
    "answer": 1,
    "explanation": "Provisioned IOPS SSD (io2/io1) volumes deliver the highest performance with up to 64,000 IOPS for I/O intensive workloads.",
    "difficulty": "Easy",
    "choiceExplanations": {
      "0": "While gp3 provides good performance with up to 16,000 IOPS, this is significantly lower than io2's maximum of 64,000 IOPS, making it unsuitable for the highest IOPS requirements of mission-critical applications.",
      "2": "This HDD-based volume type is optimized for throughput-intensive workloads like big data and data warehouses, delivering only up to 500 IOPS, which is far below SSD performance levels.",
      "3": "This is the lowest-cost HDD option designed for infrequently accessed data, providing only up to 250 IOPS, making it completely unsuitable for high-performance mission-critical applications."
    }
  },
  {
    "id": "SAA-451",
    "domainId": "D3",
    "domain": "Design High-Performing Architectures",
    "section": "CloudFront",
    "question": "How does CloudFront improve content delivery performance?",
    "choices": [
      "By increasing server capacity",
      "By caching content at edge locations closer to users",
      "By compressing all files",
      "By upgrading network bandwidth"
    ],
    "answer": 1,
    "explanation": "CloudFront caches content at edge locations around the world, reducing latency by serving content from locations closest to end users.",
    "difficulty": "Easy",
    "choiceExplanations": {
      "0": "CloudFront does not increase the capacity of your origin servers; it reduces the load on them by caching content at edge locations, which is a fundamentally different approach to improving performance.",
      "2": "While CloudFront can compress certain file types when configured, this is an optional feature and not the primary mechanism by which it improves content delivery performance; edge caching is the core functionality.",
      "3": "CloudFront does not upgrade your network bandwidth; it improves performance by distributing content to edge locations geographically closer to users, reducing the distance data must travel rather than increasing bandwidth capacity."
    }
  },
  {
    "id": "SAA-452",
    "domainId": "D3",
    "domain": "Design High-Performing Architectures",
    "section": "DynamoDB",
    "question": "What type of database is Amazon DynamoDB?",
    "choices": [
      "Relational database",
      "NoSQL key-value and document database",
      "Graph database",
      "Time-series database"
    ],
    "answer": 1,
    "explanation": "DynamoDB is a fully managed NoSQL database that provides fast and predictable performance with seamless scalability.",
    "difficulty": "Easy",
    "choiceExplanations": {
      "0": "DynamoDB is not a relational database; it does not use SQL, tables with fixed schemas, or support complex joins. AWS offers Amazon RDS and Amazon Aurora for relational database needs.",
      "2": "DynamoDB is not a graph database designed for storing and querying highly connected data. AWS offers Amazon Neptune as its managed graph database service for use cases requiring graph traversals and relationship queries.",
      "3": "DynamoDB is not optimized specifically for time-series data with built-in time-based aggregations and retention policies. AWS offers Amazon Timestream as its purpose-built time-series database service."
    }
  },
  {
    "id": "SAA-453",
    "domainId": "D3",
    "domain": "Design High-Performing Architectures",
    "section": "Aurora",
    "question": "What is Amazon Aurora?",
    "choices": [
      "A NoSQL database service",
      "A MySQL and PostgreSQL-compatible relational database",
      "A data warehouse service",
      "A caching service"
    ],
    "answer": 1,
    "explanation": "Amazon Aurora is a MySQL and PostgreSQL-compatible relational database that offers high performance and availability with cloud-native architecture.",
    "difficulty": "Easy",
    "choiceExplanations": {
      "0": "Amazon Aurora is a relational database, not a NoSQL database. AWS offers DynamoDB as its managed NoSQL database service, which provides key-value and document data models.",
      "2": "Amazon Aurora is designed for OLTP (Online Transaction Processing) workloads, not data warehousing. AWS offers Amazon Redshift as its managed data warehouse service for OLAP (Online Analytical Processing) workloads.",
      "3": "Amazon Aurora is a persistent relational database, not a caching service. AWS offers Amazon ElastiCache (supporting Redis and Memcached) as its managed in-memory caching service."
    }
  },
  {
    "id": "SAA-454",
    "domainId": "D3",
    "domain": "Design High-Performing Architectures",
    "section": "S3",
    "question": "Which S3 feature accelerates uploads and downloads of large files over long distances?",
    "choices": [
      "S3 Versioning",
      "S3 Transfer Acceleration",
      "S3 Replication",
      "S3 Lifecycle policies"
    ],
    "answer": 1,
    "explanation": "S3 Transfer Acceleration uses CloudFront edge locations to accelerate uploads and downloads of large objects over long distances.",
    "difficulty": "Easy",
    "choiceExplanations": {
      "0": "This feature preserves, retrieves, and restores every version of every object stored in a bucket for data protection and recovery purposes, but it does not accelerate data transfers.",
      "2": "This feature automatically copies objects across S3 buckets in the same or different AWS Regions for compliance or disaster recovery, but it does not accelerate client uploads or downloads.",
      "3": "These automate transitioning objects between storage classes or expiring objects after a specified time to manage costs and data retention, but they do not improve transfer speeds."
    }
  },
  {
    "id": "SAA-455",
    "domainId": "D3",
    "domain": "Design High-Performing Architectures",
    "section": "EBS",
    "question": "What is the advantage of using EBS-optimized instances?",
    "choices": [
      "Lower cost",
      "Dedicated bandwidth for EBS I/O",
      "Larger storage capacity",
      "Automatic backups"
    ],
    "answer": 1,
    "explanation": "EBS-optimized instances provide dedicated network bandwidth for EBS volumes, ensuring consistent I/O performance.",
    "difficulty": "Easy",
    "choiceExplanations": {
      "0": "EBS-optimized instances typically cost more than non-optimized instances because they provide additional dedicated bandwidth for EBS traffic, not lower cost.",
      "2": "EBS-optimized instances do not affect storage capacity; storage capacity is determined by the EBS volume size and type you provision, which is independent of the instance optimization setting.",
      "3": "EBS-optimized instances do not provide automatic backups; automatic backups are a feature of Amazon Data Lifecycle Manager or AWS Backup, not a characteristic of EBS-optimized instances."
    }
  },
  {
    "id": "SAA-456",
    "domainId": "D3",
    "domain": "Design High-Performing Architectures",
    "section": "RDS",
    "question": "Which AWS database service is best for online transaction processing (OLTP) workloads?",
    "choices": [
      "Amazon Redshift",
      "Amazon RDS",
      "Amazon EMR",
      "Amazon Athena"
    ],
    "answer": 1,
    "explanation": "Amazon RDS is optimized for OLTP workloads requiring fast, consistent transaction processing with ACID compliance.",
    "difficulty": "Easy",
    "choiceExplanations": {
      "0": "This is a data warehousing service optimized for Online Analytical Processing (OLAP) workloads, designed for complex analytical queries across large datasets rather than high-volume transactional operations.",
      "2": "This is a managed big data platform for processing large amounts of data using frameworks like Apache Spark and Hadoop, not a transactional database service for OLTP workloads.",
      "3": "This is a serverless interactive query service for analyzing data in Amazon S3 using SQL, designed for ad-hoc analytics rather than transaction processing with ACID compliance."
    }
  },
  {
    "id": "SAA-457",
    "domainId": "D3",
    "domain": "Design High-Performing Architectures",
    "section": "Lambda",
    "question": "What is the maximum execution time for a single AWS Lambda function?",
    "choices": [
      "5 minutes",
      "15 minutes",
      "30 minutes",
      "1 hour"
    ],
    "answer": 1,
    "explanation": "AWS Lambda functions can run for a maximum of 15 minutes per execution.",
    "difficulty": "Easy",
    "choiceExplanations": {
      "0": "This was the original Lambda timeout limit when the service first launched, but AWS increased the maximum execution time to 15 minutes in 2018 to support longer-running workloads.",
      "2": "This exceeds the actual Lambda maximum timeout of 15 minutes; Lambda functions requiring longer execution times must be redesigned using Step Functions or other orchestration methods.",
      "3": "This far exceeds Lambda's 15-minute maximum timeout limit; workloads requiring hour-long processing should use services like AWS Batch, ECS, or EC2 instead of Lambda."
    }
  },
  {
    "id": "SAA-458",
    "domainId": "D3",
    "domain": "Design High-Performing Architectures",
    "section": "EFS",
    "question": "Which storage service provides a scalable file system that can be mounted by multiple EC2 instances concurrently?",
    "choices": [
      "Amazon EBS",
      "Amazon S3",
      "Amazon EFS",
      "Instance Store"
    ],
    "answer": 2,
    "explanation": "Amazon EFS (Elastic File System) provides a scalable, shared file system that can be mounted by multiple EC2 instances simultaneously.",
    "difficulty": "Easy",
    "choiceExplanations": {
      "0": "EBS volumes can only be attached to a single EC2 instance at a time (except for Multi-Attach on io1/io2 volumes which is limited to specific use cases), making it unsuitable for concurrent access by multiple instances.",
      "1": "S3 is an object storage service, not a file system, and cannot be directly mounted as a file system on EC2 instances without using additional tools like S3 Mountpoint or third-party solutions.",
      "3": "Instance store provides temporary block-level storage that is physically attached to the host computer and is only accessible by the single EC2 instance it's attached to, not shareable across multiple instances."
    }
  },
  {
    "id": "SAA-459",
    "domainId": "D3",
    "domain": "Design High-Performing Architectures",
    "section": "DynamoDB",
    "question": "Which DynamoDB feature provides microsecond read latency for frequently accessed data?",
    "choices": [
      "DynamoDB Streams",
      "DynamoDB Accelerator (DAX)",
      "Global Tables",
      "Point-in-time recovery"
    ],
    "answer": 1,
    "explanation": "DynamoDB Accelerator (DAX) is an in-memory cache that provides microsecond response times for read-heavy workloads.",
    "difficulty": "Easy",
    "choiceExplanations": {
      "0": "This feature captures time-ordered sequences of item-level modifications in DynamoDB tables for change data capture and event-driven architectures, but does not provide caching or improve read latency.",
      "2": "This feature provides multi-region, multi-active replication for disaster recovery and low-latency access across geographic regions, but does not provide microsecond-level caching for frequently accessed data.",
      "3": "This is a backup and restore feature that enables continuous backups of DynamoDB table data for up to 35 days, but has no impact on read performance or latency."
    }
  },
  {
    "id": "SAA-460",
    "domainId": "D3",
    "domain": "Design High-Performing Architectures",
    "section": "Global Accelerator",
    "question": "What is the primary benefit of AWS Global Accelerator?",
    "choices": [
      "Reduces storage costs",
      "Improves application availability and performance using the AWS global network",
      "Provides database replication",
      "Manages user authentication"
    ],
    "answer": 1,
    "explanation": "AWS Global Accelerator improves application availability and performance by routing traffic through the AWS global network to optimal endpoints.",
    "difficulty": "Easy",
    "choiceExplanations": {
      "0": "AWS Global Accelerator is a networking service that optimizes traffic routing and has no functionality related to storage management or cost reduction; storage cost optimization would involve services like S3 storage classes or EBS volume types.",
      "2": "AWS Global Accelerator does not handle database replication; database replication is managed by services like Amazon RDS with read replicas, Aurora Global Database, or DynamoDB Global Tables.",
      "3": "AWS Global Accelerator does not provide authentication capabilities; user authentication is handled by services like Amazon Cognito, AWS IAM, or AWS Directory Service."
    }
  },
  {
    "id": "SAA-461",
    "domainId": "D3",
    "domain": "Design High-Performing Architectures",
    "section": "Redshift",
    "question": "Which AWS service is designed for data warehousing and analytics on large datasets?",
    "choices": [
      "Amazon RDS",
      "Amazon DynamoDB",
      "Amazon Redshift",
      "Amazon Aurora"
    ],
    "answer": 2,
    "explanation": "Amazon Redshift is a fast, fully managed data warehouse service designed for analytics on petabyte-scale data.",
    "difficulty": "Easy",
    "choiceExplanations": {
      "0": "This is a managed relational database service designed for Online Transaction Processing (OLTP) workloads, not for data warehousing and analytics on large datasets which require columnar storage and massively parallel processing.",
      "1": "This is a fully managed NoSQL key-value database designed for high-performance applications requiring single-digit millisecond latency, not for complex analytical queries across petabyte-scale data warehouses.",
      "3": "This is a MySQL and PostgreSQL-compatible relational database optimized for OLTP workloads with high availability, not specifically designed for data warehousing analytics that require columnar storage and parallel query processing."
    }
  },
  {
    "id": "SAA-462",
    "domainId": "D3",
    "domain": "Design High-Performing Architectures",
    "section": "CloudFront",
    "question": "A media company needs to deliver video content to users worldwide with low latency. They also want to reduce the load on their origin servers by caching content closer to users. Which TWO AWS services should they use? (Choose TWO.)",
    "choices": [
      "Amazon CloudFront",
      "Amazon S3",
      "AWS Direct Connect",
      "Amazon Route 53",
      "AWS Global Accelerator"
    ],
    "answer": [
      0,
      1
    ],
    "explanation": "CloudFront caches and delivers content from edge locations for low latency. S3 serves as the origin for storing and serving the video content to CloudFront.",
    "difficulty": "Easy",
    "choiceExplanations": {
      "2": "This service establishes a dedicated private network connection between your on-premises data center and AWS, which is used for hybrid connectivity rather than content delivery and caching to global end users.",
      "3": "While Route 53 is a DNS service that can route users to the nearest endpoint using latency-based or geolocation routing, it does not cache content or reduce origin server load like a CDN does.",
      "4": "This service improves application availability and performance by routing traffic through AWS's global network to optimal endpoints, but it does not cache content at edge locations to reduce origin server load."
    }
  },
  {
    "id": "SAA-463",
    "domainId": "D4",
    "domain": "Design Cost-Optimized Architectures",
    "section": "S3",
    "question": "Which S3 storage class offers the lowest storage cost for rarely accessed data?",
    "choices": [
      "S3 Standard",
      "S3 Standard-IA",
      "S3 Glacier Deep Archive",
      "S3 One Zone-IA"
    ],
    "answer": 2,
    "explanation": "S3 Glacier Deep Archive provides the lowest storage cost for long-term archival data that is rarely accessed.",
    "difficulty": "Easy",
    "choiceExplanations": {
      "0": "This storage class is designed for frequently accessed data and has the highest storage cost among all S3 storage classes, making it unsuitable for rarely accessed data where cost optimization is the priority.",
      "1": "While this class offers lower storage costs than S3 Standard for infrequently accessed data, it is still significantly more expensive than S3 Glacier Deep Archive, which provides the absolute lowest storage cost.",
      "3": "Although this class has lower storage costs than S3 Standard-IA by storing data in a single Availability Zone, it is still more expensive than S3 Glacier Deep Archive for long-term archival storage of rarely accessed data."
    }
  },
  {
    "id": "SAA-464",
    "domainId": "D4",
    "domain": "Design Cost-Optimized Architectures",
    "section": "EC2 Pricing",
    "question": "Which EC2 purchasing option offers the largest discount for workloads with predictable usage?",
    "choices": [
      "On-Demand Instances",
      "Spot Instances",
      "Reserved Instances",
      "Dedicated Hosts"
    ],
    "answer": 2,
    "explanation": "Reserved Instances provide up to 72% discount compared to On-Demand pricing for predictable, steady-state workloads with 1 or 3-year commitments.",
    "difficulty": "Easy",
    "choiceExplanations": {
      "0": "These provide no discount as they are the baseline pricing model where you pay full price per hour or second with no commitment, making them the most expensive option for sustained workloads.",
      "1": "While Spot Instances offer up to 90% discount (larger than Reserved Instances), they are not suitable for predictable workloads because they can be interrupted with a 2-minute warning when AWS needs the capacity back.",
      "3": "These are physical servers dedicated to your use for compliance or licensing requirements, and while they can be purchased as Reserved to save costs, they are not a discount model themselves and are typically more expensive than shared tenancy options."
    }
  },
  {
    "id": "SAA-465",
    "domainId": "D4",
    "domain": "Design Cost-Optimized Architectures",
    "section": "EC2 Pricing",
    "question": "Which EC2 pricing model is best for fault-tolerant workloads that can handle interruptions?",
    "choices": [
      "On-Demand Instances",
      "Reserved Instances",
      "Spot Instances",
      "Savings Plans"
    ],
    "answer": 2,
    "explanation": "Spot Instances offer up to 90% discount but can be interrupted by AWS, making them ideal for fault-tolerant, flexible workloads.",
    "difficulty": "Easy",
    "choiceExplanations": {
      "0": "While On-Demand provides flexibility with no commitment, it offers no discount and is not specifically designed for interruptible workloads, making it a more expensive option when fault tolerance allows for interruptions.",
      "1": "Reserved Instances provide discounts (up to 72%) for committing to 1 or 3-year terms but guarantee capacity without interruptions, making them suited for steady-state workloads rather than interruptible fault-tolerant applications.",
      "3": "Savings Plans offer discounts (up to 72%) based on committed hourly spend over 1 or 3 years but do not involve interruptions, making them better suited for predictable usage rather than specifically fault-tolerant workloads that can handle being stopped."
    }
  },
  {
    "id": "SAA-466",
    "domainId": "D4",
    "domain": "Design Cost-Optimized Architectures",
    "section": "CloudWatch",
    "question": "Which AWS service helps you monitor and analyze resource utilization to identify cost optimization opportunities?",
    "choices": [
      "AWS Cost Explorer",
      "AWS Budgets",
      "Amazon CloudWatch",
      "AWS Trusted Advisor"
    ],
    "answer": 2,
    "explanation": "Amazon CloudWatch monitors resource utilization metrics, helping identify underutilized resources for cost optimization.",
    "difficulty": "Easy",
    "choiceExplanations": {
      "0": "While Cost Explorer helps analyze costs and usage patterns, it focuses on billing data and spending trends rather than monitoring real-time resource utilization metrics like CPU, memory, or network performance.",
      "1": "AWS Budgets is designed for setting cost and usage thresholds with alerts when budgets are exceeded, not for monitoring actual resource utilization metrics to identify optimization opportunities.",
      "3": "While Trusted Advisor does provide cost optimization recommendations including identifying underutilized resources, it provides periodic checks and recommendations rather than continuous monitoring and analysis of resource utilization metrics."
    }
  },
  {
    "id": "SAA-467",
    "domainId": "D4",
    "domain": "Design Cost-Optimized Architectures",
    "section": "S3",
    "question": "What S3 feature automatically transitions objects between storage classes based on access patterns?",
    "choices": [
      "S3 Lifecycle policies",
      "S3 Intelligent-Tiering",
      "S3 Object Lock",
      "S3 Versioning"
    ],
    "answer": 1,
    "explanation": "S3 Intelligent-Tiering automatically moves objects between access tiers based on changing access patterns without performance impact or operational overhead. While Lifecycle policies can transition objects, they require manual configuration of rules rather than automatic pattern detection.",
    "difficulty": "Easy",
    "choiceExplanations": {
      "0": "While Lifecycle policies can transition objects between storage classes, they require manual configuration of rules based on object age or other criteria, not automatic detection of access patterns like Intelligent-Tiering provides.",
      "2": "Object Lock is a data protection feature that prevents objects from being deleted or overwritten for a specified retention period using WORM (Write Once Read Many) model, not a storage class transition feature.",
      "3": "Versioning preserves, retrieves, and restores every version of every object stored in a bucket for data protection and recovery purposes, but does not transition objects between storage classes based on access patterns."
    }
  },
  {
    "id": "SAA-468",
    "domainId": "D4",
    "domain": "Design Cost-Optimized Architectures",
    "section": "Cost Management",
    "question": "Which AWS tool provides recommendations for cost optimization based on your usage patterns?",
    "choices": [
      "AWS Billing Dashboard",
      "AWS Cost and Usage Report",
      "AWS Trusted Advisor",
      "AWS Price List API"
    ],
    "answer": 2,
    "explanation": "AWS Trusted Advisor provides cost optimization recommendations including idle resources, Reserved Instance opportunities, and right-sizing suggestions.",
    "difficulty": "Easy",
    "choiceExplanations": {
      "0": "This tool displays your current charges and billing information but does not provide recommendations for cost optimization; it only shows what you have already spent.",
      "1": "This service provides detailed billing data and usage information for analysis and reporting purposes, but it does not generate recommendations for cost optimization based on usage patterns.",
      "3": "This API provides access to AWS service pricing information programmatically, but it does not analyze your usage patterns or provide cost optimization recommendations."
    }
  },
  {
    "id": "SAA-469",
    "domainId": "D4",
    "domain": "Design Cost-Optimized Architectures",
    "section": "Auto Scaling",
    "question": "How does Auto Scaling help with cost optimization?",
    "choices": [
      "By using cheaper instance types",
      "By automatically adjusting capacity based on demand",
      "By negotiating better pricing with AWS",
      "By consolidating workloads"
    ],
    "answer": 1,
    "explanation": "Auto Scaling automatically adds or removes instances based on demand, ensuring you only pay for the capacity you need.",
    "difficulty": "Easy",
    "choiceExplanations": {
      "0": "Auto Scaling does not automatically select cheaper instance types; it scales the number of instances you have configured in your launch template or launch configuration, regardless of instance type pricing.",
      "2": "Auto Scaling has no pricing negotiation capabilities; AWS pricing is determined by published rates, Reserved Instances, Savings Plans, or Enterprise agreements, not by Auto Scaling functionality.",
      "3": "Auto Scaling does not consolidate workloads across instances; it dynamically adjusts the number of instances based on demand, which is different from workload consolidation strategies."
    }
  },
  {
    "id": "SAA-470",
    "domainId": "D4",
    "domain": "Design Cost-Optimized Architectures",
    "section": "EBS",
    "question": "Which EBS volume type provides the lowest cost per GB for throughput-intensive workloads?",
    "choices": [
      "General Purpose SSD (gp3)",
      "Provisioned IOPS SSD (io2)",
      "Throughput Optimized HDD (st1)",
      "Cold HDD (sc1)"
    ],
    "answer": 2,
    "explanation": "Throughput Optimized HDD (st1) provides low-cost magnetic storage designed for frequently accessed, throughput-intensive workloads.",
    "difficulty": "Easy",
    "choiceExplanations": {
      "0": "While gp3 offers good performance for a variety of workloads, it costs approximately $0.08/GB-month compared to st1's $0.045/GB-month, making it more expensive for throughput-intensive workloads that don't require SSD latency.",
      "1": "This is the most expensive EBS volume type at $0.125/GB-month, designed for I/O-intensive workloads requiring sustained IOPS performance rather than cost-optimized throughput.",
      "3": "Although sc1 has the lowest cost per GB at $0.015/GB-month, it is designed for infrequently accessed data and provides lower throughput (250 MB/s max) compared to st1 (500 MB/s max), making it unsuitable for throughput-intensive workloads."
    }
  },
  {
    "id": "SAA-471",
    "domainId": "D4",
    "domain": "Design Cost-Optimized Architectures",
    "section": "RDS",
    "question": "What RDS feature can help reduce costs for development and test environments?",
    "choices": [
      "Multi-AZ deployment",
      "Automated backups",
      "Stop and start DB instances",
      "Encryption at rest"
    ],
    "answer": 2,
    "explanation": "Stopping RDS instances when not in use (e.g., during non-business hours for dev/test) reduces costs as you only pay for storage, not compute.",
    "difficulty": "Easy",
    "choiceExplanations": {
      "0": "This feature actually increases costs by maintaining a synchronous standby replica in another Availability Zone for high availability, which is typically unnecessary for development and test environments.",
      "1": "While automated backups provide data protection and point-in-time recovery, they do not reduce costs and actually incur storage charges for backup data beyond the free allocation equal to your provisioned database storage.",
      "3": "This is a security feature that encrypts stored data using AWS KMS keys, but it does not reduce costs and may incur minimal additional charges for KMS key usage."
    }
  },
  {
    "id": "SAA-472",
    "domainId": "D4",
    "domain": "Design Cost-Optimized Architectures",
    "section": "Lambda",
    "question": "How are you charged for AWS Lambda usage?",
    "choices": [
      "Per hour of function deployment",
      "Based on number of requests and compute time",
      "Fixed monthly fee",
      "Per GB of code uploaded"
    ],
    "answer": 1,
    "explanation": "Lambda charges based on the number of requests and the duration/memory consumed during code execution, with no charges when code isn't running.",
    "difficulty": "Easy",
    "choiceExplanations": {
      "0": "Lambda does not charge for deployment time or idle time; you only pay when your function code is actually executing in response to requests, making it a true pay-per-use service.",
      "2": "Lambda has no fixed monthly subscription or base fee; it uses a pure consumption-based pricing model where you pay only for actual usage (requests and compute time), plus a generous free tier.",
      "3": "Lambda does not charge based on the size of your deployment package; while there are limits on package size (50 MB zipped, 250 MB unzipped), storage of function code is not a billing dimension."
    }
  },
  {
    "id": "SAA-473",
    "domainId": "D4",
    "domain": "Design Cost-Optimized Architectures",
    "section": "S3",
    "question": "Which S3 storage class automatically moves data between access tiers based on changing access patterns?",
    "choices": [
      "S3 Standard",
      "S3 Intelligent-Tiering",
      "S3 Glacier",
      "S3 One Zone-IA"
    ],
    "answer": 1,
    "explanation": "S3 Intelligent-Tiering automatically moves objects between access tiers based on usage patterns, optimizing costs without performance impact.",
    "difficulty": "Easy",
    "choiceExplanations": {
      "0": "This storage class provides high durability and availability for frequently accessed data but does not automatically move data between tiers based on access patterns; objects remain in S3 Standard until manually moved or transitioned via lifecycle policies.",
      "2": "This is an archive storage class designed for long-term data retention with retrieval times ranging from minutes to hours, but it does not automatically tier data based on access patterns; data must be explicitly archived and retrieved.",
      "3": "This storage class is designed for infrequently accessed data stored in a single Availability Zone at lower cost, but it does not automatically move data between access tiers based on changing access patterns."
    }
  },
  {
    "id": "SAA-474",
    "domainId": "D4",
    "domain": "Design Cost-Optimized Architectures",
    "section": "Cost Management",
    "question": "A company wants to receive alerts when their AWS spending exceeds a certain threshold. They also want to forecast future costs based on current usage. Which TWO AWS services should they use? (Choose TWO.)",
    "choices": [
      "AWS Budgets",
      "AWS Cost Explorer",
      "Amazon CloudWatch",
      "AWS Config",
      "AWS Systems Manager"
    ],
    "answer": [
      0,
      1
    ],
    "explanation": "AWS Budgets allows setting custom cost and usage budgets with alerts. AWS Cost Explorer provides cost forecasting and analysis tools to understand spending patterns.",
    "difficulty": "Easy",
    "choiceExplanations": {
      "2": "While CloudWatch monitors AWS resources and applications through metrics, logs, and alarms, it is not designed for cost management, spending alerts, or cost forecasting—those capabilities are specific to AWS Budgets and Cost Explorer.",
      "3": "AWS Config is used to assess, audit, and evaluate the configurations of AWS resources for compliance and security purposes, not for monitoring spending thresholds or forecasting costs.",
      "4": "AWS Systems Manager provides operational management capabilities for AWS resources such as patching, configuration management, and automation, but it does not offer cost monitoring, spending alerts, or cost forecasting features."
    }
  },
  {
    "id": "SAA-475",
    "domainId": "D4",
    "domain": "Design Cost-Optimized Architectures",
    "section": "EC2 Pricing",
    "question": "A development team runs EC2 instances 24/7 for testing but only actively uses them during business hours (8 hours daily). They need a solution that minimizes costs while maintaining the ability to quickly resume work. Which TWO actions would be MOST cost-effective? (Choose TWO.)",
    "choices": [
      "Use Reserved Instances for all development instances",
      "Stop instances during non-business hours",
      "Use Auto Scaling to reduce instance count during off-hours",
      "Migrate to Spot Instances",
      "Use larger instance types with burstable performance"
    ],
    "answer": [
      1,
      2
    ],
    "explanation": "Stopping instances during non-business hours eliminates compute charges while preserving instance state. Auto Scaling can reduce the number of running instances during low-usage periods, both optimizing costs for variable usage patterns.",
    "difficulty": "Easy",
    "choiceExplanations": {
      "0": "Reserved Instances require a 1 or 3-year commitment and are cost-effective only when instances run consistently (ideally 24/7), but since these instances are only actively used 8 hours daily, the team would be paying for reserved capacity they don't fully utilize, making this less cost-effective than stopping instances.",
      "3": "Spot Instances can be interrupted by AWS with only 2 minutes notice when capacity is needed, which would disrupt development work and prevent the team from quickly resuming their testing activities as required.",
      "4": "Using larger instance types would increase costs rather than reduce them, and burstable performance (T-series instances) is designed for workloads with variable CPU usage, not for reducing costs when instances are idle during non-business hours."
    }
  },
  {
    "id": "SAA-476",
    "domainId": "D1",
    "domain": "Design Secure Architectures",
    "section": "IAM",
    "question": "A team wants an EC2-hosted application to call AWS APIs without storing long-term credentials on the instance. The security team also wants the permissions to be tightly scoped to only what the app needs.\nWhich approach should the Solutions Architect implement?",
    "choices": [
      "Create an IAM user and store access keys in the application configuration file",
      "Attach an IAM role to the EC2 instance with a least-privilege policy",
      "Store IAM user access keys in AWS Systems Manager Run Command documents",
      "Generate temporary credentials using AWS STS from a shared IAM user"
    ],
    "answer": 1,
    "explanation": "An IAM role attached to the EC2 instance provides temporary credentials via the instance metadata service and supports least-privilege permissions without storing long-term keys.",
    "difficulty": "Medium",
    "choiceExplanations": {
      "0": "This approach stores long-term credentials directly on the instance, which violates the security requirement of not storing long-term credentials and creates a security risk if the configuration file is compromised.",
      "2": "This still involves using long-term IAM user access keys rather than temporary credentials, and storing credentials in Run Command documents is not a secure credential management practice.",
      "3": "While STS provides temporary credentials, this approach still requires storing long-term IAM user credentials somewhere to call STS initially, and using a shared IAM user violates the principle of least privilege and makes auditing difficult."
    }
  },
  {
    "id": "SAA-477",
    "domainId": "D1",
    "domain": "Design Secure Architectures",
    "section": "S3",
    "question": "A company hosts a static website in an S3 bucket behind CloudFront. Security requirements state that the S3 bucket must not be publicly accessible, and only CloudFront should be able to read objects.\nWhat should you do?",
    "choices": [
      "Enable S3 static website hosting and restrict access using a bucket ACL",
      "Use an Origin Access Control (OAC) or Origin Access Identity (OAI) and a bucket policy that allows only CloudFront",
      "Allow public read on the bucket and restrict CloudFront by signed cookies only",
      "Put the bucket in a private subnet and access it through a NAT Gateway"
    ],
    "answer": 1,
    "explanation": "Using CloudFront OAC/OAI with a restrictive bucket policy keeps the bucket private while allowing CloudFront to fetch content securely.",
    "difficulty": "Medium",
    "choiceExplanations": {
      "0": "S3 static website hosting endpoints require public access to serve content and cannot be restricted to CloudFront only using ACLs; ACLs also cannot grant access specifically to CloudFront, making this approach unable to meet the security requirement of keeping the bucket private.",
      "2": "This directly violates the security requirement that the S3 bucket must not be publicly accessible; signed cookies only restrict who can access content through CloudFront but do not prevent direct public access to the S3 bucket itself.",
      "3": "S3 is a regional service that exists outside of VPCs and cannot be placed in subnets; S3 buckets are not network resources that can be deployed into private subnets, making this approach architecturally impossible."
    }
  },
  {
    "id": "SAA-478",
    "domainId": "D1",
    "domain": "Design Secure Architectures",
    "section": "KMS",
    "question": "A company must encrypt objects in S3 using customer-managed keys and must be able to immediately revoke access to the encrypted data if a breach is detected.\nWhich solution meets this requirement?",
    "choices": [
      "Use SSE-S3 and remove the bucket policy during a breach",
      "Use SSE-KMS with a customer managed key and disable the KMS key if needed",
      "Use client-side encryption and store the key in an EC2 instance user-data script",
      "Use SSE-C and rotate the customer-provided key daily"
    ],
    "answer": 1,
    "explanation": "SSE-KMS with a customer managed key allows immediate revocation by disabling the key (or tightening the key policy), preventing further decrypt operations.",
    "difficulty": "Medium",
    "choiceExplanations": {
      "0": "SSE-S3 uses AWS-managed keys that customers cannot control or disable, and removing a bucket policy doesn't prevent access by users with IAM permissions or the root account, making immediate revocation unreliable.",
      "2": "Storing encryption keys in EC2 user-data is a serious security vulnerability as user-data is accessible to anyone with describe-instance-attribute permissions and is not a secure key management solution.",
      "3": "SSE-C requires the customer to provide the key with each request but doesn't provide immediate revocation capability since previously encrypted objects remain accessible if the old key is known, and daily rotation doesn't address immediate breach response."
    }
  },
  {
    "id": "SAA-479",
    "domainId": "D1",
    "domain": "Design Secure Architectures",
    "section": "VPC",
    "question": "Instances in a private subnet must call DynamoDB without using the public internet. The company wants the simplest approach with minimal ongoing management.\nWhat should you configure?",
    "choices": [
      "A NAT Gateway in a public subnet and route DynamoDB traffic through it",
      "A gateway VPC endpoint for DynamoDB and update the route tables",
      "A VPC peering connection to a VPC that has internet access",
      "AWS Direct Connect to DynamoDB public endpoints"
    ],
    "answer": 1,
    "explanation": "A DynamoDB gateway endpoint keeps traffic on the AWS network and avoids internet egress and NAT costs/management.",
    "difficulty": "Medium",
    "choiceExplanations": {
      "0": "While this would work, it routes traffic through the public internet, incurs NAT Gateway data processing charges, and requires more management compared to a free gateway VPC endpoint that keeps traffic entirely within the AWS network.",
      "2": "VPC peering connects two VPCs for private communication between them, but it cannot be used to access AWS public services like DynamoDB, and peering does not support transitive routing through another VPC's internet gateway.",
      "3": "Direct Connect provides a dedicated network connection from on-premises to AWS, not from within a VPC to AWS services; this is unnecessarily complex, expensive, and not designed for VPC-to-DynamoDB connectivity."
    }
  },
  {
    "id": "SAA-480",
    "domainId": "D1",
    "domain": "Design Secure Architectures",
    "section": "Security Groups",
    "question": "A workload has a public ALB and private EC2 instances in an Auto Scaling group. Only the ALB should be able to reach the instances on port 443.\nHow should the instance security group be configured?",
    "choices": [
      "Allow inbound 443 from 0.0.0.0/0",
      "Allow inbound 443 from the ALB security group",
      "Allow inbound 443 from the ALB subnet CIDR blocks only",
      "Allow inbound 443 from the VPC CIDR block"
    ],
    "answer": 1,
    "explanation": "Referencing the ALB security group in the instance security group rule ensures only the ALB can connect, even if ALB IPs change.",
    "difficulty": "Medium",
    "choiceExplanations": {
      "0": "This allows traffic from any IP address on the internet, which violates the requirement that only the ALB should reach the instances and exposes the private instances to potential unauthorized access.",
      "2": "This is overly permissive as it allows any resource in the ALB subnets to access the instances on port 443, not just the ALB itself, and requires manual updates if ALB subnets change.",
      "3": "This allows any resource within the entire VPC to access the instances on port 443, which is far too broad and does not restrict access to only the ALB as required."
    }
  },
  {
    "id": "SAA-481",
    "domainId": "D1",
    "domain": "Design Secure Architectures",
    "section": "CloudTrail",
    "question": "A company needs an immutable audit trail of API activity for all accounts in an AWS Organization. They also want to prevent member accounts from turning off logging.\nWhat should you implement?",
    "choices": [
      "Enable CloudTrail in each account and restrict it with IAM policies",
      "Create an Organization trail in the management account and use SCPs to prevent CloudTrail changes",
      "Enable VPC Flow Logs and store them in an encrypted S3 bucket",
      "Enable AWS Config and send configuration changes to a central account"
    ],
    "answer": 1,
    "explanation": "An Organization trail centralizes logging across accounts, and SCPs can prevent disabling or tampering with CloudTrail configuration in member accounts.",
    "difficulty": "Medium",
    "choiceExplanations": {
      "0": "IAM policies alone cannot prevent account administrators or root users from disabling CloudTrail, and this approach requires managing trails individually in each account rather than centrally, making it less effective than Organization trails with SCPs.",
      "2": "VPC Flow Logs capture network traffic metadata at the VPC level, not API activity, so they cannot provide an audit trail of AWS API calls which is what CloudTrail is designed to capture.",
      "3": "AWS Config tracks resource configuration changes and compliance, not API activity; while it can detect when CloudTrail is modified, it does not provide the comprehensive API audit trail that CloudTrail delivers."
    }
  },
  {
    "id": "SAA-482",
    "domainId": "D1",
    "domain": "Design Secure Architectures",
    "section": "Secrets Manager",
    "question": "A Lambda function must connect to an RDS database. The database password must be rotated automatically without changing application code.\nWhich solution is best?",
    "choices": [
      "Store the password in Lambda environment variables and update them manually",
      "Store the password in Secrets Manager and enable automatic rotation",
      "Store the password in Parameter Store Standard tier and rotate it with a cron job on EC2",
      "Store the password in an encrypted S3 object and download it on each invocation"
    ],
    "answer": 1,
    "explanation": "Secrets Manager supports managed secret rotation workflows and integrates well with Lambda/RDS patterns.",
    "difficulty": "Medium",
    "choiceExplanations": {
      "0": "This requires manual intervention to rotate passwords, which violates the requirement for automatic rotation without changing application code, and environment variables are less secure than dedicated secrets management services.",
      "2": "Parameter Store Standard tier does not support automatic rotation natively, and using an EC2 cron job adds operational overhead, additional infrastructure costs, and is not a managed solution compared to Secrets Manager's built-in rotation capability.",
      "3": "S3 does not provide automatic secret rotation capabilities, downloading on each invocation adds latency and API costs, and this approach requires custom code to implement any rotation mechanism."
    }
  },
  {
    "id": "SAA-483",
    "domainId": "D1",
    "domain": "Design Secure Architectures",
    "section": "Organizations",
    "question": "A company must ensure developers can only deploy resources in approved regions. This must be enforced centrally and must not rely on users remembering to apply IAM policies.\nWhat should the company use?",
    "choices": [
      "IAM permission boundaries in each account",
      "Service Control Policies (SCPs) in AWS Organizations",
      "Security groups that block outbound traffic to other regions",
      "AWS Config rules with auto-remediation"
    ],
    "answer": 1,
    "explanation": "SCPs provide preventive, organization-level guardrails that apply regardless of IAM permissions inside member accounts.",
    "difficulty": "Medium",
    "choiceExplanations": {
      "0": "While permission boundaries can restrict IAM principals to specific regions, they must be manually applied to each user or role in each account, which contradicts the requirement for central enforcement without relying on users to apply policies.",
      "2": "Security groups control network traffic to and from EC2 instances and cannot restrict which AWS regions users can deploy resources in; they operate at the network layer, not the AWS API/service layer.",
      "3": "AWS Config rules are detective controls that identify non-compliant resources after they are created and then remediate them, rather than preventive controls that block deployment in unapproved regions before resources are created."
    }
  },
  {
    "id": "SAA-484",
    "domainId": "D1",
    "domain": "Design Secure Architectures",
    "section": "WAF",
    "question": "A public API behind an ALB is being hit with common web exploits (SQLi/XSS) and needs basic rate limiting by client IP. The team wants a managed approach.\nWhich solution should be used?",
    "choices": [
      "Deploy AWS Shield Advanced only",
      "Use AWS WAF on the ALB with managed rules and a rate-based rule",
      "Add NACL rules to block all IPs except known customers",
      "Use IAM policies to deny requests with suspicious headers"
    ],
    "answer": 1,
    "explanation": "AWS WAF supports managed rule groups for common exploits and rate-based rules to throttle abusive IPs at the edge/ALB.",
    "difficulty": "Medium",
    "choiceExplanations": {
      "0": "AWS Shield Advanced provides protection against DDoS attacks but does not inspect application-layer content for SQL injection or XSS attacks, nor does it provide rate limiting by client IP - these capabilities require AWS WAF.",
      "2": "NACLs operate at Layer 3/4 and cannot inspect HTTP request content for SQLi/XSS patterns, and blocking all unknown IPs is impractical for a public API that needs to serve any legitimate customer.",
      "3": "IAM policies control access to AWS APIs and resources for authenticated principals, not incoming HTTP traffic to application endpoints - IAM cannot inspect or filter web application traffic for exploits."
    }
  },
  {
    "id": "SAA-485",
    "domainId": "D1",
    "domain": "Design Secure Architectures",
    "section": "VPC",
    "question": "A company wants to privately access an internal service running on an NLB in another account, without opening inbound access from the entire VPC CIDR and without VPC peering.\nWhich solution meets this requirement?",
    "choices": [
      "VPC peering and security group rules between accounts",
      "AWS PrivateLink (interface VPC endpoints) to the NLB endpoint service",
      "A Transit Gateway with a shared route table",
      "A public ALB with IP allowlists"
    ],
    "answer": 1,
    "explanation": "PrivateLink exposes a service privately via interface endpoints without broad network connectivity and is ideal for cross-account service consumption.",
    "difficulty": "Medium",
    "choiceExplanations": {
      "0": "This option is explicitly excluded by the question requirements, and VPC peering would expose connectivity between entire VPC CIDRs rather than providing granular, private access to a specific service.",
      "2": "Transit Gateway provides network-level connectivity between VPCs, which would open broader network access similar to VPC peering rather than providing targeted, private access to a specific service endpoint.",
      "3": "This approach exposes the service over the public internet rather than keeping traffic private, and the question specifically requires private access without public exposure."
    }
  },
  {
    "id": "SAA-486",
    "domainId": "D1",
    "domain": "Design Secure Architectures",
    "section": "IAM (Select TWO)",
    "question": "A company wants to reduce the risk of credential exposure for workloads running on EC2 and ECS. They also want an approach that minimizes long-term secrets.\nWhich TWO actions should be taken? (Choose TWO.)",
    "choices": [
      "Use IAM roles for EC2 instances and ECS task roles for containers",
      "Store access keys in an encrypted S3 bucket and fetch them at startup",
      "Use AWS STS-issued temporary credentials instead of long-lived access keys",
      "Hardcode credentials in the container image and restrict access to the ECR repo",
      "Share one IAM user across multiple services to simplify key rotation"
    ],
    "answer": [
      0,
      2
    ],
    "explanation": "IAM roles (including ECS task roles) and STS temporary credentials reduce reliance on long-lived secrets and follow AWS best practices for workload identity.",
    "difficulty": "Medium",
    "choiceExplanations": {
      "1": "This approach still relies on long-lived access keys which must be managed and rotated, and introduces additional security risks as credentials could be exposed during retrieval or if S3 permissions are misconfigured.",
      "3": "Hardcoding credentials in container images is a severe security anti-pattern as credentials become embedded in the image layers, cannot be easily rotated, and may be exposed if the image is compromised or accessed by unauthorized users.",
      "4": "Sharing credentials across services violates the principle of least privilege, makes it impossible to audit which service performed specific actions, and increases blast radius if credentials are compromised."
    }
  },
  {
    "id": "SAA-487",
    "domainId": "D2",
    "domain": "Design Resilient Architectures",
    "section": "RDS",
    "question": "A production database on RDS MySQL must remain available during an AZ outage with automatic failover. Read scaling is not the primary requirement.\nWhat should be enabled?",
    "choices": [
      "RDS Read Replica in the same AZ",
      "RDS Multi-AZ deployment",
      "Manual snapshots every hour",
      "Amazon ElastiCache in front of the database"
    ],
    "answer": 1,
    "explanation": "Multi-AZ provides synchronous standby and automatic failover for high availability during AZ failures.",
    "difficulty": "Medium",
    "choiceExplanations": {
      "0": "Read Replicas are designed for read scaling, not high availability, and placing one in the same AZ provides no protection against AZ outages since both primary and replica would be affected simultaneously.",
      "2": "Snapshots are point-in-time backups used for disaster recovery, not high availability; restoring from a snapshot requires manual intervention and results in significant downtime, not automatic failover.",
      "3": "ElastiCache is a caching layer that improves read performance by reducing database load, but it does not provide database high availability or automatic failover capabilities during an AZ outage."
    }
  },
  {
    "id": "SAA-488",
    "domainId": "D2",
    "domain": "Design Resilient Architectures",
    "section": "SQS",
    "question": "An application must process messages at least once and can tolerate duplicate processing. The team wants to decouple components and buffer traffic spikes.\nWhich messaging service configuration fits best?",
    "choices": [
      "SQS Standard queue with idempotent consumer logic",
      "SQS FIFO queue with content-based deduplication disabled",
      "SNS topic with email subscriptions only",
      "Kinesis Data Streams with 1 shard and no consumer retry"
    ],
    "answer": 0,
    "explanation": "SQS Standard provides high throughput and at-least-once delivery; duplicates are handled by making consumers idempotent.",
    "difficulty": "Medium",
    "choiceExplanations": {
      "1": "FIFO queues have significantly lower throughput (300-3000 messages/second) compared to Standard queues, making them less suitable for buffering traffic spikes, and FIFO is designed for exactly-once processing which exceeds the stated requirement of at-least-once delivery.",
      "2": "SNS is a push-based notification service that does not buffer messages or decouple components in the same way as a queue; email subscriptions cannot process application messages programmatically and SNS alone does not provide message persistence for traffic spike buffering.",
      "3": "A single shard limits throughput to 1 MB/second or 1000 records/second for ingestion, which is insufficient for buffering traffic spikes, and having no consumer retry means failed message processing could result in data loss rather than at-least-once delivery."
    }
  },
  {
    "id": "SAA-489",
    "domainId": "D2",
    "domain": "Design Resilient Architectures",
    "section": "Route 53",
    "question": "An application is deployed in two regions. The company needs automatic DNS failover when the primary region becomes unhealthy. Health checks must validate an application URL (not just TCP).\nWhich Route 53 routing policy should be used?",
    "choices": [
      "Latency-based routing",
      "Failover routing with health checks",
      "Geolocation routing",
      "Multivalue answer routing without health checks"
    ],
    "answer": 1,
    "explanation": "Failover routing uses Route 53 health checks to direct traffic to the secondary endpoint when the primary fails application-level checks.",
    "difficulty": "Medium",
    "choiceExplanations": {
      "0": "This policy routes traffic based on the lowest network latency for the end user, not based on health status for failover purposes. While it can be combined with health checks, its primary function is performance optimization rather than automatic failover to a secondary region when the primary becomes unhealthy.",
      "2": "This policy routes traffic based on the geographic location of users, not based on the health of resources. It is designed to serve content based on where users are located, not to provide automatic failover when a primary region becomes unhealthy.",
      "3": "Without health checks, Route 53 cannot determine if the primary region is unhealthy and therefore cannot perform automatic failover. Additionally, multivalue answer routing returns multiple healthy records randomly rather than implementing a primary/secondary failover pattern."
    }
  },
  {
    "id": "SAA-490",
    "domainId": "D2",
    "domain": "Design Resilient Architectures",
    "section": "Auto Scaling",
    "question": "A web app behind an ALB has predictable daily peaks at 09:00 and 18:00, and also occasional unexpected spikes. The company wants cost-efficient scaling with minimal manual intervention.\nWhich combination is most appropriate?",
    "choices": [
      "Scheduled scaling for predictable peaks and target tracking for unexpected spikes",
      "Only scheduled scaling with large buffers",
      "Only step scaling based on CPU at 5-minute intervals",
      "Disable scaling and buy Reserved Instances for maximum load"
    ],
    "answer": 0,
    "explanation": "Scheduled scaling handles known peaks proactively, while target tracking reacts to unexpected demand with automatic adjustments.",
    "difficulty": "Medium",
    "choiceExplanations": {
      "1": "While this handles predictable peaks, it cannot respond to unexpected spikes mentioned in the scenario, and maintaining large buffers wastes resources during normal periods, making it not cost-efficient.",
      "2": "Step scaling is reactive and requires time to detect load increases and launch instances, causing potential performance issues during sudden spikes; it also cannot proactively scale before known peak times, making it less efficient than scheduled scaling for predictable patterns.",
      "3": "This approach provisions for peak capacity at all times, resulting in significant over-provisioning and wasted costs during off-peak hours, directly contradicting the cost-efficiency requirement."
    }
  },
  {
    "id": "SAA-491",
    "domainId": "D2",
    "domain": "Design Resilient Architectures",
    "section": "ECS",
    "question": "A service runs on ECS and must support deployments without downtime. If the new version fails health checks, traffic must automatically roll back.\nWhich deployment strategy best meets this requirement?",
    "choices": [
      "In-place deployment with a manual rollback runbook",
      "Blue/green deployments using AWS CodeDeploy for ECS",
      "Recreate all tasks at once with a larger desired count",
      "Deploy to a single task and gradually increase desired count without health checks"
    ],
    "answer": 1,
    "explanation": "CodeDeploy blue/green for ECS shifts traffic between target groups and supports automatic rollback on failed health checks.",
    "difficulty": "Medium",
    "choiceExplanations": {
      "0": "Manual rollback does not meet the requirement for automatic rollback when health checks fail, and in-place deployments can cause downtime during the update process as existing tasks are replaced.",
      "2": "Recreating all tasks simultaneously causes downtime as the old version is terminated before the new version is fully running, and this approach does not provide automatic rollback capabilities when health checks fail.",
      "3": "Without health checks, there is no mechanism to detect if the new version is failing, making automatic rollback impossible and potentially routing traffic to unhealthy tasks."
    }
  },
  {
    "id": "SAA-492",
    "domainId": "D2",
    "domain": "Design Resilient Architectures",
    "section": "S3",
    "question": "A company stores critical documents in S3 and wants protection against accidental deletion or overwrite, while still allowing normal writes.\nWhich solution is most appropriate?",
    "choices": [
      "Enable S3 Transfer Acceleration",
      "Enable S3 Versioning and optionally MFA Delete for additional protection",
      "Use a public bucket policy with CloudFront caching",
      "Enable S3 Intelligent-Tiering"
    ],
    "answer": 1,
    "explanation": "Versioning preserves prior object versions and protects against accidental deletes/overwrites; MFA Delete adds protection for delete operations.",
    "difficulty": "Medium",
    "choiceExplanations": {
      "0": "This feature speeds up content transfers to and from S3 by using CloudFront edge locations, but it provides no protection against accidental deletion or overwriting of objects.",
      "2": "This approach is for content distribution and performance, not data protection; making a bucket public actually increases security risks and provides no protection against accidental deletion or overwrites.",
      "3": "This storage class automatically moves objects between access tiers to optimize costs based on access patterns, but it does not provide any protection against accidental deletion or overwriting of data."
    }
  },
  {
    "id": "SAA-493",
    "domainId": "D2",
    "domain": "Design Resilient Architectures",
    "section": "Backup",
    "question": "A company needs centralized backup policies for EC2 (EBS volumes) and RDS with cross-region copy and compliance reporting.\nWhich service should be used?",
    "choices": [
      "AWS Backup with backup plans and cross-region copy",
      "CloudWatch Logs with retention policies",
      "AWS Snowball scheduled exports",
      "Manual snapshots with local scripts on EC2"
    ],
    "answer": 0,
    "explanation": "AWS Backup provides centralized, policy-based backups across services with vaults, reporting, and cross-region copy options.",
    "difficulty": "Medium",
    "choiceExplanations": {
      "1": "CloudWatch Logs is designed for log data collection, storage, and analysis, not for backing up EC2 EBS volumes or RDS databases; retention policies only control how long log data is kept, not backup operations.",
      "2": "AWS Snowball is a physical data transfer device used for large-scale data migration to and from AWS, not for automated backup policies, cross-region replication, or compliance reporting of EC2 and RDS resources.",
      "3": "Manual scripts lack centralized management, built-in cross-region copy automation, compliance reporting capabilities, and policy-based scheduling that AWS Backup provides; this approach is error-prone and doesn't scale well across multiple services."
    }
  },
  {
    "id": "SAA-494",
    "domainId": "D2",
    "domain": "Design Resilient Architectures",
    "section": "ELB",
    "question": "A company needs a load balancer that supports HTTP/HTTPS features like host-based routing, path-based routing, and WebSocket support.\nWhich load balancer should they choose?",
    "choices": [
      "Network Load Balancer",
      "Application Load Balancer",
      "Gateway Load Balancer",
      "Classic Load Balancer (for new workloads)"
    ],
    "answer": 1,
    "explanation": "ALB is Layer 7 and supports host/path-based routing and modern HTTP features like WebSockets.",
    "difficulty": "Medium",
    "choiceExplanations": {
      "0": "NLB operates at Layer 4 (TCP/UDP) and does not support Layer 7 HTTP features like host-based routing, path-based routing, or WebSocket support since it handles traffic at the connection level rather than the application level.",
      "2": "GLB operates at Layer 3 (network layer) and is designed for deploying, scaling, and managing third-party virtual appliances like firewalls and intrusion detection systems, not for HTTP/HTTPS application routing features.",
      "3": "CLB is a legacy load balancer that AWS does not recommend for new workloads, and while it supports basic HTTP/HTTPS, it lacks advanced Layer 7 features like host-based routing and path-based routing that ALB provides."
    }
  },
  {
    "id": "SAA-495",
    "domainId": "D2",
    "domain": "Design Resilient Architectures",
    "section": "Aurora",
    "question": "A company uses Aurora and needs fast regional disaster recovery with low RPO using cross-region replication that is designed for Aurora.\nWhich feature should they use?",
    "choices": [
      "Aurora Global Database",
      "Aurora Serverless v1 only",
      "Manual snapshots copied weekly",
      "Read replicas in the same AZ"
    ],
    "answer": 0,
    "explanation": "Aurora Global Database provides cross-region replication with low-latency replication and supports DR scenarios with low RPO.",
    "difficulty": "Medium",
    "choiceExplanations": {
      "1": "Aurora Serverless v1 is an on-demand auto-scaling configuration for Aurora but does not support cross-region replication; it is designed for variable workloads, not disaster recovery across regions.",
      "2": "Weekly manual snapshots would result in a high RPO of up to 7 days of potential data loss, which does not meet the requirement for low RPO disaster recovery.",
      "3": "Read replicas in the same Availability Zone provide no regional disaster recovery capability since they remain within the same region and even the same AZ, offering no protection against regional failures."
    }
  },
  {
    "id": "SAA-496",
    "domainId": "D2",
    "domain": "Design Resilient Architectures",
    "section": "Lambda",
    "question": "A Lambda function is triggered by SQS. During outages downstream, messages should not be lost and should be retried without blocking the entire queue indefinitely.\nWhich configuration helps isolate poison messages?",
    "choices": [
      "Increase the Lambda timeout to the maximum",
      "Configure a dead-letter queue (DLQ) or redrive policy with a max receive count",
      "Disable visibility timeout",
      "Use a FIFO queue with no deduplication"
    ],
    "answer": 1,
    "explanation": "A redrive policy moves repeatedly failing messages to a DLQ after max receives, preventing stuck processing while preserving data.",
    "difficulty": "Medium",
    "choiceExplanations": {
      "0": "Increasing Lambda timeout (up to 15 minutes) only extends processing time but does not isolate poison messages; problematic messages will still be retried indefinitely and continue blocking the queue without being moved aside.",
      "2": "Disabling or setting visibility timeout to zero would cause messages to be immediately visible again while still being processed, leading to duplicate processing and potential race conditions; it does not isolate poison messages and would worsen queue behavior.",
      "3": "FIFO queues enforce strict ordering which actually worsens the blocking problem since a poison message at the head of the queue blocks all subsequent messages; additionally, this does not provide any mechanism to isolate or remove failing messages."
    }
  },
  {
    "id": "SAA-497",
    "domainId": "D2",
    "domain": "Design Resilient Architectures",
    "section": "Multi-Region",
    "question": "A global app needs a static anycast entry point that can route users to the nearest healthy regional endpoint and fail over quickly if a region is down.\nWhich AWS service is most appropriate?",
    "choices": [
      "Amazon CloudFront only",
      "AWS Global Accelerator",
      "AWS Direct Connect",
      "Amazon VPC Lattice"
    ],
    "answer": 1,
    "explanation": "Global Accelerator provides anycast IPs and health-based routing to optimal regional endpoints with fast failover.",
    "difficulty": "Medium",
    "choiceExplanations": {
      "0": "While CloudFront provides edge locations and can cache content globally, it is primarily a CDN service and does not provide static anycast IP addresses for non-HTTP/HTTPS traffic or the same level of instant regional failover that Global Accelerator offers for application endpoints.",
      "2": "Direct Connect establishes dedicated private network connections between on-premises data centers and AWS, but it does not provide anycast IP addresses, global routing, or automatic failover between regions for internet-facing applications.",
      "3": "VPC Lattice is a service networking solution for connecting, securing, and monitoring services across VPCs and accounts within a single region, but it does not provide global anycast IP addresses or multi-region routing and failover capabilities."
    }
  },
  {
    "id": "SAA-498",
    "domainId": "D2",
    "domain": "Design Resilient Architectures",
    "section": "EBS",
    "question": "An EC2 instance with an EBS volume fails. The volume must be attached to a replacement instance as quickly as possible with the same data.\nWhich approach is best?",
    "choices": [
      "Use an EBS snapshot, then create a new volume and attach it",
      "Detach the existing EBS volume and attach it to the new instance in the same AZ",
      "Copy the data from S3 Glacier and rehydrate it",
      "Use an AMI only; AMIs always include the latest data"
    ],
    "answer": 1,
    "explanation": "EBS volumes are AZ-scoped; detaching and reattaching the same volume in the same AZ is the fastest way to preserve data and restore service.",
    "difficulty": "Medium",
    "choiceExplanations": {
      "0": "While this approach works, it is slower than directly detaching and reattaching the existing volume because creating a snapshot and then restoring it takes additional time, especially for larger volumes.",
      "2": "S3 Glacier retrieval can take minutes to hours depending on the retrieval tier, and this assumes data was previously backed up to Glacier, making it the slowest option and not suitable for quick recovery.",
      "3": "AMIs are point-in-time snapshots created when the AMI was made and do not automatically contain the latest data; any data written after AMI creation would be lost."
    }
  },
  {
    "id": "SAA-499",
    "domainId": "D2",
    "domain": "Design Resilient Architectures",
    "section": "DR (Select TWO)",
    "question": "A workload requires a regional disaster recovery plan with reduced downtime and frequent data replication, but the company wants to avoid paying for full production capacity in the secondary region.\nWhich TWO DR approaches generally align with these goals? (Choose TWO.)",
    "choices": [
      "Warm standby",
      "Backup and restore only",
      "Pilot light",
      "Active/active in both regions at full scale",
      "Run everything in a single AZ with Multi-AZ disabled"
    ],
    "answer": [
      0,
      2
    ],
    "explanation": "Warm standby and pilot light reduce cost compared to full active/active while maintaining better RTO/RPO than backup-and-restore alone.",
    "difficulty": "Medium",
    "choiceExplanations": {
      "1": "While this is the lowest cost DR option, it has the longest recovery time (RTO) because infrastructure must be provisioned and data restored during a disaster, which does not meet the requirement for reduced downtime.",
      "3": "This approach provides the lowest RTO/RPO but requires running full production capacity in both regions simultaneously, directly contradicting the requirement to avoid paying for full production capacity in the secondary region.",
      "4": "This provides no disaster recovery capability at all and actually increases risk by eliminating availability zone redundancy, completely failing to address the regional DR requirement."
    }
  },
  {
    "id": "SAA-500",
    "domainId": "D2",
    "domain": "Design Resilient Architectures",
    "section": "Elastic Beanstalk",
    "question": "A team wants an easy way to deploy a web application with built-in health checks, rolling deployments, and Auto Scaling without managing most underlying infrastructure.\nWhich service is best?",
    "choices": [
      "AWS Elastic Beanstalk",
      "Amazon EMR",
      "Amazon WorkSpaces",
      "AWS Batch"
    ],
    "answer": 0,
    "explanation": "Elastic Beanstalk provides a managed application deployment experience that can provision ALB, Auto Scaling, and health monitoring with minimal overhead.",
    "difficulty": "Medium",
    "choiceExplanations": {
      "1": "This is a managed big data platform for processing large datasets using frameworks like Apache Spark and Hadoop, not a web application deployment service with built-in health checks and rolling deployments.",
      "2": "This is a managed Desktop-as-a-Service (DaaS) solution that provides virtual Windows or Linux desktops, not a platform for deploying web applications.",
      "3": "This service is designed for running batch computing workloads at scale, not for deploying web applications with features like health checks, rolling deployments, and Auto Scaling for web traffic."
    }
  },
  {
    "id": "SAA-501",
    "domainId": "D3",
    "domain": "Design High-Performing Architectures",
    "section": "CloudFront",
    "question": "A website serves static assets from S3 to a global audience. The company wants lower latency and reduced load on the origin.\nWhich solution should be used?",
    "choices": [
      "Add more S3 buckets and manually sync content",
      "Use Amazon CloudFront with the S3 bucket as origin and enable caching",
      "Use an NLB in front of S3",
      "Use Route 53 weighted routing to S3"
    ],
    "answer": 1,
    "explanation": "CloudFront caches content at edge locations, reducing latency for users and decreasing requests to the S3 origin.",
    "difficulty": "Medium",
    "choiceExplanations": {
      "0": "This approach creates significant operational overhead for content synchronization and does not provide edge caching capabilities, meaning users still experience latency when accessing the nearest S3 bucket, and every request still hits the origin.",
      "2": "Network Load Balancers operate at Layer 4 and cannot be placed directly in front of S3 buckets; NLBs are designed for load balancing traffic to compute resources like EC2 instances or containers, not for caching or serving S3 content.",
      "3": "Weighted routing distributes traffic based on assigned weights but does not provide caching or edge locations; all requests would still go directly to S3, providing no latency improvement or reduction in origin load."
    }
  },
  {
    "id": "SAA-502",
    "domainId": "D3",
    "domain": "Design High-Performing Architectures",
    "section": "ElastiCache",
    "question": "A read-heavy application needs sub-millisecond access to frequently requested items and can tolerate data being up to 30 seconds stale.\nWhat should the Solutions Architect implement?",
    "choices": [
      "Increase RDS storage size",
      "Add ElastiCache (Redis) with a suitable TTL and cache-aside pattern",
      "Move the application to a larger EC2 instance type",
      "Enable S3 Transfer Acceleration"
    ],
    "answer": 1,
    "explanation": "Redis caching can serve hot data with very low latency and reduce database read load; TTL supports acceptable staleness.",
    "difficulty": "Medium",
    "choiceExplanations": {
      "0": "Increasing storage size affects capacity and potentially IOPS for storage-bound workloads, but does not reduce read latency to sub-millisecond levels or address the caching needs for frequently accessed data.",
      "2": "Scaling up the application server does not address database read latency or reduce database load; the bottleneck is data retrieval speed, not application compute capacity.",
      "3": "S3 Transfer Acceleration speeds up uploads and downloads to S3 buckets over long distances using CloudFront edge locations, but is irrelevant for database read operations and does not provide sub-millisecond caching for application data."
    }
  },
  {
    "id": "SAA-503",
    "domainId": "D3",
    "domain": "Design High-Performing Architectures",
    "section": "EBS",
    "question": "A transactional database needs sustained high IOPS and consistent low latency. The team is choosing between gp3 and io2.\nWhich option is most appropriate for the highest, most consistent I/O performance?",
    "choices": [
      "st1",
      "sc1",
      "io2",
      "Magnetic (standard)"
    ],
    "answer": 2,
    "explanation": "io2 Provisioned IOPS SSD is built for I/O-intensive workloads requiring sustained high IOPS and consistent low latency.",
    "difficulty": "Medium",
    "choiceExplanations": {
      "0": "Throughput Optimized HDD is designed for frequently accessed, throughput-intensive workloads like big data and log processing, not for high IOPS transactional databases; it offers a maximum of only 500 IOPS and cannot deliver the sustained high IOPS required.",
      "1": "Cold HDD is the lowest-cost storage option designed for infrequently accessed data with a maximum of only 250 IOPS, making it completely unsuitable for transactional databases requiring sustained high IOPS and low latency.",
      "3": "This is a previous generation volume type with inconsistent performance and very limited IOPS capability, making it inappropriate for modern transactional databases that require sustained high IOPS and consistent low latency."
    }
  },
  {
    "id": "SAA-504",
    "domainId": "D3",
    "domain": "Design High-Performing Architectures",
    "section": "Lambda",
    "question": "A Lambda function is experiencing timeouts because it needs to call an external API that sometimes responds slowly. The team wants better performance and fewer cold starts.\nWhich change is most likely to help?",
    "choices": [
      "Decrease the function memory size",
      "Enable Provisioned Concurrency for the function",
      "Disable retries for asynchronous invocations",
      "Move the code to a smaller deployment package"
    ],
    "answer": 1,
    "explanation": "Provisioned Concurrency keeps functions initialized, reducing cold start latency and improving responsiveness under load.",
    "difficulty": "Medium",
    "choiceExplanations": {
      "0": "Decreasing memory would actually worsen performance because Lambda allocates CPU power proportionally to memory, resulting in slower execution and potentially more timeouts rather than fewer.",
      "2": "Disabling retries does not improve performance or reduce cold starts; it only prevents Lambda from automatically retrying failed invocations, which doesn't address the underlying timeout or cold start issues.",
      "3": "While smaller deployment packages can slightly reduce cold start initialization time, this has minimal impact compared to Provisioned Concurrency and does not address the external API latency causing timeouts."
    }
  },
  {
    "id": "SAA-505",
    "domainId": "D3",
    "domain": "Design High-Performing Architectures",
    "section": "DynamoDB",
    "question": "A DynamoDB table receives heavy writes to a small set of partition keys, causing throttling. The workload must keep using DynamoDB.\nWhat is the best way to reduce throttling caused by hot partitions?",
    "choices": [
      "Use a smaller item size",
      "Enable DynamoDB Streams",
      "Add write sharding by expanding the partition key space",
      "Turn on strongly consistent reads"
    ],
    "answer": 2,
    "explanation": "Write sharding spreads traffic across more partitions by increasing key cardinality, reducing hot partition throttling.",
    "difficulty": "Medium",
    "choiceExplanations": {
      "0": "While smaller items consume fewer write capacity units per operation, this does not address the fundamental problem of hot partitions where writes are concentrated on a small set of partition keys; the same keys would still receive disproportionate traffic.",
      "1": "DynamoDB Streams captures data modification events for downstream processing but does not affect how write traffic is distributed across partitions; it has no impact on hot partition throttling.",
      "3": "Strongly consistent reads affect read operations by ensuring the most recent data is returned, but this has no impact on write throttling or hot partition issues caused by concentrated write traffic to specific partition keys."
    }
  },
  {
    "id": "SAA-506",
    "domainId": "D3",
    "domain": "Design High-Performing Architectures",
    "section": "Kinesis",
    "question": "A company ingests clickstream events and needs near-real-time processing by multiple consumers. They expect sustained high throughput and want ordered processing per partition.\nWhich service is most appropriate?",
    "choices": [
      "Amazon SQS Standard",
      "Amazon Kinesis Data Streams",
      "AWS Step Functions Standard",
      "Amazon SNS"
    ],
    "answer": 1,
    "explanation": "Kinesis Data Streams supports high-throughput streaming with multiple consumers and ordering within shards (partitions).",
    "difficulty": "Medium",
    "choiceExplanations": {
      "0": "SQS Standard queues do not guarantee message ordering and use best-effort ordering, which fails the requirement for ordered processing per partition. Additionally, SQS is designed for single-consumer patterns rather than multiple consumers processing the same messages.",
      "2": "Step Functions is a workflow orchestration service for coordinating distributed applications and microservices, not a streaming data ingestion service. It is not designed for high-throughput real-time event processing or streaming data scenarios.",
      "3": "SNS is a pub/sub messaging service that delivers messages to subscribers but does not provide message ordering guarantees or retain messages for replay. It pushes messages immediately and does not support the sustained high-throughput streaming ingestion pattern required for clickstream processing."
    }
  },
  {
    "id": "SAA-507",
    "domainId": "D3",
    "domain": "Design High-Performing Architectures",
    "section": "Caching (Select TWO)",
    "question": "A company wants to reduce latency and origin load for a global web application serving dynamic and static content.\nWhich TWO approaches are most effective? (Choose TWO.)",
    "choices": [
      "Use CloudFront to cache static content close to users",
      "Use ElastiCache to cache frequently accessed database/query results",
      "Store all dynamic content in S3 Glacier Deep Archive",
      "Increase DNS TTL to 24 hours to improve application performance",
      "Disable compression to reduce CPU usage on clients"
    ],
    "answer": [
      0,
      1
    ],
    "explanation": "CloudFront helps with edge caching for static/edge-eligible content, and ElastiCache reduces backend latency by caching hot data and query results.",
    "difficulty": "Medium",
    "choiceExplanations": {
      "2": "S3 Glacier Deep Archive is designed for long-term archival storage with retrieval times of 12-48 hours, making it completely unsuitable for serving dynamic web content that requires low-latency access.",
      "3": "While higher DNS TTL reduces DNS lookup frequency, it does not reduce application latency or origin load for content delivery, and can actually cause problems during failover scenarios or infrastructure changes by directing users to stale endpoints.",
      "4": "Disabling compression would actually increase latency by requiring more data to be transferred over the network, and compression overhead on modern clients is negligible compared to the bandwidth savings it provides."
    }
  },
  {
    "id": "SAA-508",
    "domainId": "D3",
    "domain": "Design High-Performing Architectures",
    "section": "EFS",
    "question": "Multiple EC2 instances across different AZs need a shared POSIX file system for application content. The team wants a managed service that scales automatically.\nWhich storage service should be used?",
    "choices": [
      "Amazon EFS",
      "Amazon EBS Multi-Attach only",
      "Instance Store",
      "Amazon S3 Glacier"
    ],
    "answer": 0,
    "explanation": "EFS is a managed NFS file system that can be mounted by many instances across AZs and scales automatically.",
    "difficulty": "Medium",
    "choiceExplanations": {
      "1": "EBS Multi-Attach is limited to instances within a single Availability Zone and only works with io1/io2 Provisioned IOPS volumes, so it cannot provide shared storage across multiple AZs as required.",
      "2": "Instance store provides temporary block-level storage that is physically attached to the host computer, cannot be shared between instances, and data is lost when the instance stops or terminates.",
      "3": "S3 Glacier is an archive storage class designed for long-term data retention with retrieval times ranging from minutes to hours, not a POSIX-compliant file system that can be mounted by EC2 instances."
    }
  },
  {
    "id": "SAA-509",
    "domainId": "D3",
    "domain": "Design High-Performing Architectures",
    "section": "RDS",
    "question": "A MySQL workload is read-heavy and needs to scale reads without changing the application significantly. Writes must remain on the primary.\nWhat is the best option?",
    "choices": [
      "Add RDS read replicas and direct read traffic to them",
      "Enable Multi-AZ for read scaling",
      "Move the database to S3",
      "Use AWS Backup to copy the database"
    ],
    "answer": 0,
    "explanation": "RDS read replicas offload read traffic and help scale read throughput while keeping writes on the primary instance.",
    "difficulty": "Medium",
    "choiceExplanations": {
      "1": "Multi-AZ deployments are designed for high availability and automatic failover, not for read scaling. The standby instance in Multi-AZ cannot serve read traffic; it only becomes active if the primary fails.",
      "2": "S3 is an object storage service, not a relational database, and cannot process MySQL queries or handle transactional workloads. This would require completely rewriting the application and is not suitable for relational database operations.",
      "3": "AWS Backup is used for creating point-in-time backups for disaster recovery purposes, not for scaling read operations. Backup copies cannot serve live read traffic to applications."
    }
  },
  {
    "id": "SAA-510",
    "domainId": "D3",
    "domain": "Design High-Performing Architectures",
    "section": "CloudWatch",
    "question": "An application needs to scale based on business metrics (orders per minute) rather than CPU. The team wants an AWS-native approach.\nWhat should they do?",
    "choices": [
      "Use CloudWatch custom metrics and target tracking scaling policies",
      "Use only EC2 scheduled scaling",
      "Use CloudTrail events to trigger scaling actions",
      "Use S3 event notifications to scale EC2"
    ],
    "answer": 0,
    "explanation": "Publishing custom metrics to CloudWatch enables Auto Scaling to scale based on business KPIs using target tracking or step policies.",
    "difficulty": "Medium",
    "choiceExplanations": {
      "1": "Scheduled scaling adjusts capacity based on predictable time-based patterns, not real-time business metrics like orders per minute, so it cannot dynamically respond to actual demand fluctuations.",
      "2": "CloudTrail records API calls for auditing and compliance purposes, not application-level business metrics like orders per minute, making it unsuitable for metric-based scaling decisions.",
      "3": "S3 event notifications are designed to trigger actions based on object-level operations in S3 buckets (like object creation or deletion), not for monitoring application business metrics or directly scaling EC2 instances."
    }
  },
  {
    "id": "SAA-511",
    "domainId": "D3",
    "domain": "Design High-Performing Architectures",
    "section": "S3",
    "question": "A global user base frequently downloads large files stored in S3. The company wants to improve download performance without duplicating data to multiple buckets.\nWhich solution is most appropriate?",
    "choices": [
      "Use CloudFront in front of S3",
      "Use EBS snapshots and share them publicly",
      "Use Amazon EFS and mount it globally",
      "Use AWS Backup to accelerate downloads"
    ],
    "answer": 0,
    "explanation": "CloudFront improves download performance by caching at edge locations and optimizing delivery from the S3 origin.",
    "difficulty": "Medium",
    "choiceExplanations": {
      "1": "EBS snapshots are block-level storage backups designed for EC2 volumes, not for content distribution; they cannot be directly downloaded by end users and would require launching EC2 instances to access the data, making this impractical for global file distribution.",
      "2": "EFS is a regional file system designed for EC2 instances within a VPC and cannot be mounted globally across the internet by end users; it requires network connectivity via VPC and is not suitable for public file downloads.",
      "3": "AWS Backup is a centralized backup service for managing and automating backups across AWS services; it has no content delivery or download acceleration capabilities and is unrelated to improving download performance for end users."
    }
  },
  {
    "id": "SAA-512",
    "domainId": "D3",
    "domain": "Design High-Performing Architectures",
    "section": "Networking",
    "question": "A latency-sensitive TCP application requires a static IP and very high throughput load balancing. The application does not need Layer 7 routing features.\nWhich load balancer is best?",
    "choices": [
      "Application Load Balancer",
      "Network Load Balancer",
      "Gateway Load Balancer",
      "Classic Load Balancer"
    ],
    "answer": 1,
    "explanation": "NLB provides high performance for TCP/UDP and supports static IPs (or Elastic IPs) and low latency.",
    "difficulty": "Medium",
    "choiceExplanations": {
      "0": "ALB operates at Layer 7 and is designed for HTTP/HTTPS traffic with advanced routing features, but it does not natively support static IP addresses and has higher latency compared to NLB, making it unsuitable for this latency-sensitive TCP application.",
      "2": "GLB is designed for deploying, scaling, and managing third-party virtual appliances like firewalls and intrusion detection systems, not for load balancing application traffic directly to backend servers.",
      "3": "CLB is a legacy load balancer that does not support static IP addresses and offers lower performance compared to NLB; AWS recommends migrating to newer load balancer types for better features and performance."
    }
  },
  {
    "id": "SAA-513",
    "domainId": "D3",
    "domain": "Design High-Performing Architectures",
    "section": "Aurora",
    "question": "A company wants better read scalability and faster failover than standard RDS MySQL, while staying MySQL-compatible.\nWhich database choice is most appropriate?",
    "choices": [
      "Amazon Aurora MySQL-Compatible",
      "Amazon Neptune",
      "Amazon Redshift",
      "Amazon DocumentDB"
    ],
    "answer": 0,
    "explanation": "Aurora MySQL offers higher performance, improved replication, and faster failover while maintaining MySQL compatibility.",
    "difficulty": "Medium",
    "choiceExplanations": {
      "1": "Neptune is a graph database service designed for highly connected datasets and graph queries, not a MySQL-compatible relational database, so it cannot serve as a drop-in replacement for MySQL workloads.",
      "2": "Redshift is a data warehousing service optimized for analytics and OLAP workloads using columnar storage, not an OLTP MySQL-compatible database suitable for transactional applications.",
      "3": "DocumentDB is a document database service with MongoDB compatibility, not MySQL compatibility, making it unsuitable for applications requiring MySQL relational database features."
    }
  },
  {
    "id": "SAA-514",
    "domainId": "D3",
    "domain": "Design High-Performing Architectures",
    "section": "DynamoDB",
    "question": "An application needs consistent single-digit millisecond reads and writes at massive scale, and the data model is key-value with predictable access patterns.\nWhich database is best?",
    "choices": [
      "Amazon DynamoDB",
      "Amazon RDS PostgreSQL",
      "Amazon OpenSearch Service",
      "Amazon Athena"
    ],
    "answer": 0,
    "explanation": "DynamoDB is designed for low-latency key-value access at scale, making it ideal for predictable key-based access patterns.",
    "difficulty": "Medium",
    "choiceExplanations": {
      "1": "While RDS PostgreSQL is a powerful relational database, it cannot match DynamoDB's consistent single-digit millisecond latency at massive scale, and its relational model adds unnecessary complexity for simple key-value access patterns.",
      "2": "OpenSearch is designed for full-text search, log analytics, and complex queries across documents, not optimized for simple key-value lookups requiring consistent single-digit millisecond performance at massive scale.",
      "3": "Athena is a serverless query service for analyzing data in S3 using SQL, with query response times typically measured in seconds, making it unsuitable for low-latency key-value access requirements."
    }
  },
  {
    "id": "SAA-515",
    "domainId": "D4",
    "domain": "Design Cost-Optimized Architectures",
    "section": "S3",
    "question": "A company stores access logs in S3. Logs are queried frequently for the first 14 days, then rarely accessed but must be retained for 1 year.\nWhich cost-optimized approach is best?",
    "choices": [
      "Keep logs in S3 Standard for the full year",
      "Use S3 Lifecycle to transition to S3 Standard-IA after 14 days",
      "Move logs to EBS volumes after 14 days",
      "Move logs to S3 One Zone-IA immediately"
    ],
    "answer": 1,
    "explanation": "Standard-IA reduces storage cost for infrequently accessed data while keeping it quickly retrievable; lifecycle rules automate transitions.",
    "difficulty": "Medium",
    "choiceExplanations": {
      "0": "This is not cost-optimized because S3 Standard has higher storage costs than S3 Standard-IA, and since logs are rarely accessed after 14 days, paying for frequent access pricing for the remaining 351 days wastes money.",
      "2": "EBS volumes are block storage designed for EC2 instances, not for archival log storage; this approach is significantly more expensive, requires managing EC2 instances, and lacks the durability and scalability of S3.",
      "3": "This is incorrect for two reasons - logs are frequently accessed for the first 14 days making IA inappropriate initially, and One Zone-IA stores data in only one Availability Zone, reducing durability which may not meet compliance requirements for log retention."
    }
  },
  {
    "id": "SAA-516",
    "domainId": "D4",
    "domain": "Design Cost-Optimized Architectures",
    "section": "EC2 Pricing",
    "question": "A service needs 20 EC2 instances running 24/7 for the next 3 years with a stable instance type. The company wants the lowest compute cost.\nWhat should they purchase?",
    "choices": [
      "On-Demand Instances only",
      "Spot Instances only",
      "Standard Reserved Instances (3-year) or a 3-year Savings Plan covering the baseline",
      "Dedicated Hosts"
    ],
    "answer": 2,
    "explanation": "For steady-state workloads, 3-year commitment discounts (Standard RIs or Savings Plans) typically provide the best cost reduction.",
    "difficulty": "Medium",
    "choiceExplanations": {
      "0": "On-Demand pricing is the most expensive option with no discounts, costing significantly more than Reserved Instances or Savings Plans which can provide up to 72% savings for 3-year commitments on steady-state workloads.",
      "1": "While Spot Instances offer up to 90% discount, they can be interrupted with only 2 minutes notice when AWS needs the capacity back, making them unsuitable for workloads requiring 24/7 continuous availability.",
      "3": "Dedicated Hosts provide physical servers dedicated to your use for compliance or licensing requirements, but they are significantly more expensive than shared tenancy options and do not optimize for lowest compute cost."
    }
  },
  {
    "id": "SAA-517",
    "domainId": "D4",
    "domain": "Design Cost-Optimized Architectures",
    "section": "EBS",
    "question": "A team is paying for large gp3 volumes with more provisioned IOPS than needed. They want to reduce costs while keeping performance adequate.\nWhat should they do first?",
    "choices": [
      "Switch all volumes to io2",
      "Right-size EBS volume size and provisioned IOPS/throughput based on actual metrics",
      "Move the workload to instance store",
      "Disable CloudWatch monitoring"
    ],
    "answer": 1,
    "explanation": "Right-sizing gp3 capacity, IOPS, and throughput to match real usage is a direct way to reduce EBS spend without sacrificing required performance.",
    "difficulty": "Medium",
    "choiceExplanations": {
      "0": "io2 volumes are designed for mission-critical workloads requiring high IOPS and are more expensive than gp3 volumes, so switching to io2 would increase costs rather than reduce them.",
      "2": "Instance store provides temporary block-level storage that is lost when the instance stops or terminates, making it unsuitable for persistent data and introducing significant risk without addressing the cost optimization goal safely.",
      "3": "Disabling CloudWatch monitoring would eliminate the visibility needed to understand actual usage patterns and make informed right-sizing decisions, and the minimal cost savings from disabling monitoring would not address the core issue of over-provisioned IOPS."
    }
  },
  {
    "id": "SAA-518",
    "domainId": "D4",
    "domain": "Design Cost-Optimized Architectures",
    "section": "Compute (Select TWO)",
    "question": "A company runs nightly batch jobs that can be interrupted and restarted. They want to minimize cost while keeping completion time reasonable.\nWhich TWO options are most cost-effective? (Choose TWO.)",
    "choices": [
      "Use EC2 Spot Instances with checkpointing",
      "Use AWS Batch with Spot capacity enabled",
      "Use Dedicated Hosts to reserve capacity",
      "Use On-Demand Instances only",
      "Use 3-year Standard Reserved Instances for the batch fleet"
    ],
    "answer": [
      0,
      1
    ],
    "explanation": "Spot is ideal for interruptible workloads. AWS Batch can manage job queues and leverage Spot capacity automatically while handling retries and scaling.",
    "difficulty": "Medium",
    "choiceExplanations": {
      "2": "Dedicated Hosts are the most expensive EC2 pricing option, designed for licensing compliance and regulatory requirements rather than cost optimization, making them unsuitable for minimizing costs on interruptible batch workloads.",
      "3": "On-Demand Instances cost significantly more than Spot Instances (up to 90% more), and since the workload can tolerate interruptions, there is no justification for paying the premium On-Demand pricing.",
      "4": "Reserved Instances require upfront commitment for continuous usage and are not cost-effective for nightly batch jobs that only run periodically, as you would pay for capacity during idle hours when the jobs are not running."
    }
  },
  {
    "id": "SAA-519",
    "domainId": "D4",
    "domain": "Design Cost-Optimized Architectures",
    "section": "RDS",
    "question": "A company runs a dev/test RDS database that is only needed during business hours. They want to reduce cost while keeping the same DB engine.\nWhat should they do?",
    "choices": [
      "Enable Multi-AZ to reduce costs",
      "Stop the RDS instance outside business hours (where supported) or use Aurora Serverless v2 for variable usage",
      "Move the database to an EC2 instance store volume",
      "Enable CloudFront caching"
    ],
    "answer": 1,
    "explanation": "Stopping non-production databases during off-hours (or using an auto-scaling serverless option where appropriate) reduces compute costs significantly.",
    "difficulty": "Medium",
    "choiceExplanations": {
      "0": "Multi-AZ deployments actually increase costs by approximately double because AWS provisions a synchronous standby replica in a different Availability Zone for high availability, not cost reduction.",
      "2": "Instance store volumes are ephemeral storage that lose data when the instance stops or terminates, making them completely unsuitable for database workloads that require data persistence and durability.",
      "3": "CloudFront is a CDN designed for caching static content and HTTP/HTTPS responses at edge locations; it cannot cache database queries or reduce RDS compute costs for a dev/test database that needs direct database access."
    }
  },
  {
    "id": "SAA-520",
    "domainId": "D4",
    "domain": "Design Cost-Optimized Architectures",
    "section": "S3",
    "question": "A dataset has unpredictable access patterns. The team wants to reduce storage costs without manually creating complex lifecycle rules and without impacting retrieval for frequently accessed objects.\nWhich S3 storage class is most appropriate?",
    "choices": [
      "S3 Glacier Deep Archive",
      "S3 Intelligent-Tiering",
      "S3 One Zone-IA",
      "S3 Reduced Redundancy Storage (RRS)"
    ],
    "answer": 1,
    "explanation": "Intelligent-Tiering automatically moves objects between tiers based on access while keeping retrieval seamless for frequently accessed data.",
    "difficulty": "Medium",
    "choiceExplanations": {
      "0": "This is designed for long-term archival with retrieval times of 12-48 hours, which would significantly impact retrieval for frequently accessed objects and is not suitable for unpredictable access patterns requiring immediate access.",
      "2": "This requires you to know that data is infrequently accessed (it charges retrieval fees and has minimum storage duration), and would still require manual lifecycle rules to move data between tiers based on access patterns.",
      "3": "This is a legacy storage class that AWS no longer recommends, offers lower durability than standard S3, does not automatically tier data based on access patterns, and is actually more expensive than S3 Standard."
    }
  },
  {
    "id": "SAA-521",
    "domainId": "D4",
    "domain": "Design Cost-Optimized Architectures",
    "section": "Data Transfer",
    "question": "A workload moves large amounts of data between two EC2 instances in the same AZ. The company wants to minimize data transfer costs.\nWhich placement is most cost-effective?",
    "choices": [
      "Place the instances in different regions",
      "Place the instances in different AZs in the same region",
      "Place the instances in the same AZ (and same VPC) when possible",
      "Route traffic through the internet gateway"
    ],
    "answer": 2,
    "explanation": "Keeping traffic within the same AZ generally reduces cross-AZ data transfer charges and can improve latency.",
    "difficulty": "Medium",
    "choiceExplanations": {
      "0": "Cross-region data transfer incurs the highest data transfer costs in AWS, as traffic must traverse AWS's global backbone network and is charged at inter-region rates, which are significantly more expensive than intra-AZ or cross-AZ transfers.",
      "1": "Cross-AZ data transfer within a region incurs charges (typically $0.01/GB in each direction), whereas data transfer between instances in the same AZ using private IP addresses is free, making this option more expensive than same-AZ placement.",
      "3": "Routing traffic through an internet gateway incurs data transfer charges for outbound traffic to the internet and requires public IP addresses, making it both more expensive and less secure than using private IP communication within the same AZ."
    }
  },
  {
    "id": "SAA-522",
    "domainId": "D4",
    "domain": "Design Cost-Optimized Architectures",
    "section": "Logging",
    "question": "A company stores application logs in CloudWatch Logs indefinitely and costs are growing. Logs are only needed for search for 30 days, but must be retained for 1 year for compliance.\nWhat is the best cost-optimized approach?",
    "choices": [
      "Reduce the log level and keep indefinite retention",
      "Set CloudWatch Logs retention to 30 days and export/archive logs to S3 for long-term retention",
      "Disable logging to reduce cost",
      "Store logs only on EC2 instance disks"
    ],
    "answer": 1,
    "explanation": "CloudWatch Logs retention limits ongoing ingestion/storage costs, while S3 provides cheaper long-term retention for compliance.",
    "difficulty": "Medium",
    "choiceExplanations": {
      "0": "While reducing log level decreases data volume, keeping indefinite retention in CloudWatch Logs is significantly more expensive than archiving to S3, and this approach doesn't address the core cost issue of long-term storage in CloudWatch.",
      "2": "This violates the compliance requirement to retain logs for 1 year and eliminates the ability to search logs for the required 30-day period, making it an unacceptable solution regardless of cost savings.",
      "3": "This approach lacks durability, scalability, and centralized search capabilities; logs would be lost if instances terminate, and it doesn't meet compliance requirements for reliable 1-year retention."
    }
  },
  {
    "id": "SAA-523",
    "domainId": "D4",
    "domain": "Design Cost-Optimized Architectures",
    "section": "Compute",
    "question": "A workload runs on multiple EC2 instance families and sizes, but has a consistent monthly spend pattern. The company wants flexible discounts without locking to a single instance type.\nWhat should they use?",
    "choices": [
      "Dedicated Hosts",
      "Compute Savings Plans",
      "Spot Instances only",
      "On-Demand Capacity Reservations"
    ],
    "answer": 1,
    "explanation": "Compute Savings Plans offer flexible discounts across instance families and regions (within terms) compared to instance-specific reservations.",
    "difficulty": "Medium",
    "choiceExplanations": {
      "0": "These provide physical servers dedicated to your use for compliance or licensing requirements, but they are tied to specific instance families and are more expensive than shared tenancy, not designed for flexible cost optimization across multiple instance types.",
      "2": "While Spot Instances offer significant discounts (up to 90%), they can be interrupted with 2-minute notice when AWS needs capacity back, making them unsuitable as the sole solution for workloads requiring consistent availability and predictable monthly spend patterns.",
      "3": "These reserve capacity in a specific Availability Zone for specific instance types but do not provide any billing discount; they only guarantee capacity availability and still charge On-Demand rates whether instances are running or not."
    }
  },
  {
    "id": "SAA-524",
    "domainId": "D4",
    "domain": "Design Cost-Optimized Architectures",
    "section": "DynamoDB",
    "question": "A DynamoDB table has highly variable traffic: very high on weekends and low during weekdays. The team wants to avoid capacity planning while keeping costs reasonable for spiky usage.\nWhich capacity mode is most suitable?",
    "choices": [
      "Provisioned capacity with auto scaling disabled",
      "Provisioned capacity with a fixed high WCU/RCU",
      "On-demand capacity mode",
      "Local secondary indexes only"
    ],
    "answer": 2,
    "explanation": "On-demand automatically scales with workload spikes and removes the need for capacity planning, which fits highly variable usage patterns.",
    "difficulty": "Medium",
    "choiceExplanations": {
      "0": "This requires manual capacity planning and cannot automatically adjust to traffic spikes, leading to either throttling during high weekend traffic or wasted capacity during low weekday periods.",
      "1": "While this would handle weekend peaks, it results in significant cost waste during low weekday traffic since you pay for provisioned capacity whether used or not, making it not cost-optimized for variable workloads.",
      "3": "LSIs are a feature for alternative query patterns on a table, not a capacity mode; they do not address capacity planning or scaling requirements and are unrelated to managing variable traffic patterns."
    }
  },
  {
    "id": "SAA-525",
    "domainId": "D1",
    "domain": "Design Secure Architectures",
    "section": "Cognito",
    "question": "A web app needs user sign-up/sign-in and should receive temporary AWS credentials to access S3 with least privilege. The company wants a managed user directory.\nWhich solution is best?",
    "choices": [
      "IAM users for every customer",
      "Amazon Cognito User Pools with an Identity Pool for AWS credentials",
      "Store usernames/passwords in DynamoDB and create STS sessions manually",
      "Use EC2 instance profiles for end users"
    ],
    "answer": 1,
    "explanation": "User Pools manage identities and authentication; Identity Pools can exchange tokens for temporary AWS credentials scoped via IAM roles.",
    "difficulty": "Medium",
    "choiceExplanations": {
      "0": "IAM users are designed for internal AWS account access, not for external application users; this approach doesn't scale, exceeds IAM user limits (5,000 per account), and violates AWS best practices for customer-facing applications.",
      "2": "This is a custom, undifferentiated solution that requires managing password hashing, security, and credential lifecycle manually, whereas Cognito provides these capabilities as a fully managed service with built-in security features.",
      "3": "Instance profiles provide credentials to EC2 instances for server-side operations, not to end users; they cannot be used to grant temporary credentials to external application users accessing resources from client devices."
    }
  },
  {
    "id": "SAA-526",
    "domainId": "D1",
    "domain": "Design Secure Architectures",
    "section": "NACL",
    "question": "A security team wants to explicitly block traffic from a known malicious IP range at the subnet boundary for a public subnet. They want a stateless rule that can deny traffic.\nWhat should they use?",
    "choices": [
      "Security group deny rules",
      "Network ACL deny rules",
      "Route table blackhole routes for the IP range",
      "IAM policies"
    ],
    "answer": 1,
    "explanation": "NACLs are stateless and support explicit allow and deny rules, making them suitable for subnet-level IP blocking.",
    "difficulty": "Medium",
    "choiceExplanations": {
      "0": "Security groups only support allow rules and do not have the capability to create explicit deny rules; they implicitly deny all traffic that is not explicitly allowed.",
      "2": "Route tables control where network traffic is directed for outbound routing decisions, not for blocking inbound traffic from specific IP addresses; blackhole routes drop traffic destined for specific CIDRs, not traffic originating from them.",
      "3": "IAM policies control access to AWS services and resources through API calls, not network-level traffic flow; they cannot block IP-based network traffic at the subnet boundary."
    }
  },
  {
    "id": "SAA-527",
    "domainId": "D2",
    "domain": "Design Resilient Architectures",
    "section": "SQS/SNS",
    "question": "An event-driven system must deliver the same event to multiple independent consumers (email, SMS, and a processing service). The company wants loose coupling.\nWhich solution is most appropriate?",
    "choices": [
      "Send all events directly to each consumer from the producer",
      "Use SNS to publish events and have multiple subscriptions (including SQS for processing)",
      "Use a single SQS queue and have all consumers compete for messages",
      "Use EBS snapshots to store events"
    ],
    "answer": 1,
    "explanation": "SNS provides pub/sub fanout. SQS subscriptions allow durable processing by services while other subscribers can use different protocols.",
    "difficulty": "Medium",
    "choiceExplanations": {
      "0": "This creates tight coupling between the producer and all consumers, requiring the producer to know about and manage connections to each consumer, which violates the loose coupling requirement and makes the system harder to maintain and scale.",
      "2": "SQS queues deliver each message to only one consumer (competing consumers pattern), meaning email, SMS, and processing services would not all receive the same event, failing the requirement to deliver the same event to multiple independent consumers.",
      "3": "EBS snapshots are point-in-time backups of EBS volumes used for data persistence and disaster recovery, not for event messaging or pub/sub communication patterns, making this completely inappropriate for an event-driven messaging architecture."
    }
  },
  {
    "id": "SAA-528",
    "domainId": "D3",
    "domain": "Design High-Performing Architectures",
    "section": "S3 Performance",
    "question": "A workload uploads many large objects to S3 from a single client and wants faster upload throughput while also enabling retries of parts.\nWhich approach should be used?",
    "choices": [
      "Use S3 Select",
      "Use multipart upload",
      "Use Glacier Deep Archive for faster ingest",
      "Use S3 bucket ACLs"
    ],
    "answer": 1,
    "explanation": "Multipart upload increases throughput by uploading parts in parallel and improves resiliency by retrying only failed parts.",
    "difficulty": "Medium",
    "choiceExplanations": {
      "0": "S3 Select is designed for retrieving subsets of data from objects using SQL expressions, not for uploading data. It optimizes read operations by filtering data server-side, but provides no benefit for upload throughput or retry capabilities.",
      "2": "Glacier Deep Archive is the lowest-cost storage class designed for long-term archival with retrieval times of 12-48 hours. It does not provide faster upload speeds and is optimized for rarely accessed data, not upload performance.",
      "3": "Bucket ACLs are access control mechanisms that define permissions for buckets and objects. They have no impact on upload throughput or the ability to retry failed parts during data transfer operations."
    }
  },
  {
    "id": "SAA-529",
    "domainId": "D1",
    "domain": "Design Secure Architectures",
    "section": "Monitoring (Select TWO)",
    "question": "A company wants to detect suspicious API activity and potential credential compromise in AWS accounts.\nWhich TWO services are best suited for this? (Choose TWO.)",
    "choices": [
      "Amazon GuardDuty",
      "AWS CloudTrail",
      "Amazon CloudFront",
      "AWS Snowcone",
      "Amazon EFS"
    ],
    "answer": [
      0,
      1
    ],
    "explanation": "CloudTrail records API activity, and GuardDuty analyzes logs (including CloudTrail) for threats like anomalous access patterns and compromised credentials.",
    "difficulty": "Medium",
    "choiceExplanations": {
      "2": "This is a Content Delivery Network (CDN) service that caches and delivers content from edge locations to improve performance and reduce latency, not a security monitoring or threat detection service for API activity.",
      "3": "This is a portable edge computing and data transfer device used for collecting data in disconnected environments and migrating data to AWS, not a security monitoring service for detecting suspicious API activity.",
      "4": "This is a fully managed elastic file storage service that provides shared file system access for EC2 instances, not a security or monitoring service capable of detecting credential compromise or suspicious API activity."
    }
  },
  {
    "id": "SAA-530",
    "domainId": "D4",
    "domain": "Design Cost-Optimized Architectures",
    "section": "Auto Scaling Costs",
    "question": "A service scales out during peak, but scale-in is slow and costs are higher than expected. The team wants to reduce cost without impacting availability.\nWhat should they adjust first?",
    "choices": [
      "Increase the minimum desired capacity permanently",
      "Review cooldowns and scale-in policies (including target tracking settings) to allow faster scale-in",
      "Switch all instances to Dedicated Hosts",
      "Disable health checks to prevent replacements"
    ],
    "answer": 1,
    "explanation": "Overly conservative cooldowns and scale-in settings can keep extra instances running longer than needed. Tuning them reduces cost while preserving availability.",
    "difficulty": "Medium",
    "choiceExplanations": {
      "0": "This would increase costs by maintaining more instances at all times, including during low-demand periods, which is the opposite of the cost reduction goal.",
      "2": "Dedicated Hosts are significantly more expensive than shared tenancy instances and are used for licensing compliance or regulatory requirements, not cost optimization.",
      "3": "This would compromise availability by allowing unhealthy instances to remain in service, potentially causing application failures and degraded user experience."
    }
  },
  {
    "id": "SAA-531",
    "domainId": "D1",
    "domain": "Design Secure Architectures",
    "section": "IAM",
    "question": "A company is moving to an attribute-based access control (ABAC) model across 60 AWS accounts. Each developer assumes a role from a central identity provider and receives session tags such as Department, Project, and Environment. The security team requires that users can create and manage EC2 resources only when the resource tags match their session tags, and they must not be able to bypass tagging restrictions by changing tags after creation.\nWhich solution BEST enforces these requirements?",
    "choices": [
      "Use a permission boundary that allows ec2:* but relies on developers to apply correct tags",
      "Use IAM policies with aws:RequestTag and aws:ResourceTag conditions, and explicitly deny tag changes that would break ABAC rules",
      "Use AWS Config rules to detect incorrect tags and remediate after the fact with Lambda",
      "Use security groups and NACLs to restrict who can manage EC2 instances"
    ],
    "answer": 1,
    "explanation": "ABAC is enforced with IAM conditions on request tags and resource tags. Adding explicit deny conditions for tag mutations prevents users from creating resources with compliant tags and later changing them to bypass access controls.",
    "difficulty": "Hard",
    "choiceExplanations": {
      "0": "Permission boundaries alone cannot enforce tagging requirements at resource creation time, and relying on developers to voluntarily apply correct tags provides no technical enforcement mechanism, allowing users to create resources without proper tags or change tags after creation.",
      "2": "This is a detective control that identifies non-compliance after resources are created, not a preventive control that blocks unauthorized actions at the time of request, meaning users could still create improperly tagged resources or modify tags before remediation occurs.",
      "3": "Security groups and NACLs are network-level controls that filter traffic based on IP addresses, ports, and protocols; they cannot enforce IAM-level access control, tag-based authorization, or prevent users from managing EC2 resources through the AWS API."
    }
  },
  {
    "id": "SAA-532",
    "domainId": "D1",
    "domain": "Design Secure Architectures",
    "section": "S3 / Organizations",
    "question": "A security team must ensure that no team in any account can upload objects to any S3 bucket unless the objects are encrypted with SSE-KMS using a specific customer managed key. The control must be preventive across the AWS Organization and must remain effective even if a team changes IAM policies in their account.\nWhich approach BEST meets this requirement?",
    "choices": [
      "Enable S3 default encryption with SSE-S3 on all buckets and rely on developers to follow guidance",
      "Apply an SCP that denies s3:PutObject unless the correct SSE-KMS headers are present, and enforce a bucket policy requiring the specific KMS key",
      "Use AWS Config managed rules to detect unencrypted objects and delete them automatically",
      "Use CloudTrail alerts to notify security when an unencrypted upload occurs"
    ],
    "answer": 1,
    "explanation": "SCPs provide org-wide preventive guardrails that cannot be overridden by member account IAM. Combining SCP enforcement with bucket policy conditions ensures uploads are rejected unless the required SSE-KMS settings and key are used.",
    "difficulty": "Hard",
    "choiceExplanations": {
      "0": "This uses SSE-S3 (AWS managed keys) instead of the required SSE-KMS with a specific customer managed key, and relying on developer guidance is not a preventive control that can enforce compliance across the organization.",
      "2": "This is a detective control that identifies non-compliance after objects are already uploaded, not a preventive control that blocks uploads before they occur, and it cannot enforce the use of a specific KMS key.",
      "3": "This is a detective and reactive approach that only notifies after the violation has occurred, rather than a preventive control that blocks non-compliant uploads from happening in the first place."
    }
  },
  {
    "id": "SAA-533",
    "domainId": "D1",
    "domain": "Design Secure Architectures",
    "section": "VPC Endpoints",
    "question": "An ECS cluster runs entirely in private subnets. The workloads must pull images from Amazon ECR, write logs to CloudWatch Logs, and read configuration from AWS Systems Manager Parameter Store. The security team prohibits any internet egress and does not allow NAT Gateways.\nWhich solution enables the workloads to function while meeting the constraints?",
    "choices": [
      "Create a NAT instance in a public subnet and route all outbound traffic through it",
      "Create interface VPC endpoints for ECR (api and dkr), CloudWatch Logs, Systems Manager/SSM Messages, and a gateway endpoint for S3 if required by ECR",
      "Use an Internet Gateway with restrictive security group egress rules to block most destinations",
      "Use VPC peering to a shared services VPC that has a NAT Gateway"
    ],
    "answer": 1,
    "explanation": "Private connectivity to AWS services without internet egress is achieved using VPC endpoints. ECR commonly requires interface endpoints (and often S3 gateway endpoint for image layer retrieval). CloudWatch Logs and SSM also require interface endpoints.",
    "difficulty": "Hard",
    "choiceExplanations": {
      "0": "A NAT instance provides internet egress by translating private IP addresses to public ones, which directly violates the security team's prohibition against any internet egress, even though it's self-managed rather than a NAT Gateway.",
      "2": "An Internet Gateway enables direct internet connectivity, which violates the no internet egress requirement; additionally, security groups cannot filter traffic by destination domain or service, only by IP addresses and ports, making this approach both non-compliant and ineffective.",
      "3": "This approach still routes traffic through a NAT Gateway to reach the internet, which violates the explicit prohibition against NAT Gateways and internet egress, regardless of whether the NAT Gateway exists in the same VPC or a peered VPC."
    }
  },
  {
    "id": "SAA-534",
    "domainId": "D1",
    "domain": "Design Secure Architectures",
    "section": "CloudTrail",
    "question": "A company must keep an immutable audit record of all management events for 7 years. Requirements: centralized logging for all accounts, encryption with customer managed keys, and protection against log deletion or overwrite even by administrators in member accounts.\nWhich solution BEST satisfies these requirements?",
    "choices": [
      "Enable CloudTrail in each account and store logs in local S3 buckets with bucket versioning",
      "Create an organization CloudTrail trail to a central S3 bucket, enable S3 Object Lock in compliance mode, and encrypt using SSE-KMS with restricted key policies",
      "Store CloudTrail logs in CloudWatch Logs with infinite retention and restrict deletion using IAM policies",
      "Use VPC Flow Logs instead of CloudTrail and archive to Glacier Deep Archive"
    ],
    "answer": 1,
    "explanation": "An organization trail centralizes CloudTrail across accounts. S3 Object Lock (compliance mode) and SSE-KMS provide immutability and encryption. Proper key and bucket policies prevent tampering by member accounts.",
    "difficulty": "Hard",
    "choiceExplanations": {
      "0": "This approach fails to provide centralized logging as required, and bucket versioning alone does not prevent deletion or overwrite - administrators in each member account could still delete versioned objects or the entire bucket. S3 Object Lock in compliance mode is needed for true immutability.",
      "2": "CloudWatch Logs does not support infinite retention (maximum is 10 years), IAM policies can be modified by administrators which doesn't provide protection against admin-level deletion, and CloudWatch Logs lacks the immutability guarantees that S3 Object Lock compliance mode provides.",
      "3": "VPC Flow Logs capture network traffic metadata at the VPC level, not management events (API calls). CloudTrail is specifically designed to record AWS API activity and management events, making VPC Flow Logs completely unsuitable for this audit requirement."
    }
  },
  {
    "id": "SAA-535",
    "domainId": "D1",
    "domain": "Design Secure Architectures",
    "section": "WAF / Shield",
    "question": "A public application is fronted by CloudFront with an ALB as origin. The company is experiencing both large volumetric attacks and application-layer attacks (SQLi, XSS, and high-rate bot traffic). Requirements: managed protection with minimal custom code, centralized visibility, and the ability to quickly block abusive IPs.\nWhich combination provides the BEST protection?",
    "choices": [
      "Enable AWS Shield Standard only and rely on ALB security groups",
      "Use AWS Shield Advanced and AWS WAF on CloudFront with managed rule groups and rate-based rules",
      "Move the application to private subnets and remove CloudFront",
      "Use NACL deny rules and manually update them on every incident"
    ],
    "answer": 1,
    "explanation": "Shield Advanced improves DDoS protections and response, while AWS WAF at CloudFront provides managed L7 protections (SQLi/XSS) plus rate limiting and centralized management/visibility.",
    "difficulty": "Hard",
    "choiceExplanations": {
      "0": "Shield Standard only provides basic L3/L4 DDoS protection without advanced mitigation capabilities, and security groups cannot protect against application-layer attacks like SQLi, XSS, or bot traffic since they only filter by IP/port, not by request content or patterns.",
      "2": "This eliminates the edge protection benefits of CloudFront (global DDoS mitigation, caching, geographic distribution) and still requires exposing the application somehow to serve public traffic, leaving it vulnerable to both volumetric and application-layer attacks without proper protection.",
      "3": "This approach requires significant manual effort and custom code to maintain, provides no protection against application-layer attacks (SQLi/XSS), lacks centralized visibility, and cannot respond quickly enough to dynamic attack patterns or high-rate bot traffic."
    }
  },
  {
    "id": "SAA-536",
    "domainId": "D1",
    "domain": "Design Secure Architectures",
    "section": "Secrets Manager / RDS Proxy",
    "question": "A serverless application uses Lambda to connect to an RDS MySQL database. During traffic spikes, the database hits connection limits and credentials must be rotated automatically without redeploying the Lambdas. The solution must minimize downtime during credential rotation.\nWhich solution BEST meets these requirements?",
    "choices": [
      "Store credentials in Lambda environment variables and rotate them manually on a schedule",
      "Store credentials in Secrets Manager with rotation enabled and use RDS Proxy to manage database connections",
      "Store credentials in Parameter Store Standard and rotate them weekly using an EC2 cron job",
      "Use IAM database authentication and disable Secrets Manager"
    ],
    "answer": 1,
    "explanation": "Secrets Manager provides managed rotation workflows, and RDS Proxy reduces connection storms and allows smoother credential rotation with fewer failed connections during spikes.",
    "difficulty": "Hard",
    "choiceExplanations": {
      "0": "Manual rotation requires redeploying Lambda functions to update environment variables, which contradicts the requirement to rotate credentials without redeploying Lambdas and does not minimize downtime during rotation.",
      "2": "Parameter Store Standard does not have native automatic rotation capabilities, requires managing an EC2 instance for the cron job (adding operational overhead), and does not address the connection limit issue during traffic spikes.",
      "3": "While IAM database authentication eliminates credential rotation concerns, it does not solve the connection limit problem during traffic spikes since Lambda functions would still create individual database connections without connection pooling provided by RDS Proxy."
    }
  },
  {
    "id": "SAA-537",
    "domainId": "D1",
    "domain": "Design Secure Architectures",
    "section": "ACM / TLS",
    "question": "A company runs internal microservices accessed only from private subnets. They require mutual TLS between services and want certificate issuance, renewal, and revocation managed centrally. The certificates must be private (not publicly trusted).\nWhich solution BEST satisfies these requirements with minimal operational overhead?",
    "choices": [
      "Use public ACM certificates on all internal services and manually distribute private keys",
      "Use ACM Private CA to issue private certificates and integrate services to automatically renew certificates",
      "Use self-signed certificates generated on each EC2 instance and rotate them manually",
      "Store certificates in S3 and rotate by copying new files to every host"
    ],
    "answer": 1,
    "explanation": "ACM Private CA enables private certificate issuance and lifecycle management (including renewal) without needing public trust, reducing manual certificate handling and operational burden.",
    "difficulty": "Hard",
    "choiceExplanations": {
      "0": "Public ACM certificates are publicly trusted (not private as required), and ACM does not allow exporting private keys for public certificates, making manual distribution impossible and violating the private certificate requirement.",
      "2": "Self-signed certificates on each instance create decentralized management without central issuance, renewal, or revocation capabilities, and manual rotation significantly increases operational overhead contrary to the minimal overhead requirement.",
      "3": "This approach requires manual certificate generation, distribution, and rotation processes across all hosts, providing no centralized lifecycle management and creating significant operational overhead compared to ACM Private CA's automated renewal capabilities."
    }
  },
  {
    "id": "SAA-538",
    "domainId": "D1",
    "domain": "Design Secure Architectures",
    "section": "PrivateLink",
    "question": "A platform team provides an internal API hosted behind an NLB in a shared services account. Over the next year, 40 application accounts must consume the API from their own VPCs without opening broad network connectivity. The consumers must not be able to reach any other resources in the provider VPC.\nWhich solution BEST meets these requirements?",
    "choices": [
      "Use VPC peering between every consumer VPC and the provider VPC",
      "Use AWS PrivateLink with an endpoint service on the provider NLB and interface endpoints in each consumer VPC",
      "Use a Transit Gateway shared with all accounts and a single route table for all traffic",
      "Expose the API through a public ALB and restrict access by source IP"
    ],
    "answer": 1,
    "explanation": "PrivateLink provides private, service-level connectivity across accounts without broad VPC-to-VPC routing. Consumers can access only the exposed endpoint service, not other provider VPC resources.",
    "difficulty": "Hard",
    "choiceExplanations": {
      "0": "VPC peering creates broad network connectivity between VPCs, allowing consumers to potentially reach any resource in the provider VPC (not just the API), which violates the requirement to restrict access to only the API endpoint. Additionally, managing 40 separate peering connections creates significant operational overhead.",
      "2": "Transit Gateway provides broad network-level connectivity between all attached VPCs, which would allow consumers to potentially access other resources in the provider VPC beyond just the API. This violates the requirement that consumers must not reach any other resources in the provider VPC.",
      "3": "This approach routes traffic over the public internet rather than keeping it private within AWS, which contradicts the requirement to avoid broad network connectivity. Source IP restrictions are also difficult to manage with 40 accounts and provide weaker security compared to private connectivity solutions."
    }
  },
  {
    "id": "SAA-539",
    "domainId": "D1",
    "domain": "Design Secure Architectures",
    "section": "Governance (Select TWO)",
    "question": "A company wants to prevent accidental public exposure of S3 data across all accounts while also ensuring security can detect and remediate misconfigurations that slip through. The solution must scale to hundreds of accounts with minimal manual work.\nWhich TWO actions BEST meet these requirements? (Choose TWO.)",
    "choices": [
      "Enable S3 Block Public Access at the account level for all accounts via organizations controls",
      "Rely on bucket ACLs because they are simpler than policies",
      "Deploy AWS Config rules for S3 public access settings and use auto-remediation to fix noncompliant buckets",
      "Allow public access by default and require teams to request exceptions through tickets",
      "Disable CloudTrail data events to reduce cost"
    ],
    "answer": [
      0,
      2
    ],
    "explanation": "Account-level S3 Block Public Access provides preventive guardrails, while AWS Config with auto-remediation provides detective controls and automated correction at scale.",
    "difficulty": "Hard",
    "choiceExplanations": {
      "1": "Bucket ACLs are legacy access control mechanisms that AWS recommends disabling in favor of bucket policies. ACLs do not prevent public exposure and are actually less secure and harder to manage at scale compared to S3 Block Public Access and bucket policies.",
      "3": "This approach directly contradicts the requirement to prevent accidental public exposure. Allowing public access by default creates security risks and relies on manual ticket processes that do not scale to hundreds of accounts with minimal manual work.",
      "4": "Disabling CloudTrail data events reduces visibility into S3 operations and compromises security monitoring capabilities. This action would hinder the ability to detect and investigate security incidents, directly opposing the requirement to detect and remediate misconfigurations."
    }
  },
  {
    "id": "SAA-540",
    "domainId": "D2",
    "domain": "Design Resilient Architectures",
    "section": "Multi-Region",
    "question": "A global application stores user profile data in DynamoDB and serves images from S3. Requirements: regional failover with minimal downtime, low RPO for profile updates, and global read performance. Operations wants a solution that keeps the architecture mostly serverless.\nWhich solution BEST meets these requirements?",
    "choices": [
      "Use DynamoDB Global Tables for profiles and S3 Cross-Region Replication for images, with Route 53 failover routing",
      "Use a single DynamoDB table in one region and back it up daily to S3 in another region",
      "Use S3 Transfer Acceleration for images and keep DynamoDB single-region",
      "Use CloudFront for images and keep profiles in an RDS database with manual snapshots"
    ],
    "answer": 0,
    "explanation": "Global Tables provide multi-region replication and low RPO for DynamoDB writes. S3 CRR keeps objects replicated. Route 53 failover can direct clients to the healthy region with minimal downtime.",
    "difficulty": "Hard",
    "choiceExplanations": {
      "1": "Daily backups result in a high RPO of up to 24 hours, failing the low RPO requirement for profile updates, and this approach does not provide regional failover capability or global read performance since data exists only in one region.",
      "2": "S3 Transfer Acceleration only speeds up uploads to S3, it does not provide regional failover or data replication, and keeping DynamoDB single-region fails to meet the regional failover, low RPO, and global read performance requirements.",
      "3": "This abandons the serverless architecture requirement by replacing DynamoDB with RDS, manual snapshots provide high RPO and significant downtime during failover, and CloudFront alone does not replicate source images to another region for true regional failover."
    }
  },
  {
    "id": "SAA-541",
    "domainId": "D2",
    "domain": "Design Resilient Architectures",
    "section": "RDS DR",
    "question": "A company runs an RDS PostgreSQL database in eu-west-1. DR requirements: fail over to eu-central-1 within 15 minutes and lose no more than 5 minutes of data. The company wants to avoid maintaining a full active/active database setup.\nWhich design BEST meets these requirements?",
    "choices": [
      "Take manual snapshots every hour and copy them to eu-central-1",
      "Create a cross-region read replica in eu-central-1 and promote it during failover, using automated runbooks and Route 53 failover",
      "Use Multi-AZ in eu-west-1 only",
      "Use AWS Backup daily backups with cross-region copy"
    ],
    "answer": 1,
    "explanation": "A cross-region read replica provides near-real-time replication that can meet a 5-minute RPO and can be promoted to become primary, achieving a faster RTO than snapshot-based restore while avoiding full active/active.",
    "difficulty": "Hard",
    "choiceExplanations": {
      "0": "Hourly snapshots would result in up to 60 minutes of data loss (RPO), which exceeds the 5-minute RPO requirement. Additionally, restoring from a snapshot takes significant time, potentially exceeding the 15-minute RTO requirement.",
      "2": "Multi-AZ provides high availability within a single region through synchronous replication to a standby in another Availability Zone, but it does not provide cross-region disaster recovery to eu-central-1 as required.",
      "3": "Daily backups would result in up to 24 hours of potential data loss, far exceeding the 5-minute RPO requirement. Restoring from backup would also likely exceed the 15-minute RTO requirement."
    }
  },
  {
    "id": "SAA-542",
    "domainId": "D2",
    "domain": "Design Resilient Architectures",
    "section": "EFS Backup",
    "question": "A company uses Amazon EFS for shared application content. Compliance requires centralized backup policies, retention for 5 years, and protection against backup deletion. They also want cross-region copy for disaster recovery.\nWhich solution BEST satisfies these requirements?",
    "choices": [
      "Use EFS replication only; replication replaces the need for backups",
      "Use AWS Backup to back up EFS with cross-region copy and enable Backup Vault Lock for retention enforcement",
      "Create a cron job on EC2 to rsync EFS to an S3 bucket",
      "Create EFS snapshots manually every week"
    ],
    "answer": 1,
    "explanation": "AWS Backup supports EFS backups with centralized policies, cross-region copy, and Vault Lock to enforce retention and prevent deletion, aligning with compliance needs.",
    "difficulty": "Hard",
    "choiceExplanations": {
      "0": "EFS replication provides near real-time synchronization to another region but does not replace backups because it replicates deletions and corruptions as well, offers no point-in-time recovery, no retention policies, and no protection against accidental or malicious deletion of data.",
      "2": "This approach lacks centralized backup management, does not provide built-in retention enforcement, has no protection against backup deletion (no Vault Lock equivalent), requires manual maintenance of EC2 instances and scripts, and does not meet compliance requirements for centralized policies.",
      "3": "Manual snapshots do not provide centralized backup policies, cannot enforce retention periods or deletion protection, lack automation for consistent compliance, and do not support cross-region copy for disaster recovery as required by the scenario."
    }
  },
  {
    "id": "SAA-543",
    "domainId": "D2",
    "domain": "Design Resilient Architectures",
    "section": "SQS FIFO",
    "question": "A payment processing pipeline must preserve strict ordering per customer and avoid duplicate processing of charge events. Throughput is high but can be partitioned by customer ID. The system must provide exactly-once processing semantics at the queue level.\nWhich solution BEST meets these requirements?",
    "choices": [
      "SQS Standard queue with a single consumer instance",
      "SQS FIFO queue using MessageGroupId = customer ID and content-based deduplication or a DeduplicationId",
      "SNS topic with multiple HTTP subscriptions",
      "Kinesis Data Firehose with S3 destination"
    ],
    "answer": 1,
    "explanation": "SQS FIFO provides ordering within a message group and supports exactly-once processing at the queue level with deduplication features, fitting payment events partitioned by customer.",
    "difficulty": "Hard",
    "choiceExplanations": {
      "0": "SQS Standard queues provide best-effort ordering (not strict ordering) and at-least-once delivery, meaning messages can be delivered more than once and out of order, which fails both the strict ordering and exactly-once processing requirements for payment processing.",
      "2": "SNS is a pub/sub messaging service that does not guarantee message ordering or provide exactly-once delivery semantics; it delivers messages at-least-once and cannot ensure strict per-customer ordering required for payment processing.",
      "3": "Kinesis Data Firehose is designed for streaming data delivery to destinations like S3, Redshift, or Elasticsearch, not for queue-based message processing with exactly-once semantics; it lacks the deduplication and ordering guarantees needed for payment event processing."
    }
  },
  {
    "id": "SAA-544",
    "domainId": "D2",
    "domain": "Design Resilient Architectures",
    "section": "Deployments",
    "question": "A production service runs on EC2 in an Auto Scaling group behind an ALB. During deployments, the company must avoid dropping in-flight requests and ensure instances are replaced gradually with automatic rollback if health checks fail.\nWhich approach BEST meets these requirements?",
    "choices": [
      "Terminate all instances at once and let Auto Scaling replace them quickly",
      "Use an Auto Scaling Instance Refresh with a minimum healthy percentage, ALB health checks, and a sufficient deregistration delay",
      "Use a single large EC2 instance to avoid deployment complexity",
      "Disable ALB health checks during deployments to prevent replacements"
    ],
    "answer": 1,
    "explanation": "Instance Refresh performs controlled, rolling replacements with health validation. ALB deregistration delay helps drain connections to avoid dropped requests, and failed health checks can stop/rollback the refresh.",
    "difficulty": "Hard",
    "choiceExplanations": {
      "0": "This approach causes complete service downtime during the replacement period, dropping all in-flight requests and providing no gradual replacement or rollback capability, directly violating the requirements for zero dropped requests and gradual instance replacement.",
      "2": "A single instance eliminates high availability and fault tolerance, creates a single point of failure, and still requires downtime during deployments since there are no other instances to handle traffic while the single instance is being replaced.",
      "3": "Disabling health checks removes the ability to detect unhealthy instances and trigger automatic rollback when deployments fail, which directly contradicts the requirement for automatic rollback if health checks fail and could route traffic to broken instances."
    }
  },
  {
    "id": "SAA-545",
    "domainId": "D2",
    "domain": "Design Resilient Architectures",
    "section": "Centralized Logging",
    "question": "A company must centralize VPC Flow Logs from 90 accounts to a dedicated security account. They want near-real-time delivery, durable storage, and the ability to query logs later. Teams must not be able to modify or delete the centralized logs.\nWhich solution BEST meets these requirements?",
    "choices": [
      "Send VPC Flow Logs to CloudWatch Logs in each account and rely on cross-account IAM to read them",
      "Publish VPC Flow Logs to a centralized Kinesis Data Firehose delivery stream in the security account and store in an S3 bucket with restrictive policies and optional Object Lock",
      "Export Flow Logs to local EBS volumes and copy them weekly to the security account",
      "Use AWS Config to collect Flow Logs automatically into a central bucket"
    ],
    "answer": 1,
    "explanation": "Kinesis Data Firehose can deliver near-real-time log data to S3 in a central account. Restrictive bucket policies (and Object Lock if needed) prevent member accounts from tampering with centralized logs.",
    "difficulty": "Hard",
    "choiceExplanations": {
      "0": "This approach does not centralize the logs; they remain distributed across 90 accounts, making management complex and leaving logs vulnerable to modification or deletion by local account administrators who retain control over their CloudWatch Logs.",
      "2": "Weekly copying does not meet the near-real-time delivery requirement, EBS volumes are not a supported direct destination for VPC Flow Logs, and this manual approach lacks durability and scalability for 90 accounts.",
      "3": "AWS Config is designed to track resource configuration changes and compliance, not to collect or aggregate VPC Flow Logs; it cannot be used as a mechanism to centralize flow log data."
    }
  },
  {
    "id": "SAA-546",
    "domainId": "D2",
    "domain": "Design Resilient Architectures",
    "section": "EventBridge",
    "question": "Security findings from multiple AWS accounts must be routed to a central account for automated response. The central team wants to keep rules in one place and avoid deploying identical rules into every account.\nWhich design BEST meets these requirements?",
    "choices": [
      "Create CloudWatch alarms in every account and email the security team",
      "Use EventBridge with a centralized event bus in the security account and add resource policies to allow member accounts to put events to it",
      "Use SQS queues in every account and have the security team poll them continuously",
      "Use VPC Flow Logs to detect security findings and forward them to SNS"
    ],
    "answer": 1,
    "explanation": "A centralized EventBridge event bus with appropriate permissions allows multi-account event ingestion and centralized rule management for automated response workflows.",
    "difficulty": "Hard",
    "choiceExplanations": {
      "0": "This approach requires deploying and managing identical alarms in every account, which contradicts the requirement to keep rules in one place and avoid deploying identical rules across accounts. Additionally, email notifications are manual and do not support automated response workflows.",
      "2": "This requires deploying infrastructure in every account and continuous polling is inefficient compared to event-driven architectures. It does not centralize rule management and creates operational overhead for the security team to manage multiple queues.",
      "3": "VPC Flow Logs capture network traffic metadata (IP addresses, ports, protocols) but cannot detect security findings like those from AWS Security Hub, GuardDuty, or IAM Access Analyzer. This solution addresses network monitoring, not security finding aggregation and automated response."
    }
  },
  {
    "id": "SAA-547",
    "domainId": "D2",
    "domain": "Design Resilient Architectures",
    "section": "Step Functions",
    "question": "An order workflow triggers multiple microservices: reserve inventory, charge payment, and schedule shipment. Failures require compensating actions (refund payment or release inventory). The company needs built-in retries, timeouts, and clear execution history for audits.\nWhich solution BEST meets these requirements?",
    "choices": [
      "Use a single Lambda function that calls all services sequentially",
      "Use AWS Step Functions to orchestrate the workflow with retries, catch/compensation steps, and execution history",
      "Use an S3 bucket as a state store and a cron job that checks status",
      "Use an EC2 instance running a custom workflow engine"
    ],
    "answer": 1,
    "explanation": "Step Functions provides native orchestration, retries, timeouts, error handling with compensations, and a full execution history suitable for audits and operational visibility.",
    "difficulty": "Hard",
    "choiceExplanations": {
      "0": "A single Lambda function lacks built-in retry mechanisms, timeout handling per step, automatic compensation workflows, and execution history for audits; it also risks timeout limits (15 minutes max) and provides no visibility into individual step failures or state management.",
      "2": "This approach requires custom implementation for retries, timeouts, and compensation logic, lacks real-time execution tracking, provides no built-in audit trail, and introduces latency due to polling intervals rather than event-driven orchestration.",
      "3": "Running a custom workflow engine on EC2 requires significant development effort, ongoing maintenance, and operational overhead to implement retries, timeouts, compensation handling, and audit logging that Step Functions provides natively as a managed service."
    }
  },
  {
    "id": "SAA-548",
    "domainId": "D2",
    "domain": "Design Resilient Architectures",
    "section": "EKS",
    "question": "A company runs a critical service on Amazon EKS. Requirements: survive an AZ failure, minimize downtime during node replacements, and ensure workloads are spread across AZs without manual pod placement. The company wants a managed approach.\nWhich design BEST meets these requirements?",
    "choices": [
      "Run a single node group in one AZ and scale vertically for reliability",
      "Use managed node groups spanning multiple AZs, configure multiple replicas, and define Pod Disruption Budgets to control voluntary disruptions",
      "Use self-managed nodes only and disable cluster autoscaler to prevent changes",
      "Run the service on Fargate only and pin all pods to the same subnet"
    ],
    "answer": 1,
    "explanation": "Multi-AZ managed node groups, replicated workloads, and Pod Disruption Budgets improve resiliency and control disruptions during maintenance/replacements in a managed, scalable way.",
    "difficulty": "Hard",
    "choiceExplanations": {
      "0": "This approach fails to survive an AZ failure since all nodes are in a single Availability Zone, and vertical scaling does not provide high availability or fault tolerance across AZs as required.",
      "2": "Self-managed nodes require manual management and patching, contradicting the managed approach requirement, and disabling the cluster autoscaler prevents automatic scaling needed to handle node replacements and workload demands.",
      "3": "Pinning all pods to the same subnet places them in a single AZ, which fails the requirement to survive an AZ failure and contradicts the need to spread workloads across AZs without manual placement."
    }
  },
  {
    "id": "SAA-549",
    "domainId": "D2",
    "domain": "Design Resilient Architectures",
    "section": "S3 Replication",
    "question": "A company must replicate critical documents to a second region. The destination copy must be tamper-resistant (including protection from deletions) and retained for at least 1 year even if the source is deleted or encrypted key access is revoked.\nWhich solution BEST meets these requirements?",
    "choices": [
      "Enable S3 Cross-Region Replication to a destination bucket with S3 Object Lock enabled in compliance mode and a retention period of 1 year",
      "Enable S3 Transfer Acceleration and upload the objects twice",
      "Use S3 Lifecycle to move objects to Glacier in the same bucket after 30 days",
      "Use CloudFront caching to keep copies at edge locations"
    ],
    "answer": 0,
    "explanation": "CRR replicates objects to another region. S3 Object Lock in compliance mode enforces retention and prevents deletion/overwrite in the destination during the retention period.",
    "difficulty": "Hard",
    "choiceExplanations": {
      "1": "Transfer Acceleration only speeds up uploads over long distances but does not provide cross-region replication, tamper protection, or retention enforcement. Manually uploading twice is error-prone and offers no protection against deletion or modification.",
      "2": "This keeps objects in the same region (no cross-region protection), does not provide tamper resistance or deletion protection, and Glacier storage class alone does not enforce retention periods or prevent object deletion.",
      "3": "CloudFront is a CDN that temporarily caches content for performance, not for durable storage. Cached copies are transient, not tamper-resistant, cannot be retained for a specific period, and will be invalidated when the source is deleted or becomes inaccessible."
    }
  },
  {
    "id": "SAA-550",
    "domainId": "D2",
    "domain": "Design Resilient Architectures",
    "section": "CloudFront",
    "question": "A company serves static content through CloudFront. They store the same content in two S3 buckets in different regions. Requirements: CloudFront must automatically fail over to the secondary bucket if the primary bucket becomes unavailable, and the solution must not require DNS changes during an outage.\nWhich configuration BEST meets these requirements?",
    "choices": [
      "Use Route 53 weighted routing between the two S3 buckets",
      "Use a CloudFront origin group with primary and secondary origins and configure origin failover criteria",
      "Use S3 Transfer Acceleration and rely on faster routing",
      "Create an ALB in front of S3 and configure health checks"
    ],
    "answer": 1,
    "explanation": "CloudFront origin groups support origin failover from primary to secondary based on configured failover criteria, without DNS changes during incidents.",
    "difficulty": "Hard",
    "choiceExplanations": {
      "0": "Route 53 weighted routing distributes traffic based on assigned weights but does not provide automatic failover based on origin health, and this approach would require DNS changes or propagation time during an outage, violating the requirement.",
      "2": "S3 Transfer Acceleration optimizes upload speeds to S3 by routing through CloudFront edge locations, but it does not provide failover capabilities between buckets or address availability concerns for content delivery.",
      "3": "Application Load Balancers cannot directly target S3 buckets as backend targets since ALB targets must be EC2 instances, IP addresses, Lambda functions, or other ALBs, making this configuration technically impossible."
    }
  },
  {
    "id": "SAA-551",
    "domainId": "D2",
    "domain": "Design Resilient Architectures",
    "section": "Auto Scaling (Select TWO)",
    "question": "A workload has predictable daily traffic spikes at known times and also random flash spikes. Requirements: pre-provision capacity for known spikes, react quickly to random spikes, and reduce unnecessary spend when traffic drops.\nWhich TWO Auto Scaling features should be used together? (Choose TWO.)",
    "choices": [
      "Scheduled scaling actions for predictable spikes",
      "Target tracking scaling based on ALB request count per target",
      "Disable scale-in to avoid churn",
      "Use a fixed desired capacity and manually adjust weekly",
      "Use only CPU-based step scaling with 10-minute evaluation periods"
    ],
    "answer": [
      0,
      1
    ],
    "explanation": "Scheduled scaling prepares capacity for known events, while target tracking reacts quickly to unexpected demand and scales back when traffic drops, optimizing both performance and cost.",
    "difficulty": "Hard",
    "choiceExplanations": {
      "2": "Disabling scale-in prevents Auto Scaling from removing instances when traffic drops, which directly contradicts the requirement to reduce unnecessary spend during low-traffic periods and would result in paying for unused capacity.",
      "3": "Using a fixed capacity with weekly manual adjustments cannot handle daily predictable spikes or react quickly to random flash spikes, failing to meet the requirements for automated scaling and cost optimization.",
      "4": "A 10-minute evaluation period is too slow to react quickly to random flash spikes, and CPU-based metrics alone may not accurately reflect web traffic patterns; ALB request count per target provides more direct traffic measurement for web workloads."
    }
  },
  {
    "id": "SAA-552",
    "domainId": "D3",
    "domain": "Design High-Performing Architectures",
    "section": "DynamoDB / DAX",
    "question": "A gaming API uses DynamoDB for player sessions and receives extremely read-heavy traffic with strict low-latency requirements. The application can tolerate eventually consistent reads for session lookups, and the team wants a managed caching layer that integrates directly with DynamoDB without rewriting the data model.\nWhich solution BEST improves read performance?",
    "choices": [
      "Add DynamoDB Streams to speed up reads",
      "Use DynamoDB Accelerator (DAX) in front of the table for cached reads",
      "Move the session store to S3 and cache with CloudFront",
      "Use RDS read replicas and migrate the session table to MySQL"
    ],
    "answer": 1,
    "explanation": "DAX is a managed, DynamoDB-compatible cache that improves read performance significantly with minimal application changes, especially for read-heavy, eventually consistent access patterns.",
    "difficulty": "Hard",
    "choiceExplanations": {
      "0": "DynamoDB Streams captures data modification events (inserts, updates, deletes) for triggering downstream processing like Lambda functions, but does not improve read performance or provide caching capabilities.",
      "2": "S3 is designed for object storage, not low-latency key-value lookups required for session management, and CloudFront is optimized for static content delivery rather than dynamic session data with frequent updates.",
      "3": "This requires a complete migration away from DynamoDB and rewriting the data model, which contradicts the requirement for a solution that integrates directly with DynamoDB without rewriting the data model."
    }
  },
  {
    "id": "SAA-553",
    "domainId": "D3",
    "domain": "Design High-Performing Architectures",
    "section": "Kinesis",
    "question": "A real-time analytics platform uses Kinesis Data Streams and has 15 independent consumer applications that all need sub-second access to the same data. The current shared throughput per shard is causing consumer lag.\nWhich option BEST reduces consumer contention while keeping low latency?",
    "choices": [
      "Reduce the number of shards to concentrate throughput",
      "Enable enhanced fan-out for the consumer applications",
      "Switch to SQS Standard queues and have each consumer poll",
      "Write the stream directly to S3 and query with Athena"
    ],
    "answer": 1,
    "explanation": "Enhanced fan-out provides dedicated read throughput per consumer and improves parallel consumption performance while maintaining low latency.",
    "difficulty": "Hard",
    "choiceExplanations": {
      "0": "This would worsen the problem, not solve it. Reducing shards decreases total throughput capacity, and with 15 consumers sharing the standard 2 MB/sec read throughput per shard, consumer lag would increase significantly.",
      "2": "SQS is designed for message queuing where each message is processed by one consumer, not for streaming scenarios where multiple consumers need access to the same data. This would require complex fan-out patterns and does not provide the real-time streaming capabilities needed.",
      "3": "This approach introduces significant latency as data must first be written to S3 and then queried, making it unsuitable for sub-second real-time analytics requirements. Athena is designed for batch analytics, not real-time streaming use cases."
    }
  },
  {
    "id": "SAA-554",
    "domainId": "D3",
    "domain": "Design High-Performing Architectures",
    "section": "S3 Transfer",
    "question": "A mobile app uploads large videos from users around the world into a single S3 bucket in us-east-1. Upload performance is inconsistent for users far from the region. The company wants the simplest managed solution to accelerate uploads without deploying additional servers.\nWhich solution BEST meets these requirements?",
    "choices": [
      "Enable S3 Transfer Acceleration for the bucket",
      "Enable CloudFront with the bucket as origin and use signed cookies",
      "Create multiple buckets in different regions and build custom routing logic",
      "Use Amazon EFS mounted in multiple regions"
    ],
    "answer": 0,
    "explanation": "S3 Transfer Acceleration uses AWS edge locations to speed up long-distance uploads to a single bucket without extra infrastructure.",
    "difficulty": "Hard",
    "choiceExplanations": {
      "1": "CloudFront is primarily designed to accelerate content delivery (downloads) to users, not uploads to S3. While CloudFront can accept POST/PUT requests, it does not optimize upload performance the way S3 Transfer Acceleration does, and signed cookies add unnecessary complexity for this use case.",
      "2": "This approach requires deploying and maintaining custom routing logic, which violates the requirement for the simplest managed solution without deploying additional servers. It also adds operational complexity for data management across multiple buckets.",
      "3": "Amazon EFS is a file storage service designed for EC2 instances and cannot be directly accessed by mobile applications for uploads. It would require additional servers to mount the file system, violating the requirement for no additional server deployment."
    }
  },
  {
    "id": "SAA-555",
    "domainId": "D3",
    "domain": "Design High-Performing Architectures",
    "section": "FSx",
    "question": "A company migrates Windows file shares used by hundreds of users. They require SMB support, Windows ACLs, Multi-AZ high availability, and integrated backups/snapshots. They also want to minimize operational effort and keep a familiar file-server experience.\nWhich solution BEST meets these requirements?",
    "choices": [
      "Amazon EFS with Max I/O mode",
      "Amazon FSx for Windows File Server with Multi-AZ deployment",
      "Amazon S3 with static website hosting",
      "Amazon FSx for Lustre with scratch deployment"
    ],
    "answer": 1,
    "explanation": "FSx for Windows File Server is purpose-built for SMB shares with Windows permissions and supports Multi-AZ and native integration for backups and availability.",
    "difficulty": "Hard",
    "choiceExplanations": {
      "0": "EFS is a Linux-based file system that uses the NFS protocol, not SMB, and does not support Windows ACLs or provide a native Windows file server experience required for migrating Windows file shares.",
      "2": "S3 is object storage designed for web content delivery, not a file system, and does not support SMB protocol, Windows ACLs, or provide the familiar Windows file-server experience needed for user file shares.",
      "3": "FSx for Lustre is designed for high-performance computing workloads using Linux clients, does not support SMB protocol or Windows ACLs, and scratch deployments are temporary storage without data persistence or high availability."
    }
  },
  {
    "id": "SAA-556",
    "domainId": "D3",
    "domain": "Design High-Performing Architectures",
    "section": "Load Balancing",
    "question": "A microservice uses gRPC over HTTP/2 and requires Layer 7 routing based on host/path while maintaining end-to-end TLS. The team wants managed routing features rather than building them in the service.\nWhich load balancer BEST meets these requirements?",
    "choices": [
      "Application Load Balancer",
      "Network Load Balancer",
      "Gateway Load Balancer",
      "Classic Load Balancer"
    ],
    "answer": 0,
    "explanation": "ALB supports Layer 7 routing and gRPC over HTTP/2, enabling host/path routing and managed request handling capabilities.",
    "difficulty": "Hard",
    "choiceExplanations": {
      "1": "NLB operates at Layer 4 (TCP/UDP) and cannot perform Layer 7 routing based on host/path headers, as it does not inspect HTTP/2 or gRPC protocol content for routing decisions.",
      "2": "Gateway Load Balancer operates at Layer 3 (network layer) and is designed for deploying third-party virtual appliances like firewalls and intrusion detection systems, not for application-level routing of gRPC traffic.",
      "3": "Classic Load Balancer is a legacy option that does not support HTTP/2 or gRPC protocols, and lacks the advanced Layer 7 routing features like host-based and path-based routing required for this use case."
    }
  },
  {
    "id": "SAA-557",
    "domainId": "D3",
    "domain": "Design High-Performing Architectures",
    "section": "EBS",
    "question": "A big data workload performs large sequential reads and writes and is sensitive to throughput rather than random IOPS. The data does not require the low-latency characteristics of SSD. The team wants the most suitable EBS volume type for sustained throughput.\nWhich volume type is BEST?",
    "choices": [
      "io2",
      "gp3",
      "st1",
      "sc1"
    ],
    "answer": 2,
    "explanation": "st1 (Throughput Optimized HDD) is designed for frequently accessed, throughput-intensive workloads with large sequential I/O patterns.",
    "difficulty": "Hard",
    "choiceExplanations": {
      "0": "This is a Provisioned IOPS SSD volume designed for workloads requiring sustained IOPS performance and low latency, making it unnecessarily expensive for throughput-intensive sequential workloads that don't need SSD characteristics.",
      "1": "This is a General Purpose SSD volume optimized for a balance of price and performance with low-latency access, but it's more expensive than HDD options and designed for workloads needing SSD performance rather than pure sequential throughput.",
      "3": "This is Cold HDD designed for infrequently accessed data with the lowest cost, offering lower throughput (250 MB/s max) compared to st1 (500 MB/s max), making it unsuitable for frequently accessed, throughput-intensive workloads."
    }
  },
  {
    "id": "SAA-558",
    "domainId": "D3",
    "domain": "Design High-Performing Architectures",
    "section": "RDS",
    "question": "A serverless API experiences sudden bursts of traffic and opens thousands of database connections to an RDS PostgreSQL instance. The database frequently reaches max connections, causing errors. The team wants a managed solution that reduces connection overhead without rewriting the application significantly.\nWhich solution BEST addresses this issue?",
    "choices": [
      "Increase the RDS instance storage size",
      "Use RDS Proxy to pool and manage connections",
      "Enable Multi-AZ to increase max connections automatically",
      "Move the database to an EC2 instance store volume"
    ],
    "answer": 1,
    "explanation": "RDS Proxy pools and multiplexes connections to reduce connection storms and improves database availability during traffic spikes with minimal application changes.",
    "difficulty": "Hard",
    "choiceExplanations": {
      "0": "Storage size affects data capacity, not database connection limits. Maximum connections are determined by the instance class (memory) and database parameters, not storage allocation.",
      "2": "Multi-AZ provides high availability through a standby replica for failover purposes, but it does not increase the maximum number of connections since the standby cannot serve read traffic or accept connections during normal operation.",
      "3": "This would remove the managed RDS benefits, require significant operational overhead, and instance store volumes are ephemeral storage that loses data when the instance stops, making it completely unsuitable for database workloads."
    }
  },
  {
    "id": "SAA-559",
    "domainId": "D3",
    "domain": "Design High-Performing Architectures",
    "section": "CloudFront Security",
    "question": "A media company sells premium downloadable content. Files are stored privately in S3 and delivered through CloudFront. Requirements: prevent direct S3 access, ensure only paying users can download, and allow access to expire after a short period. The company also wants to reduce origin load.\nWhich solution BEST meets these requirements?",
    "choices": [
      "Make the S3 bucket public and rely on obscurity of object keys",
      "Use CloudFront signed URLs or signed cookies with an Origin Access Control (OAC) to a private S3 bucket",
      "Use S3 static website hosting with basic auth",
      "Use Route 53 geolocation routing to restrict access"
    ],
    "answer": 1,
    "explanation": "CloudFront signed URLs/cookies enforce time-bound access for authorized users, while OAC keeps S3 private and prevents direct access. CloudFront caching reduces origin load.",
    "difficulty": "Hard",
    "choiceExplanations": {
      "0": "Security through obscurity is not a valid security practice; public buckets allow anyone who discovers or guesses the URL to access content without authentication, violating the requirement to prevent direct S3 access and ensure only paying users can download.",
      "2": "S3 static website hosting does not natively support basic authentication, and enabling website hosting would make content publicly accessible, failing to meet the requirements for private access and time-limited downloads for paying users only.",
      "3": "Geolocation routing only directs traffic based on user location and does not provide authentication, authorization, or time-based access expiration; it cannot verify paying users or prevent unauthorized downloads."
    }
  },
  {
    "id": "SAA-560",
    "domainId": "D3",
    "domain": "Design High-Performing Architectures",
    "section": "DynamoDB",
    "question": "A fintech service needs to update multiple items in DynamoDB as part of a single operation (debit one account, credit another, and write an audit record). Partial updates are not allowed, and the system must guarantee all-or-nothing behavior.\nWhich DynamoDB feature BEST meets this requirement?",
    "choices": [
      "DynamoDB Streams",
      "DynamoDB Transactions",
      "Global Secondary Indexes",
      "Time to Live (TTL)"
    ],
    "answer": 1,
    "explanation": "DynamoDB transactions provide atomic, all-or-nothing updates across multiple items and tables, preventing partial writes in financial transfer scenarios.",
    "difficulty": "Hard",
    "choiceExplanations": {
      "0": "This feature captures item-level changes in a table as a time-ordered sequence for event-driven processing and replication, but it does not provide atomic multi-item write operations or all-or-nothing guarantees required for financial transactions.",
      "2": "GSIs provide alternative query patterns by allowing queries on non-primary key attributes, but they are a read optimization feature and do not offer any transactional capabilities or atomic write guarantees across multiple items.",
      "3": "TTL automatically deletes expired items based on a timestamp attribute to manage storage costs, but it has no relationship to transactional processing or ensuring atomic updates across multiple items."
    }
  },
  {
    "id": "SAA-561",
    "domainId": "D3",
    "domain": "Design High-Performing Architectures",
    "section": "ECS",
    "question": "A stateless service on ECS must scale rapidly and minimize cost using Spot where possible, but it also needs a guaranteed baseline capacity to avoid outages when Spot capacity is reclaimed. The team wants ECS to manage placement and scaling automatically.\nWhich solution BEST meets these requirements?",
    "choices": [
      "Run everything on On-Demand only",
      "Use ECS capacity providers with a base capacity on On-Demand and additional capacity on Spot",
      "Use a single EC2 instance with Docker Compose",
      "Use Lambda for all workloads including long-running services"
    ],
    "answer": 1,
    "explanation": "ECS capacity providers can define baseline On-Demand capacity with additional Spot capacity for cost savings while maintaining availability during Spot interruptions.",
    "difficulty": "Hard",
    "choiceExplanations": {
      "0": "While this provides guaranteed baseline capacity and avoids Spot interruptions, it fails to minimize cost as required since On-Demand pricing is significantly higher than Spot pricing for the additional scaling capacity.",
      "2": "This approach does not provide automatic scaling, high availability, or the ability to leverage Spot instances, and a single instance creates a single point of failure that cannot meet the requirement to scale rapidly or avoid outages.",
      "3": "Lambda has a maximum execution timeout of 15 minutes, making it unsuitable for long-running services, and it does not provide the same container orchestration capabilities or Spot/On-Demand capacity management that ECS capacity providers offer."
    }
  },
  {
    "id": "SAA-562",
    "domainId": "D3",
    "domain": "Design High-Performing Architectures",
    "section": "Global Networking",
    "question": "A real-time multiplayer game uses UDP and requires consistently low latency for players worldwide. The game servers run in multiple regions and the company wants fast regional failover without relying on DNS TTL.\nWhich AWS service BEST meets these requirements?",
    "choices": [
      "Amazon CloudFront",
      "AWS Global Accelerator",
      "Amazon Route 53 weighted routing only",
      "AWS Direct Connect"
    ],
    "answer": 1,
    "explanation": "Global Accelerator provides static anycast IPs, routes users to the nearest healthy regional endpoint over the AWS global network, supports TCP/UDP, and enables fast health-based failover without DNS delays.",
    "difficulty": "Hard",
    "choiceExplanations": {
      "0": "CloudFront is a content delivery network designed for HTTP/HTTPS traffic and does not support UDP protocol, which is required for real-time multiplayer gaming traffic.",
      "2": "Route 53 relies on DNS-based routing which is subject to DNS TTL caching delays, making it unsuitable when the requirement explicitly states fast failover without relying on DNS TTL.",
      "3": "Direct Connect provides dedicated private network connections between on-premises data centers and AWS, but does not address global player connectivity or provide the anycast-based routing needed for worldwide low-latency access to game servers."
    }
  },
  {
    "id": "SAA-563",
    "domainId": "D3",
    "domain": "Design High-Performing Architectures",
    "section": "Multi-Region Performance (Select TWO)",
    "question": "A global API is deployed active/active in two regions. Requirements: users should automatically reach the nearest healthy region, failover must be fast (no long DNS caching delays), and the solution must work well for both HTTP and non-HTTP protocols.\nWhich TWO solutions BEST meet these requirements? (Choose TWO.)",
    "choices": [
      "AWS Global Accelerator with health checks and endpoint weights",
      "Route 53 latency-based routing with health checks",
      "CloudFront only, without any origin health-based routing",
      "Manual DNS updates during incidents",
      "Using a single regional endpoint and scaling vertically"
    ],
    "answer": [
      0,
      1
    ],
    "explanation": "Global Accelerator provides fast, anycast-based routing and failover for multiple protocols. Route 53 latency routing with health checks is also appropriate for directing users to the nearest healthy region for DNS-based clients.",
    "difficulty": "Hard",
    "choiceExplanations": {
      "2": "Without origin failover configuration, CloudFront cannot automatically route traffic to a healthy region when one origin fails, failing to meet the fast failover requirement. Additionally, CloudFront is designed specifically for HTTP/HTTPS content delivery and does not support non-HTTP protocols like TCP or UDP.",
      "3": "Manual DNS updates are slow and error-prone, introducing significant delays during incidents rather than providing fast automated failover. DNS propagation delays and TTL caching would further extend recovery time, directly contradicting the requirement for fast failover without long DNS caching delays.",
      "4": "A single regional endpoint completely fails to meet the active/active multi-region requirement and provides no geographic proximity routing or failover capability. This approach creates a single point of failure and does not address the need for users to reach the nearest healthy region."
    }
  },
  {
    "id": "SAA-564",
    "domainId": "D4",
    "domain": "Design Cost-Optimized Architectures",
    "section": "S3 Lifecycle",
    "question": "A company stores compliance archives in S3. Data is frequently accessed for the first 45 days, occasionally accessed for the next 6 months, and then rarely accessed but must be retrievable within 24 hours for 7 years. The company wants maximum cost savings while meeting access SLAs.\nWhich storage strategy BEST fits these requirements?",
    "choices": [
      "Keep everything in S3 Standard for 7 years",
      "Use lifecycle transitions: S3 Standard (45 days) -> S3 Standard-IA (6 months) -> S3 Glacier Flexible Retrieval for long-term retention",
      "Move everything directly to S3 Glacier Deep Archive after 45 days",
      "Use S3 One Zone-IA for all objects to reduce cost"
    ],
    "answer": 1,
    "explanation": "The lifecycle strategy aligns storage tiers with access frequency while meeting the 24-hour retrieval requirement using Glacier Flexible Retrieval for long-term archival.",
    "difficulty": "Hard",
    "choiceExplanations": {
      "0": "While this meets all access requirements, S3 Standard is the most expensive storage class and provides no cost optimization for data that becomes infrequently or rarely accessed over time, failing the maximum cost savings requirement.",
      "2": "S3 Glacier Deep Archive has a standard retrieval time of 12 hours and maximum of 48 hours, but the data is still occasionally accessed for 6 months after the initial 45 days, making this tier inappropriate for that access pattern and potentially failing the 24-hour SLA during bulk retrievals.",
      "3": "S3 One Zone-IA stores data in only one Availability Zone, providing lower durability and availability compared to other classes, which is unsuitable for compliance archives that require high durability over 7 years; it also doesn't optimize costs for the varying access patterns described."
    }
  },
  {
    "id": "SAA-565",
    "domainId": "D4",
    "domain": "Design Cost-Optimized Architectures",
    "section": "Savings Plans",
    "question": "A company runs a large fleet of EC2 instances across multiple instance families and plans to continue for at least 3 years. They frequently change instance types as they optimize performance, but overall compute spend is stable. They want the best discount without being locked to a single instance family.\nWhich option provides the BEST fit?",
    "choices": [
      "Standard Reserved Instances for a single instance type",
      "Compute Savings Plans for a 3-year term",
      "Spot Instances only for all workloads",
      "Dedicated Hosts with 3-year commitments"
    ],
    "answer": 1,
    "explanation": "Compute Savings Plans provide flexible discounts across instance families and sizes, matching stable spend while allowing frequent instance type changes.",
    "difficulty": "Hard",
    "choiceExplanations": {
      "0": "Standard RIs are locked to a specific instance family, size, and Availability Zone (or Region with zonal flexibility), which contradicts the requirement to frequently change instance types across multiple instance families without being locked to a single one.",
      "2": "Spot Instances can be interrupted with 2-minute notice when AWS needs capacity back, making them unsuitable as the sole compute option for all workloads, especially those requiring consistent availability over a 3-year period.",
      "3": "Dedicated Hosts are designed for licensing compliance and regulatory requirements, not cost optimization; they are significantly more expensive than shared tenancy options and provide no additional discount benefit for this use case of flexible compute across instance families."
    }
  },
  {
    "id": "SAA-566",
    "domainId": "D4",
    "domain": "Design Cost-Optimized Architectures",
    "section": "NAT Cost Optimization",
    "question": "A workload in private subnets generates high monthly NAT Gateway charges. Most traffic is to S3 and DynamoDB, and the security team prefers traffic stay on the AWS network. The company wants to reduce cost without changing the application.\nWhich change provides the MOST cost-effective improvement?",
    "choices": [
      "Replace NAT Gateway with a NAT instance",
      "Create gateway VPC endpoints for S3 and DynamoDB and update route tables",
      "Add more NAT Gateways (one per AZ) to distribute traffic",
      "Move the instances to public subnets"
    ],
    "answer": 1,
    "explanation": "Gateway endpoints keep S3 and DynamoDB traffic off NAT, reducing data processing charges and keeping traffic private on the AWS network.",
    "difficulty": "Hard",
    "choiceExplanations": {
      "0": "While NAT instances may have lower hourly costs, they require management overhead, lack the scalability and availability of NAT Gateway, and still incur data processing charges for S3/DynamoDB traffic, making this less cost-effective than free gateway endpoints.",
      "2": "Adding more NAT Gateways increases costs by adding additional hourly charges and does not reduce data processing fees, as traffic to S3 and DynamoDB would still flow through NAT Gateways incurring per-GB charges.",
      "3": "Moving instances to public subnets would expose them directly to the internet, violating the security requirement to keep traffic on the AWS network, and requires application architecture changes which the company wants to avoid."
    }
  },
  {
    "id": "SAA-567",
    "domainId": "D4",
    "domain": "Design Cost-Optimized Architectures",
    "section": "Analytics",
    "question": "A team stores 200 TB of logs in S3 and needs to run occasional ad hoc SQL queries without managing servers or clusters. Most queries scan only a few columns and the team wants to minimize cost.\nWhich service is MOST appropriate?",
    "choices": [
      "Amazon Redshift provisioned cluster",
      "Amazon Athena querying data in S3",
      "Amazon RDS MySQL with the logs imported into tables",
      "Amazon OpenSearch with all logs indexed immediately"
    ],
    "answer": 1,
    "explanation": "Athena is serverless and cost-effective for ad hoc SQL over data in S3, especially when using columnar formats and partitioning to reduce scanned data.",
    "difficulty": "Hard",
    "choiceExplanations": {
      "0": "Requires managing and paying for always-on cluster infrastructure regardless of query frequency, making it cost-inefficient for occasional ad hoc queries compared to Athena's pay-per-query model.",
      "2": "Requires provisioning and managing database servers, importing 200 TB of data would be impractical and expensive, and RDS is not designed for large-scale log analytics workloads.",
      "3": "Requires provisioning and managing cluster infrastructure, indexing 200 TB of logs would be extremely expensive in storage and compute costs, and is optimized for full-text search rather than SQL analytics on columnar data."
    }
  },
  {
    "id": "SAA-568",
    "domainId": "D4",
    "domain": "Design Cost-Optimized Architectures",
    "section": "CloudFront Pricing",
    "question": "A company distributes content mostly to Europe and North America. They want CloudFront but want to reduce costs by limiting edge locations used while still serving these regions well.\nWhich configuration BEST meets this requirement?",
    "choices": [
      "Enable S3 Transfer Acceleration",
      "Set CloudFront to use a restricted Price Class that includes only the needed regions",
      "Disable caching and forward all requests to the origin",
      "Use Route 53 geolocation routing instead of CloudFront"
    ],
    "answer": 1,
    "explanation": "CloudFront Price Classes restrict edge locations to a subset of regions, reducing cost while still providing good performance in targeted geographies.",
    "difficulty": "Hard",
    "choiceExplanations": {
      "0": "This feature speeds up uploads to S3 buckets using CloudFront edge locations, but it does not control which edge locations CloudFront uses for content distribution or reduce CloudFront costs for serving content to end users.",
      "2": "This would significantly increase costs by forcing every request to go to the origin, eliminating the cost savings and performance benefits that CloudFront caching provides, and does not limit edge locations.",
      "3": "Route 53 geolocation routing only directs users to different endpoints based on location but does not provide CDN capabilities like edge caching, content delivery optimization, or the cost reduction features that CloudFront Price Classes offer."
    }
  },
  {
    "id": "SAA-569",
    "domainId": "D4",
    "domain": "Design Cost-Optimized Architectures",
    "section": "EBS Optimization",
    "question": "A company uses gp2 volumes and sees unpredictable performance and growing costs. Metrics show they need consistent baseline performance with occasional bursts. They also want the ability to tune IOPS and throughput independently.\nWhich change is MOST cost-effective?",
    "choices": [
      "Migrate all volumes to io2",
      "Migrate to gp3 and right-size IOPS and throughput to match observed metrics",
      "Switch volumes to sc1 for lower cost",
      "Move the data to instance store only"
    ],
    "answer": 1,
    "explanation": "gp3 provides predictable performance and separates volume size from IOPS/throughput settings, enabling cost-effective right-sizing compared to gp2 and avoiding io2 overkill.",
    "difficulty": "Hard",
    "choiceExplanations": {
      "0": "While io2 provides consistent high performance and independent IOPS tuning, it is significantly more expensive than gp3 and is designed for mission-critical workloads requiring the highest durability and performance, making it overkill for workloads that only need consistent baseline performance with occasional bursts.",
      "2": "Switch volumes to sc1: sc1 (Cold HDD) is designed for infrequently accessed, throughput-oriented workloads with the lowest cost, but it provides very low IOPS (maximum 250) and cannot deliver the consistent baseline performance with burst capability that the company requires.",
      "3": "Instance store provides temporary block-level storage that is physically attached to the host and data is lost when the instance stops or terminates, making it unsuitable for persistent data storage and not providing the independent IOPS/throughput tuning capability requested."
    }
  },
  {
    "id": "SAA-570",
    "domainId": "D4",
    "domain": "Design Cost-Optimized Architectures",
    "section": "Spot / Mixed Instances",
    "question": "A stateless web tier runs behind an ALB with Auto Scaling. The company wants to reduce cost using Spot but must keep a guaranteed minimum capacity and automatically replace interrupted instances without downtime.\nWhich solution BEST meets these requirements?",
    "choices": [
      "Use Spot Instances only with no On-Demand",
      "Use an Auto Scaling group with a mixed instances policy: On-Demand base capacity and Spot for the remainder, with capacity rebalance enabled",
      "Use Dedicated Hosts for all instances",
      "Use Reserved Instances for peak capacity and On-Demand for baseline"
    ],
    "answer": 1,
    "explanation": "Mixed instances with an On-Demand base ensures availability, while Spot reduces costs for additional capacity. Capacity rebalance helps proactively replace Spot instances when interruption risk rises.",
    "difficulty": "Hard",
    "choiceExplanations": {
      "0": "Using only Spot Instances cannot guarantee minimum capacity because Spot Instances can be interrupted with a 2-minute warning when AWS needs the capacity back, which violates the requirement for guaranteed minimum capacity without downtime.",
      "2": "Dedicated Hosts are the most expensive EC2 pricing option, designed for licensing compliance or regulatory requirements, not cost optimization. This would significantly increase costs rather than reduce them.",
      "3": "This approach is backwards for cost optimization; Reserved Instances should cover predictable baseline capacity (not peak), and this solution doesn't use Spot Instances at all, missing the primary cost-reduction requirement and not addressing automatic replacement of interrupted instances."
    }
  },
  {
    "id": "SAA-571",
    "domainId": "D4",
    "domain": "Design Cost-Optimized Architectures",
    "section": "Databases",
    "question": "A development environment database is used intermittently, with heavy usage during daytime and almost no usage at night. The team wants to reduce costs while keeping the same relational engine and minimizing operational effort.\nWhich option BEST meets these requirements?",
    "choices": [
      "Enable Multi-AZ to reduce cost during off hours",
      "Automate start/stop schedules for the database where supported, or use an auto-scaling serverless relational option for variable usage",
      "Move the database to a larger instance to finish daytime work faster",
      "Store the database files in S3 and mount them from EC2"
    ],
    "answer": 1,
    "explanation": "Stopping nonproduction databases during idle hours or using a serverless relational option for variable demand reduces compute spend with minimal operational complexity.",
    "difficulty": "Hard",
    "choiceExplanations": {
      "0": "Multi-AZ deployments actually increase costs by running a synchronous standby replica in another Availability Zone for high availability, not reduce them. Multi-AZ is designed for production workloads requiring fault tolerance, not cost optimization for development environments.",
      "2": "Using a larger instance increases costs due to higher hourly rates, and does not address the core issue of paying for unused capacity during nighttime idle periods. This approach optimizes for performance rather than cost.",
      "3": "S3 is object storage and cannot be directly mounted as a file system for relational database operations. This approach would require significant operational effort to manage, loses the benefits of managed database services, and is not a supported architecture for relational databases."
    }
  },
  {
    "id": "SAA-572",
    "domainId": "D4",
    "domain": "Design Cost-Optimized Architectures",
    "section": "Data Transfer",
    "question": "A service has two tightly coupled tiers with high east-west traffic. They are deployed across multiple AZs and data transfer charges are unexpectedly high. The system must remain highly available, but the company wants to reduce cross-AZ transfer costs.\nWhich design change BEST reduces cost without eliminating high availability?",
    "choices": [
      "Pin both tiers to a single AZ and remove Multi-AZ for the service",
      "Use zonal awareness: keep paired components in the same AZ where possible, and use an ALB with cross-zone load balancing disabled while maintaining instances in multiple AZs",
      "Move the service to a single EC2 instance and scale vertically",
      "Route all traffic through a NAT Gateway to simplify networking"
    ],
    "answer": 1,
    "explanation": "Keeping chatty traffic within the same AZ reduces cross-AZ data transfer while maintaining multi-AZ capacity. Disabling cross-zone load balancing can help keep traffic zonal depending on the architecture and client flow.",
    "difficulty": "Hard",
    "choiceExplanations": {
      "0": "While this eliminates cross-AZ data transfer costs, it completely removes high availability by creating a single point of failure, which violates the requirement that the system must remain highly available.",
      "2": "This eliminates high availability entirely by creating a single point of failure, and vertical scaling has hard limits that may not meet capacity requirements; it also removes the ability to survive instance or AZ failures.",
      "3": "NAT Gateways are designed for outbound internet access from private subnets, not for east-west traffic between application tiers; this would add unnecessary cost (NAT Gateway processing charges) and latency without reducing cross-AZ transfer costs."
    }
  },
  {
    "id": "SAA-573",
    "domainId": "D4",
    "domain": "Design Cost-Optimized Architectures",
    "section": "S3",
    "question": "A dataset has unpredictable access patterns across millions of objects. The team does not want to constantly tune lifecycle policies, but they do want to minimize storage cost while keeping retrieval straightforward for frequently accessed data.\nWhich S3 option BEST meets these requirements?",
    "choices": [
      "S3 Glacier Deep Archive",
      "S3 Intelligent-Tiering",
      "S3 One Zone-IA",
      "S3 Standard only"
    ],
    "answer": 1,
    "explanation": "Intelligent-Tiering automatically moves objects between access tiers based on usage while keeping retrieval seamless, reducing the need for complex lifecycle tuning.",
    "difficulty": "Hard",
    "choiceExplanations": {
      "0": "This storage class is designed for long-term archival with retrieval times of 12-48 hours, making it unsuitable for data with unpredictable access patterns that may require straightforward retrieval for frequently accessed objects.",
      "2": "This storage class requires manual lifecycle policy management to move objects between tiers, which contradicts the requirement to avoid constantly tuning lifecycle policies, and it stores data in only one Availability Zone reducing durability.",
      "3": "While this provides straightforward retrieval, it does not minimize storage costs for infrequently accessed data since all objects remain in the highest-cost tier regardless of access patterns, failing to optimize costs automatically."
    }
  },
  {
    "id": "SAA-574",
    "domainId": "D4",
    "domain": "Design Cost-Optimized Architectures",
    "section": "EFS",
    "question": "A company stores large amounts of shared files on EFS. Analysis shows most files are rarely accessed after 30 days, but they must remain available immediately. The company wants to reduce storage cost automatically.\nWhich option BEST meets these requirements?",
    "choices": [
      "Enable EFS Lifecycle Management to move files to EFS Infrequent Access after 30 days",
      "Move the entire file system to S3 Glacier Deep Archive",
      "Disable backups to reduce cost",
      "Switch to Provisioned IOPS SSD volumes on EBS"
    ],
    "answer": 0,
    "explanation": "EFS Lifecycle Management transitions files to EFS Infrequent Access automatically based on last access, reducing cost while keeping immediate availability.",
    "difficulty": "Hard",
    "choiceExplanations": {
      "1": "S3 Glacier Deep Archive does not provide immediate access to files (retrieval takes hours), and it would require migrating away from EFS entirely, losing the shared file system functionality that EFS provides.",
      "2": "Disabling backups does not address storage costs for the actual data and creates significant risk of data loss, which is not a recommended cost optimization strategy.",
      "3": "EBS volumes cannot be shared across multiple EC2 instances like EFS can (except Multi-Attach for io1/io2 with limited use cases), and Provisioned IOPS SSD is a premium, higher-cost storage option designed for high-performance workloads, not cost optimization."
    }
  },
  {
    "id": "SAA-575",
    "domainId": "D4",
    "domain": "Design Cost-Optimized Architectures",
    "section": "Compute Strategy (Select TWO)",
    "question": "A company runs three workloads: (1) a 24/7 web tier with steady demand, (2) nightly batch processing that can be interrupted and resumes from checkpoints, and (3) a stateful workload that must complete once started and runs a few times per week. The company wants the greatest cost savings while maintaining reliability.\nWhich TWO purchasing approaches BEST match these requirements? (Choose TWO.)",
    "choices": [
      "Use 3-year commitment discounts (Savings Plans or Standard RIs) for the steady 24/7 web tier",
      "Use Spot Instances for the interruptible batch jobs with checkpointing",
      "Use Spot Instances only for the stateful workload that cannot be interrupted",
      "Use Dedicated Hosts for all workloads to maximize discounts",
      "Use On-Demand only for all workloads to avoid commitments"
    ],
    "answer": [
      0,
      1
    ],
    "explanation": "Committed discounts are best for predictable 24/7 usage, and Spot is ideal for interruptible batch workloads with checkpointing. Stateful jobs that cannot be interrupted generally need On-Demand or committed capacity, not Spot-only.",
    "difficulty": "Hard",
    "choiceExplanations": {
      "2": "Spot Instances can be terminated by AWS with only 2 minutes notice when capacity is needed, making them unsuitable for stateful workloads that must complete once started. Using Spot for workloads that cannot tolerate interruption risks data loss and incomplete processing.",
      "3": "Dedicated Hosts are designed for licensing compliance and regulatory requirements, not cost optimization. They are typically more expensive than shared tenancy options and do not provide cost savings compared to Savings Plans, Reserved Instances, or Spot Instances.",
      "4": "On-Demand pricing is the most expensive option and provides no cost savings. For predictable 24/7 workloads, commitment discounts can save up to 72%, and for interruptible batch jobs, Spot Instances can save up to 90% compared to On-Demand pricing."
    }
  },
  {
    "id": "SAA-576",
    "domainId": "D1",
    "domain": "Design Secure Architectures",
    "section": "Egress Filtering",
    "question": "A company must enforce outbound web access controls for workloads in private subnets: only allow traffic to approved domains, log all DNS queries, and block known malicious domains. The solution must be managed and require minimal custom infrastructure.\nWhich solution BEST meets these requirements?",
    "choices": [
      "Use only security groups with destination CIDR allowlists",
      "Use Route 53 Resolver DNS Firewall for domain blocking and logging, and route outbound traffic through a controlled egress point",
      "Use S3 bucket policies to restrict outbound traffic",
      "Use IAM policies to deny access to the internet"
    ],
    "answer": 1,
    "explanation": "Route 53 Resolver DNS Firewall supports managed domain allow/deny lists and DNS query logging. Combined with controlled egress, it enforces outbound domain policies without heavy custom infrastructure.",
    "difficulty": "Hard",
    "choiceExplanations": {
      "0": "Security groups operate at the IP address level (Layer 3/4) and cannot filter traffic based on domain names, making it impossible to allow or block specific domains. Additionally, security groups do not provide DNS query logging or the ability to block known malicious domains.",
      "2": "S3 bucket policies control access to S3 buckets and their objects, not outbound internet traffic from EC2 instances or other compute resources. They have no capability to filter web traffic, log DNS queries, or block malicious domains.",
      "3": "IAM policies control access to AWS API actions and resources, not network-level traffic or internet connectivity. IAM cannot filter outbound web requests, log DNS queries, or block access to external domains."
    }
  },
  {
    "id": "SAA-577",
    "domainId": "D1",
    "domain": "Design Secure Architectures",
    "section": "Systems Manager",
    "question": "A company forbids inbound SSH/RDP to production instances. Administrators must still access instances for troubleshooting, sessions must be logged, and access must be controlled via IAM with MFA. The solution must work in private subnets.\nWhich solution BEST meets these requirements?",
    "choices": [
      "Open port 22 to the corporate IP range and log sessions locally",
      "Use AWS Systems Manager Session Manager with IAM-based access control and session logging to CloudWatch Logs or S3",
      "Use a bastion host in a public subnet and allow SSH from 0.0.0.0/0",
      "Use EC2 serial console and share the credentials across the team"
    ],
    "answer": 1,
    "explanation": "Session Manager provides agent-based access without inbound ports, supports IAM controls (including MFA via federation), and can log sessions to CloudWatch Logs/S3 for auditing.",
    "difficulty": "Hard",
    "choiceExplanations": {
      "0": "This directly violates the company policy that forbids inbound SSH/RDP to production instances, and local logging does not provide centralized audit capabilities or integration with IAM/MFA controls.",
      "2": "This violates the policy against inbound SSH/RDP, exposes the bastion to the entire internet creating a security risk, and does not inherently provide IAM-based access control with MFA or centralized session logging.",
      "3": "Sharing credentials violates security best practices and prevents individual accountability, does not integrate with IAM for access control or MFA enforcement, and EC2 Serial Console is designed for boot-level troubleshooting rather than routine administrative access."
    }
  },
  {
    "id": "SAA-578",
    "domainId": "D1",
    "domain": "Design Secure Architectures",
    "section": "Certificate Management",
    "question": "A company operates multiple internal APIs and wants end-to-end TLS with privately trusted certificates. They also require centralized issuance and automated renewal without manual distribution of private keys.\nWhich solution BEST meets these requirements?",
    "choices": [
      "Use public ACM certificates for internal endpoints",
      "Use ACM Private CA to issue private certificates and integrate renewal with the services",
      "Use self-signed certs and store them in S3 for manual updates",
      "Use AWS Secrets Manager to store certificates and rotate them weekly"
    ],
    "answer": 1,
    "explanation": "ACM Private CA provides centralized issuance of private certificates with managed lifecycle features, enabling automated renewals without manual key distribution workflows.",
    "difficulty": "Hard",
    "choiceExplanations": {
      "0": "Public ACM certificates require domain validation through public DNS and are designed for publicly accessible endpoints, not internal APIs that need privately trusted certificates within an organization's private PKI infrastructure.",
      "2": "Self-signed certificates stored in S3 require manual distribution and updates, which directly contradicts the requirements for centralized issuance, automated renewal, and avoiding manual distribution of private keys.",
      "3": "Secrets Manager is designed for storing and rotating secrets like database credentials, not for issuing or managing TLS certificates; it lacks certificate authority capabilities and would still require manual certificate generation and distribution."
    }
  },
  {
    "id": "SAA-579",
    "domainId": "D2",
    "domain": "Design Resilient Architectures",
    "section": "DR Automation",
    "question": "A company uses a cross-region RDS read replica for disaster recovery. They want automated failover that promotes the replica when the primary region fails, updates application endpoints, and avoids human intervention. The company is fine with DNS-based client routing.\nWhich approach BEST meets these requirements?",
    "choices": [
      "Write a manual runbook and have on-call engineers promote the replica and update DNS",
      "Use Route 53 failover records with health checks plus automation (Lambda/SSM) to promote the replica and update records if needed",
      "Use S3 Transfer Acceleration to improve database replication speed",
      "Enable Multi-AZ only and rely on it for regional failover"
    ],
    "answer": 1,
    "explanation": "Route 53 health-based failover can switch endpoints, while automation can promote the replica to primary. Multi-AZ does not provide cross-region failover, and manual runbooks do not meet the automation requirement.",
    "difficulty": "Hard",
    "choiceExplanations": {
      "0": "This approach requires human intervention, which directly contradicts the requirement to avoid human intervention and achieve automated failover during a regional failure.",
      "2": "S3 Transfer Acceleration is designed to speed up transfers to and from S3 buckets over long distances, not for database replication; it has no relevance to RDS read replica promotion or disaster recovery failover.",
      "3": "Multi-AZ provides high availability within a single region by maintaining a synchronous standby replica in a different Availability Zone, but it does not provide cross-region failover capabilities required for regional disaster recovery."
    }
  },
  {
    "id": "SAA-580",
    "domainId": "D2",
    "domain": "Design Resilient Architectures",
    "section": "DynamoDB Recovery",
    "question": "A company must protect a DynamoDB table from accidental writes and deletes. They require the ability to restore the table to any point within the last 35 days and also need periodic retained backups for long-term retention beyond that window.\nWhich solution BEST meets these requirements?",
    "choices": [
      "Enable DynamoDB Streams and replay events for 35 days",
      "Enable DynamoDB Point-in-Time Recovery (PITR) and also create on-demand backups for long-term retention",
      "Export the table to S3 daily and delete the table after each export",
      "Use TTL to remove items and treat that as backup"
    ],
    "answer": 1,
    "explanation": "PITR enables point-in-time restore within the retention window. On-demand backups can be retained for longer periods to satisfy long-term retention requirements.",
    "difficulty": "Hard",
    "choiceExplanations": {
      "0": "DynamoDB Streams only retains data for 24 hours, not 35 days, making it impossible to replay events for the required retention period. Additionally, replaying streams is complex and not designed as a backup/restore mechanism.",
      "2": "Deleting the table after each export eliminates the ability to restore to any point in time within 35 days, as you would only have daily snapshots. This approach also disrupts table availability and does not provide continuous protection against accidental modifications.",
      "3": "TTL (Time to Live) is designed to automatically delete expired items from a table, not to create backups. TTL removes data rather than preserving it, which is the opposite of what backup and recovery requires."
    }
  },
  {
    "id": "SAA-581",
    "domainId": "D3",
    "domain": "Design High-Performing Architectures",
    "section": "S3 Select",
    "question": "A data pipeline stores large CSV objects in S3. A downstream job frequently needs only a few columns and a subset of rows. The company wants to reduce data transfer and speed up processing without building a separate database.\nWhich solution BEST meets these requirements?",
    "choices": [
      "Use S3 Select to retrieve only required columns/rows from objects",
      "Enable S3 Object Lock to speed up reads",
      "Use CloudFront to cache the entire CSV files",
      "Move the data to EBS volumes and run queries locally"
    ],
    "answer": 0,
    "explanation": "S3 Select allows querying and retrieving a subset of data within an object, reducing both transferred bytes and processing time for selective reads.",
    "difficulty": "Hard",
    "choiceExplanations": {
      "1": "S3 Object Lock is a data protection feature that prevents objects from being deleted or overwritten for a specified retention period using WORM (Write Once Read Many) model; it has no effect on read performance or data filtering capabilities.",
      "2": "CloudFront caches and delivers entire objects closer to users for faster access, but it does not reduce data transfer or provide filtering capabilities; the downstream job would still need to download and process the complete CSV files.",
      "3": "This approach requires provisioning and managing EC2 instances with EBS volumes, which adds infrastructure complexity and cost; it also contradicts the requirement of not building a separate database or processing system, and doesn't leverage S3's native query capabilities."
    }
  },
  {
    "id": "SAA-582",
    "domainId": "D3",
    "domain": "Design High-Performing Architectures",
    "section": "HPC Storage",
    "question": "A scientific simulation workload runs on hundreds of Linux instances and needs a shared file system with extremely high aggregate throughput and low-latency metadata operations. Data must be staged from and persisted to S3 for long-term storage, while the compute phase needs high-speed POSIX access.\nWhich solution BEST meets these requirements?",
    "choices": [
      "Amazon EFS with Elastic throughput only",
      "Amazon FSx for Lustre integrated with S3 for import/export",
      "Amazon S3 Glacier Flexible Retrieval as primary storage",
      "Amazon RDS as a file store with BLOB columns"
    ],
    "answer": 1,
    "explanation": "FSx for Lustre is designed for HPC-style parallel file system performance and supports integration with S3 to stage and persist data while providing high-speed POSIX access during compute phases.",
    "difficulty": "Hard",
    "choiceExplanations": {
      "0": "While EFS provides shared POSIX-compliant storage, it lacks the extreme aggregate throughput and low-latency metadata operations that Lustre provides for HPC workloads, and does not have native S3 integration for data staging and persistence.",
      "2": "Glacier is designed for archival storage with retrieval times ranging from minutes to hours, making it completely unsuitable for high-speed compute workloads requiring low-latency POSIX file system access.",
      "3": "RDS is a relational database service, not a file system, and cannot provide POSIX file system access, high aggregate throughput, or the parallel I/O capabilities required for HPC scientific simulation workloads."
    }
  },
  {
    "id": "SAA-583",
    "domainId": "D2",
    "domain": "Design Resilient Architectures",
    "section": "Messaging (Select TWO)",
    "question": "A system must distribute the same event to multiple independent processing services. Requirements: each service must receive its own copy, processing must be durable even if a consumer is down for hours, and the publisher should not need to know who the consumers are.\nWhich TWO AWS services should be used together to BEST meet these requirements? (Choose TWO.)",
    "choices": [
      "Amazon SNS topic for fanout publishing",
      "Amazon SQS queues subscribed to the SNS topic for durable per-consumer processing",
      "A single SQS queue with multiple consumers competing for messages",
      "An EBS volume shared across instances",
      "A Route 53 hosted zone with multiple A records"
    ],
    "answer": [
      0,
      1
    ],
    "explanation": "SNS provides pub/sub fanout while SQS subscriptions give each consumer a durable queue, ensuring each service gets its own copy and can process asynchronously even if temporarily offline.",
    "difficulty": "Hard",
    "choiceExplanations": {
      "2": "With a single queue, messages are processed by only one consumer (competing consumers pattern), meaning each service would NOT receive its own copy of every event as required.",
      "3": "EBS volumes can only be attached to instances within a single Availability Zone and cannot be shared across multiple instances simultaneously (except Multi-Attach for specific use cases), making it unsuitable for distributed event processing across independent services.",
      "4": "Route 53 is a DNS service for routing traffic to endpoints and has no capability for message distribution, event fanout, or durable message storage required for this messaging scenario."
    }
  },
  {
    "id": "SAA-584",
    "domainId": "D4",
    "domain": "Design Cost-Optimized Architectures",
    "section": "Logging Costs",
    "question": "A company ingests large volumes of application logs to CloudWatch Logs and costs are growing rapidly. They need fast search for the last 14 days but must retain raw logs for 2 years. The company wants to reduce cost while preserving query capability for recent data.\nWhich solution BEST meets these requirements?",
    "choices": [
      "Set CloudWatch Logs retention to 14 days and stream logs to S3 (for long-term retention) using a subscription to Kinesis Data Firehose",
      "Keep CloudWatch Logs forever and export to S3 once per year",
      "Disable logs during peak hours to reduce ingestion cost",
      "Store logs only on instance disks and rotate weekly"
    ],
    "answer": 0,
    "explanation": "Short retention in CloudWatch supports fast recent queries while Firehose delivery to S3 provides low-cost long-term retention. This aligns storage tiers with access needs and reduces ongoing CloudWatch cost.",
    "difficulty": "Hard",
    "choiceExplanations": {
      "1": "This approach does not reduce costs because CloudWatch Logs charges for storage, and keeping logs indefinitely would result in continuously growing storage costs rather than limiting retention to 14 days; annual exports also create gaps in long-term data availability.",
      "2": "This creates gaps in log data during critical high-traffic periods when logs are most needed for troubleshooting and analysis, compromising operational visibility and failing to meet the 2-year retention requirement for all raw logs.",
      "3": "Instance storage is ephemeral and not durable, logs would be lost if instances terminate or fail, weekly rotation does not meet the 2-year retention requirement, and this approach lacks centralized search capability for recent data."
    }
  },
  {
    "id": "SAA-585",
    "domainId": "D3",
    "domain": "Design High-Performing Architectures",
    "section": "Search Analytics",
    "question": "A company needs near real-time search and filtering over application logs (seconds to minutes), including full-text search and aggregations. Logs are produced continuously and the team wants managed scaling and high availability.\nWhich solution BEST meets these requirements?",
    "choices": [
      "Amazon Athena over S3 with partitioning",
      "Amazon OpenSearch Service with an ingestion pipeline (for example, Firehose) to index logs",
      "Amazon RDS MySQL with a single table for all logs",
      "S3 Glacier Deep Archive with restore-on-demand"
    ],
    "answer": 1,
    "explanation": "OpenSearch is designed for near real-time indexing, full-text search, and aggregations over log data, and can be fed by managed ingestion services such as Firehose.",
    "difficulty": "Hard",
    "choiceExplanations": {
      "0": "While Athena provides serverless querying and supports some text search functions, it is optimized for ad-hoc analytical queries rather than near real-time search scenarios, as data must first be written to S3 and queries have higher latency compared to OpenSearch's sub-second indexing and search capabilities.",
      "2": "Relational databases are not designed for full-text search and aggregations at scale over log data, and a single table approach would create performance bottlenecks as log volume grows, lacking the distributed indexing and search optimization that OpenSearch provides.",
      "3": "This storage class is designed for long-term archival with retrieval times of 12-48 hours, making it completely unsuitable for near real-time search requirements that need responses within seconds to minutes."
    }
  },
  {
    "id": "SAA-586",
    "domainId": "D1",
    "domain": "Design Secure Architectures",
    "section": "Secrets Manager",
    "question": "A company is developing a web application that connects to an Amazon RDS MySQL database. The application currently stores the database credentials in a configuration file on the Amazon EC2 instances. The security team has raised concerns about this approach and wants a more secure solution that can automatically rotate the database credentials without requiring application changes.\n\nWhich AWS service should the solutions architect recommend to meet these requirements?",
    "choices": [
      "AWS Systems Manager Parameter Store with standard parameters",
      "AWS Secrets Manager",
      "AWS Key Management Service (AWS KMS)",
      "Amazon S3 with server-side encryption"
    ],
    "answer": 1,
    "explanation": "AWS Secrets Manager is designed to store, manage, and automatically rotate database credentials and other secrets, with native integration for Amazon RDS.",
    "difficulty": "Easy",
    "choiceExplanations": {
      "0": "Parameter Store standard parameters can store credentials but do not provide built-in automatic rotation functionality for database credentials.",
      "2": "AWS KMS is used for encryption key management, not for storing or rotating application secrets like database credentials.",
      "3": "Amazon S3 is an object storage service and is not designed for secure credential management or automatic rotation of secrets."
    }
  },
  {
    "id": "SAA-587",
    "domainId": "D2",
    "domain": "Design Resilient Architectures",
    "section": "S3 Replication",
    "question": "A company stores critical business documents in an Amazon S3 bucket in the us-east-1 region. The compliance team requires that all objects must be automatically replicated to a different AWS region to protect against regional failures. The solution should ensure that any new objects uploaded to the source bucket are copied to the destination bucket without manual intervention.\n\nWhich S3 feature should the solutions architect configure to meet this requirement?",
    "choices": [
      "S3 Transfer Acceleration",
      "S3 Cross-Region Replication (CRR)",
      "S3 Lifecycle policies",
      "S3 Versioning only"
    ],
    "answer": 1,
    "explanation": "S3 Cross-Region Replication (CRR) automatically replicates objects across buckets in different AWS regions, providing disaster recovery protection against regional failures.",
    "difficulty": "Easy",
    "choiceExplanations": {
      "0": "S3 Transfer Acceleration speeds up uploads to S3 using CloudFront edge locations but does not replicate data to another region.",
      "2": "S3 Lifecycle policies manage object transitions between storage classes or deletion but do not replicate objects to other regions.",
      "3": "S3 Versioning preserves multiple versions of objects in the same bucket but does not copy objects to a different region."
    }
  },
  {
    "id": "SAA-588",
    "domainId": "D3",
    "domain": "Design High-Performing Architectures",
    "section": "ElastiCache",
    "question": "A company runs a web application that displays product information from an Amazon RDS MySQL database. The application experiences high read traffic during business hours, causing slow response times for users. The product data changes infrequently throughout the day. A solutions architect needs to improve the application's read performance with minimal changes to the existing architecture.\n\nWhich solution will MOST effectively improve read performance?",
    "choices": [
      "Migrate the database from Amazon RDS MySQL to Amazon DynamoDB",
      "Add an Amazon ElastiCache cluster in front of the database to cache frequently accessed data",
      "Enable Multi-AZ deployment for the Amazon RDS instance",
      "Increase the storage size of the Amazon RDS instance"
    ],
    "answer": 1,
    "explanation": "Amazon ElastiCache is designed to cache frequently accessed data in memory, reducing database read load and improving response times for read-heavy workloads with infrequently changing data.",
    "difficulty": "Easy",
    "choiceExplanations": {
      "0": "Migrating to DynamoDB requires significant application changes and is not necessary when the issue is read performance that can be solved with caching.",
      "2": "Multi-AZ deployment provides high availability and automatic failover, but does not improve read performance for the primary database.",
      "3": "Increasing storage size does not improve read performance. Storage size affects data capacity, not query response times or throughput."
    }
  },
  {
    "id": "SAA-589",
    "domainId": "D1",
    "domain": "Design Secure Architectures",
    "section": "Secrets Manager",
    "question": "A company is developing a web application that connects to an Amazon RDS MySQL database. The application runs on Amazon EC2 instances and currently stores the database credentials in a configuration file on each instance. The security team has raised concerns about this approach and wants a more secure solution for managing database credentials.\n\nWhich AWS service should the solutions architect recommend to securely store and manage the database credentials?",
    "choices": [
      "Store the credentials in an Amazon S3 bucket with server-side encryption enabled",
      "Store the credentials in AWS Secrets Manager with automatic rotation enabled",
      "Store the credentials in AWS Systems Manager Parameter Store as a standard parameter",
      "Store the credentials in an encrypted Amazon EBS volume attached to each EC2 instance"
    ],
    "answer": 1,
    "explanation": "AWS Secrets Manager is designed specifically for storing and managing secrets like database credentials, with built-in automatic rotation capabilities for RDS databases.",
    "difficulty": "Easy",
    "choiceExplanations": {
      "0": "S3 is not designed for secrets management. It lacks automatic rotation and requires additional application logic to retrieve credentials securely.",
      "2": "Parameter Store standard parameters do not support automatic rotation. While SecureString parameters can encrypt values, Secrets Manager is purpose-built for credentials.",
      "3": "Storing credentials on EBS volumes still keeps them on the instances, which doesn't address the security concern and doesn't provide centralized management or rotation."
    }
  },
  {
    "id": "SAA-590",
    "domainId": "D1",
    "domain": "Design Secure Architectures",
    "section": "Secrets Manager",
    "question": "A company is developing a web application that connects to an Amazon RDS MySQL database. The application runs on Amazon EC2 instances and currently stores database credentials in a configuration file on each instance. The security team has raised concerns about this approach and wants to implement a more secure method for managing database credentials.\n\nWhich AWS service should the solutions architect recommend to securely store and manage the database credentials?",
    "choices": [
      "AWS Systems Manager Parameter Store with standard parameters",
      "AWS Secrets Manager",
      "Amazon S3 with server-side encryption",
      "AWS CloudHSM"
    ],
    "answer": 1,
    "explanation": "AWS Secrets Manager is designed specifically for storing, managing, and rotating secrets like database credentials securely with built-in integration for RDS.",
    "difficulty": "Easy",
    "choiceExplanations": {
      "0": "Parameter Store standard parameters can store credentials but lack automatic rotation capabilities and native RDS integration that Secrets Manager provides.",
      "2": "S3 is an object storage service not designed for secrets management. It lacks automatic rotation and secure retrieval mechanisms for credentials.",
      "3": "CloudHSM is for hardware-based key management and cryptographic operations, not for storing and managing application secrets like database credentials."
    }
  },
  {
    "id": "SAA-591",
    "domainId": "D1",
    "domain": "Design Secure Architectures",
    "section": "Secrets Manager",
    "question": "A company is developing a web application that connects to an Amazon RDS MySQL database. The application runs on Amazon EC2 instances. Currently, the database credentials are stored in a configuration file on each EC2 instance. The security team has raised concerns about this approach and wants a more secure method to manage the database credentials. The solution should also support automatic rotation of credentials without requiring application changes.\n\nWhich AWS service should the solutions architect recommend to meet these requirements?",
    "choices": [
      "Store the credentials in AWS Systems Manager Parameter Store with standard parameters",
      "Store the credentials in AWS Secrets Manager with automatic rotation enabled",
      "Store the credentials in Amazon S3 with server-side encryption enabled",
      "Store the credentials in environment variables on the EC2 instances"
    ],
    "answer": 1,
    "explanation": "AWS Secrets Manager is designed to store, manage, and automatically rotate database credentials. It provides native integration with Amazon RDS for automatic credential rotation.",
    "difficulty": "Easy",
    "choiceExplanations": {
      "0": "Parameter Store standard parameters do not support automatic rotation. While SecureString parameters can store secrets, built-in rotation for RDS credentials requires Secrets Manager.",
      "2": "S3 is an object storage service not designed for secrets management. It lacks automatic credential rotation capabilities and is not suitable for storing database credentials.",
      "3": "Environment variables on EC2 instances are not secure and do not support automatic rotation. Credentials would still be exposed on the instance and require manual updates."
    }
  },
  {
    "id": "SAA-592",
    "domainId": "D1",
    "domain": "Design Secure Architectures",
    "section": "Secrets Manager",
    "question": "A company is developing a web application that connects to an Amazon RDS MySQL database. The application runs on Amazon EC2 instances and currently stores the database credentials in a configuration file on each instance. The security team has raised concerns about this approach and wants a more secure solution that can also automatically rotate the database credentials on a regular schedule.\n\nWhich AWS service should the solutions architect recommend to meet these requirements?",
    "choices": [
      "AWS Systems Manager Parameter Store with standard parameters",
      "AWS Key Management Service (AWS KMS)",
      "AWS Secrets Manager",
      "Amazon S3 with server-side encryption"
    ],
    "answer": 2,
    "explanation": "AWS Secrets Manager is designed to store, retrieve, and automatically rotate database credentials and other secrets securely.",
    "difficulty": "Easy",
    "choiceExplanations": {
      "0": "Parameter Store standard parameters can store secrets but do not provide built-in automatic rotation for database credentials like Secrets Manager does.",
      "1": "AWS KMS is used for encryption key management, not for storing and rotating application secrets or database credentials.",
      "3": "Amazon S3 is an object storage service not designed for secure credential management or automatic rotation of secrets."
    }
  },
  {
    "id": "SAA-593",
    "domainId": "D1",
    "domain": "Design Secure Architectures",
    "section": "Secrets Manager",
    "question": "A company is developing a web application that connects to an Amazon RDS MySQL database. The development team currently stores the database credentials in a configuration file within the application code repository. The security team has raised concerns about this practice and wants a more secure solution for managing database credentials.\n\nWhich AWS service should the solutions architect recommend to securely store and manage the database credentials?",
    "choices": [
      "AWS Secrets Manager",
      "Amazon S3 with server-side encryption",
      "AWS Systems Manager Parameter Store with standard parameters",
      "AWS Identity and Access Management (IAM) user access keys"
    ],
    "answer": 0,
    "explanation": "AWS Secrets Manager is designed specifically for storing and managing secrets like database credentials, with built-in automatic rotation capabilities for RDS databases.",
    "difficulty": "Easy",
    "choiceExplanations": {
      "1": "S3 is an object storage service, not designed for secrets management. It lacks credential rotation and secure retrieval mechanisms needed for application secrets.",
      "2": "While Parameter Store can store secrets, it lacks native automatic rotation for RDS credentials. Secrets Manager is purpose-built for database credential management.",
      "3": "IAM access keys are for authenticating AWS API calls, not for storing database credentials. They cannot be used to connect to RDS databases."
    }
  },
  {
    "id": "SAA-594",
    "domainId": "D1",
    "domain": "Design Secure Architectures",
    "section": "IAM Best Practices (Select TWO)",
    "question": "A startup company is setting up their AWS environment for the first time. The IT administrator wants to follow AWS security best practices when configuring IAM for the development team. The team consists of 10 developers who need similar permissions to access Amazon EC2 and Amazon S3 resources.\n\nWhich TWO actions should the administrator take to follow IAM security best practices? (Choose TWO.)",
    "choices": [
      "Share a single IAM user account among all developers to simplify management",
      "Enable multi-factor authentication (MFA) for all IAM users",
      "Create an IAM group with the required permissions and add the developers' IAM users to the group",
      "Use the AWS account root user credentials for daily development tasks",
      "Create individual IAM users for each developer and attach policies directly to each user account"
    ],
    "answer": [
      1,
      2
    ],
    "explanation": "IAM best practices recommend using groups to assign permissions to users with similar access needs, and enabling MFA for all users to add an extra layer of security.",
    "difficulty": "Easy",
    "choiceExplanations": {
      "0": "Sharing IAM credentials violates AWS security best practices. Each user should have their own unique IAM user account for accountability and auditing purposes.",
      "3": "Using root user credentials for daily tasks is a serious security risk. AWS strongly recommends locking away root user credentials and using IAM users instead.",
      "4": "Attaching policies directly to individual users is not a best practice. Using IAM groups simplifies permission management and reduces administrative overhead."
    }
  },
  {
    "id": "SAA-596",
    "domainId": "D1",
    "domain": "Design Secure Architectures",
    "section": "Secrets Manager",
    "question": "A company is developing a new web application that connects to an Amazon RDS MySQL database. The development team currently stores the database credentials in a configuration file on the Amazon EC2 instances running the application. The security team has raised concerns about this approach and wants a more secure solution that can automatically rotate the database credentials without requiring application changes.\n\nWhich AWS service should the solutions architect recommend to meet these requirements?",
    "choices": [
      "AWS Secrets Manager",
      "AWS Systems Manager Parameter Store with standard parameters",
      "AWS Key Management Service (AWS KMS)",
      "Amazon S3 with server-side encryption"
    ],
    "answer": 0,
    "explanation": "AWS Secrets Manager is designed to store, manage, and automatically rotate database credentials and other secrets with built-in RDS integration.",
    "difficulty": "Easy",
    "choiceExplanations": {
      "1": "Parameter Store standard parameters can store secrets but do not provide built-in automatic rotation for database credentials like Secrets Manager does.",
      "2": "AWS KMS is used for encryption key management, not for storing or rotating database credentials. It encrypts data but doesn't manage secrets.",
      "3": "Amazon S3 is an object storage service. Even with encryption, it doesn't provide automatic credential rotation or secrets management capabilities."
    }
  },
  {
    "id": "SAA-597",
    "domainId": "D1",
    "domain": "Design Secure Architectures",
    "section": "Secrets Manager",
    "question": "A company is developing a web application that connects to an Amazon RDS MySQL database. The development team currently stores the database credentials in a configuration file on the Amazon EC2 instances running the application. The security team has raised concerns about this approach and wants a more secure solution that can automatically rotate the database credentials without requiring application changes.\n\nWhich AWS service should the solutions architect recommend to meet these requirements?",
    "choices": [
      "AWS Systems Manager Parameter Store with standard parameters",
      "Amazon S3 with server-side encryption",
      "AWS Key Management Service (AWS KMS)",
      "AWS Secrets Manager"
    ],
    "answer": 3,
    "explanation": "AWS Secrets Manager is designed to store, manage, and automatically rotate database credentials and other secrets with native RDS integration.",
    "difficulty": "Easy",
    "choiceExplanations": {
      "0": "Parameter Store standard parameters can store credentials but do not provide built-in automatic rotation for database credentials like Secrets Manager does.",
      "1": "Amazon S3 is an object storage service and is not designed for secure credential management or automatic rotation of secrets.",
      "2": "AWS KMS is used for encryption key management, not for storing and rotating application secrets or database credentials."
    }
  },
  {
    "id": "SAA-599",
    "domainId": "D1",
    "domain": "Design Secure Architectures",
    "section": "Secrets Manager",
    "question": "A company is developing a web application that connects to an Amazon RDS MySQL database. The application runs on Amazon EC2 instances and currently stores the database credentials in a configuration file on each instance. The security team has raised concerns about this approach and wants a more secure method to manage database credentials.\n\nWhich AWS service should the solutions architect recommend to securely store and manage the database credentials?",
    "choices": [
      "Store the credentials in an Amazon S3 bucket with server-side encryption enabled",
      "Store the credentials in AWS Systems Manager Parameter Store as plain text parameters",
      "Store the credentials in AWS Secrets Manager with automatic rotation enabled",
      "Store the credentials in an Amazon DynamoDB table with encryption at rest"
    ],
    "answer": 2,
    "explanation": "AWS Secrets Manager is designed specifically for storing and managing secrets like database credentials, with built-in automatic rotation capabilities for RDS databases.",
    "difficulty": "Easy",
    "choiceExplanations": {
      "0": "S3 is not designed for secrets management. It lacks native credential rotation and requires additional application logic to retrieve credentials securely.",
      "1": "Parameter Store plain text parameters do not encrypt the values. While Parameter Store can use SecureString, it lacks native automatic rotation for RDS credentials.",
      "3": "DynamoDB is a database service, not a secrets management solution. It lacks native credential rotation and is not designed for this use case."
    }
  },
  {
    "id": "SAA-600",
    "domainId": "D1",
    "domain": "Design Secure Architectures",
    "section": "Secrets Manager",
    "question": "A company is developing a web application that connects to an Amazon RDS MySQL database. The application runs on Amazon EC2 instances and currently stores the database credentials in a configuration file on each instance. The security team has raised concerns about this approach and wants a more secure solution that can also automatically rotate the database credentials.\n\nWhich AWS service should the solutions architect recommend to securely store and manage the database credentials?",
    "choices": [
      "AWS Secrets Manager",
      "Amazon S3 with server-side encryption",
      "AWS Systems Manager Parameter Store with standard parameters",
      "AWS Key Management Service (AWS KMS)"
    ],
    "answer": 0,
    "explanation": "AWS Secrets Manager is designed to securely store, retrieve, and automatically rotate credentials for databases including Amazon RDS.",
    "difficulty": "Easy",
    "choiceExplanations": {
      "1": "S3 is an object storage service not designed for credential management. It lacks automatic rotation capabilities and is not suitable for storing application secrets.",
      "2": "Parameter Store standard parameters can store secrets but do not provide built-in automatic rotation for database credentials like Secrets Manager does.",
      "3": "KMS is for managing encryption keys, not for storing secrets or credentials. It encrypts data but does not store or rotate database passwords."
    }
  },
  {
    "id": "SAA-601",
    "domainId": "D1",
    "domain": "Design Secure Architectures",
    "section": "IAM",
    "question": "A startup company has recently created an AWS account and needs to grant their development team access to Amazon EC2 and Amazon S3 services. The security team wants to ensure that developers can only perform specific actions on these services and that permissions can be easily managed as the team grows.\n\nWhich AWS service should the solutions architect use to manage access permissions for the development team?",
    "choices": [
      "Amazon Cognito",
      "AWS Directory Service",
      "AWS IAM (Identity and Access Management)",
      "Amazon Inspector"
    ],
    "answer": 2,
    "explanation": "AWS IAM enables you to create users, groups, and policies to securely control access to AWS services and resources like EC2 and S3.",
    "difficulty": "Easy",
    "choiceExplanations": {
      "0": "Amazon Cognito is designed for managing user authentication for web and mobile applications, not for managing AWS resource access for internal teams.",
      "1": "AWS Directory Service is used to connect AWS resources with on-premises Microsoft Active Directory, not for basic AWS resource permission management.",
      "3": "Amazon Inspector is a security assessment service that scans workloads for vulnerabilities, not a service for managing user permissions."
    }
  },
  {
    "id": "SAA-602",
    "domainId": "D1",
    "domain": "Design Secure Architectures",
    "section": "Secrets Manager",
    "question": "A company is developing a web application that connects to an Amazon RDS MySQL database. The application runs on Amazon EC2 instances. The development team currently stores the database credentials in a configuration file on each EC2 instance. The security team has raised concerns about this approach and wants a more secure solution that can automatically rotate the database credentials without requiring application changes.\n\nWhich AWS service should the solutions architect recommend to meet these requirements?",
    "choices": [
      "AWS Secrets Manager",
      "AWS Systems Manager Parameter Store with standard parameters",
      "AWS Key Management Service (AWS KMS)",
      "Amazon S3 with server-side encryption"
    ],
    "answer": 0,
    "explanation": "AWS Secrets Manager is designed to store, manage, and automatically rotate database credentials and other secrets, with native integration for Amazon RDS.",
    "difficulty": "Easy",
    "choiceExplanations": {
      "1": "Parameter Store can store secrets but does not provide built-in automatic rotation for database credentials like Secrets Manager does.",
      "2": "AWS KMS is for managing encryption keys, not for storing or rotating database credentials and secrets.",
      "3": "Amazon S3 is object storage and is not designed for secure credential management or automatic rotation of secrets."
    }
  },
  {
    "id": "SAA-603",
    "domainId": "D1",
    "domain": "Design Secure Architectures",
    "section": "Secrets Manager",
    "question": "A company is developing a new web application that connects to an Amazon RDS MySQL database. The development team currently stores the database credentials in a configuration file within the application code repository. The security team has raised concerns about this practice and wants a more secure solution for managing database credentials.\n\nWhich AWS service should the solutions architect recommend to securely store and manage the database credentials?",
    "choices": [
      "AWS Secrets Manager",
      "AWS Systems Manager Parameter Store with standard parameters",
      "Amazon S3 with server-side encryption",
      "Amazon DynamoDB with encryption at rest"
    ],
    "answer": 0,
    "explanation": "AWS Secrets Manager is designed specifically for storing and managing secrets like database credentials, with built-in rotation capabilities for RDS databases.",
    "difficulty": "Easy",
    "choiceExplanations": {
      "1": "While Parameter Store can store secrets, Secrets Manager is purpose-built for database credentials with native RDS rotation support and is the recommended choice.",
      "2": "Amazon S3 is an object storage service, not designed for secrets management. It lacks features like automatic credential rotation and native RDS integration.",
      "3": "DynamoDB is a NoSQL database service for storing application data, not a secrets management solution. It lacks credential rotation features."
    }
  },
  {
    "id": "SAA-604",
    "domainId": "D1",
    "domain": "Design Secure Architectures",
    "section": "Secrets Manager",
    "question": "A company is developing a web application that connects to an Amazon RDS MySQL database. The application runs on Amazon EC2 instances and currently stores database credentials in a configuration file on each instance. The security team has raised concerns about this approach and wants a more secure solution that can automatically rotate the database credentials without requiring application changes.\n\nWhich AWS service should the solutions architect recommend to securely store and manage the database credentials?",
    "choices": [
      "AWS Systems Manager Parameter Store with standard parameters",
      "Amazon S3 with server-side encryption",
      "AWS Secrets Manager",
      "AWS Key Management Service (AWS KMS)"
    ],
    "answer": 2,
    "explanation": "AWS Secrets Manager is designed to store, rotate, and manage secrets like database credentials. It provides built-in automatic rotation for RDS databases.",
    "difficulty": "Easy",
    "choiceExplanations": {
      "0": "Parameter Store can store secrets but does not provide built-in automatic rotation for database credentials like Secrets Manager does.",
      "1": "S3 is an object storage service, not designed for secrets management. It lacks rotation capabilities and secure credential retrieval mechanisms.",
      "3": "KMS manages encryption keys, not secrets. It encrypts data but cannot store or rotate database credentials."
    }
  },
  {
    "id": "SAA-605",
    "domainId": "D1",
    "domain": "Design Secure Architectures",
    "section": "IAM and S3 Security (Select TWO)",
    "question": "A startup company is setting up their first AWS environment. They need to store application configuration files in Amazon S3 and want to ensure the data is protected. The security team requires that all data stored in S3 must be encrypted and that access to the S3 bucket should follow the principle of least privilege.\n\nWhich TWO actions should the solutions architect recommend to meet these security requirements? (Choose TWO.)",
    "choices": [
      "Enable S3 Transfer Acceleration on the bucket to encrypt data during transfer",
      "Enable S3 Versioning to automatically encrypt all object versions",
      "Configure the bucket as a public bucket and use signed URLs for all access",
      "Configure server-side encryption with Amazon S3 managed keys (SSE-S3) as the default encryption for the bucket",
      "Create an IAM policy that grants only the specific permissions needed and attach it to the IAM roles or users that require access"
    ],
    "answer": [
      3,
      4
    ],
    "explanation": "SSE-S3 provides encryption at rest for S3 objects. IAM policies with specific permissions implement least privilege access control, granting only necessary permissions.",
    "difficulty": "Easy",
    "choiceExplanations": {
      "0": "S3 Transfer Acceleration improves upload speeds for distant clients but does not provide encryption. HTTPS provides encryption in transit separately.",
      "1": "S3 Versioning maintains multiple versions of objects for recovery purposes but does not provide encryption functionality.",
      "2": "Making a bucket public violates the principle of least privilege and exposes data to unauthorized access, which is the opposite of the security requirement."
    }
  },
  {
    "id": "SAA-607",
    "domainId": "D1",
    "domain": "Design Secure Architectures",
    "section": "Secrets Manager",
    "question": "A company is developing a web application that connects to an Amazon RDS MySQL database. The application runs on Amazon EC2 instances and currently stores the database credentials in a configuration file on each instance. The security team has raised concerns about this approach and wants a more secure solution that can automatically rotate the database credentials without requiring application changes.\n\nWhich AWS service should the solutions architect recommend to securely store and manage the database credentials?",
    "choices": [
      "AWS Systems Manager Parameter Store with standard parameters",
      "AWS Secrets Manager",
      "Amazon S3 with server-side encryption",
      "AWS Key Management Service (AWS KMS)"
    ],
    "answer": 1,
    "explanation": "AWS Secrets Manager is designed to store, retrieve, and automatically rotate database credentials and other secrets, with native integration for Amazon RDS.",
    "difficulty": "Easy",
    "choiceExplanations": {
      "0": "Parameter Store can store secrets but does not provide built-in automatic rotation for database credentials like Secrets Manager does.",
      "2": "S3 is an object storage service not designed for secrets management. It lacks automatic credential rotation capabilities.",
      "3": "KMS manages encryption keys, not secrets or credentials. It encrypts data but does not store or rotate database passwords."
    }
  },
  {
    "id": "SAA-609",
    "domainId": "D2",
    "domain": "Design Resilient Architectures",
    "section": "S3 Replication",
    "question": "A company stores critical business documents in an Amazon S3 bucket in the us-east-1 region. The compliance team requires that all objects must be automatically replicated to a different AWS region to protect against regional failures. The solution must ensure that any new objects uploaded to the source bucket are copied to the destination bucket without manual intervention.\n\nWhich solution meets these requirements?",
    "choices": [
      "Enable S3 Transfer Acceleration on the source bucket to speed up cross-region transfers",
      "Create an S3 Lifecycle policy to move objects to another region after 30 days",
      "Configure S3 Cross-Region Replication (CRR) from the source bucket to a destination bucket in another region",
      "Use AWS DataSync to periodically copy objects between the two S3 buckets"
    ],
    "answer": 2,
    "explanation": "S3 Cross-Region Replication (CRR) automatically replicates objects to a destination bucket in a different AWS region, providing disaster recovery protection.",
    "difficulty": "Easy",
    "choiceExplanations": {
      "0": "S3 Transfer Acceleration improves upload speeds to S3 using CloudFront edge locations but does not replicate objects to another region.",
      "1": "S3 Lifecycle policies manage object transitions between storage classes or deletion, but cannot move objects to different regions.",
      "3": "AWS DataSync requires scheduled or manual execution and is designed for data migration tasks, not automatic real-time replication of S3 objects."
    }
  },
  {
    "id": "SAA-610",
    "domainId": "D2",
    "domain": "Design Resilient Architectures",
    "section": "S3 Replication",
    "question": "A company stores critical business documents in an Amazon S3 bucket in the us-east-1 region. The compliance team requires that all objects must be automatically replicated to a different AWS region to protect against regional disasters. The solution must ensure that any new objects uploaded to the source bucket are copied to the destination bucket without manual intervention.\n\nWhich solution meets these requirements?",
    "choices": [
      "Enable S3 Transfer Acceleration on the source bucket to speed up transfers to another region",
      "Create an S3 Lifecycle policy to move objects to another region after 30 days",
      "Use S3 Intelligent-Tiering to automatically distribute objects across multiple regions",
      "Configure S3 Cross-Region Replication (CRR) from the source bucket to a destination bucket in another region"
    ],
    "answer": 3,
    "explanation": "S3 Cross-Region Replication (CRR) automatically replicates objects from a source bucket to a destination bucket in a different AWS region, meeting disaster recovery requirements.",
    "difficulty": "Easy",
    "choiceExplanations": {
      "0": "S3 Transfer Acceleration improves upload speeds to a single bucket using CloudFront edge locations. It does not replicate objects to another region.",
      "1": "S3 Lifecycle policies manage object transitions between storage classes or deletion. They cannot move or copy objects to different regions.",
      "2": "S3 Intelligent-Tiering automatically moves objects between access tiers within the same bucket to optimize costs. It does not replicate data across regions."
    }
  },
  {
    "id": "SAA-612",
    "domainId": "D2",
    "domain": "Design Resilient Architectures",
    "section": "S3 Replication",
    "question": "A company stores critical business documents in an Amazon S3 bucket in the us-east-1 region. The compliance team requires that all objects must be automatically replicated to a different AWS region to protect against regional outages. The solution must replicate all new objects uploaded to the source bucket.\n\nWhich S3 feature should the solutions architect configure to meet this requirement?",
    "choices": [
      "S3 Transfer Acceleration",
      "S3 Versioning only",
      "S3 Lifecycle policies",
      "S3 Cross-Region Replication (CRR)"
    ],
    "answer": 3,
    "explanation": "S3 Cross-Region Replication (CRR) automatically replicates objects across S3 buckets in different AWS regions, providing disaster recovery protection against regional failures.",
    "difficulty": "Easy",
    "choiceExplanations": {
      "0": "S3 Transfer Acceleration speeds up uploads to S3 using CloudFront edge locations but does not replicate data to another region for disaster recovery.",
      "1": "S3 Versioning preserves multiple versions of objects in the same bucket but does not replicate data to another region. Versioning is a prerequisite for replication but not sufficient alone.",
      "2": "S3 Lifecycle policies automate transitioning objects between storage classes or deleting them, but they do not replicate objects to another region."
    }
  },
  {
    "id": "SAA-613",
    "domainId": "D2",
    "domain": "Design Resilient Architectures",
    "section": "S3 Replication",
    "question": "A company stores critical business documents in an Amazon S3 bucket in the us-east-1 region. The compliance team requires that all objects must be automatically replicated to a different AWS region to protect against regional failures. The solution should ensure that any new objects uploaded to the source bucket are copied to the destination bucket without manual intervention.\n\nWhich solution meets these requirements?",
    "choices": [
      "Enable S3 Transfer Acceleration on the source bucket to speed up transfers to another region",
      "Create a Lambda function triggered by S3 events to copy objects to another region",
      "Configure S3 Cross-Region Replication (CRR) on the source bucket with a destination bucket in another region",
      "Use S3 Lifecycle policies to move objects to another region after creation"
    ],
    "answer": 2,
    "explanation": "S3 Cross-Region Replication (CRR) automatically replicates objects to a destination bucket in a different AWS region, providing disaster recovery protection.",
    "difficulty": "Easy",
    "choiceExplanations": {
      "0": "S3 Transfer Acceleration improves upload speeds to a single bucket using CloudFront edge locations. It does not replicate objects to another region.",
      "1": "While Lambda could copy objects, this adds unnecessary complexity. S3 CRR is the native, managed solution designed specifically for this use case.",
      "3": "S3 Lifecycle policies manage object storage classes and expiration within the same bucket or to Glacier. They cannot replicate objects to another region."
    }
  },
  {
    "id": "SAA-617",
    "domainId": "D2",
    "domain": "Design Resilient Architectures",
    "section": "S3 Replication (Select TWO)",
    "question": "A company stores critical business documents in an Amazon S3 bucket in the us-east-1 Region. The compliance team requires that all documents must be replicated to a different AWS Region for disaster recovery purposes. The company also needs to ensure that if objects are accidentally deleted from the source bucket, the replicated copies are preserved in the destination bucket.\n\nWhich two configurations should a solutions architect implement to meet these requirements? (Choose TWO.)",
    "choices": [
      "Enable S3 Cross-Region Replication (CRR) on the source bucket",
      "Enable versioning on both the source and destination buckets",
      "Enable S3 Same-Region Replication (SRR) on the source bucket",
      "Configure the replication rule to replicate delete markers",
      "Enable S3 Transfer Acceleration on the source bucket"
    ],
    "answer": [
      0,
      1
    ],
    "explanation": "S3 Cross-Region Replication (CRR) copies objects to a bucket in a different Region for DR. Versioning must be enabled on both source and destination buckets for replication to work, and it preserves objects even when delete markers are created.",
    "difficulty": "Easy",
    "choiceExplanations": {
      "2": "Same-Region Replication (SRR) copies objects within the same Region, which does not meet the requirement for cross-Region disaster recovery.",
      "3": "Replicating delete markers would cause deletions to propagate to the destination bucket, which contradicts the requirement to preserve replicated copies when source objects are deleted.",
      "4": "S3 Transfer Acceleration improves upload speeds to S3 using CloudFront edge locations but does not provide replication or disaster recovery capabilities."
    }
  },
  {
    "id": "SAA-618",
    "domainId": "D2",
    "domain": "Design Resilient Architectures",
    "section": "S3 Replication (Select TWO)",
    "question": "A company stores critical business documents in an Amazon S3 bucket in the us-east-1 Region. The compliance team requires that all documents must be replicated to another AWS Region for disaster recovery purposes. The company also needs to ensure that if objects are accidentally deleted from the source bucket, the replicated copies remain intact in the destination bucket.\n\nWhich two configurations should a solutions architect implement to meet these requirements? (Choose TWO.)",
    "choices": [
      "Enable S3 Same-Region Replication (SRR) on the source bucket",
      "Enable S3 Cross-Region Replication (CRR) on the source bucket",
      "Configure the replication rule to replicate delete markers",
      "Enable S3 Transfer Acceleration on the source bucket",
      "Do not enable delete marker replication in the replication rule"
    ],
    "answer": [
      1,
      4
    ],
    "explanation": "S3 Cross-Region Replication (CRR) copies objects to a bucket in a different Region for DR. Disabling delete marker replication ensures deleted objects remain in the destination bucket.",
    "difficulty": "Easy",
    "choiceExplanations": {
      "0": "Same-Region Replication (SRR) copies objects within the same Region, which does not meet the requirement for cross-Region disaster recovery.",
      "2": "Replicating delete markers would cause deletions in the source bucket to also delete objects in the destination, failing to protect against accidental deletions.",
      "3": "S3 Transfer Acceleration speeds up uploads to S3 using CloudFront edge locations but does not provide replication or disaster recovery capabilities."
    }
  },
  {
    "id": "SAA-619",
    "domainId": "D2",
    "domain": "Design Resilient Architectures",
    "section": "S3 Replication",
    "question": "A media company stores critical video assets in an Amazon S3 bucket in the us-east-1 region. The company wants to protect these assets against regional failures by automatically copying all objects to another AWS region. The solution should maintain the same storage class and object metadata in the destination bucket.\n\nWhich solution meets these requirements with the LEAST operational overhead?",
    "choices": [
      "Create an AWS Lambda function triggered by S3 events to copy objects to another region",
      "Use AWS DataSync to schedule periodic transfers between S3 buckets in different regions",
      "Configure S3 Cross-Region Replication (CRR) on the source bucket",
      "Set up an Amazon EventBridge rule to trigger AWS Batch jobs for copying objects"
    ],
    "answer": 2,
    "explanation": "S3 Cross-Region Replication (CRR) automatically and asynchronously copies objects across buckets in different AWS regions, preserving metadata and storage class with minimal operational overhead.",
    "difficulty": "Easy",
    "choiceExplanations": {
      "0": "Lambda functions require custom code development and maintenance, adding significant operational overhead compared to native S3 replication features.",
      "1": "AWS DataSync is designed for data transfer between on-premises and AWS or between AWS storage services, but CRR is the native, simpler solution for S3-to-S3 cross-region replication.",
      "3": "Using EventBridge with AWS Batch requires managing compute resources, job definitions, and custom scripts, creating unnecessary complexity for a simple replication requirement."
    }
  },
  {
    "id": "SAA-620",
    "domainId": "D2",
    "domain": "Design Resilient Architectures",
    "section": "S3 Replication",
    "question": "A media company stores critical video assets in an Amazon S3 bucket in the us-east-1 region. The company wants to protect these assets against regional failures by automatically copying all objects to another AWS region. The solution should maintain the same object metadata and access control lists (ACLs) as the source objects.\n\nWhich solution meets these requirements with the LEAST operational overhead?",
    "choices": [
      "Configure S3 Cross-Region Replication (CRR) on the source bucket to replicate objects to a destination bucket in another region",
      "Use AWS DataSync to schedule periodic transfers between S3 buckets in different regions",
      "Create an AWS Lambda function triggered by S3 events to copy objects to another region",
      "Set up an Amazon EventBridge rule to trigger an AWS Step Functions workflow that copies objects between regions"
    ],
    "answer": 0,
    "explanation": "S3 Cross-Region Replication (CRR) automatically replicates objects between buckets in different AWS regions, preserving metadata and ACLs with minimal operational overhead.",
    "difficulty": "Easy",
    "choiceExplanations": {
      "1": "AWS DataSync is designed for data transfer between on-premises and AWS or between AWS storage services, but CRR is the native, lower-overhead solution for S3-to-S3 replication.",
      "2": "Lambda functions require custom code development and maintenance, increasing operational overhead compared to native S3 replication features.",
      "3": "Using EventBridge with Step Functions requires building and maintaining a custom workflow, adding unnecessary complexity when S3 CRR provides this functionality natively."
    }
  },
  {
    "id": "SAA-623",
    "domainId": "D2",
    "domain": "Design Resilient Architectures",
    "section": "S3 Replication",
    "question": "A company stores critical business documents in an Amazon S3 bucket in the us-east-1 region. The compliance team requires that all objects must be automatically replicated to a different AWS region to protect against regional failures. The solution must replicate all new objects uploaded to the source bucket.\n\nWhich S3 feature should the solutions architect configure to meet this requirement?",
    "choices": [
      "S3 Cross-Region Replication (CRR)",
      "S3 Transfer Acceleration",
      "S3 Lifecycle policies",
      "S3 Versioning only"
    ],
    "answer": 0,
    "explanation": "S3 Cross-Region Replication (CRR) automatically replicates objects across S3 buckets in different AWS regions, providing disaster recovery protection against regional failures.",
    "difficulty": "Easy",
    "choiceExplanations": {
      "1": "S3 Transfer Acceleration speeds up uploads to S3 using CloudFront edge locations but does not replicate data to another region.",
      "2": "S3 Lifecycle policies automate transitioning objects between storage classes or deleting them, but do not replicate objects to other regions.",
      "3": "S3 Versioning preserves multiple versions of objects in the same bucket but does not copy objects to another region for disaster recovery."
    }
  },
  {
    "id": "SAA-625",
    "domainId": "D2",
    "domain": "Design Resilient Architectures",
    "section": "S3 Replication",
    "question": "A company stores critical business documents in an Amazon S3 bucket in the us-east-1 region. The compliance team requires that all documents must be automatically replicated to a different AWS region to protect against regional failures. The solution should maintain the same storage class as the source objects.\n\nWhich solution meets these requirements with the LEAST operational overhead?",
    "choices": [
      "Create a Lambda function triggered by S3 events to copy objects to another region",
      "Use AWS DataSync to schedule periodic transfers to another region",
      "Configure S3 Cross-Region Replication (CRR) to automatically replicate objects to a bucket in another region",
      "Set up an EC2 instance with a cron job to sync objects between buckets using the AWS CLI"
    ],
    "answer": 2,
    "explanation": "S3 Cross-Region Replication (CRR) automatically replicates objects to a destination bucket in a different region with minimal operational overhead.",
    "difficulty": "Easy",
    "choiceExplanations": {
      "0": "Lambda functions require custom code development and maintenance, adding significant operational overhead compared to native S3 replication.",
      "1": "AWS DataSync is designed for data migration and hybrid scenarios, not for continuous automatic replication. It requires scheduling and more configuration.",
      "3": "Running an EC2 instance with cron jobs requires managing infrastructure, patching, and monitoring, creating unnecessary operational overhead."
    }
  },
  {
    "id": "SAA-626",
    "domainId": "D3",
    "domain": "Design High-Performing Architectures",
    "section": "ElastiCache",
    "question": "A company runs a web application that frequently reads the same product information from an Amazon RDS MySQL database. The database is experiencing high CPU utilization due to repetitive read queries for popular products. The application team wants to reduce database load and improve response times for these frequently accessed items.\n\nWhich AWS service should a solutions architect recommend to address this requirement?",
    "choices": [
      "Amazon Redshift",
      "AWS Direct Connect",
      "Amazon S3 Transfer Acceleration",
      "Amazon ElastiCache"
    ],
    "answer": 3,
    "explanation": "Amazon ElastiCache is an in-memory caching service that reduces database load by caching frequently accessed data, significantly improving read performance.",
    "difficulty": "Easy",
    "choiceExplanations": {
      "0": "Amazon Redshift is a data warehouse service designed for analytics and reporting workloads, not for caching frequently accessed application data.",
      "1": "AWS Direct Connect provides dedicated network connections from on-premises to AWS. It does not address database read performance or caching needs.",
      "2": "S3 Transfer Acceleration speeds up file transfers to S3 buckets over long distances. It does not cache database query results."
    }
  },
  {
    "id": "SAA-627",
    "domainId": "D3",
    "domain": "Design High-Performing Architectures",
    "section": "ElastiCache",
    "question": "A company runs a web application that frequently reads the same data from an Amazon RDS MySQL database. The database is experiencing high CPU utilization due to repetitive read queries for product catalog information that rarely changes. The solutions architect needs to reduce the database load and improve application response times.\n\nWhich solution will MOST effectively address this requirement?",
    "choices": [
      "Create additional read replicas for the RDS database",
      "Migrate the database to Amazon Aurora MySQL",
      "Implement Amazon ElastiCache to cache frequently accessed data",
      "Increase the RDS instance size to handle more queries"
    ],
    "answer": 2,
    "explanation": "Amazon ElastiCache provides an in-memory caching layer that stores frequently accessed data, reducing database load and significantly improving response times for repetitive read queries.",
    "difficulty": "Easy",
    "choiceExplanations": {
      "0": "Read replicas help distribute read traffic but still require database queries. Caching eliminates redundant queries entirely for frequently accessed, rarely changing data.",
      "1": "Aurora offers better performance than standard MySQL but doesn't address the fundamental issue of repetitive queries. Caching is more effective for static data.",
      "3": "Scaling up the instance size adds more capacity but doesn't solve the inefficiency of repeatedly querying the same unchanged data. This is a costly approach."
    }
  },
  {
    "id": "SAA-628",
    "domainId": "D3",
    "domain": "Design High-Performing Architectures",
    "section": "ElastiCache",
    "question": "A company runs a web application that queries an Amazon RDS MySQL database to display product information. The application experiences high read traffic, and users are reporting slow page load times. Analysis shows that the same product queries are being executed repeatedly, causing unnecessary load on the database.\n\nWhich solution will improve the application's read performance with minimal changes to the existing architecture?",
    "choices": [
      "Create additional read replicas for the RDS MySQL database",
      "Migrate the database from RDS MySQL to Amazon DynamoDB",
      "Enable Multi-AZ deployment for the RDS MySQL database",
      "Implement Amazon ElastiCache to cache frequently accessed query results"
    ],
    "answer": 3,
    "explanation": "Amazon ElastiCache is designed to cache frequently accessed data in memory, reducing database load and improving response times for repeated queries.",
    "difficulty": "Easy",
    "choiceExplanations": {
      "0": "Read replicas help distribute read traffic but don't eliminate redundant queries. ElastiCache is more efficient for caching repeated identical queries.",
      "1": "Migrating to DynamoDB requires significant application changes and doesn't address the core issue of repeated queries hitting the database.",
      "2": "Multi-AZ provides high availability and automatic failover, not performance improvement for read operations."
    }
  },
  {
    "id": "SAA-629",
    "domainId": "D3",
    "domain": "Design High-Performing Architectures",
    "section": "ElastiCache",
    "question": "A company runs a web application that displays product information from an Amazon RDS MySQL database. The application experiences high read traffic during business hours, causing slow response times. The product data changes infrequently throughout the day. The solutions architect needs to improve the application's read performance without modifying the database schema.\n\nWhich solution will MOST effectively improve the application's read performance?",
    "choices": [
      "Create additional read replicas for the RDS MySQL database",
      "Migrate the database to Amazon DynamoDB with on-demand capacity",
      "Enable Multi-AZ deployment for the RDS MySQL database",
      "Implement Amazon ElastiCache to cache frequently accessed product data"
    ],
    "answer": 3,
    "explanation": "Amazon ElastiCache provides in-memory caching that dramatically improves read performance for frequently accessed, infrequently changing data by reducing database load.",
    "difficulty": "Easy",
    "choiceExplanations": {
      "0": "Read replicas help distribute read traffic but still require database queries. ElastiCache provides faster in-memory access for frequently read, static data.",
      "1": "Migrating to DynamoDB requires significant application changes and schema redesign, which violates the requirement to not modify the database schema.",
      "2": "Multi-AZ deployment provides high availability and automatic failover, not improved read performance. It does not help with read-heavy workloads."
    }
  },
  {
    "id": "SAA-630",
    "domainId": "D3",
    "domain": "Design High-Performing Architectures",
    "section": "ElastiCache",
    "question": "A company runs a web application that queries a MySQL database hosted on Amazon RDS. The application frequently retrieves the same product catalog data, which changes only once per day. Users are experiencing slow response times during peak hours due to repeated database queries for this static data.\n\nWhich solution will improve the application's read performance with minimal changes to the existing architecture?",
    "choices": [
      "Implement Amazon ElastiCache to store frequently accessed product catalog data",
      "Migrate the database from Amazon RDS to Amazon DynamoDB for faster reads",
      "Create additional RDS read replicas and distribute read traffic across them",
      "Enable Amazon RDS Multi-AZ deployment to handle more read requests"
    ],
    "answer": 0,
    "explanation": "Amazon ElastiCache provides an in-memory caching layer that stores frequently accessed data, reducing database load and improving response times for repeated queries.",
    "difficulty": "Easy",
    "choiceExplanations": {
      "1": "Migrating to DynamoDB requires significant application changes and is not necessary. The issue is repeated queries for static data, which caching solves more efficiently.",
      "2": "Read replicas help distribute read traffic but still require database queries. Caching eliminates repeated queries entirely for static data, providing better performance improvement.",
      "3": "Multi-AZ deployment provides high availability through a standby instance for failover, not improved read performance. The standby cannot serve read traffic."
    }
  },
  {
    "id": "SAA-631",
    "domainId": "D3",
    "domain": "Design High-Performing Architectures",
    "section": "ElastiCache (Select TWO)",
    "question": "A company runs a web application that reads frequently from an Amazon RDS MySQL database. The database is experiencing high read load, causing slow response times for users. The solutions architect needs to implement a caching solution to improve read performance and reduce database load.\n\nWhich TWO actions should the solutions architect take to improve the application's read performance? (Choose TWO.)",
    "choices": [
      "Deploy Amazon ElastiCache for Redis between the application and the database to cache frequently accessed data",
      "Enable RDS Multi-AZ deployment to distribute read traffic across multiple Availability Zones",
      "Implement Amazon ElastiCache for Memcached to store session data and frequently queried results",
      "Enable Amazon RDS automated backups with a longer retention period",
      "Increase the RDS instance storage size to improve read throughput"
    ],
    "answer": [
      0,
      2
    ],
    "explanation": "ElastiCache for Redis and ElastiCache for Memcached are both in-memory caching solutions that reduce database read load by caching frequently accessed data, significantly improving application response times.",
    "difficulty": "Easy",
    "choiceExplanations": {
      "1": "Multi-AZ deployment provides high availability and failover support, not read scaling. Read replicas would help distribute read traffic, but Multi-AZ standby instances do not serve read traffic.",
      "3": "Automated backups provide data recovery capabilities but do not improve read performance or reduce database load during normal operations.",
      "4": "Increasing storage size affects storage capacity, not read performance. Storage IOPS and instance class affect performance, but storage size alone does not improve read throughput."
    }
  },
  {
    "id": "SAA-632",
    "domainId": "D3",
    "domain": "Design High-Performing Architectures",
    "section": "ElastiCache",
    "question": "A company runs a web application that queries an Amazon RDS MySQL database. The application frequently retrieves the same product catalog data, which changes only once per day. Users are experiencing slow response times during peak hours due to repeated database queries for this static data.\n\nWhich solution will improve the application's read performance with minimal changes to the existing architecture?",
    "choices": [
      "Create additional RDS read replicas and distribute read traffic across them",
      "Migrate the database from RDS MySQL to Amazon DynamoDB for faster reads",
      "Enable Multi-AZ deployment for the RDS database to improve read performance",
      "Implement Amazon ElastiCache to store frequently accessed product catalog data"
    ],
    "answer": 3,
    "explanation": "Amazon ElastiCache is designed to cache frequently accessed data in-memory, reducing database load and improving read performance for repetitive queries.",
    "difficulty": "Easy",
    "choiceExplanations": {
      "0": "Read replicas help distribute read traffic but still require database queries. Caching eliminates redundant queries for static data that rarely changes.",
      "1": "Migrating to DynamoDB requires significant application changes and is not minimal effort. The data access pattern suits caching better than a database migration.",
      "2": "Multi-AZ deployment provides high availability and automatic failover, not improved read performance. The standby instance cannot serve read traffic."
    }
  },
  {
    "id": "SAA-633",
    "domainId": "D3",
    "domain": "Design High-Performing Architectures",
    "section": "ElastiCache",
    "question": "A company runs a web application that frequently reads the same product information from an Amazon RDS MySQL database. The database is experiencing high read load, causing slow response times for users. The product data changes infrequently, typically only a few times per day.\n\nWhich solution will improve the application's read performance with minimal changes to the existing architecture?",
    "choices": [
      "Create multiple read replicas of the RDS database and distribute read traffic across them",
      "Migrate the database from RDS MySQL to Amazon DynamoDB for faster reads",
      "Implement Amazon ElastiCache to cache frequently accessed product data",
      "Increase the RDS instance size to a larger instance type with more CPU and memory"
    ],
    "answer": 2,
    "explanation": "Amazon ElastiCache provides in-memory caching for frequently accessed data, reducing database load and improving response times for read-heavy workloads with infrequently changing data.",
    "difficulty": "Easy",
    "choiceExplanations": {
      "0": "Read replicas help distribute load but add complexity and cost. Caching is more efficient for frequently accessed, rarely changing data.",
      "1": "Migrating to DynamoDB requires significant application changes and is not a minimal change solution. It also may not be the best fit for relational data.",
      "3": "Scaling up the instance increases costs without addressing the root cause. Caching is more cost-effective for repetitive read patterns."
    }
  },
  {
    "id": "SAA-634",
    "domainId": "D3",
    "domain": "Design High-Performing Architectures",
    "section": "ElastiCache",
    "question": "A company runs a web application that reads frequently accessed data from an Amazon RDS MySQL database. The application experiences slow response times during peak hours due to repeated database queries for the same data. The data changes infrequently throughout the day.\n\nWhich solution will improve the application's read performance with minimal changes to the existing architecture?",
    "choices": [
      "Implement Amazon ElastiCache to cache frequently accessed data",
      "Migrate the database to Amazon DynamoDB",
      "Add a read replica to the RDS MySQL database",
      "Enable Multi-AZ deployment for the RDS instance"
    ],
    "answer": 0,
    "explanation": "Amazon ElastiCache provides an in-memory caching layer that stores frequently accessed data, reducing database load and significantly improving read performance for data that changes infrequently.",
    "difficulty": "Easy",
    "choiceExplanations": {
      "1": "Migrating to DynamoDB requires significant application changes and doesn't directly address the caching need. This is not a minimal change solution.",
      "2": "Read replicas help distribute read traffic but still require database queries. Caching eliminates repeated queries entirely for frequently accessed, infrequently changing data.",
      "3": "Multi-AZ deployment provides high availability and automatic failover, not improved read performance. It's designed for disaster recovery, not performance optimization."
    }
  },
  {
    "id": "SAA-636",
    "domainId": "D3",
    "domain": "Design High-Performing Architectures",
    "section": "ElastiCache",
    "question": "A company runs a web application that frequently reads the same product information from an Amazon RDS MySQL database. The database is experiencing high read traffic, causing increased latency for users. The product data changes infrequently, typically only a few times per day.\n\nWhich solution will improve the application's read performance with minimal changes to the existing architecture?",
    "choices": [
      "Create multiple read replicas for the RDS database and distribute read traffic across them",
      "Migrate the database from RDS MySQL to Amazon DynamoDB for faster reads",
      "Implement Amazon ElastiCache to cache frequently accessed product data",
      "Enable Multi-AZ deployment for the RDS database to handle more read requests"
    ],
    "answer": 2,
    "explanation": "Amazon ElastiCache is ideal for caching frequently accessed, infrequently changing data, reducing database load and improving read latency significantly.",
    "difficulty": "Easy",
    "choiceExplanations": {
      "0": "Read replicas help distribute read traffic but add complexity and cost. Caching is more efficient for data that rarely changes.",
      "1": "Migrating to DynamoDB requires significant application changes and is not a minimal change solution for this use case.",
      "3": "Multi-AZ provides high availability and failover capability, not improved read performance. The standby instance does not serve read traffic."
    }
  },
  {
    "id": "SAA-638",
    "domainId": "D3",
    "domain": "Design High-Performing Architectures",
    "section": "CloudFront and S3 Performance (Select TWO)",
    "question": "A company hosts a popular website that serves static content including images, CSS files, and JavaScript files from an Amazon S3 bucket. Users from around the world are reporting slow page load times. The solutions architect needs to improve the performance for global users while keeping costs reasonable.\n\nWhich TWO actions should the solutions architect take to improve performance? (Choose TWO.)",
    "choices": [
      "Configure CloudFront to cache content at edge locations worldwide",
      "Enable S3 Transfer Acceleration on the bucket",
      "Enable S3 versioning to improve read performance",
      "Create an Amazon CloudFront distribution with the S3 bucket as the origin",
      "Move the S3 bucket to a region closer to the majority of users"
    ],
    "answer": [
      0,
      3
    ],
    "explanation": "CloudFront is a CDN that caches content at edge locations globally, reducing latency for users worldwide. Configuring CloudFront caching at edge locations ensures content is served from locations closest to users.",
    "difficulty": "Easy",
    "choiceExplanations": {
      "1": "S3 Transfer Acceleration improves upload speeds to S3, not download performance for end users accessing static content.",
      "2": "S3 versioning is for maintaining multiple versions of objects for data protection, not for improving read performance.",
      "4": "Moving the bucket to one region only helps users near that region and doesn't solve the global performance issue."
    }
  },
  {
    "id": "SAA-639",
    "domainId": "D3",
    "domain": "Design High-Performing Architectures",
    "section": "ElastiCache",
    "question": "A company runs a web application that retrieves product information from an Amazon RDS MySQL database. The application experiences high read traffic, and users are reporting slow response times during peak hours. Database monitoring shows that the same product queries are being executed repeatedly, causing high CPU utilization on the RDS instance.\n\nWhich solution will improve the application's read performance with minimal changes to the existing architecture?",
    "choices": [
      "Implement Amazon ElastiCache to cache frequently accessed product data",
      "Migrate the database from RDS MySQL to Amazon DynamoDB for better read performance",
      "Create multiple read replicas of the RDS instance and distribute read traffic across them",
      "Increase the RDS instance size to handle more concurrent connections"
    ],
    "answer": 0,
    "explanation": "Amazon ElastiCache provides an in-memory caching layer that stores frequently accessed data, reducing database load and improving response times for repeated queries.",
    "difficulty": "Easy",
    "choiceExplanations": {
      "1": "Migrating to DynamoDB requires significant application changes and schema redesign. This is not a minimal change solution and may not be appropriate for relational data.",
      "2": "Read replicas help distribute read traffic but don't address the inefficiency of repeatedly executing the same queries. Caching is more effective for repeated identical queries.",
      "3": "Increasing instance size adds cost but doesn't solve the fundamental problem of repeated identical queries hitting the database unnecessarily."
    }
  },
  {
    "id": "SAA-640",
    "domainId": "D3",
    "domain": "Design High-Performing Architectures",
    "section": "ElastiCache",
    "question": "A company runs a web application that reads frequently from an Amazon RDS MySQL database. The application experiences slow response times during peak hours due to repetitive database queries for the same product catalog data. The data changes infrequently, approximately once per day.\n\nWhich solution will improve the application's read performance with minimal changes to the existing architecture?",
    "choices": [
      "Implement Amazon ElastiCache to cache frequently accessed data",
      "Migrate the database from RDS MySQL to Amazon Aurora MySQL",
      "Create additional RDS read replicas and distribute read traffic across them",
      "Enable Multi-AZ deployment for the RDS database"
    ],
    "answer": 0,
    "explanation": "Amazon ElastiCache is designed to cache frequently accessed data in-memory, reducing database load and improving read performance for repetitive queries.",
    "difficulty": "Easy",
    "choiceExplanations": {
      "1": "Aurora offers better performance than MySQL but still requires database queries. Caching is more effective for frequently accessed, rarely changing data.",
      "2": "Read replicas help distribute read load but still require database queries. Caching eliminates repetitive queries entirely for better performance.",
      "3": "Multi-AZ provides high availability and failover capability, not improved read performance. It maintains a standby replica for disaster recovery."
    }
  },
  {
    "id": "SAA-642",
    "domainId": "D4",
    "domain": "Design Cost-Optimized Architectures",
    "section": "S3 Costs",
    "question": "A company stores product images in Amazon S3 Standard. Analysis shows that images are frequently accessed during the first 30 days after upload, but access drops significantly after that period. The images must remain available for immediate retrieval when needed. The company wants to reduce storage costs while maintaining performance for frequently accessed data.\n\nWhich solution will meet these requirements with the LEAST operational overhead?",
    "choices": [
      "Create an S3 Lifecycle policy to transition objects to S3 Glacier Deep Archive after 30 days.",
      "Manually move objects to S3 Standard-Infrequent Access (S3 Standard-IA) after 30 days using AWS CLI scripts.",
      "Create an S3 Lifecycle policy to transition objects to S3 Standard-Infrequent Access (S3 Standard-IA) after 30 days.",
      "Store all objects in S3 One Zone-Infrequent Access (S3 One Zone-IA) from the beginning."
    ],
    "answer": 2,
    "explanation": "S3 Lifecycle policies automate transitions to lower-cost storage classes. S3 Standard-IA provides immediate access at lower cost for infrequently accessed data.",
    "difficulty": "Easy",
    "choiceExplanations": {
      "0": "S3 Glacier Deep Archive does not provide immediate retrieval - it requires hours to restore objects, which doesn't meet the requirement for immediate access.",
      "1": "Manual scripts require significant operational overhead for scheduling, monitoring, and maintenance. Lifecycle policies automate this process without manual intervention.",
      "3": "Storing all objects in S3 One Zone-IA from the start would result in higher costs during the first 30 days when objects are frequently accessed, as S3 Standard-IA has retrieval fees."
    }
  },
  {
    "id": "SAA-644",
    "domainId": "D4",
    "domain": "Design Cost-Optimized Architectures",
    "section": "EC2 Pricing and Cost Optimization (Select TWO)",
    "question": "A startup company is deploying a new web application on AWS. The application will have predictable baseline traffic during business hours but may experience occasional traffic spikes. The company wants to minimize costs while ensuring the application remains available. The development team has confirmed that the application can tolerate brief interruptions during non-critical batch processing tasks.\n\nWhich TWO strategies should a solutions architect recommend to optimize costs? (Choose TWO.)",
    "choices": [
      "Deploy all instances in multiple Availability Zones using Dedicated Hosts",
      "Use Spot Instances for the batch processing tasks that can tolerate interruptions",
      "Purchase Reserved Instances with no upfront payment for the unpredictable traffic spikes",
      "Use On-Demand Instances for all workloads to maintain maximum flexibility",
      "Use Auto Scaling to automatically adjust capacity based on demand"
    ],
    "answer": [
      1,
      4
    ],
    "explanation": "Spot Instances offer up to 90% discount for fault-tolerant workloads like batch processing. Auto Scaling optimizes costs by matching capacity to actual demand, avoiding over-provisioning.",
    "difficulty": "Easy",
    "choiceExplanations": {
      "0": "Dedicated Hosts are the most expensive EC2 option, designed for licensing compliance or regulatory requirements, not for cost optimization.",
      "2": "Reserved Instances are designed for predictable, steady-state workloads, not for unpredictable traffic spikes. They require a 1 or 3-year commitment.",
      "3": "On-Demand Instances for all workloads is not cost-optimized. They are the most expensive option and should only be used when flexibility is required without commitment."
    }
  },
  {
    "id": "SAA-645",
    "domainId": "D4",
    "domain": "Design Cost-Optimized Architectures",
    "section": "S3 Costs",
    "question": "A company stores product images in Amazon S3. The images are frequently accessed during the first 30 days after upload but are rarely accessed afterward. The company wants to minimize storage costs while maintaining immediate access to all images when needed.\n\nWhich S3 storage class configuration will meet these requirements MOST cost-effectively?",
    "choices": [
      "Store images in S3 Standard and use an S3 Lifecycle policy to transition them to S3 Standard-IA after 30 days",
      "Store all images in S3 Standard-IA from the beginning",
      "Store all images in S3 Standard and manually move them to S3 Glacier after 30 days",
      "Store all images in S3 One Zone-IA from the beginning"
    ],
    "answer": 0,
    "explanation": "S3 Lifecycle policies automatically transition objects to cheaper storage classes like S3 Standard-IA, which provides immediate access at lower cost than S3 Standard for infrequently accessed data.",
    "difficulty": "Easy",
    "choiceExplanations": {
      "1": "S3 Standard-IA has higher retrieval costs. Using it for frequently accessed data in the first 30 days would increase costs unnecessarily.",
      "2": "Manual movement is operationally inefficient and error-prone. S3 Glacier also has retrieval delays, which doesn't meet the immediate access requirement.",
      "3": "S3 One Zone-IA stores data in a single AZ with lower durability. Using it for frequently accessed data also incurs higher retrieval costs during the first 30 days."
    }
  },
  {
    "id": "SAA-647",
    "domainId": "D4",
    "domain": "Design Cost-Optimized Architectures",
    "section": "S3 Costs",
    "question": "A company stores product images in Amazon S3. The images are frequently accessed during the first 30 days after upload, but after that, they are rarely accessed. However, when the older images are needed, they must be retrieved within seconds. The company wants to minimize storage costs while maintaining quick access to all images.\n\nWhich S3 storage class strategy should a solutions architect recommend?",
    "choices": [
      "Store all images in S3 Standard and manually move them to S3 Glacier after 30 days",
      "Store all images in S3 One Zone-Infrequent Access from the beginning",
      "Use S3 Lifecycle policies to transition objects from S3 Standard to S3 Standard-Infrequent Access after 30 days",
      "Store all images in S3 Intelligent-Tiering with no lifecycle policy"
    ],
    "answer": 2,
    "explanation": "S3 Lifecycle policies can automatically transition objects to S3 Standard-IA after 30 days, reducing costs while maintaining millisecond retrieval times.",
    "difficulty": "Easy",
    "choiceExplanations": {
      "0": "S3 Glacier has retrieval times of minutes to hours, not seconds. This does not meet the requirement for immediate access to older images.",
      "1": "S3 One Zone-IA from the start would not be cost-effective for frequently accessed images in the first 30 days due to retrieval charges.",
      "3": "S3 Intelligent-Tiering has a monthly monitoring fee per object. When access patterns are predictable (as stated), lifecycle policies are more cost-effective."
    }
  },
  {
    "id": "SAA-648",
    "domainId": "D4",
    "domain": "Design Cost-Optimized Architectures",
    "section": "S3 Costs",
    "question": "A company stores product images in Amazon S3. The images are frequently accessed during the first 30 days after upload but are rarely accessed afterward. The company wants to minimize storage costs while maintaining immediate access to all images when needed.\n\nWhich S3 storage class strategy should a solutions architect recommend?",
    "choices": [
      "Store all images in S3 Standard and manually move them to S3 Glacier after 30 days",
      "Store all images in S3 One Zone-Infrequent Access from the beginning",
      "Store all images in S3 Glacier Instant Retrieval from the beginning",
      "Store images in S3 Standard and use an S3 Lifecycle policy to transition them to S3 Standard-Infrequent Access after 30 days"
    ],
    "answer": 3,
    "explanation": "S3 Lifecycle policies automate transitions between storage classes. Moving to S3 Standard-IA after 30 days reduces costs while maintaining immediate access.",
    "difficulty": "Easy",
    "choiceExplanations": {
      "0": "Manual movement is operationally inefficient and error-prone. S3 Glacier also requires retrieval requests, not providing immediate access.",
      "1": "S3 One Zone-IA has higher retrieval costs and is not optimal for frequently accessed data in the first 30 days.",
      "2": "S3 Glacier Instant Retrieval has higher retrieval costs and is designed for rarely accessed data, making it expensive for frequently accessed images in the first 30 days."
    }
  },
  {
    "id": "SAA-651",
    "domainId": "D4",
    "domain": "Design Cost-Optimized Architectures",
    "section": "EC2 Pricing",
    "question": "A startup company is running a development environment on Amazon EC2 instances. The developers work Monday through Friday from 9 AM to 6 PM, and the instances are not needed outside of these hours. The company wants to reduce costs for these development instances while maintaining the ability to start and stop them as needed.\n\nWhich EC2 purchasing option is the MOST cost-effective for this use case?",
    "choices": [
      "Reserved Instances with a 1-year term",
      "Spot Instances",
      "Dedicated Hosts",
      "On-Demand Instances with scheduled start/stop"
    ],
    "answer": 3,
    "explanation": "On-Demand Instances with scheduled start/stop is most cost-effective because you only pay for the hours used during business hours, avoiding 24/7 costs.",
    "difficulty": "Easy",
    "choiceExplanations": {
      "0": "Reserved Instances require payment for 24/7 capacity regardless of usage. For instances running only 45 hours per week, this would be more expensive than On-Demand with scheduling.",
      "1": "Spot Instances can be interrupted by AWS with 2-minute notice, making them unsuitable for development work where developers need consistent access to their environments.",
      "2": "Dedicated Hosts are the most expensive option, designed for licensing compliance or regulatory requirements, not cost optimization for development workloads."
    }
  },
  {
    "id": "SAA-652",
    "domainId": "D4",
    "domain": "Design Cost-Optimized Architectures",
    "section": "EC2 Pricing and Cost Optimization (Select TWO)",
    "question": "A startup company is launching a new web application on AWS. The application will run on Amazon EC2 instances and is expected to have steady, predictable traffic during business hours for at least the next year. The company wants to minimize compute costs while maintaining reliable performance.\n\nWhich TWO purchasing options should the solutions architect recommend to optimize costs? (Choose TWO.)",
    "choices": [
      "Use Spot Instances for all production workloads to achieve the lowest possible cost",
      "Purchase EC2 Reserved Instances with a 1-year term for the baseline capacity",
      "Use On-Demand Instances exclusively to maintain maximum flexibility",
      "Purchase a Compute Savings Plan with a 1-year commitment for predictable workloads",
      "Deploy all instances in multiple Availability Zones using Dedicated Hosts"
    ],
    "answer": [
      1,
      3
    ],
    "explanation": "Reserved Instances and Compute Savings Plans both offer significant discounts (up to 72%) compared to On-Demand pricing for predictable, steady-state workloads with 1-year or 3-year commitments.",
    "difficulty": "Easy",
    "choiceExplanations": {
      "0": "Spot Instances can be interrupted with 2-minute notice, making them unsuitable for production workloads requiring reliable, consistent performance.",
      "2": "On-Demand Instances provide flexibility but are the most expensive option. For predictable workloads running for a year, commitment-based pricing offers substantial savings.",
      "4": "Dedicated Hosts are the most expensive EC2 option, designed for licensing compliance or regulatory requirements, not cost optimization for standard workloads."
    }
  },
  {
    "id": "SAA-654",
    "domainId": "D1",
    "domain": "Design Secure Architectures",
    "section": "Secrets Manager",
    "question": "Which AWS service is specifically designed to securely store, rotate, and manage database credentials and API keys?",
    "choices": [
      "AWS Systems Manager Parameter Store",
      "AWS Key Management Service (KMS)",
      "AWS Secrets Manager",
      "AWS Identity and Access Management (IAM)"
    ],
    "answer": 2,
    "explanation": "AWS Secrets Manager is purpose-built for storing and automatically rotating secrets like database credentials and API keys.",
    "difficulty": "Easy",
    "choiceExplanations": {
      "0": "Parameter Store can store configuration data and secrets but lacks built-in automatic rotation capabilities for database credentials.",
      "1": "KMS manages encryption keys used to encrypt data, not the storage and rotation of application secrets like passwords.",
      "3": "IAM manages user identities and permissions for AWS resources, not the storage of application secrets or credentials."
    }
  },
  {
    "id": "SAA-654",
    "domainId": "D1",
    "domain": "Design Secure Architectures",
    "section": "GuardDuty",
    "question": "A media streaming company runs its video processing workloads on Amazon EC2 instances in multiple AWS accounts. The security team has noticed unusual API activity patterns and suspects that some instances may have been compromised. They need a solution that can automatically detect potential threats such as cryptocurrency mining, unauthorized access attempts, and communication with known malicious IP addresses across all their AWS accounts with minimal operational overhead.\n\nWhich solution should a solutions architect recommend?",
    "choices": [
      "Enable Amazon GuardDuty in a delegated administrator account and configure it to monitor all member accounts in the organization.",
      "Deploy Amazon Inspector agents on all EC2 instances to continuously scan for vulnerabilities and suspicious network activity.",
      "Enable AWS CloudTrail in each account and create custom CloudWatch Alarms to detect suspicious API patterns based on predefined rules.",
      "Configure VPC Flow Logs in each account and use Amazon Athena queries to analyze traffic patterns for malicious activity."
    ],
    "answer": 0,
    "explanation": "Amazon GuardDuty uses machine learning to detect threats like cryptocurrency mining and malicious IPs across multiple accounts with minimal setup when configured with AWS Organizations.",
    "difficulty": "Medium",
    "choiceExplanations": {
      "1": "Amazon Inspector focuses on vulnerability assessments and software CVEs, not real-time threat detection like cryptocurrency mining or communication with malicious IP addresses.",
      "2": "CloudTrail with custom CloudWatch Alarms requires significant manual rule creation and maintenance. It cannot automatically detect cryptocurrency mining or correlate with threat intelligence feeds.",
      "3": "VPC Flow Logs with Athena requires manual query development and lacks built-in threat intelligence. This approach has high operational overhead and cannot detect account-level threats."
    }
  },
  {
    "id": "SAA-655",
    "domainId": "D1",
    "domain": "Design Secure Architectures",
    "section": "Secrets Manager",
    "question": "Which AWS service is specifically designed to store, rotate, and manage database credentials and API keys securely?",
    "choices": [
      "AWS Systems Manager Parameter Store",
      "AWS Key Management Service (KMS)",
      "AWS Identity and Access Management (IAM)",
      "AWS Secrets Manager"
    ],
    "answer": 3,
    "explanation": "AWS Secrets Manager is purpose-built for storing and automatically rotating secrets like database credentials and API keys.",
    "difficulty": "Easy",
    "choiceExplanations": {
      "0": "Parameter Store can store configuration data and secrets but lacks built-in automatic rotation capabilities for database credentials.",
      "1": "KMS manages encryption keys used to encrypt data, not the storage and rotation of application secrets like passwords.",
      "2": "IAM manages user identities and permissions for AWS resources, not the storage of application secrets or credentials."
    }
  },
  {
    "id": "SAA-655",
    "domainId": "D1",
    "domain": "Design Secure Architectures",
    "section": "GuardDuty",
    "question": "A media streaming company hosts its video processing workloads on Amazon EC2 instances in multiple AWS accounts. The security team has noticed unusual API activity patterns in their CloudTrail logs and suspects potential cryptocurrency mining attempts on compromised instances. They need an automated solution that can detect these threats across all accounts with minimal operational overhead.\n\nWhich solution should a solutions architect recommend?",
    "choices": [
      "Enable Amazon GuardDuty in a delegated administrator account and configure it to monitor all member accounts in the organization.",
      "Deploy Amazon Inspector agents on all EC2 instances to continuously scan for vulnerabilities and malware signatures.",
      "Enable AWS Config rules across all accounts to monitor for unauthorized EC2 instance types and trigger AWS Lambda functions for remediation.",
      "Configure Amazon CloudWatch anomaly detection on CPU utilization metrics and create alarms to notify the security team."
    ],
    "answer": 0,
    "explanation": "GuardDuty uses machine learning to detect cryptocurrency mining and other threats across multiple accounts with minimal setup when configured with AWS Organizations.",
    "difficulty": "Medium",
    "choiceExplanations": {
      "1": "Amazon Inspector assesses vulnerabilities and network exposure but does not detect active cryptocurrency mining or analyze CloudTrail logs for suspicious API activity.",
      "2": "AWS Config monitors resource configurations but does not detect cryptocurrency mining behavior or analyze API activity patterns for threat detection.",
      "3": "CloudWatch anomaly detection monitors metrics but cannot identify specific threat patterns like cryptocurrency mining or correlate suspicious API activities across accounts."
    }
  },
  {
    "id": "SAA-656",
    "domainId": "D2",
    "domain": "Design Resilient Architectures",
    "section": "S3 Replication",
    "question": "Which Amazon S3 feature automatically replicates objects across different AWS Regions to improve data durability and meet compliance requirements?",
    "choices": [
      "S3 Transfer Acceleration",
      "S3 Versioning",
      "S3 Lifecycle Policies",
      "S3 Cross-Region Replication (CRR)"
    ],
    "answer": 3,
    "explanation": "S3 Cross-Region Replication (CRR) automatically replicates objects across AWS Regions for disaster recovery and compliance.",
    "difficulty": "Easy",
    "choiceExplanations": {
      "0": "S3 Transfer Acceleration speeds up uploads using CloudFront edge locations but does not replicate data across regions.",
      "1": "S3 Versioning keeps multiple versions of objects in the same bucket but does not copy data to other regions.",
      "2": "S3 Lifecycle Policies automate transitioning objects between storage classes or deleting them, not replicating across regions."
    }
  },
  {
    "id": "SAA-656",
    "domainId": "D2",
    "domain": "Design Resilient Architectures",
    "section": "Auto Scaling",
    "question": "A healthcare company runs a patient appointment scheduling application on Amazon EC2 instances behind an Application Load Balancer. The application experiences predictable traffic spikes every weekday morning from 8 AM to 10 AM when patients call to schedule appointments. During these peak hours, the current infrastructure struggles to handle the load, causing slow response times. The company wants to ensure the application can handle the morning traffic surge without over-provisioning resources during off-peak hours. Which solution will MOST effectively address this requirement?",
    "choices": [
      "Configure Amazon EC2 Auto Scaling with a target tracking scaling policy based on average CPU utilization of 70%",
      "Configure Amazon EC2 Auto Scaling with a scheduled scaling action to increase capacity before 8 AM and decrease after 10 AM on weekdays",
      "Deploy additional EC2 instances manually each morning and terminate them after the peak period",
      "Migrate the application to AWS Lambda to automatically scale based on incoming requests"
    ],
    "answer": 1,
    "explanation": "Scheduled scaling is ideal for predictable, recurring traffic patterns. It proactively adds capacity before the known peak time, preventing performance issues.",
    "difficulty": "Medium",
    "choiceExplanations": {
      "0": "Target tracking scaling is reactive and adds instances after CPU increases. This causes delays during sudden traffic spikes, resulting in slow response times before new instances are ready.",
      "2": "Manual scaling is operationally inefficient, error-prone, and doesn't align with AWS best practices for automation. It requires human intervention daily and lacks reliability.",
      "3": "Migrating to Lambda requires significant application refactoring and may not be suitable for all workloads. The question asks for the most effective solution for the existing EC2-based architecture."
    }
  },
  {
    "id": "SAA-657",
    "domainId": "D3",
    "domain": "Design High-Performing Architectures",
    "section": "ElastiCache",
    "question": "Which AWS service provides a fully managed in-memory data store that can be used to improve application performance by caching frequently accessed data?",
    "choices": [
      "Amazon RDS",
      "Amazon DynamoDB",
      "Amazon ElastiCache",
      "Amazon Redshift"
    ],
    "answer": 2,
    "explanation": "Amazon ElastiCache is a fully managed in-memory caching service that supports Redis and Memcached to improve application performance.",
    "difficulty": "Easy",
    "choiceExplanations": {
      "0": "Amazon RDS is a managed relational database service, not an in-memory caching solution.",
      "1": "Amazon DynamoDB is a NoSQL database service. While it has DAX for caching, DynamoDB itself is not an in-memory cache.",
      "3": "Amazon Redshift is a data warehouse service for analytics, not an in-memory caching solution."
    }
  },
  {
    "id": "SAA-657",
    "domainId": "D3",
    "domain": "Design High-Performing Architectures",
    "section": "EC2 Performance",
    "question": "A genomics research company runs compute-intensive DNA sequencing workloads on Amazon EC2. The application processes large datasets stored locally and requires high sequential read/write throughput to temporary storage during analysis. Each analysis job runs for 2-4 hours and generates approximately 500 GB of intermediate data that is discarded after processing completes. The company wants to optimize storage performance while minimizing costs for this temporary data. Which storage solution should a solutions architect recommend?",
    "choices": [
      "Attach an Amazon EBS Provisioned IOPS SSD (io2) volume with 64,000 IOPS",
      "Use Amazon EFS with Max I/O performance mode mounted to the EC2 instance",
      "Store temporary data on Amazon S3 with S3 Transfer Acceleration enabled",
      "Use NVMe-based instance store volumes on a storage-optimized EC2 instance"
    ],
    "answer": 3,
    "explanation": "Instance store volumes provide the highest throughput for temporary data with no additional cost, ideal for ephemeral processing workloads.",
    "difficulty": "Medium",
    "choiceExplanations": {
      "0": "EBS io2 provides high IOPS but is expensive for temporary data that will be discarded. Instance store is included with the instance at no extra cost.",
      "1": "EFS adds network latency and is designed for shared file access across instances, not optimal for single-instance high-throughput temporary storage.",
      "2": "S3 is object storage with higher latency than local storage. Transfer Acceleration is for cross-region uploads, not local compute performance."
    }
  },
  {
    "id": "SAA-658",
    "domainId": "D4",
    "domain": "Design Cost-Optimized Architectures",
    "section": "EC2 Pricing",
    "question": "Which Amazon EC2 purchasing option provides the LOWEST cost for workloads that can be interrupted?",
    "choices": [
      "On-Demand Instances",
      "Reserved Instances",
      "Dedicated Hosts",
      "Spot Instances"
    ],
    "answer": 3,
    "explanation": "Spot Instances offer up to 90% discount compared to On-Demand pricing but can be interrupted by AWS with 2-minute notice.",
    "difficulty": "Easy",
    "choiceExplanations": {
      "0": "On-Demand Instances provide no discount and are billed at full price per hour or second with no commitment.",
      "1": "Reserved Instances require 1 or 3-year commitments and are designed for steady-state workloads, not interruptible ones.",
      "2": "Dedicated Hosts are the most expensive option, providing physical servers for compliance or licensing requirements."
    }
  },
  {
    "id": "SAA-658",
    "domainId": "D4",
    "domain": "Design Cost-Optimized Architectures",
    "section": "Cost Optimization",
    "question": "A healthcare analytics company runs batch processing jobs on Amazon EMR clusters. The jobs process patient data reports every night between 2 AM and 6 AM, and the processing time varies between 2 to 4 hours depending on data volume. The company wants to reduce costs while maintaining reliable job completion. The EMR clusters currently use On-Demand instances for both master and core nodes. Which approach provides the MOST cost-effective solution while ensuring job reliability?",
    "choices": [
      "Use Spot Instances for all master and core nodes with a single Availability Zone deployment",
      "Purchase 3-year Reserved Instances for all master and core nodes to maximize savings",
      "Use On-Demand Instances for master nodes and Spot Instances for core nodes with instance fleet configuration",
      "Use Spot Instances for master nodes and On-Demand Instances for core nodes"
    ],
    "answer": 2,
    "explanation": "Using On-Demand for master nodes ensures cluster stability while Spot Instances for core nodes with instance fleet provides cost savings and capacity flexibility.",
    "difficulty": "Medium",
    "choiceExplanations": {
      "0": "Using Spot Instances for master nodes risks cluster termination if the master is interrupted, causing job failures and data loss.",
      "1": "Reserved Instances are not cost-effective for workloads running only 4 hours daily. The utilization would be too low to justify the commitment.",
      "3": "Master nodes should never use Spot Instances as their termination would cause the entire cluster to fail, compromising job reliability."
    }
  },
  {
    "id": "SAA-659",
    "domainId": "D1",
    "domain": "Design Secure Architectures",
    "section": "Secrets Manager",
    "question": "A company is migrating a legacy application to AWS that connects to an Amazon RDS MySQL database. The application currently stores database credentials in a configuration file on the application server. The security team requires that database credentials must be rotated every 30 days without requiring application code changes or manual intervention. The solution should also encrypt the credentials at rest.\n\nWhich solution meets these requirements with the LEAST operational overhead?",
    "choices": [
      "Store the credentials in AWS Systems Manager Parameter Store as a SecureString parameter. Create an AWS Lambda function triggered by Amazon EventBridge every 30 days to rotate the credentials and update the parameter.",
      "Store the credentials in an encrypted Amazon S3 bucket using server-side encryption with AWS KMS. Create a scheduled AWS Lambda function to generate new credentials and update the S3 object every 30 days.",
      "Store the credentials in AWS Secrets Manager and enable automatic rotation with a 30-day rotation schedule. Update the application to retrieve credentials from Secrets Manager at runtime.",
      "Store the credentials in AWS Systems Manager Parameter Store as a SecureString parameter with AWS KMS encryption. Manually update the credentials every 30 days using the AWS Management Console."
    ],
    "answer": 2,
    "explanation": "AWS Secrets Manager provides native automatic rotation for RDS databases with built-in Lambda functions, encrypts secrets at rest using KMS, and requires no custom code for rotation.",
    "difficulty": "Medium",
    "choiceExplanations": {
      "0": "Parameter Store SecureString provides encryption but lacks built-in automatic rotation for RDS credentials. This requires custom Lambda code and additional operational overhead to maintain.",
      "1": "Storing credentials in S3 is not a recommended practice for secrets management. This approach requires custom rotation logic and lacks the native database integration that Secrets Manager provides.",
      "3": "This solution requires manual intervention every 30 days, which violates the requirement for no manual intervention and increases operational overhead significantly."
    }
  },
  {
    "id": "SAA-660",
    "domainId": "D1",
    "domain": "Design Secure Architectures",
    "section": "Secrets Manager",
    "question": "A company is migrating a legacy application to AWS. The application connects to an Amazon RDS MySQL database and currently stores database credentials in a configuration file on the application server. The security team requires that database credentials be stored securely, rotated automatically every 30 days, and that the application retrieves credentials programmatically without storing them locally. Which solution meets these requirements with the LEAST operational overhead?",
    "choices": [
      "Store the credentials in AWS Systems Manager Parameter Store as a SecureString parameter. Create an AWS Lambda function triggered by Amazon EventBridge every 30 days to rotate the credentials.",
      "Store the credentials in AWS Secrets Manager. Enable automatic rotation and configure the rotation schedule to 30 days.",
      "Store the credentials in an encrypted Amazon S3 bucket. Configure an S3 Lifecycle policy to rotate the credentials file every 30 days.",
      "Store the credentials in AWS Key Management Service (KMS). Use KMS key rotation to automatically rotate the credentials every 30 days."
    ],
    "answer": 1,
    "explanation": "AWS Secrets Manager provides native automatic rotation for RDS database credentials with minimal setup, meeting all requirements with least operational overhead.",
    "difficulty": "Medium",
    "choiceExplanations": {
      "0": "Parameter Store SecureString can store secrets but lacks native automatic rotation for RDS credentials - requires custom Lambda function development and maintenance.",
      "2": "S3 Lifecycle policies manage object storage transitions and expiration, not credential rotation. This approach doesn't actually rotate database passwords.",
      "3": "KMS manages encryption keys, not database credentials. KMS key rotation rotates the key material, not application secrets like database passwords."
    }
  },
  {
    "id": "SAA-661",
    "domainId": "D2",
    "domain": "Design Resilient Architectures",
    "section": "Multi-Region",
    "question": "A retail company operates a web application that serves customers across North America and Europe. The application uses an Amazon RDS MySQL database in the us-east-1 region. The company wants to improve read performance for European customers while also ensuring the database can be quickly promoted to a standalone database in eu-west-1 if the primary region becomes unavailable. The solution should minimize data loss during a regional failover.\n\nWhich solution meets these requirements?",
    "choices": [
      "Create daily automated snapshots and copy them to eu-west-1 for manual restoration if needed",
      "Enable Amazon RDS Multi-AZ deployment and configure automatic failover to eu-west-1",
      "Use AWS Database Migration Service (DMS) to continuously replicate data to a new RDS instance in eu-west-1",
      "Create an Amazon RDS Read Replica in eu-west-1 and configure the application to direct European read traffic to this replica"
    ],
    "answer": 3,
    "explanation": "RDS Cross-Region Read Replicas improve read performance in remote regions and can be promoted to standalone databases during regional failures with minimal data loss.",
    "difficulty": "Medium",
    "choiceExplanations": {
      "0": "Daily snapshots would result in up to 24 hours of data loss during failover, which does not meet the requirement to minimize data loss during regional failover.",
      "1": "Multi-AZ deployment only provides failover within the same region to a standby instance in a different Availability Zone, not cross-region failover to eu-west-1.",
      "2": "While DMS can replicate data cross-region, it adds operational complexity and is not the native solution for this use case. Read Replicas are purpose-built for this scenario."
    }
  },
  {
    "id": "SAA-662",
    "domainId": "D3",
    "domain": "Design High-Performing Architectures",
    "section": "DynamoDB Performance",
    "question": "A retail company is building an e-commerce application that stores product catalog data in Amazon DynamoDB. The application experiences highly variable traffic patterns, with read requests spiking to 10x normal levels during flash sales that occur unpredictably throughout the month. During normal operations, the table handles approximately 500 read capacity units (RCUs), but during sales events, it needs up to 5,000 RCUs. The company wants to ensure consistent low-latency reads during peak traffic while minimizing costs during normal operations. Which solution should a solutions architect recommend?",
    "choices": [
      "Provision the DynamoDB table with 5,000 RCUs to handle peak traffic at all times",
      "Use DynamoDB on-demand capacity mode for the table",
      "Create a DynamoDB global table replicated across multiple AWS Regions",
      "Enable DynamoDB Streams to buffer read requests during peak periods"
    ],
    "answer": 1,
    "explanation": "DynamoDB on-demand capacity mode automatically scales to handle traffic spikes without capacity planning, charging only for actual reads/writes used.",
    "difficulty": "Medium",
    "choiceExplanations": {
      "0": "Provisioning for peak capacity (5,000 RCUs) constantly would result in significant wasted costs during normal operations when only 500 RCUs are needed.",
      "2": "Global tables provide multi-Region replication for disaster recovery and low-latency global access, but don't address the variable capacity scaling requirement within a single Region.",
      "3": "DynamoDB Streams capture data modification events for downstream processing; they do not buffer or queue read requests and cannot help with read capacity scaling."
    }
  },
  {
    "id": "SAA-663",
    "domainId": "D4",
    "domain": "Design Cost-Optimized Architectures",
    "section": "Spot Instances",
    "question": "A media company runs a video transcoding application on Amazon EC2. The application processes uploaded videos into multiple formats and resolutions. Processing jobs typically take 15-30 minutes to complete, and the application is designed to automatically retry failed jobs. The workload is flexible and can tolerate occasional interruptions. The company wants to reduce EC2 costs by at least 60% compared to their current On-Demand instances while maintaining processing capacity.\n\nWhich solution meets these requirements?",
    "choices": [
      "Purchase 1-year EC2 Reserved Instances with partial upfront payment for the transcoding workload",
      "Deploy the application on AWS Lambda functions with provisioned concurrency enabled",
      "Use EC2 Spot Instances and configure the application to save job progress to Amazon S3 for recovery",
      "Use EC2 On-Demand Instances with Savings Plans for a 1-year commitment"
    ],
    "answer": 2,
    "explanation": "Spot Instances offer up to 90% discount over On-Demand pricing. The workload is fault-tolerant with retry capability, making it ideal for Spot.",
    "difficulty": "Medium",
    "choiceExplanations": {
      "0": "Reserved Instances provide up to 72% savings but require commitment to specific instance types. Spot offers greater savings for interruptible workloads.",
      "1": "Lambda has a 15-minute execution timeout, which cannot accommodate 15-30 minute video transcoding jobs. This solution would not work.",
      "3": "Savings Plans offer up to 72% savings but still cost more than Spot Instances. For fault-tolerant workloads, Spot provides better cost optimization."
    }
  },
  {
    "id": "SAA-664",
    "domainId": "D1",
    "domain": "Design Secure Architectures",
    "section": "KMS, S3 Security, IAM",
    "question": "A healthcare company stores protected health information (PHI) in Amazon S3 buckets across multiple AWS accounts within an AWS Organization. The security team requires that all S3 objects must be encrypted using customer managed keys (CMKs) stored in a centralized security account. They also need to ensure that even if a bucket policy is misconfigured, objects cannot be accessed without proper KMS permissions. The company wants to prevent any AWS service or principal from bypassing the encryption requirements. Additionally, they need to audit all key usage across accounts and automatically rotate keys annually.\n\nWhich combination of configurations meets these requirements with the LEAST operational overhead?",
    "choices": [
      "Create CMKs in each member account with automatic key rotation enabled. Use S3 bucket policies to enforce server-side encryption with aws:kms. Enable CloudTrail in each account to log KMS API calls. Use AWS Config rules to detect unencrypted objects.",
      "Create CMKs in the security account with imported key material for manual rotation control. Use AWS RAM to share keys across accounts. Apply SCPs to deny s3:PutObject without encryption. Use Amazon Macie to audit key usage patterns.",
      "Create CMKs in the security account and replicate them to member accounts using AWS KMS multi-Region keys. Use S3 Object Lock to prevent unauthorized access. Enable AWS Config aggregator to monitor encryption compliance across all accounts.",
      "Create CMKs in the security account with automatic key rotation enabled. Configure KMS key policies to allow cross-account access for specific IAM roles. Use S3 bucket policies with conditions requiring aws:SecureTransport and s3:x-amz-server-side-encryption-aws-kms-key-id. Enable CloudTrail with organization trail to log KMS events to a centralized bucket."
    ],
    "answer": 3,
    "explanation": "Centralized CMKs in security account with cross-account key policies, S3 bucket conditions enforcing specific KMS keys, and organization-wide CloudTrail provides centralized control, encryption enforcement, and comprehensive auditing with minimal overhead.",
    "difficulty": "Hard",
    "choiceExplanations": {
      "0": "Creating CMKs in each member account defeats the centralized key management requirement and increases operational overhead for key management and auditing across multiple accounts.",
      "1": "Imported key material requires manual rotation, increasing operational overhead. AWS RAM cannot share KMS keys directly. Macie is for sensitive data discovery, not KMS key usage auditing.",
      "2": "Multi-Region keys are for disaster recovery, not cross-account access. S3 Object Lock prevents deletion, not unauthorized access. This doesn't address the cross-account encryption requirement properly."
    }
  },
  {
    "id": "SAA-665",
    "domainId": "D1",
    "domain": "Design Secure Architectures",
    "section": "KMS, Secrets Manager, IAM",
    "question": "A financial services company is migrating a critical trading application to AWS. The application uses a multi-tier architecture with Amazon EC2 instances in private subnets, an Amazon RDS for PostgreSQL database with sensitive financial data, and integration with third-party trading APIs. The security team has the following requirements:\n\n1. Database credentials must be rotated automatically every 30 days without application downtime\n2. All data at rest must be encrypted using keys that the company controls and can audit\n3. The EC2 instances must only be able to retrieve their specific credentials, not credentials for other applications\n4. API keys for third-party services must be stored securely and accessed programmatically\n5. All access to secrets must be logged for compliance auditing\n\nWhich combination of AWS services and configurations meets ALL of these requirements?",
    "choices": [
      "Store database credentials in AWS Secrets Manager with automatic rotation enabled using a Lambda rotation function. Store API keys in Secrets Manager without rotation. Use customer managed KMS keys for encryption. Attach IAM policies to EC2 instance roles with resource tags and conditions to restrict secret access. Enable CloudTrail logging.",
      "Store all credentials in AWS Systems Manager Parameter Store SecureString parameters encrypted with AWS managed keys. Use IAM instance profiles with resource-based policies to restrict access. Enable AWS CloudTrail to log Parameter Store API calls.",
      "Store all credentials in an encrypted Amazon S3 bucket using SSE-KMS with customer managed keys. Create a Lambda function triggered by EventBridge every 30 days to rotate credentials. Use S3 bucket policies to restrict access per application. Enable S3 access logging and CloudTrail.",
      "Store credentials in AWS Secrets Manager encrypted with AWS managed keys. Enable automatic rotation for all secrets. Use VPC endpoints with endpoint policies to restrict access. Configure Amazon GuardDuty to monitor for unauthorized access attempts."
    ],
    "answer": 0,
    "explanation": "AWS Secrets Manager with Lambda rotation functions supports automatic credential rotation for RDS. Customer managed KMS keys provide control and auditability. IAM policies with conditions and resource tags enable granular per-application access control. CloudTrail logs all Secrets Manager API calls.",
    "difficulty": "Hard",
    "choiceExplanations": {
      "1": "Parameter Store SecureString doesn't support automatic rotation natively - requires custom implementation. AWS managed keys don't provide the customer control and audit capabilities required for compliance.",
      "2": "S3 is not designed for secrets management. Custom Lambda rotation lacks native RDS integration that Secrets Manager provides. This approach doesn't handle credential rotation without application downtime effectively.",
      "3": "AWS managed keys don't meet the requirement for customer-controlled keys with audit capabilities. VPC endpoints alone don't provide per-application access restriction. GuardDuty monitors for threats but doesn't provide the compliance audit logging required."
    }
  },
  {
    "id": "SAA-666",
    "domainId": "D2",
    "domain": "Design Resilient Architectures",
    "section": "Multi-Region Disaster Recovery",
    "question": "A financial services company operates a critical trading platform hosted in us-east-1. The platform uses Amazon RDS for PostgreSQL with Multi-AZ deployment, Amazon ElastiCache for Redis for session management, and stores transaction logs in Amazon S3. Regulatory requirements mandate that the platform must be recoverable in a different AWS Region within 15 minutes (RTO) with no more than 1 minute of data loss (RPO). The company wants to minimize costs while meeting these strict requirements. During normal operations, the DR region should not serve any production traffic. Which combination of services and configurations will meet these requirements MOST cost-effectively?",
    "choices": [
      "Create an RDS cross-Region read replica in us-west-2 with automated promotion. Use ElastiCache Global Datastore for Redis. Configure S3 Cross-Region Replication with Replication Time Control. Deploy the application on EC2 instances in us-west-2 in a stopped state. Use Route 53 health checks with DNS failover.",
      "Use AWS Database Migration Service for continuous replication to a standby RDS instance in us-west-2. Create ElastiCache snapshots every minute and copy to us-west-2. Enable S3 Cross-Region Replication. Use AWS Lambda to launch EC2 instances during failover.",
      "Configure RDS automated backups with cross-Region backup replication to us-west-2. Use ElastiCache backup and restore. Enable S3 Cross-Region Replication. Deploy Auto Scaling groups in us-west-2 with desired capacity set to zero. Use Route 53 failover routing.",
      "Create an Aurora PostgreSQL Global Database spanning us-east-1 and us-west-2. Use ElastiCache Global Datastore for Redis. Configure S3 Cross-Region Replication with Replication Time Control. Deploy the application using AWS Elastic Beanstalk in us-west-2 with zero running instances. Use Route 53 health checks with failover routing."
    ],
    "answer": 0,
    "explanation": "RDS cross-Region read replica provides sub-minute RPO with fast promotion. ElastiCache Global Datastore enables sub-second replication. S3 CRR with RTC ensures 15-minute replication SLA. Stopped EC2 instances minimize costs while enabling quick startup.",
    "difficulty": "Hard",
    "choiceExplanations": {
      "1": "DMS adds unnecessary complexity and cost for this use case. ElastiCache snapshots every minute cannot meet 1-minute RPO due to snapshot creation time. Lambda-based EC2 launch adds latency that may exceed 15-minute RTO.",
      "2": "RDS automated backup replication has hours of RPO, not meeting the 1-minute requirement. ElastiCache backup and restore is too slow for 15-minute RTO. This approach is suitable for pilot light but not for strict RPO requirements.",
      "3": "Aurora Global Database is more expensive than RDS cross-Region read replica and exceeds cost optimization requirements. While technically capable, the question asks for the MOST cost-effective solution, and Aurora pricing is significantly higher than standard RDS PostgreSQL."
    }
  },
  {
    "id": "SAA-667",
    "domainId": "D3",
    "domain": "Design High-Performing Architectures",
    "section": "DynamoDB Performance",
    "question": "A financial services company operates a high-frequency trading platform that processes millions of transactions per second. The platform uses Amazon DynamoDB to store real-time market data with a table that has a partition key of 'stock_symbol' and sort key of 'timestamp'. During peak trading hours, the application experiences throttling on specific partitions because 15 highly-traded stocks account for 80% of all read and write operations. The table uses provisioned capacity mode with 50,000 RCUs and 30,000 WCUs. The company requires sub-millisecond read latency for the most frequently accessed data while maintaining cost efficiency. The solution must handle sudden traffic spikes without manual intervention and ensure consistent performance across all stock symbols.\n\nWhich combination of solutions will BEST address the hot partition issue while meeting the latency and scalability requirements?",
    "choices": [
      "Enable DynamoDB on-demand capacity mode and implement write sharding by appending a random suffix to the partition key for hot stocks",
      "Enable DynamoDB Accelerator (DAX) for read operations and implement write sharding by appending a calculated suffix (0-9) to the partition key based on a hash of the timestamp",
      "Increase the provisioned capacity to 100,000 RCUs and 60,000 WCUs, and enable DynamoDB auto scaling with a target utilization of 50%",
      "Create a Global Secondary Index with a different partition key distribution and enable DynamoDB Streams to populate an ElastiCache Redis cluster for reads"
    ],
    "answer": 1,
    "explanation": "DAX provides sub-millisecond read latency for cached data, while write sharding with a calculated suffix distributes writes across multiple partitions, solving the hot partition problem while maintaining query predictability.",
    "difficulty": "Hard",
    "choiceExplanations": {
      "0": "On-demand mode helps with capacity but doesn't solve hot partition issues. Random suffixes make querying difficult since you can't predict which partition contains specific data without scanning all shards.",
      "2": "Simply increasing provisioned capacity doesn't solve hot partition problems - DynamoDB has per-partition limits (3,000 RCUs/1,000 WCUs per partition) regardless of total table capacity.",
      "3": "GSIs inherit the same partition limits and would still experience hot partitions. Adding ElastiCache adds complexity and doesn't address the write throttling issue on the base table."
    }
  },
  {
    "id": "SAA-668",
    "domainId": "D4",
    "domain": "Design Cost-Optimized Architectures",
    "section": "Cost Optimization",
    "question": "A financial services company runs a data analytics platform on AWS that processes market data. The platform consists of three workload types: a web application tier running 24/7 with predictable traffic patterns, a batch processing cluster that runs for 8 hours daily during market hours with strict completion deadlines, and a machine learning training pipeline that runs overnight with flexible completion times and can tolerate interruptions. The company has analyzed 12 months of usage data showing consistent patterns. They want to minimize costs while ensuring the batch processing jobs always complete on time. The web tier uses m6i.xlarge instances, the batch cluster uses c6i.2xlarge instances, and the ML training uses p3.2xlarge GPU instances. Which combination of purchasing options provides the MOST cost-effective solution while meeting all requirements?",
    "choices": [
      "Purchase 3-year Compute Savings Plans for all workloads to maximize the discount rate across all instance types and sizes.",
      "Use On-Demand Instances for the web tier, Spot Instances with Spot Fleet for the batch processing cluster, and Reserved Instances for the ML training pipeline.",
      "Purchase 3-year Standard Reserved Instances for the web tier, use Spot Instances with On-Demand fallback in an Auto Scaling group for the batch processing cluster, and use Spot Instances for the ML training pipeline.",
      "Purchase 1-year EC2 Instance Savings Plans for the web tier baseline, use On-Demand Instances for the batch processing cluster, and use Spot Instances with checkpointing for the ML training pipeline."
    ],
    "answer": 3,
    "explanation": "EC2 Instance Savings Plans provide significant discounts for the predictable web tier, On-Demand ensures batch jobs complete on time, and Spot Instances are ideal for interruptible ML workloads.",
    "difficulty": "Hard",
    "choiceExplanations": {
      "0": "3-year Compute Savings Plans for all workloads is wasteful - the batch processing only runs 8 hours daily and ML training runs overnight, so committing to 24/7 coverage wastes money on unused capacity.",
      "1": "Using Spot Instances for batch processing with strict deadlines is risky - Spot interruptions could cause jobs to miss completion deadlines. Reserved Instances for overnight-only ML training wastes money during unused hours.",
      "2": "Standard Reserved Instances lack flexibility if instance needs change. Using Spot with On-Demand fallback for time-critical batch processing adds complexity and may still cause delays during Spot interruptions when scaling up."
    }
  }
]