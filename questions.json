[
  {
    "id": "SAA-001",
    "domainId": "D1",
    "domain": "Design Secure Architectures",
    "section": "IAM",
    "question": "Which feature lets you grant temporary permissions to access AWS resources?",
    "choices": [
      "Resource Tags",
      "IAM Roles",
      "IAM Groups",
      "IAM Users"
    ],
    "answer": 1,
    "explanation": "IAM Roles provide temporary credentials and are commonly assumed by services/users.",
    "difficulty": "Easy"
  },
  {
    "id": "SAA-002",
    "domainId": "D1",
    "domain": "Design Secure Architectures",
    "section": "IAM",
    "question": "What is the best practice for the AWS account root user?",
    "choices": [
      "Share it with admins",
      "Enable MFA and avoid using it",
      "Disable it",
      "Use it daily"
    ],
    "answer": 1,
    "explanation": "Best practice: enable MFA on root and use it only for rare account tasks.",
    "difficulty": "Easy"
  },
  {
    "id": "SAA-003",
    "domainId": "D1",
    "domain": "Design Secure Architectures",
    "section": "KMS",
    "question": "Which AWS service manages encryption keys used to encrypt data in AWS services?",
    "choices": [
      "AWS KMS",
      "AWS Budgets",
      "AWS Shield",
      "Amazon Inspector"
    ],
    "answer": 0,
    "explanation": "AWS KMS manages keys and integrates with many AWS services for encryption.",
    "difficulty": "Easy"
  },
  {
    "id": "SAA-004",
    "domainId": "D1",
    "domain": "Design Secure Architectures",
    "section": "S3",
    "question": "Which S3 feature prevents objects from being deleted or overwritten for a retention period?",
    "choices": [
      "S3 Select",
      "S3 Transfer Acceleration",
      "S3 Inventory",
      "S3 Object Lock"
    ],
    "answer": 3,
    "explanation": "S3 Object Lock helps enforce WORM (write once, read many) retention.",
    "difficulty": "Easy"
  },
  {
    "id": "SAA-005",
    "domainId": "D1",
    "domain": "Design Secure Architectures",
    "section": "VPC",
    "question": "Which VPC component acts as a virtual firewall at the instance level?",
    "choices": [
      "Route Table",
      "Internet Gateway",
      "Network ACL",
      "Security Group"
    ],
    "answer": 3,
    "explanation": "Security Groups are stateful and apply at the ENI/instance level.",
    "difficulty": "Easy"
  },
  {
    "id": "SAA-006",
    "domainId": "D1",
    "domain": "Design Secure Architectures",
    "section": "VPC",
    "question": "Which VPC component is stateless and filters traffic at the subnet boundary?",
    "choices": [
      "NAT Gateway",
      "Network ACL",
      "VPC Peering",
      "Security Group"
    ],
    "answer": 1,
    "explanation": "Network ACLs are stateless and operate at the subnet level.",
    "difficulty": "Easy"
  },
  {
    "id": "SAA-007",
    "domainId": "D1",
    "domain": "Design Secure Architectures",
    "section": "CloudWatch",
    "question": "Which service records AWS API calls for auditing and compliance?",
    "choices": [
      "Config",
      "CloudWatch",
      "CloudTrail",
      "X-Ray"
    ],
    "answer": 2,
    "explanation": "CloudTrail logs API activity (who did what, when, and from where).",
    "difficulty": "Easy"
  },
  {
    "id": "SAA-008",
    "domainId": "D1",
    "domain": "Design Secure Architectures",
    "section": "CloudFront",
    "question": "To block common web exploits (like SQL injection) in front of a CloudFront distribution, what should you use?",
    "choices": [
      "AWS Config",
      "Amazon EBS",
      "AWS WAF",
      "AWS KMS"
    ],
    "answer": 2,
    "explanation": "AWS WAF integrates with CloudFront (and ALB/API Gateway) to filter malicious HTTP requests.",
    "difficulty": "Easy"
  },
  {
    "id": "SAA-009",
    "domainId": "D1",
    "domain": "Design Secure Architectures",
    "section": "RDS",
    "question": "Where should you store database credentials securely with automatic rotation support?",
    "choices": [
      "AWS Secrets Manager",
      "CloudWatch Logs",
      "Hardcode in app config",
      "S3 Standard"
    ],
    "answer": 0,
    "explanation": "Secrets Manager is designed for secrets storage and rotation workflows.",
    "difficulty": "Easy"
  },
  {
    "id": "SAA-010",
    "domainId": "D1",
    "domain": "Design Secure Architectures",
    "section": "S3",
    "question": "How do you restrict S3 access so only CloudFront can read objects privately?",
    "choices": [
      "Use an Origin Access Control/Identity with bucket policy",
      "Disable Block Public Access",
      "Use S3 website hosting",
      "Make the bucket public"
    ],
    "answer": 0,
    "explanation": "Use CloudFront OAC/OAI + a bucket policy to keep S3 private.",
    "difficulty": "Easy"
  },
  {
    "id": "SAA-011",
    "domainId": "D2",
    "domain": "Design Resilient Architectures",
    "section": "ELB",
    "question": "Which load balancer feature helps route traffic to healthy targets only?",
    "choices": [
      "TLS termination",
      "Path rewriting",
      "Health checks",
      "Sticky sessions"
    ],
    "answer": 2,
    "explanation": "Health checks detect unhealthy targets so traffic stops routing to them.",
    "difficulty": "Easy"
  },
  {
    "id": "SAA-012",
    "domainId": "D2",
    "domain": "Design Resilient Architectures",
    "section": "Auto Scaling",
    "question": "What AWS feature automatically replaces unhealthy EC2 instances in a fleet?",
    "choices": [
      "EC2 Spot",
      "Auto Scaling Group",
      "AWS Batch",
      "Elastic Beanstalk"
    ],
    "answer": 1,
    "explanation": "ASGs can perform health checks and replace unhealthy instances.",
    "difficulty": "Easy"
  },
  {
    "id": "SAA-013",
    "domainId": "D2",
    "domain": "Design Resilient Architectures",
    "section": "RDS",
    "question": "Which RDS option provides automatic failover to a standby in another AZ?",
    "choices": [
      "Multi-AZ",
      "Reserved Instances",
      "Read Replica",
      "RDS Proxy"
    ],
    "answer": 0,
    "explanation": "Multi-AZ is for HA and automatic failover across AZs.",
    "difficulty": "Easy"
  },
  {
    "id": "SAA-014",
    "domainId": "D2",
    "domain": "Design Resilient Architectures",
    "section": "Route 53",
    "question": "Which Route 53 policy routes traffic to the endpoint with the lowest latency?",
    "choices": [
      "Weighted",
      "Geolocation",
      "Latency-based",
      "Failover"
    ],
    "answer": 2,
    "explanation": "Latency-based routing selects the region/endpoint with the lowest latency.",
    "difficulty": "Easy"
  },
  {
    "id": "SAA-015",
    "domainId": "D2",
    "domain": "Design Resilient Architectures",
    "section": "S3",
    "question": "Which S3 feature replicates objects automatically to another region?",
    "choices": [
      "S3 Glacier",
      "S3 CRR",
      "S3 Object Lambda",
      "S3 Select"
    ],
    "answer": 1,
    "explanation": "Cross-Region Replication (CRR) replicates objects to another region.",
    "difficulty": "Easy"
  },
  {
    "id": "SAA-016",
    "domainId": "D2",
    "domain": "Design Resilient Architectures",
    "section": "EBS",
    "question": "EBS volumes are replicated within which scope by default?",
    "choices": [
      "Across accounts",
      "Across regions",
      "Within a single AZ",
      "Across AZs"
    ],
    "answer": 2,
    "explanation": "EBS is AZ-scoped; it replicates within the same AZ for durability.",
    "difficulty": "Easy"
  },
  {
    "id": "SAA-017",
    "domainId": "D2",
    "domain": "Design Resilient Architectures",
    "section": "DynamoDB",
    "question": "Which DynamoDB feature provides multi-region, active-active replication?",
    "choices": [
      "Global Tables",
      "TTL",
      "DAX",
      "Streams"
    ],
    "answer": 0,
    "explanation": "DynamoDB Global Tables supports multi-region active-active replication.",
    "difficulty": "Easy"
  },
  {
    "id": "SAA-018",
    "domainId": "D2",
    "domain": "Design Resilient Architectures",
    "section": "SQS",
    "question": "Which service decouples components by buffering messages for later processing?",
    "choices": [
      "EFS",
      "CloudFront",
      "SQS",
      "SNS"
    ],
    "answer": 2,
    "explanation": "SQS is a message queue used to decouple and buffer workloads.",
    "difficulty": "Easy"
  },
  {
    "id": "SAA-019",
    "domainId": "D2",
    "domain": "Design Resilient Architectures",
    "section": "Lambda",
    "question": "What happens if an SQS-triggered Lambda cannot process a message repeatedly?",
    "choices": [
      "Message disappears immediately",
      "Queue is deleted",
      "Lambda shuts down permanently",
      "Message is moved to a DLQ (if configured)"
    ],
    "answer": 3,
    "explanation": "After retries/max receive count, messages can go to a DLQ if configured.",
    "difficulty": "Easy"
  },
  {
    "id": "SAA-020",
    "domainId": "D2",
    "domain": "Design Resilient Architectures",
    "section": "CloudFront",
    "question": "Which CloudFront feature helps keep content available if the primary origin fails?",
    "choices": [
      "Cache invalidations",
      "Origin failover",
      "Geo restriction only",
      "Signed URLs only"
    ],
    "answer": 1,
    "explanation": "Origin failover can route requests to a secondary origin if the primary fails.",
    "difficulty": "Easy"
  },
  {
    "id": "SAA-021",
    "domainId": "D3",
    "domain": "Design High-Performing Architectures",
    "section": "CloudFront",
    "question": "What is the main benefit of CloudFront for global users?",
    "choices": [
      "Cheaper EC2",
      "Lower latency via edge caching",
      "Faster RDS writes",
      "More durable EBS"
    ],
    "answer": 1,
    "explanation": "CloudFront caches content at edge locations, reducing latency for users.",
    "difficulty": "Easy"
  },
  {
    "id": "SAA-022",
    "domainId": "D3",
    "domain": "Design High-Performing Architectures",
    "section": "S3",
    "question": "Which S3 feature lets you retrieve only a portion of an object using SQL-like queries?",
    "choices": [
      "S3 Object Lock",
      "S3 Batch Operations",
      "S3 CRR",
      "S3 Select"
    ],
    "answer": 3,
    "explanation": "S3 Select can query subsets of data from an object (like CSV/JSON) to reduce data transfer.",
    "difficulty": "Easy"
  },
  {
    "id": "SAA-023",
    "domainId": "D3",
    "domain": "Design High-Performing Architectures",
    "section": "EFS",
    "question": "Which storage is best for a shared POSIX file system across multiple EC2 instances?",
    "choices": [
      "S3 Standard",
      "Instance Store",
      "EBS",
      "EFS"
    ],
    "answer": 3,
    "explanation": "EFS is a managed NFS file system that can be mounted by many instances.",
    "difficulty": "Easy"
  },
  {
    "id": "SAA-024",
    "domainId": "D3",
    "domain": "Design High-Performing Architectures",
    "section": "EC2",
    "question": "Which feature increases network throughput for supported EC2 instance types?",
    "choices": [
      "AMI Copy",
      "Placement Groups",
      "Enhanced Networking",
      "EBS Snapshots"
    ],
    "answer": 2,
    "explanation": "Enhanced networking (ENA) improves packet per second and throughput.",
    "difficulty": "Easy"
  },
  {
    "id": "SAA-025",
    "domainId": "D3",
    "domain": "Design High-Performing Architectures",
    "section": "ELB",
    "question": "Which load balancer is best for HTTP/HTTPS with path-based routing?",
    "choices": [
      "ALB",
      "Classic Load Balancer only",
      "NLB",
      "GWLB"
    ],
    "answer": 0,
    "explanation": "ALB supports Layer 7 routing features like host/path-based routing.",
    "difficulty": "Easy"
  },
  {
    "id": "SAA-026",
    "domainId": "D3",
    "domain": "Design High-Performing Architectures",
    "section": "DynamoDB",
    "question": "Which DynamoDB feature accelerates read-heavy workloads with in-memory caching?",
    "choices": [
      "DAX",
      "TTL",
      "Global Secondary Index",
      "Streams"
    ],
    "answer": 0,
    "explanation": "DynamoDB Accelerator (DAX) is an in-memory cache for read performance.",
    "difficulty": "Easy"
  },
  {
    "id": "SAA-027",
    "domainId": "D3",
    "domain": "Design High-Performing Architectures",
    "section": "RDS",
    "question": "What is the main purpose of an RDS Read Replica?",
    "choices": [
      "Encrypt the database",
      "Reduce storage costs",
      "Scale reads and offload reporting queries",
      "Automatic failover"
    ],
    "answer": 2,
    "explanation": "Read replicas are for scaling reads, not for automatic HA failover.",
    "difficulty": "Easy"
  },
  {
    "id": "SAA-028",
    "domainId": "D3",
    "domain": "Design High-Performing Architectures",
    "section": "EBS",
    "question": "Which EBS volume type is generally best for general-purpose SSD workloads with tunable performance?",
    "choices": [
      "gp3",
      "st1",
      "sc1",
      "Glacier Instant Retrieval"
    ],
    "answer": 0,
    "explanation": "gp3 provides good baseline performance and can be provisioned for higher IOPS/throughput.",
    "difficulty": "Easy"
  },
  {
    "id": "SAA-029",
    "domainId": "D3",
    "domain": "Design High-Performing Architectures",
    "section": "SQS",
    "question": "Which SQS feature reduces empty receives by waiting for messages before returning a response?",
    "choices": [
      "FIFO ordering",
      "Dead-letter queue",
      "Message deduplication",
      "Long polling"
    ],
    "answer": 3,
    "explanation": "Long polling waits up to the configured time for messages, reducing empty responses and cost.",
    "difficulty": "Easy"
  },
  {
    "id": "SAA-030",
    "domainId": "D3",
    "domain": "Design High-Performing Architectures",
    "section": "SQS",
    "question": "Which SQS type preserves message order and supports exactly-once processing?",
    "choices": [
      "Standard",
      "FIFO",
      "Priority",
      "Delayed"
    ],
    "answer": 1,
    "explanation": "SQS FIFO provides ordering and exactly-once processing (within FIFO semantics).",
    "difficulty": "Easy"
  },
  {
    "id": "SAA-031",
    "domainId": "D4",
    "domain": "Design Cost-Optimized Architectures",
    "section": "EC2",
    "question": "Which EC2 pricing model offers the biggest discount for interruptible workloads?",
    "choices": [
      "Savings Plans only",
      "Spot Instances",
      "Reserved Instances",
      "On-Demand"
    ],
    "answer": 1,
    "explanation": "Spot Instances are discounted but can be interrupted when capacity is needed.",
    "difficulty": "Easy"
  },
  {
    "id": "SAA-032",
    "domainId": "D4",
    "domain": "Design Cost-Optimized Architectures",
    "section": "S3",
    "question": "Which S3 storage class is best for rarely accessed data with milliseconds retrieval?",
    "choices": [
      "S3 Glacier Deep Archive",
      "S3 One Zone-IA (always best)",
      "S3 Standard-IA",
      "S3 Standard"
    ],
    "answer": 2,
    "explanation": "Standard-IA is for infrequently accessed data with low storage cost and millisecond access.",
    "difficulty": "Easy"
  },
  {
    "id": "SAA-033",
    "domainId": "D4",
    "domain": "Design Cost-Optimized Architectures",
    "section": "S3",
    "question": "Which S3 feature automatically moves objects between storage tiers based on access patterns?",
    "choices": [
      "S3 Object Lock",
      "S3 Select",
      "S3 Intelligent-Tiering",
      "S3 Transfer Acceleration"
    ],
    "answer": 2,
    "explanation": "Intelligent-Tiering optimizes cost by moving objects between access tiers.",
    "difficulty": "Easy"
  },
  {
    "id": "SAA-034",
    "domainId": "D4",
    "domain": "Design Cost-Optimized Architectures",
    "section": "CloudWatch",
    "question": "Which CloudWatch feature notifies you when a metric crosses a threshold?",
    "choices": [
      "CloudWatch Dashboards only",
      "CloudWatch Logs only",
      "CloudWatch Events only",
      "CloudWatch Alarms"
    ],
    "answer": 3,
    "explanation": "CloudWatch Alarms watch metrics and can trigger actions/notifications when thresholds are breached.",
    "difficulty": "Easy"
  },
  {
    "id": "SAA-035",
    "domainId": "D4",
    "domain": "Design Cost-Optimized Architectures",
    "section": "Auto Scaling",
    "question": "For unpredictable spiky traffic, which approach avoids paying for idle EC2 capacity most effectively?",
    "choices": [
      "Use Auto Scaling Group with policies",
      "Use Dedicated Hosts",
      "Disable scaling and accept downtime",
      "Run one very large instance"
    ],
    "answer": 0,
    "explanation": "Auto Scaling matches capacity to demand, reducing idle cost while maintaining availability.",
    "difficulty": "Easy"
  },
  {
    "id": "SAA-036",
    "domainId": "D4",
    "domain": "Design Cost-Optimized Architectures",
    "section": "RDS",
    "question": "Which approach can reduce RDS connection overhead for spiky Lambda traffic?",
    "choices": [
      "Increase instance size always",
      "RDS Proxy",
      "Disable backups",
      "Use Multi-AZ only"
    ],
    "answer": 1,
    "explanation": "RDS Proxy pools and reuses connections, reducing overhead in bursty workloads.",
    "difficulty": "Easy"
  },
  {
    "id": "SAA-037",
    "domainId": "D4",
    "domain": "Design Cost-Optimized Architectures",
    "section": "EBS",
    "question": "Which action can reduce EBS snapshot storage costs over time?",
    "choices": [
      "Turn off encryption",
      "Use larger volumes",
      "Delete old/unused snapshots",
      "Disable backups forever"
    ],
    "answer": 2,
    "explanation": "Deleting unused snapshots reduces storage costs.",
    "difficulty": "Easy"
  },
  {
    "id": "SAA-038",
    "domainId": "D4",
    "domain": "Design Cost-Optimized Architectures",
    "section": "S3",
    "question": "Which storage class is typically the lowest cost for long-term archival with hours retrieval?",
    "choices": [
      "S3 Standard-IA",
      "S3 Standard",
      "S3 Glacier Deep Archive",
      "S3 Glacier Flexible Retrieval"
    ],
    "answer": 2,
    "explanation": "Deep Archive is designed for lowest-cost archival with slower retrieval.",
    "difficulty": "Easy"
  },
  {
    "id": "SAA-039",
    "domainId": "D4",
    "domain": "Design Cost-Optimized Architectures",
    "section": "CloudFront",
    "question": "How can CloudFront reduce costs for a global audience?",
    "choices": [
      "By replacing IAM",
      "By caching content at the edge to reduce origin load and transfer",
      "By increasing RDS IOPS",
      "By disabling TLS"
    ],
    "answer": 1,
    "explanation": "Edge caching reduces origin requests and can reduce backend load and data transfer.",
    "difficulty": "Easy"
  },
  {
    "id": "SAA-040",
    "domainId": "D4",
    "domain": "Design Cost-Optimized Architectures",
    "section": "EC2",
    "question": "Which commitment generally lowers compute cost for steady-state usage over 1–3 years?",
    "choices": [
      "Always Spot",
      "On-Demand only",
      "Always Dedicated Hosts",
      "Reserved Instances or Savings Plans"
    ],
    "answer": 3,
    "explanation": "Reservations/Savings Plans provide discounts for committed usage.",
    "difficulty": "Easy"
  },
  {
    "id": "SAA-041",
    "domainId": "D1",
    "domain": "Design Secure Architectures",
    "section": "IAM",
    "question": "In IAM evaluation, what happens if a request matches an explicit Deny and an Allow?",
    "choices": [
      "Deny wins",
      "It depends on the service",
      "The request is retried",
      "Allow wins"
    ],
    "answer": 0,
    "explanation": "Explicit Deny always overrides Allow in IAM policy evaluation.",
    "difficulty": "Easy"
  },
  {
    "id": "SAA-042",
    "domainId": "D1",
    "domain": "Design Secure Architectures",
    "section": "VPC",
    "question": "What enables private connectivity from a VPC to supported AWS services without internet?",
    "choices": [
      "Public Subnet",
      "VPC Endpoints",
      "VPC Peering",
      "Internet Gateway"
    ],
    "answer": 1,
    "explanation": "VPC endpoints (Gateway/Interface) provide private access to AWS services.",
    "difficulty": "Easy"
  },
  {
    "id": "SAA-043",
    "domainId": "D1",
    "domain": "Design Secure Architectures",
    "section": "KMS",
    "question": "Which S3 server-side encryption option uses KMS-managed keys?",
    "choices": [
      "SSE-S3",
      "Unencrypted",
      "Client-side only",
      "SSE-KMS"
    ],
    "answer": 3,
    "explanation": "SSE-KMS uses AWS KMS keys to encrypt S3 objects.",
    "difficulty": "Easy"
  },
  {
    "id": "SAA-044",
    "domainId": "D2",
    "domain": "Design Resilient Architectures",
    "section": "EFS",
    "question": "EFS offers high availability primarily by being accessible across what?",
    "choices": [
      "Multiple regions by default",
      "Only one AZ",
      "Only one subnet",
      "Multiple AZs in a region"
    ],
    "answer": 3,
    "explanation": "EFS is a regional service and is designed to be accessible across multiple AZs.",
    "difficulty": "Easy"
  },
  {
    "id": "SAA-045",
    "domainId": "D2",
    "domain": "Design Resilient Architectures",
    "section": "SQS",
    "question": "What is the main difference between SQS Standard and FIFO?",
    "choices": [
      "FIFO preserves order and supports exactly-once processing",
      "FIFO is faster for unlimited throughput always",
      "Standard requires VPC endpoints",
      "Standard is encrypted, FIFO is not"
    ],
    "answer": 0,
    "explanation": "FIFO preserves ordering and avoids duplicates (within FIFO semantics).",
    "difficulty": "Easy"
  },
  {
    "id": "SAA-046",
    "domainId": "D3",
    "domain": "Design High-Performing Architectures",
    "section": "VPC",
    "question": "Which design improves throughput between EC2 instances with low network latency needs?",
    "choices": [
      "Cluster Placement Group",
      "Use only public IPs",
      "Spread Placement Group",
      "Disable security groups"
    ],
    "answer": 0,
    "explanation": "Cluster placement groups provide low-latency, high-throughput networking in a single AZ.",
    "difficulty": "Easy"
  },
  {
    "id": "SAA-047",
    "domainId": "D4",
    "domain": "Design Cost-Optimized Architectures",
    "section": "S3",
    "question": "To reduce storage costs for objects with known lifecycle, what should you use?",
    "choices": [
      "S3 Lifecycle rules",
      "S3 Inventory only",
      "IAM Policy Simulator",
      "CloudTrail"
    ],
    "answer": 0,
    "explanation": "Lifecycle rules can transition objects to cheaper classes or expire them automatically.",
    "difficulty": "Easy"
  },
  {
    "id": "SAA-048",
    "domainId": "D3",
    "domain": "Design High-Performing Architectures",
    "section": "Lambda",
    "question": "Which Lambda feature provides a built-in HTTPS endpoint without API Gateway?",
    "choices": [
      "Lambda Layers",
      "Lambda@Edge only",
      "Lambda Function URLs",
      "Provisioned Concurrency"
    ],
    "answer": 2,
    "explanation": "Lambda Function URLs expose a native HTTPS endpoint for a function.",
    "difficulty": "Easy"
  },
  {
    "id": "SAA-049",
    "domainId": "D2",
    "domain": "Design Resilient Architectures",
    "section": "CloudWatch",
    "question": "Which service provides alarms based on metrics like CPUUtilization?",
    "choices": [
      "KMS",
      "CloudTrail",
      "Artifact",
      "CloudWatch"
    ],
    "answer": 3,
    "explanation": "CloudWatch provides metrics, alarms, and dashboards.",
    "difficulty": "Easy"
  },
  {
    "id": "SAA-050",
    "domainId": "D1",
    "domain": "Design Secure Architectures",
    "section": "IAM",
    "question": "Which IAM feature sets the maximum permissions an IAM role/user can have (as a boundary)?",
    "choices": [
      "VPC Endpoints",
      "Route Tables",
      "Permission Boundaries",
      "Security Groups"
    ],
    "answer": 2,
    "explanation": "Permission boundaries define the maximum permissions identity-based policies can grant.",
    "difficulty": "Easy"
  },
  {
    "id": "SAA-051",
    "domainId": "D3",
    "domain": "Design High-Performing Architectures",
    "section": "DynamoDB",
    "question": "Which DynamoDB capacity mode is easiest for unpredictable traffic without capacity planning?",
    "choices": [
      "On-demand",
      "Provisioned",
      "Spot",
      "Reserved"
    ],
    "answer": 0,
    "explanation": "On-demand capacity scales automatically and avoids manual capacity planning.",
    "difficulty": "Easy"
  },
  {
    "id": "SAA-052",
    "domainId": "D3",
    "domain": "Design High-Performing Architectures",
    "section": "SQS",
    "question": "What does the SQS Visibility Timeout control?",
    "choices": [
      "How long long polling waits",
      "How long a received message is hidden from other consumers",
      "Maximum message size",
      "How long messages are stored"
    ],
    "answer": 1,
    "explanation": "Visibility timeout hides a message after receive so another consumer doesn’t process it simultaneously.",
    "difficulty": "Easy"
  },
  {
    "id": "SAA-053",
    "domainId": "D1",
    "domain": "Design Secure Architectures",
    "section": "CloudFront",
    "question": "Which AWS service provides DDoS protection that commonly protects CloudFront by default (Standard)?",
    "choices": [
      "AWS Snowball",
      "AWS Shield",
      "AWS Glue",
      "AWS Batch"
    ],
    "answer": 1,
    "explanation": "AWS Shield Standard helps protect against common DDoS attacks and is included for CloudFront.",
    "difficulty": "Easy"
  },
  {
    "id": "SAA-054",
    "domainId": "D4",
    "domain": "Design Cost-Optimized Architectures",
    "section": "Lambda",
    "question": "For short-lived, event-driven tasks, which compute option can be cost-effective?",
    "choices": [
      "Dedicated Hosts",
      "Biggest EC2 only",
      "Lambda",
      "Always-on EC2"
    ],
    "answer": 2,
    "explanation": "Lambda can be cost-effective for sporadic workloads because you pay per execution.",
    "difficulty": "Easy"
  },
  {
    "id": "SAA-055",
    "domainId": "D3",
    "domain": "Design High-Performing Architectures",
    "section": "EC2",
    "question": "Which EC2 feature is the recommended way to define instance configuration for an Auto Scaling Group today?",
    "choices": [
      "Launch Configuration only",
      "Placement Group",
      "AMI Copy",
      "Launch Template"
    ],
    "answer": 3,
    "explanation": "Launch Templates are the modern, recommended way to define ASG instance configuration.",
    "difficulty": "Easy"
  },
  {
    "id": "SAA-056",
    "domainId": "D2",
    "domain": "Design Resilient Architectures",
    "section": "RDS",
    "question": "Aurora is designed to replicate storage across how many AZs (typical design)?",
    "choices": [
      "1",
      "3",
      "2",
      "6 regions"
    ],
    "answer": 1,
    "explanation": "Aurora typically replicates storage across 3 AZs for durability.",
    "difficulty": "Easy"
  },
  {
    "id": "SAA-057",
    "domainId": "D1",
    "domain": "Design Secure Architectures",
    "section": "S3",
    "question": "Which setting helps ensure all S3 uploads are encrypted automatically?",
    "choices": [
      "Default encryption",
      "Requester Pays",
      "Transfer Acceleration",
      "Disable versioning"
    ],
    "answer": 0,
    "explanation": "Default encryption ensures objects are encrypted when written to the bucket.",
    "difficulty": "Easy"
  },
  {
    "id": "SAA-058",
    "domainId": "D4",
    "domain": "Design Cost-Optimized Architectures",
    "section": "CloudWatch",
    "question": "Which action can reduce CloudWatch Logs costs?",
    "choices": [
      "Set retention policies and filter what you log",
      "Turn off encryption always",
      "Send logs to more log groups",
      "Increase log retention to never expire"
    ],
    "answer": 0,
    "explanation": "Retention policies and logging only what you need help reduce log storage/ingest costs.",
    "difficulty": "Easy"
  },
  {
    "id": "SAA-059",
    "domainId": "D3",
    "domain": "Design High-Performing Architectures",
    "section": "S3",
    "question": "For large file uploads to S3, which feature improves reliability and throughput?",
    "choices": [
      "S3 Batch Operations only",
      "S3 Object Lock",
      "S3 Multipart Upload",
      "S3 Static Website Hosting"
    ],
    "answer": 2,
    "explanation": "Multipart upload uploads parts in parallel and can retry parts independently.",
    "difficulty": "Easy"
  },
  {
    "id": "SAA-060",
    "domainId": "D2",
    "domain": "Design Resilient Architectures",
    "section": "VPC",
    "question": "What provides outbound internet access for private subnets without inbound internet access?",
    "choices": [
      "VPC Endpoint only",
      "NAT Gateway",
      "Internet Gateway",
      "Route 53 Resolver"
    ],
    "answer": 1,
    "explanation": "A NAT Gateway allows instances in private subnets to initiate outbound connections to the internet.",
    "difficulty": "Easy"
  },
  {
    "id": "SAA-061",
    "domainId": "D1",
    "domain": "Design Secure Architectures",
    "section": "IAM",
    "question": "Which IAM policy type is attached directly to an AWS resource like an S3 bucket?",
    "choices": [
      "Permission boundary only",
      "Identity-based policy",
      "Session policy only",
      "Resource-based policy"
    ],
    "answer": 3,
    "explanation": "Resource-based policies are attached to resources (e.g., S3 bucket policy).",
    "difficulty": "Easy"
  },
  {
    "id": "SAA-062",
    "domainId": "D3",
    "domain": "Design High-Performing Architectures",
    "section": "ELB",
    "question": "Which ALB capability helps route traffic to different target groups based on URL path?",
    "choices": [
      "BGP routing",
      "NAT translation",
      "Layer 4 routing",
      "Path-based routing"
    ],
    "answer": 3,
    "explanation": "ALB supports Layer 7 features like host- and path-based routing.",
    "difficulty": "Easy"
  },
  {
    "id": "SAA-063",
    "domainId": "D2",
    "domain": "Design Resilient Architectures",
    "section": "RDS",
    "question": "Which RDS feature enables point-in-time recovery within the backup retention window?",
    "choices": [
      "Automated backups",
      "Security groups",
      "Read replicas",
      "Manual snapshots only"
    ],
    "answer": 0,
    "explanation": "Automated backups (with transaction logs) enable point-in-time recovery.",
    "difficulty": "Easy"
  },
  {
    "id": "SAA-064",
    "domainId": "D4",
    "domain": "Design Cost-Optimized Architectures",
    "section": "RDS",
    "question": "Which choice can reduce cost for dev/test databases that are not used 24/7?",
    "choices": [
      "Right-size and stop/start where supported",
      "Use the largest instance",
      "Run Multi-AZ always",
      "Disable monitoring"
    ],
    "answer": 0,
    "explanation": "Right-sizing and stopping non-prod resources where possible reduces cost.",
    "difficulty": "Easy"
  },
  {
    "id": "SAA-065",
    "domainId": "D1",
    "domain": "Design Secure Architectures",
    "section": "VPC",
    "question": "Which is the most secure way to allow EC2 to access S3 without hardcoding keys?",
    "choices": [
      "Put keys in a public S3 bucket",
      "Share root credentials",
      "Use an IAM Role attached to the instance",
      "Store keys in code"
    ],
    "answer": 2,
    "explanation": "Attach an IAM role to the instance so it receives temporary credentials automatically.",
    "difficulty": "Easy"
  },
  {
    "id": "SAA-066",
    "domainId": "D1",
    "domain": "Design Secure Architectures",
    "section": "IAM",
    "question": "A company has just set up a new AWS account for production workloads and wants to follow best practices for privileged access. Which practice should be mandated for the root user account?",
    "choices": [
      "Use the root account only for initial setup and never share credentials.",
      "Configure Multi-Factor Authentication (MFA) only for critical IAM users, as the root account is already inherently secure.",
      "Create an IAM user for all day-to-day operations and delete the root account immediately.",
      "Set a strong password policy for all IAM users, but the root account password can be simple since it's rarely used."
    ],
    "answer": 0,
    "explanation": "Root is the most privileged identity, so it should be tightly controlled and used only when absolutely necessary; never share it and keep it for account-level tasks.",
    "difficulty": "Medium"
  },
  {
    "id": "SAA-067",
    "domainId": "D4",
    "domain": "Design Cost-Optimized Architectures",
    "section": "EC2",
    "question": "A company must run a critical, stateful database application with stable capacity 24/7 for the next three years and wants the best cost savings. Which EC2 purchasing option provides the greatest savings for this steady-state workload?",
    "choices": [
      "Spot Instances, leveraging up to 90% discount for non-critical workloads.",
      "Capacity Reservations, ensuring capacity in a specific AZ for any duration.",
      "Reserved Instances (3-year term, All Upfront payment).",
      "On-Demand Instances, due to the flexibility of paying per second."
    ],
    "answer": 2,
    "explanation": "A 3-year All Upfront Reserved Instance provides the largest discount for predictable, always-on workloads while keeping capacity stable.",
    "difficulty": "Medium"
  },
  {
    "id": "SAA-068",
    "domainId": "D1",
    "domain": "Design Secure Architectures",
    "section": "Security Groups",
    "question": "An EC2 instance security group allows inbound HTTP (port 80), but client connections time out and outbound rules are default. Based on security group fundamentals, what is the most likely cause?",
    "choices": [
      "The default Network ACL (NACL) is implicitly denying the inbound connection.",
      "The default outbound rule in the security group is denying the return traffic.",
      "The inbound security group rule is configured incorrectly or traffic is being blocked before reaching the instance, resulting in a timeout.",
      "The application server is not running, resulting in a connection refused error."
    ],
    "answer": 2,
    "explanation": "Security groups are stateful, so return traffic is allowed automatically; a timeout usually indicates the request never successfully reaches a listening service (routing/NACL/host firewall/app issue) rather than an outbound SG problem.",
    "difficulty": "Medium"
  },
  {
    "id": "SAA-069",
    "domainId": "D2",
    "domain": "Design Resilient Architectures",
    "section": "ALB",
    "question": "An Application Load Balancer (ALB) distributes traffic across two Availability Zones for high availability. How is cross-zone load balancing configured by default on an ALB, and what is the pricing impact?",
    "choices": [
      "Disabled by default, and inter-AZ data transfer is charged if enabled.",
      "Enabled by default, but inter-AZ data transfer is charged if enabled.",
      "Enabled by default, and there are no additional charges for this cross-zone regional data transfer behavior on ALB.",
      "Disabled by default, but there are no charges for inter-AZ data transfer."
    ],
    "answer": 2,
    "explanation": "ALBs use cross-zone load balancing by default, and ALB does not add a specific cross-zone data transfer fee for this behavior.",
    "difficulty": "Medium"
  },
  {
    "id": "SAA-070",
    "domainId": "D2",
    "domain": "Design Resilient Architectures",
    "section": "SQS",
    "question": "A payment system requires messages to be processed in the exact order received and must prevent duplicate processing. Which Amazon SQS queue type meets these requirements?",
    "choices": [
      "SQS FIFO Queue.",
      "SQS Standard Queue with short polling.",
      "SQS Standard Queue with long polling.",
      "Amazon SNS topic fan-out pattern."
    ],
    "answer": 0,
    "explanation": "SQS FIFO provides ordered message processing and supports exactly-once processing semantics (with deduplication) for correctly designed consumers.",
    "difficulty": "Medium"
  },
  {
    "id": "SAA-071",
    "domainId": "D4",
    "domain": "Design Cost-Optimized Architectures",
    "section": "S3",
    "question": "A media company stores video data in S3: frequent access for 30 days, rare access from day 30 to 90 (but fast retrieval), then long-term archive after 90 days where hours of retrieval time is acceptable. Which lifecycle transition is most cost-effective while meeting access needs?",
    "choices": [
      "Standard for 30 days -> transition to S3 Standard-IA for 60 days -> transition to S3 Glacier Flexible Retrieval after 90 days.",
      "Use S3 Glacier Instant Retrieval immediately as retrieval latency is low.",
      "S3 One Zone-IA for 30 days -> S3 Standard-IA for 60 days -> S3 Glacier Instant Retrieval.",
      "S3 Intelligent-Tiering -> S3 Glacier Deep Archive after 90 days."
    ],
    "answer": 0,
    "explanation": "Standard fits frequent access, Standard-IA fits infrequent-but-fast retrieval, and Glacier Flexible Retrieval fits long-term archiving with hour-level retrieval latency.",
    "difficulty": "Medium"
  },
  {
    "id": "SAA-072",
    "domainId": "D1",
    "domain": "Design Secure Architectures",
    "section": "VPC",
    "question": "VPC flow logs show outbound traffic from a private subnet instance is ACCEPTED, but the inbound return traffic is REJECTED at the subnet level. Assuming security groups are correct, what should be checked and modified to allow the connection to succeed?",
    "choices": [
      "The NACL outbound rules for the private subnet, because NACLs are stateful.",
      "The EC2 instance security group, because security groups are stateless.",
      "The NACL inbound rules for the private subnet, ensuring the ephemeral port range is explicitly allowed.",
      "The NACL outbound rules for the public subnet, ensuring port 443 is explicitly allowed."
    ],
    "answer": 2,
    "explanation": "NACLs are stateless, so you must explicitly allow return traffic on ephemeral ports in the inbound NACL rules for the subnet.",
    "difficulty": "Medium"
  },
  {
    "id": "SAA-073",
    "domainId": "D2",
    "domain": "Design Resilient Architectures",
    "section": "Aurora",
    "question": "A company uses Aurora MySQL in us-east-1 and needs cross-region expansion to eu-west-1 with very low RTO for failover (under 1 minute) and low-latency global reads. Which Aurora feature best meets both needs?",
    "choices": [
      "Aurora cross-region read replicas.",
      "Aurora Serverless deployment in eu-west-1.",
      "Aurora Global Database.",
      "RDS Multi-AZ deployment."
    ],
    "answer": 2,
    "explanation": "Aurora Global Database is designed for low-latency cross-region reads and fast disaster recovery with promoted secondary regions.",
    "difficulty": "Medium"
  },
  {
    "id": "SAA-074",
    "domainId": "D1",
    "domain": "Design Secure Architectures",
    "section": "Monitoring",
    "question": "An admin wants immediate alerts when someone attempts to terminate a production EC2 instance, a history of configuration changes, and a graph of average CPU over time. Which three AWS services meet these requirements, respectively?",
    "choices": [
      "CloudWatch (CPU), CloudTrail (API calls/history), AWS Config (configuration history).",
      "CloudWatch (CPU), CloudTrail (configuration history), CloudWatch Logs (API calls).",
      "GuardDuty (alerts), EventBridge (history), AWS Config (CPU).",
      "Trusted Advisor (security), CloudWatch (CPU), S3 (history)."
    ],
    "answer": 0,
    "explanation": "CloudWatch provides metrics and graphs, CloudTrail records API activity such as termination attempts, and AWS Config tracks configuration changes over time.",
    "difficulty": "Medium"
  },
  {
    "id": "SAA-075",
    "domainId": "D3",
    "domain": "Design High-Performing Architectures",
    "section": "Serverless",
    "question": "Users upload large images to S3, and a serverless microservice must generate thumbnails and analyze metadata immediately after each upload. What is the most appropriate serverless pattern to trigger the processing?",
    "choices": [
      "Configure S3 event notifications to publish to an SNS topic, which then triggers the microservice running on Fargate tasks.",
      "Use AWS Batch to run the thumbnail job based on a scheduled CloudWatch Event.",
      "Use a single EC2 instance with a user data script running the thumbnail application.",
      "Configure S3 event notifications to invoke an AWS Lambda function directly."
    ],
    "answer": 3,
    "explanation": "S3 event notifications can directly trigger Lambda on object creation, providing a fully serverless, scalable event-driven pipeline.",
    "difficulty": "Medium"
  },
  {
    "id": "SAA-076",
    "domainId": "D1",
    "domain": "Design Secure Architectures",
    "section": "IAM",
    "question": "A startup uses an AWS account shared by multiple teams. Developers currently attach the AdministratorAccess policy to their IAM users “temporarily” when troubleshooting, and sometimes forget to remove it.\nThe security team wants a guardrail that limits the maximum permissions developers can ever obtain, while still allowing team leads to grant temporary elevated access within that limit.\nWhich solution will meet these requirements with the LEAST operational overhead?",
    "choices": [
      "Enable AWS Config and automatically revert any policy changes detected on IAM users",
      "Use an identity-based policy that explicitly allows only read-only access for developers",
      "Create an SCP that allows AdministratorAccess only for users in a specific IAM group",
      "Attach a permissions boundary to all developer IAM users that caps their maximum permissions"
    ],
    "answer": 3,
    "explanation": "Permissions boundaries define the maximum permissions an IAM principal can receive, even if broader policies are attached later. This creates a strong guardrail without blocking legitimate temporary elevation by team leads, as long as it stays within the boundary.",
    "difficulty": "Medium"
  },
  {
    "id": "SAA-077",
    "domainId": "D1",
    "domain": "Design Secure Architectures",
    "section": "S3",
    "question": "A company stores internal build artifacts in Amazon S3. The bucket must never become publicly accessible, even if someone accidentally adds a public bucket policy or object ACL.\nWhich configuration best meets the requirement?",
    "choices": [
      "Enable S3 versioning and MFA Delete",
      "Use S3 default encryption with SSE-S3",
      "Create an S3 access point for each application and disable bucket policies",
      "Enable S3 Block Public Access at the account level and for the bucket"
    ],
    "answer": 3,
    "explanation": "S3 Block Public Access can prevent public access via bucket policies and ACLs at both the account and bucket level, providing a safety net against accidental exposure. Encryption and versioning do not prevent public access.",
    "difficulty": "Medium"
  },
  {
    "id": "SAA-078",
    "domainId": "D1",
    "domain": "Design Secure Architectures",
    "section": "KMS",
    "question": "A security policy requires that all data stored in S3 be encrypted using customer-managed keys, and that access to decrypt the data be centrally controlled and auditable.\nWhich approach should you implement?",
    "choices": [
      "Use client-side encryption and store the encryption key in the application code repository",
      "Enable default encryption on the bucket using SSE-KMS with a customer-managed KMS key",
      "Enable default encryption on the bucket using SSE-S3",
      "Store objects unencrypted and rely on TLS in transit"
    ],
    "answer": 1,
    "explanation": "SSE-KMS with a customer-managed KMS key enforces encryption at rest and allows centralized, auditable control over key usage through KMS key policies and CloudTrail logs.",
    "difficulty": "Medium"
  },
  {
    "id": "SAA-079",
    "domainId": "D1",
    "domain": "Design Secure Architectures",
    "section": "CloudTrail",
    "question": "A regulated company must retain an immutable record of all API calls in their AWS account for 7 years. The security team also wants to be alerted if CloudTrail logging is disabled or modified.\nWhich solution is MOST appropriate?",
    "choices": [
      "Enable VPC Flow Logs to S3 and store the logs for 7 years",
      "Send CloudTrail logs to an EC2 instance and back them up nightly to S3",
      "Enable AWS Config only and store configuration snapshots in S3 for 7 years",
      "Enable an organization trail (or account trail) that logs to an S3 bucket with Object Lock, and create an AWS Config rule (or CloudWatch/EventBridge alert) to detect changes to CloudTrail"
    ],
    "answer": 3,
    "explanation": "CloudTrail records API activity. Storing logs in S3 with Object Lock helps meet immutability/retention requirements, while Config and/or EventBridge/CloudWatch can alert on CloudTrail configuration changes. VPC Flow Logs capture network traffic, not API calls.",
    "difficulty": "Medium"
  },
  {
    "id": "SAA-080",
    "domainId": "D1",
    "domain": "Design Secure Architectures",
    "section": "VPC",
    "question": "A team is deploying a web app in private subnets. They want to allow HTTPS access to a third-party API on the internet, but block all inbound traffic from the internet.\nWhich network design meets these requirements?",
    "choices": [
      "Deploy instances in public subnets and use an S3 Gateway Endpoint for internet access",
      "Deploy instances in private subnets and attach an Internet Gateway directly to the private subnets",
      "Deploy instances in private subnets, route outbound internet traffic through a NAT Gateway in a public subnet, and keep inbound rules restrictive on security groups",
      "Deploy instances in public subnets with public IPs and restrict inbound traffic using NACLs"
    ],
    "answer": 2,
    "explanation": "Instances in private subnets have no direct inbound internet connectivity. A NAT Gateway in a public subnet provides outbound-only internet access for private instances. Security groups and route tables enforce the inbound restriction.",
    "difficulty": "Medium"
  },
  {
    "id": "SAA-081",
    "domainId": "D1",
    "domain": "Design Secure Architectures",
    "section": "ACM",
    "question": "A company hosts multiple HTTPS applications behind Application Load Balancers. The applications must use publicly trusted certificates and the team wants automatic certificate renewal.\nWhich solution should you choose?",
    "choices": [
      "Use AWS Certificate Manager Private CA to issue certificates for the ALBs",
      "Use AWS Certificate Manager (ACM) to provision public certificates and attach them to the ALB HTTPS listeners",
      "Run Let’s Encrypt certbot on each EC2 instance and manage renewals with cron",
      "Create self-signed certificates and import them to ACM"
    ],
    "answer": 1,
    "explanation": "ACM public certificates are publicly trusted, integrate directly with ALBs, and renew automatically. Private CA and self-signed certificates are not publicly trusted for internet clients.",
    "difficulty": "Medium"
  },
  {
    "id": "SAA-082",
    "domainId": "D1",
    "domain": "Design Secure Architectures",
    "section": "WAF",
    "question": "A security team wants to protect a public web application from common web exploits (SQL injection, XSS) and also wants to block known bad IP ranges. The solution must be managed and easy to update.\nWhich option best meets these requirements?",
    "choices": [
      "Use Security Groups to block SQL injection and XSS",
      "Use NACLs with deep packet inspection rules for HTTP payloads",
      "Attach AWS WAF to the application entry point (ALB or CloudFront) and use managed rule groups plus an IP set",
      "Enable AWS Shield Standard and configure it to block bad IPs"
    ],
    "answer": 2,
    "explanation": "AWS WAF provides managed protections for common web exploits and supports IP sets for allow/deny lists. Security groups and NACLs operate at L3/L4 and cannot inspect HTTP payloads for SQLi/XSS.",
    "difficulty": "Medium"
  },
  {
    "id": "SAA-083",
    "domainId": "D1",
    "domain": "Design Secure Architectures",
    "section": "Secrets Manager",
    "question": "An application running on ECS needs to retrieve database credentials securely. The credentials rotate every 30 days, and the app should not require redeployment when rotation happens.\nWhich solution is MOST suitable?",
    "choices": [
      "Store credentials in an S3 object encrypted with SSE-S3 and download them on container startup",
      "Store credentials in a Parameter Store standard parameter without encryption",
      "Store credentials in AWS Secrets Manager with rotation enabled and have the app retrieve them at runtime",
      "Store credentials in environment variables baked into the container image"
    ],
    "answer": 2,
    "explanation": "Secrets Manager is designed for storing and rotating secrets like database credentials. Applications can fetch the current secret value at runtime, so rotation doesn’t require rebuilding images or redeploying configs.",
    "difficulty": "Medium"
  },
  {
    "id": "SAA-084",
    "domainId": "D1",
    "domain": "Design Secure Architectures",
    "section": "IAM",
    "question": "A company wants to prevent developers from creating IAM access keys for their own users to reduce the risk of long-lived credentials. Console access with MFA is allowed.\nWhich approach provides the strongest preventive control?",
    "choices": [
      "Use a strong password policy for IAM users",
      "Enable AWS CloudTrail and review access key creation events weekly",
      "Enable AWS Config to detect access keys and notify via email",
      "Apply an SCP (in AWS Organizations) or an IAM permissions boundary/policy that explicitly denies iam:CreateAccessKey for the developer principals"
    ],
    "answer": 3,
    "explanation": "A preventive deny (via SCP or identity policies/permissions boundaries where applicable) blocks the action from occurring. Detective controls like CloudTrail/Config only alert after access keys are created.",
    "difficulty": "Medium"
  },
  {
    "id": "SAA-085",
    "domainId": "D1",
    "domain": "Design Secure Architectures",
    "section": "Security Groups",
    "question": "A team is confused about AWS network controls. They need a control that is stateful, supports allow rules only, and is associated directly with an ENI (instance/network interface).\nWhich AWS feature are they describing?",
    "choices": [
      "Network ACL",
      "VPC Flow Logs",
      "Security group",
      "Route table"
    ],
    "answer": 2,
    "explanation": "Security groups are stateful, contain allow rules only, and are attached to network interfaces. NACLs are stateless and support both allow and deny rules at the subnet level.",
    "difficulty": "Medium"
  },
  {
    "id": "SAA-086",
    "domainId": "D1",
    "domain": "Design Secure Architectures",
    "section": "GuardDuty",
    "question": "A company wants to detect potentially compromised EC2 instances, unusual API calls, and suspicious DNS activity without deploying agents.\nWhich service should they enable?",
    "choices": [
      "AWS Shield Advanced",
      "Amazon GuardDuty",
      "AWS Systems Manager",
      "Amazon Inspector"
    ],
    "answer": 1,
    "explanation": "GuardDuty is a managed threat detection service that analyzes CloudTrail, VPC Flow Logs, and DNS logs to identify suspicious activity without requiring agents on instances.",
    "difficulty": "Medium"
  },
  {
    "id": "SAA-087",
    "domainId": "D1",
    "domain": "Design Secure Architectures",
    "section": "Organizations",
    "question": "A company is setting up a multi-account environment and wants to ensure all accounts follow the same mandatory security controls, like disallowing changes to CloudTrail log buckets and restricting regions.\nWhich solution provides centralized governance?",
    "choices": [
      "Using VPC peering between all accounts",
      "Enabling AWS Shield Standard in every account",
      "AWS Organizations with Organizational Units (OUs) and Service Control Policies (SCPs)",
      "Creating identical IAM users in every account"
    ],
    "answer": 2,
    "explanation": "AWS Organizations allows centralized governance through OUs and SCPs that set account-wide permission guardrails. This is the standard approach for enforcing controls across many accounts.",
    "difficulty": "Medium"
  },
  {
    "id": "SAA-088",
    "domainId": "D1",
    "domain": "Design Secure Architectures",
    "section": "S3",
    "question": "A client stores confidential reports in S3 and wants to ensure that objects cannot be deleted unless a second factor is used, even by administrators.\nWhat should you configure?",
    "choices": [
      "Enable S3 Transfer Acceleration",
      "Enable default encryption using SSE-S3",
      "Enable versioning on the bucket and enable MFA Delete",
      "Enable S3 Block Public Access"
    ],
    "answer": 2,
    "explanation": "MFA Delete (used with versioning) requires MFA to permanently delete object versions or change the versioning state, providing stronger protection against accidental or malicious deletion.",
    "difficulty": "Medium"
  },
  {
    "id": "SAA-089",
    "domainId": "D1",
    "domain": "Design Secure Architectures",
    "section": "CloudFront",
    "question": "A company serves a static website globally using CloudFront with an S3 origin. They want to ensure viewers can access content only if they are authenticated by the company’s identity provider.\nWhich CloudFront feature best supports this?",
    "choices": [
      "Enable S3 website hosting and require Basic Auth",
      "Use S3 Transfer Acceleration to restrict access",
      "Use Route 53 geolocation routing only",
      "Use signed URLs or signed cookies with CloudFront"
    ],
    "answer": 3,
    "explanation": "CloudFront signed URLs/cookies restrict access to content by requiring a valid signature, commonly used alongside an authentication system to grant time-limited access to users.",
    "difficulty": "Medium"
  },
  {
    "id": "SAA-090",
    "domainId": "D1",
    "domain": "Design Secure Architectures",
    "section": "IAM",
    "question": "A security team wants to quickly identify S3 buckets, KMS keys, and other supported resources that have resource policies granting access to external AWS accounts.\nWhich service should they use?",
    "choices": [
      "AWS Artifact",
      "AWS Budgets",
      "AWS Trusted Advisor",
      "IAM Access Analyzer"
    ],
    "answer": 3,
    "explanation": "IAM Access Analyzer evaluates supported resource policies to identify unintended public or cross-account access, helping detect overly permissive sharing.",
    "difficulty": "Medium"
  },
  {
    "id": "SAA-091",
    "domainId": "D1",
    "domain": "Design Secure Architectures",
    "section": "VPC",
    "question": "A company wants to inspect and control outbound DNS queries from workloads in a VPC and block known malicious domains at the DNS layer.\nWhich managed AWS service capability is MOST suitable?",
    "choices": [
      "Network ACLs with domain-based rules",
      "Amazon Route 53 Resolver DNS Firewall",
      "AWS Shield Standard",
      "Security groups with DNS deny rules"
    ],
    "answer": 1,
    "explanation": "Route 53 Resolver DNS Firewall lets you define rules to allow/deny domain names for DNS queries from VPCs, providing managed DNS-layer protection. SGs/NACLs don’t filter by domain name.",
    "difficulty": "Medium"
  },
  {
    "id": "SAA-092",
    "domainId": "D2",
    "domain": "Design Resilient Architectures",
    "section": "RDS",
    "question": "A company runs a production PostgreSQL database on Amazon RDS. They need automatic failover in case the primary AZ becomes unavailable, with minimal application changes.\nWhich solution best meets this requirement?",
    "choices": [
      "Export automated snapshots daily to S3",
      "Deploy the database on a single EC2 instance with EBS snapshots",
      "Create an RDS read replica and point the application to it",
      "Enable Multi-AZ deployment for the RDS instance"
    ],
    "answer": 3,
    "explanation": "RDS Multi-AZ provides synchronous replication to a standby in another AZ and automatic failover to maintain availability with minimal application changes. Read replicas are primarily for scaling reads and can have asynchronous replication.",
    "difficulty": "Medium"
  },
  {
    "id": "SAA-093",
    "domainId": "D2",
    "domain": "Design Resilient Architectures",
    "section": "Route 53",
    "question": "A global e-commerce site runs active applications in two AWS Regions. The business wants users to be routed to the closest healthy region and fail over automatically if one region becomes unhealthy.\nWhich Route 53 routing policy best fits?",
    "choices": [
      "Weighted routing without health checks",
      "Latency-based routing with health checks",
      "Geolocation routing without health checks",
      "Simple routing"
    ],
    "answer": 1,
    "explanation": "Latency-based routing directs users to the region that provides the lowest latency, and health checks enable automatic failover away from unhealthy endpoints.",
    "difficulty": "Medium"
  },
  {
    "id": "SAA-094",
    "domainId": "D2",
    "domain": "Design Resilient Architectures",
    "section": "SQS",
    "question": "A team uses Amazon SQS to decouple a web tier from a worker tier. Sometimes, the workers fail to process a message due to a transient error, and messages get retried repeatedly.\nThe team wants a safe way to isolate problematic messages for later analysis without blocking the queue.\nWhich feature should they use?",
    "choices": [
      "Enable FIFO on the queue",
      "Enable SQS long polling",
      "Configure a dead-letter queue (DLQ) with a maxReceiveCount",
      "Increase the message retention period to 14 days"
    ],
    "answer": 2,
    "explanation": "A DLQ moves messages that fail processing too many times to a separate queue for investigation, preventing them from being retried indefinitely and blocking progress.",
    "difficulty": "Medium"
  },
  {
    "id": "SAA-095",
    "domainId": "D2",
    "domain": "Design Resilient Architectures",
    "section": "ECS",
    "question": "A service runs on Amazon ECS with the Fargate launch type across two AZs. The team needs tasks to be automatically replaced when they fail, and wants to maintain a desired number of running tasks.\nWhich ECS feature provides this behavior?",
    "choices": [
      "An ECS service with a desired count and health checks",
      "An S3 lifecycle policy",
      "ECS Exec",
      "An ECS task definition only"
    ],
    "answer": 0,
    "explanation": "An ECS service maintains the desired number of tasks and will replace failed tasks automatically. Health checks help ECS/ALB determine unhealthy tasks and trigger replacement.",
    "difficulty": "Medium"
  },
  {
    "id": "SAA-096",
    "domainId": "D2",
    "domain": "Design Resilient Architectures",
    "section": "ELB/ASG",
    "question": "A web application is deployed on EC2 instances in an Auto Scaling group behind an Application Load Balancer. The team wants unhealthy instances to be replaced automatically when they fail application-level health checks.\nWhich configuration should they implement?",
    "choices": [
      "Enable detailed monitoring on EC2 instances only",
      "Use a Network Load Balancer and disable health checks",
      "Use Amazon CloudFront in front of the ALB and rely on edge caching",
      "Configure ALB target group health checks and enable Auto Scaling health checks that use ELB health status"
    ],
    "answer": 3,
    "explanation": "ALB target group health checks detect application health. When Auto Scaling uses ELB health checks, it can terminate and replace instances that fail the load balancer health checks automatically.",
    "difficulty": "Medium"
  },
  {
    "id": "SAA-097",
    "domainId": "D2",
    "domain": "Design Resilient Architectures",
    "section": "S3",
    "question": "A company needs to protect critical S3 objects from accidental overwrites and deletions, but they also want the ability to recover previous versions.\nWhich S3 feature best meets this requirement?",
    "choices": [
      "Enable S3 Transfer Acceleration",
      "Enable S3 versioning",
      "Enable S3 Requester Pays",
      "Enable S3 static website hosting"
    ],
    "answer": 1,
    "explanation": "S3 versioning preserves multiple variants of an object in the same bucket, enabling recovery from accidental overwrites and deletions.",
    "difficulty": "Medium"
  },
  {
    "id": "SAA-098",
    "domainId": "D2",
    "domain": "Design Resilient Architectures",
    "section": "Lambda",
    "question": "A serverless workload writes items to DynamoDB. Occasionally, downstream processing fails and needs to be retried without losing events.\nWhich option provides the MOST resilient event-driven design?",
    "choices": [
      "Trigger Lambda directly from an S3 bucket event",
      "Write DynamoDB items and rely on manual reprocessing only",
      "Use DynamoDB Streams to trigger a Lambda function and configure retries with a DLQ (or on-failure destination) for failed records",
      "Have the Lambda poll DynamoDB every minute and scan the table"
    ],
    "answer": 2,
    "explanation": "DynamoDB Streams provide an ordered change log for table modifications. Lambda integrations support retries, and a DLQ/destination can capture failed records for later reprocessing, improving resilience.",
    "difficulty": "Medium"
  },
  {
    "id": "SAA-099",
    "domainId": "D2",
    "domain": "Design Resilient Architectures",
    "section": "EFS",
    "question": "A fleet of EC2 instances across multiple AZs needs shared access to the same file system for user uploads. The application requires automatic high availability across AZs.\nWhich storage service is MOST suitable?",
    "choices": [
      "Amazon S3 Glacier Deep Archive",
      "Instance store",
      "Amazon EBS",
      "Amazon EFS"
    ],
    "answer": 3,
    "explanation": "EFS is a managed, elastic NFS file system designed for shared access and is accessible from multiple AZs, supporting highly available shared storage for EC2/ECS workloads.",
    "difficulty": "Medium"
  },
  {
    "id": "SAA-100",
    "domainId": "D2",
    "domain": "Design Resilient Architectures",
    "section": "CloudFront",
    "question": "A company serves static and dynamic content worldwide. They want improved availability and reduced latency for static assets, and they want to reduce the impact of origin outages for cached content.\nWhich service should they use?",
    "choices": [
      "Amazon CloudFront",
      "Amazon EBS",
      "AWS Direct Connect",
      "AWS Snowball"
    ],
    "answer": 0,
    "explanation": "CloudFront caches content at edge locations, improving performance and providing some resilience by serving cached objects even when the origin is temporarily unavailable (subject to cache settings).",
    "difficulty": "Medium"
  },
  {
    "id": "SAA-101",
    "domainId": "D2",
    "domain": "Design Resilient Architectures",
    "section": "Backup",
    "question": "A company wants to centrally manage backups for Amazon RDS, EBS volumes, and EFS file systems across multiple accounts. They need retention policies and centralized reporting.\nWhich solution is MOST suitable?",
    "choices": [
      "Use CloudTrail to store backups",
      "Rely on each team to manually create snapshots",
      "Use AWS Backup with centralized backup policies (optionally via Organizations)",
      "Create custom scripts that take snapshots and store them in S3"
    ],
    "answer": 2,
    "explanation": "AWS Backup provides centralized backup management, scheduling, retention, and reporting for supported services and can be used across accounts with Organizations integration.",
    "difficulty": "Medium"
  },
  {
    "id": "SAA-102",
    "domainId": "D2",
    "domain": "Design Resilient Architectures",
    "section": "DynamoDB",
    "question": "A mobile app backend uses DynamoDB and must continue serving reads and writes even if an entire AWS Region becomes unavailable. The application requires near real-time replication between regions.\nWhich DynamoDB feature should you use?",
    "choices": [
      "DynamoDB Streams only in a single region",
      "DynamoDB TTL",
      "DynamoDB DAX",
      "DynamoDB global tables"
    ],
    "answer": 3,
    "explanation": "Global tables provide multi-region, multi-active replication for DynamoDB, enabling reads and writes in multiple regions with near real-time replication and improved regional resilience.",
    "difficulty": "Medium"
  },
  {
    "id": "SAA-103",
    "domainId": "D2",
    "domain": "Design Resilient Architectures",
    "section": "SNS/SQS",
    "question": "A company needs to send an event to multiple independent processing systems. Each system must receive every message and process it at its own pace. If one system is down, others must not be impacted.\nWhich design best meets these requirements?",
    "choices": [
      "Send messages to a single SQS queue shared by all systems",
      "Send events directly to each system over HTTP from the producer",
      "Write events to an S3 bucket and have systems list objects periodically",
      "Publish to an SNS topic and subscribe multiple SQS queues (one per system)"
    ],
    "answer": 3,
    "explanation": "SNS fanout to multiple SQS queues ensures each consumer system receives its own copy of each message, decouples processing rates, and isolates failures between systems.",
    "difficulty": "Medium"
  },
  {
    "id": "SAA-104",
    "domainId": "D2",
    "domain": "Design Resilient Architectures",
    "section": "ASG",
    "question": "A company wants to automatically scale a fleet of EC2 instances based on CPU utilization and replace unhealthy instances. They want the platform to handle capacity changes automatically.\nWhich solution best fits?",
    "choices": [
      "Use AWS OpsWorks to deploy the application but not scale",
      "Use a single large EC2 instance with vertical scaling",
      "Use an Auto Scaling group with scaling policies and health checks",
      "Use EC2 Spot Instances only and manually add instances when needed"
    ],
    "answer": 2,
    "explanation": "Auto Scaling groups provide automatic capacity management and instance replacement based on health checks and scaling policies, improving availability and resilience.",
    "difficulty": "Medium"
  },
  {
    "id": "SAA-105",
    "domainId": "D2",
    "domain": "Design Resilient Architectures",
    "section": "S3",
    "question": "A company needs to replicate objects from an S3 bucket in us-east-1 to another bucket in eu-west-1 for disaster recovery. Replication must be automatic after objects are uploaded.\nWhich feature should be used?",
    "choices": [
      "S3 multipart upload",
      "S3 Cross-Region Replication (CRR)",
      "S3 Transfer Acceleration",
      "S3 Select"
    ],
    "answer": 1,
    "explanation": "S3 Cross-Region Replication automatically replicates objects to a bucket in another region, supporting disaster recovery and compliance use cases.",
    "difficulty": "Medium"
  },
  {
    "id": "SAA-106",
    "domainId": "D3",
    "domain": "Design High-Performing Architectures",
    "section": "ELB",
    "question": "A multiplayer game uses UDP for real-time communication between clients and game servers running on EC2. The solution must distribute UDP traffic across instances with low latency.\nWhich load balancing option should you choose?",
    "choices": [
      "Network Load Balancer (NLB)",
      "CloudFront distribution",
      "Classic Load Balancer (CLB) with HTTP listeners",
      "Application Load Balancer (ALB)"
    ],
    "answer": 0,
    "explanation": "NLB operates at Layer 4 and supports UDP, providing very high performance and low latency load balancing. ALB is Layer 7 and supports HTTP/HTTPS, not UDP.",
    "difficulty": "Medium"
  },
  {
    "id": "SAA-107",
    "domainId": "D3",
    "domain": "Design High-Performing Architectures",
    "section": "DynamoDB",
    "question": "A product catalog API requires single-digit millisecond latency for reads at very high request rates. The data is key-value and read-heavy.\nWhich AWS service is MOST suitable as the primary datastore?",
    "choices": [
      "Amazon Redshift",
      "Amazon DynamoDB",
      "Amazon RDS MySQL",
      "Amazon S3 Select"
    ],
    "answer": 1,
    "explanation": "DynamoDB is a managed key-value/NoSQL database designed for single-digit millisecond latency at scale. Relational and analytics services are not optimized for this access pattern.",
    "difficulty": "Medium"
  },
  {
    "id": "SAA-108",
    "domainId": "D3",
    "domain": "Design High-Performing Architectures",
    "section": "CloudFront",
    "question": "A company serves large static assets (images, JS, CSS) to users worldwide. They want to reduce latency and offload requests from the origin servers.\nWhich solution should they implement?",
    "choices": [
      "Use AWS Snowball to deliver content to users",
      "Move the assets to Amazon EBS",
      "Use Amazon CloudFront to cache content at edge locations",
      "Increase the EC2 instance size of the origin servers"
    ],
    "answer": 2,
    "explanation": "CloudFront caches and serves static content from edge locations close to users, reducing latency and origin load.",
    "difficulty": "Medium"
  },
  {
    "id": "SAA-109",
    "domainId": "D3",
    "domain": "Design High-Performing Architectures",
    "section": "EBS",
    "question": "A database on EC2 needs the highest possible IOPS with consistent, low-latency storage performance.\nWhich EBS volume type is MOST appropriate?",
    "choices": [
      "Cold HDD (sc1)",
      "Throughput Optimized HDD (st1)",
      "Provisioned IOPS SSD (io1/io2)",
      "Magnetic (standard)"
    ],
    "answer": 2,
    "explanation": "io1/io2 volumes are designed for high IOPS and consistent performance, which is critical for latency-sensitive databases.",
    "difficulty": "Medium"
  },
  {
    "id": "SAA-110",
    "domainId": "D3",
    "domain": "Design High-Performing Architectures",
    "section": "S3",
    "question": "A client uploads very large files to S3, and uploads frequently fail due to unstable connections. They want higher reliability and better throughput.\nWhich S3 feature should they use?",
    "choices": [
      "S3 Multipart Upload",
      "S3 Object Lock",
      "S3 Inventory only",
      "S3 Static Website Hosting"
    ],
    "answer": 0,
    "explanation": "Multipart Upload splits large objects into parts that can be uploaded in parallel and retried independently, improving throughput and reliability for large uploads.",
    "difficulty": "Medium"
  },
  {
    "id": "SAA-111",
    "domainId": "D3",
    "domain": "Design High-Performing Architectures",
    "section": "RDS",
    "question": "An application has read-heavy traffic and uses an Amazon RDS database. The team wants to increase read throughput without changing the application’s write logic.\nWhich solution is MOST suitable?",
    "choices": [
      "Increase storage size to improve reads",
      "Add one or more RDS read replicas and direct read traffic to them",
      "Move the database to S3",
      "Enable Multi-AZ and send reads to the standby instance"
    ],
    "answer": 1,
    "explanation": "Read replicas scale out read traffic. In standard RDS Multi-AZ, the standby is for failover and typically not used for serving reads.",
    "difficulty": "Medium"
  },
  {
    "id": "SAA-112",
    "domainId": "D3",
    "domain": "Design High-Performing Architectures",
    "section": "Global Accelerator",
    "question": "A company has a global user base accessing a latency-sensitive API hosted behind an ALB in a single region. They want improved global performance without changing the application.\nWhich service can provide faster global routing to the regional endpoint?",
    "choices": [
      "AWS Snowcone",
      "Amazon S3 Glacier",
      "AWS Global Accelerator",
      "AWS Backup"
    ],
    "answer": 2,
    "explanation": "Global Accelerator uses the AWS global network to route users to the optimal endpoint, improving performance for latency-sensitive applications.",
    "difficulty": "Medium"
  },
  {
    "id": "SAA-113",
    "domainId": "D3",
    "domain": "Design High-Performing Architectures",
    "section": "ElastiCache",
    "question": "A web application repeatedly queries the same small set of product data, causing high load on the database. The team wants sub-millisecond retrieval for hot items.\nWhich solution should they implement?",
    "choices": [
      "Enable EBS snapshots more frequently",
      "Add an in-memory cache layer using Amazon ElastiCache (Redis or Memcached)",
      "Use AWS CloudTrail insights",
      "Move the product data to Glacier Deep Archive"
    ],
    "answer": 1,
    "explanation": "An in-memory cache like ElastiCache reduces database load and provides very low-latency retrieval for frequently accessed data.",
    "difficulty": "Medium"
  },
  {
    "id": "SAA-114",
    "domainId": "D3",
    "domain": "Design High-Performing Architectures",
    "section": "SQS",
    "question": "A worker application polls an SQS queue and often receives empty responses, increasing cost and CPU usage. The team wants to reduce the number of empty receives.\nWhich feature should they enable?",
    "choices": [
      "SQS long polling",
      "SQS FIFO",
      "SQS encryption",
      "SQS dead-letter queue"
    ],
    "answer": 0,
    "explanation": "Long polling waits for messages to arrive before returning a response, reducing empty receives and lowering cost.",
    "difficulty": "Medium"
  },
  {
    "id": "SAA-115",
    "domainId": "D3",
    "domain": "Design High-Performing Architectures",
    "section": "ECS",
    "question": "A containerized service needs to scale horizontally based on request rate, and tasks should be distributed across multiple AZs. The team prefers a managed container platform.\nWhich AWS service is MOST appropriate?",
    "choices": [
      "AWS Snowball Edge",
      "Amazon ECS (with Fargate or EC2 launch type) using a Service and Service Auto Scaling",
      "AWS Storage Gateway",
      "Amazon S3"
    ],
    "answer": 1,
    "explanation": "ECS provides managed container orchestration, supports multi-AZ placement, and can scale services automatically based on metrics such as request count or CPU.",
    "difficulty": "Medium"
  },
  {
    "id": "SAA-116",
    "domainId": "D3",
    "domain": "Design High-Performing Architectures",
    "section": "S3",
    "question": "An analytics team needs to run SQL queries on large CSV files stored in S3 without loading them into a database first.\nWhich service should they use?",
    "choices": [
      "Amazon RDS",
      "Amazon ElastiCache",
      "AWS Secrets Manager",
      "Amazon Athena"
    ],
    "answer": 3,
    "explanation": "Athena is a serverless query service that uses SQL to analyze data directly in S3, ideal for ad-hoc queries over files.",
    "difficulty": "Medium"
  },
  {
    "id": "SAA-117",
    "domainId": "D3",
    "domain": "Design High-Performing Architectures",
    "section": "EC2",
    "question": "A high-performance computing job requires low-latency, high-throughput network communication between EC2 instances.\nWhich EC2 placement strategy best supports this?",
    "choices": [
      "Run instances in different regions",
      "Cluster placement group",
      "Spread placement group across multiple racks",
      "Partition placement group with isolated partitions only"
    ],
    "answer": 1,
    "explanation": "Cluster placement groups place instances close together within an AZ to achieve low-latency, high-throughput networking, suitable for tightly coupled workloads.",
    "difficulty": "Medium"
  },
  {
    "id": "SAA-118",
    "domainId": "D3",
    "domain": "Design High-Performing Architectures",
    "section": "S3",
    "question": "A company uploads files to S3 from users around the world and wants faster uploads by optimizing transfer paths to S3.\nWhich S3 feature can help?",
    "choices": [
      "S3 Object Lock",
      "S3 Transfer Acceleration",
      "S3 Glacier Deep Archive",
      "S3 Batch Operations"
    ],
    "answer": 1,
    "explanation": "Transfer Acceleration uses CloudFront edge locations to accelerate uploads to S3 over long distances, improving performance for global users.",
    "difficulty": "Medium"
  },
  {
    "id": "SAA-119",
    "domainId": "D4",
    "domain": "Design Cost-Optimized Architectures",
    "section": "S3",
    "question": "A team stores monthly reports in S3. Reports are accessed frequently for the first 30 days and then rarely accessed, but they still need millisecond retrieval when they are accessed.\nWhich storage class transition is MOST cost-effective?",
    "choices": [
      "Transition objects to S3 Glacier Flexible Retrieval immediately",
      "Transition objects to S3 Standard-IA after 30 days using a lifecycle rule",
      "Transition objects to S3 Glacier Deep Archive after 30 days",
      "Keep objects in S3 Standard forever"
    ],
    "answer": 1,
    "explanation": "Standard-IA is designed for infrequently accessed data with the same millisecond access as Standard, making it a common cost optimization after the frequent-access period.",
    "difficulty": "Medium"
  },
  {
    "id": "SAA-120",
    "domainId": "D4",
    "domain": "Design Cost-Optimized Architectures",
    "section": "EC2",
    "question": "A company runs a steady-state workload 24/7 for the next 1–3 years. They want lower cost than On-Demand while keeping predictable capacity.\nWhich pricing option is typically MOST cost-effective?",
    "choices": [
      "Dedicated Hosts only",
      "Reserved Instances or Savings Plans",
      "Spot Instances only",
      "On-Demand Instances only"
    ],
    "answer": 1,
    "explanation": "For long-running steady workloads, Reserved Instances or Savings Plans usually provide significant discounts compared to On-Demand, without the interruption risk of Spot.",
    "difficulty": "Medium"
  },
  {
    "id": "SAA-121",
    "domainId": "D4",
    "domain": "Design Cost-Optimized Architectures",
    "section": "S3",
    "question": "A company stores backups in S3 that are almost never accessed. Retrieval can take hours, and the priority is minimizing storage cost.\nWhich S3 storage class is MOST suitable?",
    "choices": [
      "S3 Glacier Instant Retrieval",
      "S3 Glacier Deep Archive",
      "S3 Standard",
      "S3 Standard-IA"
    ],
    "answer": 1,
    "explanation": "Glacier Deep Archive is designed for long-term archival with the lowest storage cost, and it supports hours-level retrieval times, matching the requirement.",
    "difficulty": "Medium"
  },
  {
    "id": "SAA-122",
    "domainId": "D4",
    "domain": "Design Cost-Optimized Architectures",
    "section": "NAT/VPC",
    "question": "A workload in private subnets calls Amazon S3 frequently. Using a NAT Gateway is generating significant data processing charges.\nWhich change reduces cost while keeping traffic private?",
    "choices": [
      "Use AWS Direct Connect for internet access",
      "Add another NAT Gateway in a second AZ",
      "Add an S3 Gateway VPC endpoint and route S3 traffic through it",
      "Move the instances to public subnets with public IPs"
    ],
    "answer": 2,
    "explanation": "Gateway endpoints for S3 keep traffic within the AWS network and avoid NAT Gateway data processing charges for S3 access from private subnets.",
    "difficulty": "Medium"
  },
  {
    "id": "SAA-123",
    "domainId": "D4",
    "domain": "Design Cost-Optimized Architectures",
    "section": "DynamoDB",
    "question": "A startup has unpredictable traffic patterns and wants to avoid capacity planning for a DynamoDB table. They prefer a pay-per-request model.\nWhich DynamoDB capacity mode should they choose?",
    "choices": [
      "On-demand capacity mode",
      "Provisioned capacity with a fixed WCU/RCU",
      "Provisioned capacity without auto scaling",
      "Local DynamoDB on EC2"
    ],
    "answer": 0,
    "explanation": "On-demand capacity charges per request and automatically scales to handle traffic without manual capacity planning, which is ideal for unpredictable workloads.",
    "difficulty": "Medium"
  },
  {
    "id": "SAA-124",
    "domainId": "D4",
    "domain": "Design Cost-Optimized Architectures",
    "section": "RDS",
    "question": "A development database on RDS is used only during business hours (8 AM–6 PM weekdays). Outside those hours, it can be stopped to save cost.\nWhich approach is MOST appropriate?",
    "choices": [
      "Use an EC2 instance with the database running 24/7",
      "Enable Multi-AZ so the standby is stopped automatically",
      "Move the database to a larger instance type",
      "Stop the RDS instance outside business hours using automation (for example, AWS Instance Scheduler or a scheduled Lambda), and start it when needed"
    ],
    "answer": 3,
    "explanation": "Stopping a non-production RDS instance during off-hours can reduce cost. Multi-AZ increases cost and doesn’t stop the database; larger instances cost more.",
    "difficulty": "Medium"
  },
  {
    "id": "SAA-125",
    "domainId": "D4",
    "domain": "Design Cost-Optimized Architectures",
    "section": "S3",
    "question": "A company wants to automatically move objects to cheaper storage classes over time without changing application code.\nWhich S3 feature supports this?",
    "choices": [
      "S3 Transfer Acceleration",
      "S3 lifecycle policies",
      "S3 Object Lock",
      "S3 Select"
    ],
    "answer": 1,
    "explanation": "Lifecycle policies automate transitions between storage classes and can also expire objects, enabling cost optimization without application changes.",
    "difficulty": "Medium"
  },
  {
    "id": "SAA-126",
    "domainId": "D4",
    "domain": "Design Cost-Optimized Architectures",
    "section": "CloudFront",
    "question": "A company serves static files from S3 to users worldwide. They are paying high S3 data transfer costs and users in distant regions have high latency.\nWhich solution can both improve performance and potentially reduce origin load/cost?",
    "choices": [
      "Use Glacier Deep Archive for static files",
      "Move content from S3 to EBS",
      "Use CloudFront in front of S3 to cache content at edge locations",
      "Use a single larger EC2 instance as a file server"
    ],
    "answer": 2,
    "explanation": "CloudFront edge caching reduces repeated origin fetches and improves latency for global users, which can also reduce S3 request load and overall cost depending on access patterns.",
    "difficulty": "Medium"
  },
  {
    "id": "SAA-127",
    "domainId": "D4",
    "domain": "Design Cost-Optimized Architectures",
    "section": "EBS",
    "question": "A batch workload needs low-cost storage for infrequently accessed data, but it still requires reasonably fast access when needed.\nWhich EBS volume type is MOST cost-effective for throughput-oriented workloads?",
    "choices": [
      "Throughput Optimized HDD (st1)",
      "Provisioned IOPS SSD (io2)",
      "Magnetic (standard) for best performance",
      "Cold HDD (sc1) for high IOPS"
    ],
    "answer": 0,
    "explanation": "st1 is designed for throughput-intensive workloads at lower cost than SSD options. io2 is higher-cost and optimized for IOPS, while sc1 is lowest cost for infrequent access with lower performance.",
    "difficulty": "Medium"
  },
  {
    "id": "SAA-128",
    "domainId": "D4",
    "domain": "Design Cost-Optimized Architectures",
    "section": "Compute",
    "question": "A company runs a fault-tolerant background processing fleet where instances can be interrupted and the workload can resume.\nThey want the lowest compute cost.\nWhich EC2 pricing option is MOST suitable?",
    "choices": [
      "Reserved Instances for 3 years only",
      "On-Demand Instances",
      "Dedicated Hosts",
      "Spot Instances"
    ],
    "answer": 3,
    "explanation": "Spot Instances provide the largest discounts for fault-tolerant workloads that can handle interruptions.",
    "difficulty": "Medium"
  },
  {
    "id": "SAA-129",
    "domainId": "D4",
    "domain": "Design Cost-Optimized Architectures",
    "section": "Logs",
    "question": "A company stores application logs in CloudWatch Logs but notices that older logs are rarely accessed. They want to reduce ongoing log storage cost.\nWhat should they do?",
    "choices": [
      "Increase log verbosity to reduce storage",
      "Set log retention policies to automatically expire older log events",
      "Disable logging entirely after 30 days",
      "Move logs to EBS volumes attached to EC2"
    ],
    "answer": 1,
    "explanation": "CloudWatch Logs retention policies automatically delete log events older than a specified period, reducing storage cost while keeping recent logs available.",
    "difficulty": "Medium"
  },
  {
    "id": "SAA-130",
    "domainId": "D4",
    "domain": "Design Cost-Optimized Architectures",
    "section": "S3",
    "question": "A company stores images in S3. A subset under the prefix /realtime/ must always have millisecond retrieval. Older images under /archive/ can take hours to retrieve after 90 days.\nThey want the most cost-effective lifecycle configuration.\nWhich option best meets the requirements?",
    "choices": [
      "Lifecycle rule: keep /realtime/ in Standard or Standard-IA as appropriate, and transition /archive/ to Glacier Flexible Retrieval or Deep Archive after 90 days",
      "Enable S3 Transfer Acceleration for /archive/ objects",
      "Use Intelligent-Tiering for all objects and never transition to archive tiers",
      "Move the entire bucket to Glacier Deep Archive after 90 days"
    ],
    "answer": 0,
    "explanation": "Using prefix-based lifecycle rules lets you keep the performance-critical prefix in a millisecond-access class while moving archival content to cheaper archive tiers when retrieval time allows, optimizing cost.",
    "difficulty": "Medium"
  },
  {
    "id": "SAA-131",
    "domainId": "D1",
    "domain": "Design Secure Architectures",
    "section": "ACM",
    "question": "A company hosts dozens of internet-facing applications, each behind its own Application Load Balancer (ALB) across multiple Availability Zones. Each app has its own fully qualified domain name.\nThe security team requires publicly trusted SSL/TLS certificates and wants automatic renewal with minimal ongoing operations.\nWhich solution will meet these requirements with the LEAST operational overhead?",
    "choices": [
      "Use AWS Certificate Manager Private CA to issue certificates and upload the root certificate to all customer browsers",
      "Generate self-signed certificates and import them into ACM for each ALB",
      "Run Let’s Encrypt certbot on the EC2 instances behind the ALBs and manage renewals with a scheduled job",
      "Use AWS Certificate Manager (ACM) to request public certificates for each domain and associate them with the HTTPS listeners on each ALB"
    ],
    "answer": 3,
    "explanation": "ACM public certificates are publicly trusted, integrate directly with ALB listeners, and renew automatically. Private CA and self-signed certificates are not publicly trusted for general internet clients, and self-managing Let’s Encrypt introduces significant operational overhead.",
    "difficulty": "Hard"
  },
  {
    "id": "SAA-132",
    "domainId": "D1",
    "domain": "Design Secure Architectures",
    "section": "Organizations",
    "question": "A company uses AWS Organizations with multiple accounts. The security team mandates that no one can disable CloudTrail logging or delete CloudTrail log files, even in development accounts.\nDevelopers still need broad permissions within their accounts for day-to-day work.\nWhich combination of controls best enforces this requirement?",
    "choices": [
      "Place CloudTrail logs in each account’s local S3 bucket with bucket policies that allow deletion only by admins",
      "Attach AdministratorAccess to all developers and rely on CloudTrail alarms to detect changes",
      "Apply an SCP that denies stopping/deleting CloudTrail and denies deleting objects in the centralized log bucket; store logs in a dedicated logging account",
      "Enable AWS Config in each account and automatically revert changes to CloudTrail via a Lambda function"
    ],
    "answer": 2,
    "explanation": "SCPs provide account-level guardrails that apply even to administrators in member accounts. Centralizing CloudTrail logs in a dedicated logging account further reduces risk. Detective/auto-remediation is helpful but does not prevent the action from occurring.",
    "difficulty": "Hard"
  },
  {
    "id": "SAA-133",
    "domainId": "D1",
    "domain": "Design Secure Architectures",
    "section": "KMS",
    "question": "A partner in a separate AWS account needs read access to objects in your S3 bucket for a short-lived project. The objects are encrypted with SSE-KMS using a customer-managed KMS key in your account.\nThe partner can read the objects but gets AccessDenied when attempting to decrypt.\nWhat is the MOST appropriate fix?",
    "choices": [
      "Copy the objects to an unencrypted bucket and share that bucket publicly",
      "Enable S3 Transfer Acceleration so decryption happens at the edge",
      "Update the KMS key policy (and/or grants) to allow the partner’s IAM role to use the key for decryption, and ensure the S3 bucket policy allows the role to read the objects",
      "Disable SSE-KMS and re-upload objects with SSE-S3 so other accounts can read them"
    ],
    "answer": 2,
    "explanation": "For SSE-KMS, both S3 permissions and KMS key permissions are required. Cross-account consumers must be granted KMS decrypt permissions via the key policy or a grant, in addition to S3 read permissions.",
    "difficulty": "Hard"
  },
  {
    "id": "SAA-134",
    "domainId": "D1",
    "domain": "Design Secure Architectures",
    "section": "WAF",
    "question": "A company runs many CloudFront distributions across multiple AWS accounts. The security team wants to enforce a standard AWS WAF web ACL (managed rule groups + IP reputation lists) across all distributions and have a single place to manage these policies.\nWhich solution meets these requirements with the LEAST operational overhead?",
    "choices": [
      "Use security groups on the origin EC2 instances to block malicious HTTP payloads",
      "Create identical WAF web ACLs manually in every account and attach them to each distribution",
      "Use AWS Firewall Manager to centrally deploy and manage AWS WAF policies across accounts and CloudFront distributions",
      "Enable AWS Shield Standard on CloudFront and rely on it for application-layer protections"
    ],
    "answer": 2,
    "explanation": "AWS Firewall Manager provides centralized management and enforcement of security policies like AWS WAF across multiple accounts and resources, reducing manual configuration and drift.",
    "difficulty": "Hard"
  },
  {
    "id": "SAA-135",
    "domainId": "D1",
    "domain": "Design Secure Architectures",
    "section": "IAM Identity Center",
    "question": "A company wants employees to sign in to AWS using their corporate identity provider (IdP) and be assigned AWS permissions based on their job role. The solution should avoid creating IAM users and should be easy to manage as employees join/leave.\nWhich approach is MOST suitable?",
    "choices": [
      "Use Amazon Cognito user pools for employee access to the AWS console",
      "Use access keys distributed through a password manager and rotate them monthly",
      "Use AWS IAM Identity Center (AWS SSO) integrated with the corporate IdP and assign permission sets to users/groups",
      "Create an IAM user for each employee and enforce MFA"
    ],
    "answer": 2,
    "explanation": "IAM Identity Center is designed for workforce authentication and authorization into AWS accounts, integrating with external IdPs and mapping users/groups to permission sets. This avoids managing long-lived IAM users.",
    "difficulty": "Hard"
  },
  {
    "id": "SAA-136",
    "domainId": "D1",
    "domain": "Design Secure Architectures",
    "section": "S3",
    "question": "A company stores critical compliance evidence in S3. The files must be retained for 5 years and must not be deletable or overwriteable during the retention period, even by administrators.\nWhich solution best meets these requirements?",
    "choices": [
      "Enable S3 versioning and set a lifecycle rule to transition objects to Glacier Deep Archive after 30 days",
      "Enable MFA Delete and keep the root MFA device offline",
      "Enable S3 versioning and S3 Object Lock in Compliance mode with a 5-year retention period",
      "Encrypt objects with SSE-S3 and restrict s3:DeleteObject via IAM"
    ],
    "answer": 2,
    "explanation": "S3 Object Lock in Compliance mode provides WORM protection that prevents deletion or modification of protected object versions for the retention period, even by users with high privileges. Versioning is required for Object Lock.",
    "difficulty": "Hard"
  },
  {
    "id": "SAA-137",
    "domainId": "D1",
    "domain": "Design Secure Architectures",
    "section": "VPC",
    "question": "A security team requires that EC2 instances in private subnets can access AWS public services (like S3, DynamoDB, and Secrets Manager) without traversing the public internet, and that access can be controlled with IAM policies and VPC policies.\nWhich design best meets the requirement?",
    "choices": [
      "Create VPC peering to an AWS-managed VPC that hosts the AWS services",
      "Route all private subnet traffic through a NAT Gateway to reach AWS public endpoints",
      "Use an Internet Gateway and assign public IPs to the instances",
      "Create VPC endpoints: gateway endpoints for S3/DynamoDB and interface endpoints for Secrets Manager (and other services), and update route tables/DNS accordingly"
    ],
    "answer": 3,
    "explanation": "VPC endpoints keep traffic within the AWS network and avoid public internet routing. Gateway endpoints are used for S3 and DynamoDB, while interface endpoints (PrivateLink) are used for services like Secrets Manager.",
    "difficulty": "Hard"
  },
  {
    "id": "SAA-138",
    "domainId": "D1",
    "domain": "Design Secure Architectures",
    "section": "CloudTrail",
    "question": "A company wants to detect and alert on suspicious root account usage (console sign-in or access key usage) in near real time. They also want a searchable history of these events.\nWhich solution is MOST suitable?",
    "choices": [
      "Enable VPC Flow Logs and create alarms when port 443 traffic increases",
      "Enable CloudTrail and create an EventBridge rule for relevant CloudTrail events that sends notifications (SNS), and store logs centrally in S3/CloudWatch Logs for search",
      "Enable AWS Config and run compliance evaluations every 24 hours",
      "Enable AWS Shield Advanced and monitor Shield events"
    ],
    "answer": 1,
    "explanation": "Root account usage is captured in CloudTrail. EventBridge can match specific CloudTrail events and trigger near-real-time notifications. Centralized log storage enables audit and search.",
    "difficulty": "Hard"
  },
  {
    "id": "SAA-139",
    "domainId": "D1",
    "domain": "Design Secure Architectures",
    "section": "KMS",
    "question": "A company must encrypt EBS volumes on EC2 instances. The security team requires that encryption keys be rotated automatically, and access to use the key must be limited to a specific set of roles.\nWhich solution should you implement?",
    "choices": [
      "Use client-side encryption inside the EC2 instance and store keys in the AMI",
      "Use unencrypted EBS and enforce TLS for all disk I/O",
      "Use EBS encryption with a customer-managed KMS key, enable automatic key rotation, and restrict key usage via the key policy to approved roles",
      "Use EBS encryption with AWS-managed keys and rely on IAM user policies only"
    ],
    "answer": 2,
    "explanation": "Customer-managed KMS keys support automatic rotation and fine-grained control through key policies and grants. EBS integrates directly with KMS for encryption at rest.",
    "difficulty": "Hard"
  },
  {
    "id": "SAA-140",
    "domainId": "D1",
    "domain": "Design Secure Architectures",
    "section": "STS",
    "question": "A vendor needs temporary access to your AWS account to troubleshoot a production issue. Your company forbids sharing long-lived credentials and wants the access to automatically expire after a few hours.\nWhich solution is MOST appropriate?",
    "choices": [
      "Create a security group rule to allow the vendor’s IP and let them SSH to all instances",
      "Create an IAM role with required permissions and a trust policy for the vendor’s AWS account, and require the vendor to assume the role using STS with a short session duration",
      "Create an IAM user for the vendor and rotate the access keys after the troubleshooting session",
      "Share the root account credentials for the troubleshooting window and then change the password"
    ],
    "answer": 1,
    "explanation": "Assuming an IAM role via STS provides temporary credentials that expire automatically and avoids sharing long-lived secrets. Trust policies and session duration enforce controlled access.",
    "difficulty": "Hard"
  },
  {
    "id": "SAA-141",
    "domainId": "D1",
    "domain": "Design Secure Architectures",
    "section": "Secrets Manager",
    "question": "A microservice running on ECS retrieves DB credentials from Secrets Manager. A new compliance rule requires that services must not access secrets unless they are running in the approved VPC and use a specific VPC endpoint.\nWhich design best meets this requirement?",
    "choices": [
      "Create an interface VPC endpoint for Secrets Manager and use a resource policy/endpoint policy plus IAM conditions to restrict secret access through the endpoint",
      "Use environment variables and rotate the container image on every rotation",
      "Store the secret in an S3 bucket and restrict access with a bucket policy",
      "Use a NAT Gateway and allow the service to call Secrets Manager over the internet"
    ],
    "answer": 0,
    "explanation": "Interface endpoints allow private connectivity to Secrets Manager. Endpoint policies and IAM conditions (for example, requiring a source VPC endpoint) can enforce that secrets are accessed only through the approved private path.",
    "difficulty": "Hard"
  },
  {
    "id": "SAA-142",
    "domainId": "D1",
    "domain": "Design Secure Architectures",
    "section": "S3",
    "question": "A company exposes private documents to authenticated customers via CloudFront. Documents must remain private in S3, and direct access to the S3 bucket must be blocked.\nWhich architecture should you implement?",
    "choices": [
      "Make the S3 bucket public and rely on signed URLs to hide the object keys",
      "Expose the S3 bucket through an internet-facing ALB",
      "Use S3 static website hosting with Basic Auth enabled",
      "Use CloudFront with an Origin Access Control (or Origin Access Identity) so only CloudFront can read from the S3 origin, and use signed URLs/cookies for authenticated access"
    ],
    "answer": 3,
    "explanation": "OAC/OAI prevents direct access to the S3 origin by allowing only CloudFront to fetch objects. Signed URLs/cookies then restrict which viewers can access the content through CloudFront.",
    "difficulty": "Hard"
  },
  {
    "id": "SAA-143",
    "domainId": "D1",
    "domain": "Design Secure Architectures",
    "section": "VPC",
    "question": "A company wants to allow inbound SSH access to a small set of EC2 instances for administrators, but only after the administrators authenticate to AWS. The company wants to avoid managing bastion host patching and SSH keys.\nWhich solution provides secure access with the LEAST operational overhead?",
    "choices": [
      "Deploy a hardened bastion host in a public subnet and rotate SSH keys weekly",
      "Use AWS Systems Manager Session Manager for shell access and remove inbound SSH access from security groups",
      "Open port 22 to the administrators’ IP addresses and enforce strong SSH passwords",
      "Use a VPN appliance on EC2 and have admins connect over SSH"
    ],
    "answer": 1,
    "explanation": "Session Manager provides auditable, IAM-controlled access to instances without opening inbound SSH ports or managing bastion hosts and keys. It reduces operational overhead while improving security.",
    "difficulty": "Hard"
  },
  {
    "id": "SAA-144",
    "domainId": "D1",
    "domain": "Design Secure Architectures",
    "section": "Security Hub",
    "question": "A company wants a centralized view of security findings across GuardDuty, Inspector, and Config rules for all AWS accounts. They also want to automatically open tickets when critical findings appear.\nWhich solution is MOST suitable?",
    "choices": [
      "Enable CloudWatch Logs Insights across accounts to query for security events",
      "Enable AWS Trusted Advisor in every account and export the report weekly",
      "Use AWS Budgets alerts to detect security issues",
      "Enable AWS Security Hub organization-wide, aggregate findings to a central account, and use EventBridge rules to route critical findings to an incident/ticketing workflow"
    ],
    "answer": 3,
    "explanation": "Security Hub aggregates findings from multiple AWS services and can centralize them in a delegated administrator account. EventBridge can trigger automated workflows based on finding severity.",
    "difficulty": "Hard"
  },
  {
    "id": "SAA-145",
    "domainId": "D1",
    "domain": "Design Secure Architectures",
    "section": "IAM",
    "question": "An application in Account A needs to write objects to an S3 bucket in Account B. The security team requires least privilege, no long-lived credentials, and clear separation of duties.\nWhich option best meets these requirements?",
    "choices": [
      "Create an IAM role in Account B that Account A can assume, grant it s3:PutObject to the bucket, and allow the role in the bucket policy",
      "Use pre-signed URLs generated by Account A without changing Account B",
      "Create an IAM user in Account B and share the access keys with Account A",
      "Make the bucket public-write and use object prefixes to separate writes"
    ],
    "answer": 0,
    "explanation": "Cross-account role assumption provides temporary credentials and supports least privilege. Bucket policies can restrict writes to the role, avoiding shared long-lived access keys.",
    "difficulty": "Hard"
  },
  {
    "id": "SAA-146",
    "domainId": "D1",
    "domain": "Design Secure Architectures",
    "section": "IAM",
    "question": "A team uses IAM roles for EC2 instances. During an incident, a developer added a broad inline policy to the instance role. Security wants to ensure that role permissions cannot be expanded beyond a predefined maximum, but still allow adding narrower permissions when needed.\nWhich control should be used?",
    "choices": [
      "Enable AWS Shield Advanced on the EC2 instance",
      "Attach a permissions boundary to the role to cap its maximum permissions",
      "Use an ACL on the EC2 instance to deny outbound network traffic",
      "Add the role to an IAM group with restricted permissions"
    ],
    "answer": 1,
    "explanation": "Permissions boundaries can be applied to roles (not just users) to limit the maximum effective permissions, preventing expansion beyond a defined scope while still allowing additional allowed permissions to be attached.",
    "difficulty": "Hard"
  },
  {
    "id": "SAA-147",
    "domainId": "D1",
    "domain": "Design Secure Architectures",
    "section": "S3",
    "question": "A company requires that all S3 access to a sensitive bucket must come from within their VPC over a specific VPC endpoint, and any request from the public internet must be denied, even if credentials are valid.\nWhich solution best enforces this?",
    "choices": [
      "Enable SSE-KMS on the bucket and deny kms:Decrypt from the internet",
      "Use an S3 bucket policy that denies requests unless they come through the specified VPC endpoint (aws:sourceVpce), and use an S3 Gateway VPC endpoint",
      "Enable S3 Block Public Access only",
      "Enable S3 Transfer Acceleration to force requests through edge locations"
    ],
    "answer": 1,
    "explanation": "Bucket policies can enforce network-based conditions such as requiring a particular VPC endpoint. Using an S3 gateway endpoint ensures traffic can stay within the AWS network, and the deny condition blocks any requests not coming through that endpoint.",
    "difficulty": "Hard"
  },
  {
    "id": "SAA-148",
    "domainId": "D1",
    "domain": "Design Secure Architectures",
    "section": "Shield/WAF",
    "question": "A financial services company runs an internet-facing application behind CloudFront and ALB. They are concerned about large-scale DDoS attacks and want DDoS response support plus cost protection for scaling-related charges during an attack.\nWhich solution is MOST suitable?",
    "choices": [
      "Enable AWS Shield Standard only and rely on security groups",
      "Deploy the application only in private subnets and remove the ALB",
      "Use Amazon Inspector to detect DDoS attempts",
      "Subscribe to AWS Shield Advanced and (optionally) integrate AWS WAF for L7 protections"
    ],
    "answer": 3,
    "explanation": "Shield Advanced provides enhanced DDoS protections, access to the DDoS response team, and financial protections for scaling charges resulting from attacks. WAF complements by filtering application-layer traffic.",
    "difficulty": "Hard"
  },
  {
    "id": "SAA-149",
    "domainId": "D1",
    "domain": "Design Secure Architectures",
    "section": "KMS",
    "question": "A company uses KMS keys for encrypting data. Security requires that only a specific microservice role can decrypt data, and administrators should be able to manage the key (rotate/disable) but not decrypt application data.\nWhich configuration best meets this requirement?",
    "choices": [
      "Use a customer-managed KMS key with a key policy that separates key administration permissions from key usage (encrypt/decrypt) permissions",
      "Use an AWS-managed KMS key and attach decrypt permissions to the admin role",
      "Use S3 SSE-S3 so KMS policies are not needed",
      "Store the key material in the application container and restrict access with security groups"
    ],
    "answer": 0,
    "explanation": "KMS key policies can separate administrative actions (like enabling/disabling, rotating) from cryptographic usage actions (Encrypt/Decrypt). Grant decrypt only to the microservice role while allowing admins to administer the key without data access.",
    "difficulty": "Hard"
  },
  {
    "id": "SAA-150",
    "domainId": "D1",
    "domain": "Design Secure Architectures",
    "section": "Config",
    "question": "A company must prove that security groups never allow inbound 0.0.0.0/0 access to SSH or RDP, and they need continuous monitoring with automatic evidence for auditors.\nWhich solution best meets these requirements?",
    "choices": [
      "Use AWS Config with managed rules (or custom rules) to evaluate security group configurations continuously, and store compliance history",
      "Enable GuardDuty and rely on findings for open ports",
      "Use VPC Flow Logs and manually inspect logs for port 22/3389 traffic",
      "Use CloudTrail only and search for AuthorizeSecurityGroupIngress calls"
    ],
    "answer": 0,
    "explanation": "AWS Config continuously evaluates resource configurations against rules and retains compliance history, which is useful for audit evidence. CloudTrail and flow logs are helpful but do not provide continuous configuration compliance evaluation by themselves.",
    "difficulty": "Hard"
  },
  {
    "id": "SAA-151",
    "domainId": "D2",
    "domain": "Design Resilient Architectures",
    "section": "DR/Route 53",
    "question": "A SaaS provider runs its primary workload in Region A. The application stack includes ALB + EC2, an RDS database, and an S3 bucket for user uploads. The business requires:\n- RPO of 15 minutes for the database\n- RTO of 1 hour for the application\n- Minimal ongoing costs in the secondary region\nWhich disaster recovery strategy BEST meets these requirements?",
    "choices": [
      "Warm standby: run a fully scaled stack in Region B at all times",
      "Backup and restore only: keep no resources in Region B and rely solely on nightly backups",
      "Active-active: run the full stack at production scale in both regions at all times",
      "Pilot light: keep minimal core components running in Region B, use cross-region backups/replication (including frequent DB backups or replication) and scale up on failover"
    ],
    "answer": 3,
    "explanation": "Pilot light keeps a minimal footprint in the secondary region (lower cost than warm standby/active-active) while enabling faster recovery than backup/restore. Achieving a 15-minute RPO typically requires frequent replication/backup for the database and automated procedures to scale the rest of the stack within the 1-hour RTO.",
    "difficulty": "Hard"
  },
  {
    "id": "SAA-152",
    "domainId": "D2",
    "domain": "Design Resilient Architectures",
    "section": "RDS/Aurora",
    "question": "A company runs an Aurora MySQL cluster for a critical application. They want protection against an AZ failure with automatic failover, and they also want to be able to fail over to another region for a regional outage with the lowest RPO possible.\nWhich design is MOST appropriate?",
    "choices": [
      "Use a single-instance Aurora cluster and take manual snapshots to copy to another region",
      "Use DynamoDB global tables instead of Aurora without changing the application",
      "Use Aurora Multi-AZ (cluster with replicas in multiple AZs) and configure Aurora Global Database for cross-region replication",
      "Use RDS read replicas in the same AZ only and promote one manually"
    ],
    "answer": 2,
    "explanation": "Aurora provides Multi-AZ high availability via replicas and automatic failover within a region. Aurora Global Database provides low-latency cross-region replication to reduce RPO for regional failover scenarios.",
    "difficulty": "Hard"
  },
  {
    "id": "SAA-153",
    "domainId": "D2",
    "domain": "Design Resilient Architectures",
    "section": "SQS/Lambda",
    "question": "A company processes orders using SQS and Lambda. The same order event can be delivered more than once due to retries, and the downstream system must never create duplicate orders.\nThe team wants a resilient design that handles retries safely.\nWhich solution is MOST suitable?",
    "choices": [
      "Use SNS only without SQS so delivery happens once",
      "Make the Lambda processing idempotent using a DynamoDB table to track processed order IDs, and keep retries/DLQ for failures",
      "Increase the SQS visibility timeout to 12 hours so duplicates cannot occur",
      "Disable retries in Lambda so messages are never reprocessed"
    ],
    "answer": 1,
    "explanation": "Event-driven systems can deliver duplicates. Idempotent processing (tracking processed IDs in DynamoDB or equivalent) ensures retries do not create duplicates, while DLQs capture poison messages for investigation.",
    "difficulty": "Hard"
  },
  {
    "id": "SAA-154",
    "domainId": "D2",
    "domain": "Design Resilient Architectures",
    "section": "ECS/ALB",
    "question": "A production service runs on ECS Fargate behind an ALB. During deployments, users occasionally see 5xx errors because tasks are terminated before the new tasks are ready.\nThe team wants zero-downtime deployments with minimal effort.\nWhich approach should they implement?",
    "choices": [
      "Switch to an NLB because it does not do health checks",
      "Use an ECS service with rolling updates, configure ALB health checks, and set a deployment minimumHealthyPercent/maximumPercent so new tasks pass health checks before old tasks are drained",
      "Place CloudFront in front of the ALB and disable origin health checks",
      "Manually stop all running tasks, then start new tasks after the image is updated"
    ],
    "answer": 1,
    "explanation": "ECS service deployments can be configured to keep a minimum healthy capacity while starting new tasks. Combined with ALB health checks and connection draining, this avoids terminating old tasks until new ones are healthy.",
    "difficulty": "Hard"
  },
  {
    "id": "SAA-155",
    "domainId": "D2",
    "domain": "Design Resilient Architectures",
    "section": "Route 53",
    "question": "A company has two copies of a web application: one in us-east-1 and one in eu-west-1. They want active-active traffic distribution, but if one region fails, 100% of traffic should go to the healthy region automatically.\nWhich Route 53 configuration best meets this?",
    "choices": [
      "Use geolocation routing without health checks",
      "Use failover routing only with a single primary and no secondary health check",
      "Use multivalue answer routing without health checks",
      "Use weighted routing with health checks on each regional endpoint"
    ],
    "answer": 3,
    "explanation": "Weighted routing can split traffic across multiple endpoints and, when paired with health checks, will stop returning unhealthy endpoints—effectively shifting traffic to the healthy region automatically.",
    "difficulty": "Hard"
  },
  {
    "id": "SAA-156",
    "domainId": "D2",
    "domain": "Design Resilient Architectures",
    "section": "S3",
    "question": "A company replicates data using S3 Cross-Region Replication (CRR). They recently enabled CRR but noticed that older objects that already existed in the bucket were not replicated.\nThey want all existing objects to be replicated to the destination bucket.\nWhich action should they take?",
    "choices": [
      "Disable and re-enable CRR and it will backfill all objects automatically",
      "Use S3 Batch Operations (or a one-time copy job) to replicate existing objects, since CRR applies automatically only to new objects by default",
      "Enable S3 Select so CRR can find old objects",
      "Enable S3 Transfer Acceleration to speed up replication of existing objects"
    ],
    "answer": 1,
    "explanation": "CRR typically replicates new objects after the rule is enabled; existing objects require an explicit backfill process (such as S3 Batch Operations or a copy job) to replicate them to the destination bucket.",
    "difficulty": "Hard"
  },
  {
    "id": "SAA-157",
    "domainId": "D2",
    "domain": "Design Resilient Architectures",
    "section": "ElastiCache",
    "question": "An application stores user session state in-memory on the web servers. During Auto Scaling events, users are frequently logged out because they land on new instances.\nThe company needs a resilient approach that preserves sessions even when instances scale in/out or fail.\nWhich solution is MOST suitable?",
    "choices": [
      "Enable ALB sticky sessions and store sessions only in instance memory",
      "Increase the Auto Scaling cooldown to reduce scaling events",
      "Store sessions in a centralized shared store such as Amazon ElastiCache (Redis) or DynamoDB instead of on-instance memory",
      "Use a larger instance type so scaling isn’t needed"
    ],
    "answer": 2,
    "explanation": "Storing session state in a centralized external store decouples sessions from individual instances and improves resilience across scaling and failures. Sticky sessions help but still lose sessions if an instance fails or scales in.",
    "difficulty": "Hard"
  },
  {
    "id": "SAA-158",
    "domainId": "D2",
    "domain": "Design Resilient Architectures",
    "section": "Multi-AZ",
    "question": "A critical internal service runs on EC2 instances in a single subnet in one AZ. The business requires the service to remain available during an AZ outage.\nWhich change provides the MOST reliable improvement?",
    "choices": [
      "Enable detailed monitoring on the instance",
      "Deploy the service across at least two AZs using an Auto Scaling group and a load balancer, with subnets in each AZ",
      "Increase the instance size in the current AZ",
      "Take EBS snapshots every hour"
    ],
    "answer": 1,
    "explanation": "High availability against AZ failure requires running across multiple AZs. An ASG plus a load balancer and subnets in multiple AZs ensures the service can continue even if one AZ becomes unavailable.",
    "difficulty": "Hard"
  },
  {
    "id": "SAA-159",
    "domainId": "D2",
    "domain": "Design Resilient Architectures",
    "section": "RDS",
    "question": "A company uses an RDS MySQL database. Reporting queries occasionally cause performance issues for the production workload.\nThey want to isolate reporting reads without impacting write performance and still keep production highly available.\nWhich solution is MOST suitable?",
    "choices": [
      "Scale up the primary database instance and run reporting on it",
      "Create an RDS read replica for reporting queries, and keep Multi-AZ enabled for the primary for availability",
      "Enable Multi-AZ and direct reporting queries to the standby instance",
      "Export all production data to S3 daily and query it with S3 Select"
    ],
    "answer": 1,
    "explanation": "Read replicas offload read-heavy workloads like reporting, while Multi-AZ protects availability. The standby in Multi-AZ is not designed for reads in standard RDS Multi-AZ deployments.",
    "difficulty": "Hard"
  },
  {
    "id": "SAA-160",
    "domainId": "D2",
    "domain": "Design Resilient Architectures",
    "section": "DynamoDB",
    "question": "A company uses DynamoDB with provisioned capacity. During sudden traffic spikes, requests are throttled, causing errors.\nThe business needs the table to handle unpredictable spikes reliably while still optimizing for cost during normal traffic.\nWhich configuration is MOST appropriate?",
    "choices": [
      "Use a larger EC2 instance to host DynamoDB locally",
      "Move the table to S3 Standard to absorb spikes",
      "Disable throttling by turning off DynamoDB partitioning",
      "Enable auto scaling for provisioned read/write capacity (or use on-demand if unpredictability is extreme)"
    ],
    "answer": 3,
    "explanation": "DynamoDB auto scaling adjusts provisioned capacity based on utilization, helping handle spikes while reducing cost during low usage. For highly unpredictable patterns, on-demand capacity may be appropriate as well.",
    "difficulty": "Hard"
  },
  {
    "id": "SAA-161",
    "domainId": "D2",
    "domain": "Design Resilient Architectures",
    "section": "EventBridge",
    "question": "A company wants to decouple multiple microservices and route events based on event content (for example, route “fraud-alert” events to a specific service and “order-created” events to another).\nThey also want built-in retry and DLQ capabilities.\nWhich service is MOST suitable?",
    "choices": [
      "Amazon S3 event notifications only",
      "Amazon EC2 Auto Scaling lifecycle hooks",
      "Amazon Route 53 Resolver",
      "Amazon EventBridge with rules and targets (plus DLQ where appropriate)"
    ],
    "answer": 3,
    "explanation": "EventBridge supports content-based routing using rules and can integrate with targets that provide retry/DLQ behavior, enabling resilient event-driven architectures across services.",
    "difficulty": "Hard"
  },
  {
    "id": "SAA-162",
    "domainId": "D2",
    "domain": "Design Resilient Architectures",
    "section": "EFS",
    "question": "A media processing application runs in two AZs and writes intermediate files to a shared file system. The team wants the shared storage to remain available even if one AZ is impaired, with minimal management.\nWhich choice best meets this requirement?",
    "choices": [
      "Use S3 Glacier Deep Archive for intermediate files",
      "Use instance store on each EC2 instance",
      "Use Amazon EFS mounted from both AZs",
      "Use an EBS volume attached to one instance and share it over NFS yourself"
    ],
    "answer": 2,
    "explanation": "EFS is a managed multi-AZ file system designed for shared access from multiple AZs, providing high availability with minimal operational overhead compared to self-managed NFS on EBS.",
    "difficulty": "Hard"
  },
  {
    "id": "SAA-163",
    "domainId": "D2",
    "domain": "Design Resilient Architectures",
    "section": "S3",
    "question": "A company wants strong protection against accidental deletions and ransomware for an S3 bucket, while still being able to recover data to a previous point in time.\nThey also need the ability to replicate data to another region for DR.\nWhich combination best meets these requirements?",
    "choices": [
      "Enable S3 Transfer Acceleration and store objects as multipart uploads",
      "Use S3 static website hosting and enable logging",
      "Use S3 Select and store query results in another region",
      "Enable S3 versioning and use S3 Object Lock (if WORM is needed) plus S3 Cross-Region Replication where appropriate"
    ],
    "answer": 3,
    "explanation": "Versioning protects against overwrites and deletions by keeping prior versions. Object Lock can provide additional WORM protection. Cross-Region Replication supports region-level disaster recovery by copying objects to another region.",
    "difficulty": "Hard"
  },
  {
    "id": "SAA-164",
    "domainId": "D2",
    "domain": "Design Resilient Architectures",
    "section": "CloudFront",
    "question": "A company uses CloudFront in front of an ALB. The origin sometimes becomes temporarily overloaded, and the company wants CloudFront to serve stale cached objects during brief origin outages to improve resilience.\nWhich CloudFront setting helps achieve this?",
    "choices": [
      "Configure CloudFront to serve stale content on origin errors by using appropriate cache/error settings (stale-while-revalidate / stale-if-error behavior where supported)",
      "Use Route 53 weighted routing between two CloudFront distributions",
      "Enable S3 Transfer Acceleration on the ALB",
      "Disable caching entirely so CloudFront always fetches from the origin"
    ],
    "answer": 0,
    "explanation": "Serving stale cached content during origin errors can reduce user impact during transient origin problems. This is achieved through CloudFront cache/error behavior settings that allow stale responses under certain conditions.",
    "difficulty": "Hard"
  },
  {
    "id": "SAA-165",
    "domainId": "D2",
    "domain": "Design Resilient Architectures",
    "section": "Step Functions",
    "question": "A company has a multi-step serverless workflow (validate → charge → provision → notify). They need reliable orchestration with retries, error handling, and the ability to see where executions failed.\nWhich service is MOST suitable?",
    "choices": [
      "Amazon S3",
      "AWS Step Functions",
      "Amazon SNS",
      "AWS Glue"
    ],
    "answer": 1,
    "explanation": "Step Functions provides workflow orchestration with built-in retries, error handling, state tracking, and execution history, improving resilience and observability for multi-step serverless processes.",
    "difficulty": "Hard"
  },
  {
    "id": "SAA-166",
    "domainId": "D2",
    "domain": "Design Resilient Architectures",
    "section": "VPC",
    "question": "A company runs workloads in two AZs. During an AZ outage, they want their private subnets in the remaining AZ to continue having outbound internet access (for example, to reach a third-party API) without manual intervention.\nWhich design best meets the requirement?",
    "choices": [
      "Deploy a NAT Gateway in each AZ and configure route tables so each private subnet uses the NAT Gateway in the same AZ",
      "Use an Internet Gateway attached directly to the private subnets",
      "Deploy a single NAT Gateway in one AZ and route all private subnets to it",
      "Remove NAT and assign public IPs to instances in private subnets"
    ],
    "answer": 0,
    "explanation": "Using one NAT Gateway per AZ avoids a single-AZ dependency. If an AZ fails, private subnets in the remaining AZ can still route through their local NAT Gateway, maintaining outbound connectivity.",
    "difficulty": "Hard"
  },
  {
    "id": "SAA-167",
    "domainId": "D2",
    "domain": "Design Resilient Architectures",
    "section": "Auto Scaling",
    "question": "An application experiences sudden bursts of traffic. The team uses an Auto Scaling group but scaling out takes several minutes due to long bootstrapping, causing errors during bursts.\nThey want a more resilient way to absorb short spikes while the ASG scales.\nWhich solution is MOST suitable?",
    "choices": [
      "Increase the instance size so scale-out is unnecessary",
      "Place an SQS queue (or similar buffer) between the request intake and the workers to absorb bursts, allowing workers to scale and drain the backlog",
      "Disable health checks to avoid replacing instances",
      "Move the application to a single larger EC2 instance"
    ],
    "answer": 1,
    "explanation": "Introducing a queue buffers bursty workloads and decouples ingestion from processing. This helps maintain resilience during spikes while compute capacity scales to handle the backlog.",
    "difficulty": "Hard"
  },
  {
    "id": "SAA-168",
    "domainId": "D3",
    "domain": "Design High-Performing Architectures",
    "section": "CloudFront",
    "question": "A global news website serves dynamic HTML (personalized) and large static images from the same domain. Users complain that pages are slow during peak hours.\nRequirements:\n- Personalized HTML must not be cached for long\n- Images should be cached globally to reduce origin load\n- Minimal application code changes\nWhich solution BEST meets these requirements?",
    "choices": [
      "Use an NLB in front of the web servers to cache HTML",
      "Use S3 Glacier for images and serve them directly to users",
      "Use CloudFront with separate cache behaviors: cache images aggressively (path-based) and set minimal/zero caching for personalized HTML; forward only needed headers/cookies for dynamic paths",
      "Increase the origin server instance size and disable caching"
    ],
    "answer": 2,
    "explanation": "CloudFront cache behaviors allow different caching rules per path pattern. You can cache static assets heavily while keeping personalized content minimally cached and forwarding only what is required, improving performance and reducing origin load with limited code changes.",
    "difficulty": "Hard"
  },
  {
    "id": "SAA-169",
    "domainId": "D3",
    "domain": "Design High-Performing Architectures",
    "section": "DynamoDB/DAX",
    "question": "A shopping cart service stores cart items in DynamoDB and must serve extremely high read traffic with sub-millisecond latency for the hottest keys during flash sales.\nWrites must still be strongly consistent in DynamoDB.\nWhich solution is MOST suitable to improve read performance?",
    "choices": [
      "Add Multi-AZ to DynamoDB",
      "Move the cart data to S3 Standard and query it with Athena",
      "Add DynamoDB Accelerator (DAX) in front of DynamoDB for cached reads",
      "Use RDS read replicas for the cart table"
    ],
    "answer": 2,
    "explanation": "DAX is an in-memory caching layer for DynamoDB designed to significantly reduce read latency and improve throughput for read-heavy workloads. It complements DynamoDB, which remains the system of record for writes.",
    "difficulty": "Hard"
  },
  {
    "id": "SAA-170",
    "domainId": "D3",
    "domain": "Design High-Performing Architectures",
    "section": "ALB/NLB",
    "question": "A company runs microservices: some are HTTP/2 gRPC services, others are standard HTTP REST services, and one service uses raw TCP.\nThey want to front these services with load balancers while preserving performance and choosing the right protocol support.\nWhich design is MOST appropriate?",
    "choices": [
      "Use CloudFront as the only load balancer for TCP services",
      "Use only an ALB for all services including raw TCP",
      "Use an ALB for HTTP/HTTPS (including gRPC) services and an NLB for the TCP service",
      "Use only an NLB for all services and terminate TLS on instances"
    ],
    "answer": 2,
    "explanation": "ALB is best for Layer 7 HTTP/HTTPS use cases and supports modern features like HTTP routing and gRPC, while NLB is Layer 4 and supports TCP/UDP with high performance. Using both matches protocol needs and performance goals.",
    "difficulty": "Hard"
  },
  {
    "id": "SAA-171",
    "domainId": "D3",
    "domain": "Design High-Performing Architectures",
    "section": "EBS/EFS",
    "question": "A video rendering farm runs on hundreds of EC2 instances. Each job reads large shared media files and writes per-job output files. The shared input data needs high throughput and must be accessible concurrently by all instances.\nWhich storage approach provides the BEST performance and simplest scaling for the shared input data?",
    "choices": [
      "Attach a single EBS volume to one instance and export it via NFS to all instances",
      "Store all shared media in DynamoDB",
      "Store shared input media in S3 and download needed objects per job (or stream), optionally using CloudFront for edge caching if needed",
      "Use instance store on one instance and share it across the fleet"
    ],
    "answer": 2,
    "explanation": "S3 scales massively for shared object storage and avoids single-instance bottlenecks that occur with self-managed NFS on EBS. For large fleets, object-based distribution from S3 is typically simpler and more scalable for shared read-heavy inputs.",
    "difficulty": "Hard"
  },
  {
    "id": "SAA-172",
    "domainId": "D3",
    "domain": "Design High-Performing Architectures",
    "section": "RDS/Aurora",
    "question": "A SaaS application uses Aurora and has a heavy write workload plus a growing number of read-only analytics queries. The team wants to scale reads independently and reduce load on the writer without redesigning the schema.\nWhich solution best meets this requirement?",
    "choices": [
      "Add Aurora reader instances and route read-only queries to the reader endpoint, keeping writes on the writer endpoint",
      "Enable Multi-AZ and route analytics queries to the standby instance",
      "Increase the Aurora storage size to improve read throughput",
      "Move analytics queries to S3 Select against database snapshots"
    ],
    "answer": 0,
    "explanation": "Aurora supports multiple reader instances and provides a reader endpoint to load balance read traffic. This offloads analytics reads from the writer and scales reads independently.",
    "difficulty": "Hard"
  },
  {
    "id": "SAA-173",
    "domainId": "D3",
    "domain": "Design High-Performing Architectures",
    "section": "S3/Glacier",
    "question": "A media company stores raw video files in S3 and must support occasional reprocessing. Most files are rarely accessed after 30 days, but when they are needed they must be retrievable in minutes, not hours.\nThe team wants to reduce storage cost while maintaining the retrieval requirement.\nWhich lifecycle transition is MOST appropriate?",
    "choices": [
      "Transition objects to S3 Glacier Instant Retrieval (or S3 Glacier Flexible Retrieval with expedited where appropriate) after 30 days, based on the minutes-level access requirement",
      "Transition objects directly to S3 Glacier Deep Archive after 30 days",
      "Keep all objects in S3 Standard forever",
      "Transition objects to S3 One Zone-IA and delete them after 30 days"
    ],
    "answer": 0,
    "explanation": "For minutes-level retrieval, Glacier Instant Retrieval (or Flexible Retrieval with a suitable retrieval tier) fits better than Deep Archive, which typically has hours-level retrieval. Lifecycle transitions reduce cost while meeting access needs.",
    "difficulty": "Hard"
  },
  {
    "id": "SAA-174",
    "domainId": "D3",
    "domain": "Design High-Performing Architectures",
    "section": "Global Accelerator",
    "question": "A gaming company runs regional game server fleets in three regions. Players should always connect to the closest healthy region with the lowest latency, and fail over quickly when a region becomes unavailable.\nThey also want to keep using UDP and avoid complex client-side logic.\nWhich solution is MOST suitable?",
    "choices": [
      "Use CloudFront to cache UDP game traffic at the edge",
      "Use AWS Global Accelerator with multiple regional endpoints (NLBs) and health checks to route players to the optimal healthy region",
      "Use Route 53 simple routing with a single record",
      "Use an ALB with HTTP routing rules"
    ],
    "answer": 1,
    "explanation": "Global Accelerator provides fast, deterministic routing over the AWS global network and supports health-based failover to the closest healthy endpoint. It’s well suited for latency-sensitive, global applications and can front NLB endpoints for UDP.",
    "difficulty": "Hard"
  },
  {
    "id": "SAA-175",
    "domainId": "D3",
    "domain": "Design High-Performing Architectures",
    "section": "Kinesis",
    "question": "A company collects clickstream events from millions of users and needs near real-time processing and aggregation. The ingestion layer must handle very high throughput, and multiple consumers (fraud detection, analytics, personalization) must process the same event stream independently.\nWhich solution is MOST appropriate?",
    "choices": [
      "Use Amazon Kinesis Data Streams for ingestion and have multiple consumer applications read from the stream",
      "Use a single SQS queue shared by all consumers",
      "Send events directly to an RDS database table and run triggers",
      "Write all events to S3 and run nightly batch jobs only"
    ],
    "answer": 0,
    "explanation": "Kinesis Data Streams is designed for high-throughput streaming ingestion and supports multiple consumers processing the same stream. SQS does not naturally support multiple independent consumers each receiving all messages without fanout.",
    "difficulty": "Hard"
  },
  {
    "id": "SAA-176",
    "domainId": "D3",
    "domain": "Design High-Performing Architectures",
    "section": "VPC",
    "question": "A private application in a VPC needs low-latency access to Amazon S3 for large object reads. The company wants to avoid NAT bottlenecks and reduce latency jitter.\nWhich network configuration BEST meets this requirement?",
    "choices": [
      "Assign public IPs to instances and access S3 over the internet",
      "Create an S3 Gateway VPC endpoint and route S3 traffic through it",
      "Route S3 traffic through a NAT Gateway in a public subnet",
      "Use VPC peering to an S3 VPC in another account"
    ],
    "answer": 1,
    "explanation": "An S3 gateway endpoint provides private connectivity to S3 without NAT, improving performance and removing NAT as a throughput bottleneck for large S3 transfers.",
    "difficulty": "Hard"
  },
  {
    "id": "SAA-177",
    "domainId": "D3",
    "domain": "Design High-Performing Architectures",
    "section": "EBS",
    "question": "A transactional database on EC2 requires both high IOPS and high throughput. During peak hours, storage performance becomes the bottleneck.\nWhich combination is MOST likely to improve storage performance?",
    "choices": [
      "Move the database files to S3 and mount it as a file system",
      "Move to io2 (Provisioned IOPS) volumes and ensure the instance type supports sufficient EBS bandwidth; consider EBS-optimized instances",
      "Switch to sc1 (Cold HDD) volumes for higher IOPS",
      "Reduce EBS volume size to increase throughput"
    ],
    "answer": 1,
    "explanation": "Provisioned IOPS SSD volumes provide higher and more consistent IOPS. Instance EBS bandwidth limits can also bottleneck, so choosing an instance type with higher EBS throughput (and EBS-optimized) is important.",
    "difficulty": "Hard"
  },
  {
    "id": "SAA-178",
    "domainId": "D3",
    "domain": "Design High-Performing Architectures",
    "section": "Athena/Glue",
    "question": "A data team runs frequent SQL queries on S3 data using Athena. Query performance is inconsistent because the data is stored as large, uncompressed CSV files with many columns, but most queries read only a few columns.\nThey want faster queries and lower cost.\nWhich approach is MOST suitable?",
    "choices": [
      "Increase Athena concurrency by running queries from more clients",
      "Store the CSV files in EBS instead of S3",
      "Move the data into S3 Glacier Deep Archive",
      "Convert the data to a columnar, compressed format (like Parquet/ORC) and partition it appropriately using AWS Glue/Athena best practices"
    ],
    "answer": 3,
    "explanation": "Columnar, compressed formats and partitioning reduce scanned data and improve Athena query performance and cost. Glue can help catalog and transform data into optimized layouts.",
    "difficulty": "Hard"
  },
  {
    "id": "SAA-179",
    "domainId": "D3",
    "domain": "Design High-Performing Architectures",
    "section": "ECS",
    "question": "A company’s containerized API experiences periodic latency spikes due to noisy neighbors on shared EC2 hosts. They want more predictable performance without managing servers.\nWhich approach is MOST suitable?",
    "choices": [
      "Run the service on AWS Fargate to get serverless containers with more isolation and predictable resource allocation per task",
      "Use a single larger EC2 instance with no scaling",
      "Move the service to S3 static hosting",
      "Run the service on spot instances only"
    ],
    "answer": 0,
    "explanation": "Fargate provides task-level CPU/memory allocation and removes the need to manage the underlying EC2 fleet, often improving predictability compared to a heavily shared EC2 cluster configuration.",
    "difficulty": "Hard"
  },
  {
    "id": "SAA-180",
    "domainId": "D3",
    "domain": "Design High-Performing Architectures",
    "section": "CloudFront/ALB",
    "question": "A company serves an API through CloudFront in front of an ALB. They want to reduce latency for global users but must ensure that authentication headers are forwarded and that cached responses do not leak between users.\nWhich CloudFront configuration BEST meets these requirements?",
    "choices": [
      "Use S3 as the origin for the API",
      "Cache all API responses for 24 hours to maximize hit ratio",
      "Disable caching (or set very low TTL) for authenticated API paths and forward only required headers/cookies; cache only truly public responses",
      "Remove authentication headers at CloudFront to improve performance"
    ],
    "answer": 2,
    "explanation": "For personalized/authenticated API responses, caching can cause data leakage unless carefully keyed and controlled. The safest approach is to minimize caching for authenticated paths while forwarding only necessary headers/cookies, caching only public endpoints.",
    "difficulty": "Hard"
  },
  {
    "id": "SAA-181",
    "domainId": "D3",
    "domain": "Design High-Performing Architectures",
    "section": "EC2",
    "question": "A compute workload requires very high packet-per-second performance and low network latency. The team also wants to minimize CPU overhead for networking.\nWhich EC2 feature best supports this?",
    "choices": [
      "Using S3 Transfer Acceleration",
      "Enhanced networking (ENA) on supported instance types",
      "Using a smaller instance type to reduce noise",
      "Placing instances in multiple regions"
    ],
    "answer": 1,
    "explanation": "Enhanced networking with ENA provides higher bandwidth, higher PPS, and lower latency by using SR-IOV, reducing CPU overhead for networking on supported instances.",
    "difficulty": "Hard"
  },
  {
    "id": "SAA-182",
    "domainId": "D3",
    "domain": "Design High-Performing Architectures",
    "section": "S3",
    "question": "A company stores large log files in S3 and frequently needs to retrieve only a subset of fields from the logs (for example, a few columns) without downloading entire objects.\nWhich S3 capability best meets this requirement?",
    "choices": [
      "Use S3 Transfer Acceleration to download the full object faster",
      "Use S3 Select to retrieve only the required data from objects",
      "Use S3 Object Lock to prevent changes",
      "Use S3 Glacier Deep Archive and restore the object"
    ],
    "answer": 1,
    "explanation": "S3 Select allows applications to retrieve a subset of data (using SQL expressions) from an object, reducing data transfer and improving performance when only parts of the object are needed.",
    "difficulty": "Hard"
  },
  {
    "id": "SAA-183",
    "domainId": "D3",
    "domain": "Design High-Performing Architectures",
    "section": "Caching",
    "question": "A web application uses an RDS database and experiences spikes in read traffic for a small set of “hot” products. The team wants to reduce database load and keep response times consistently low during spikes.\nThey also want the solution to be simple to operate.\nWhich solution is MOST suitable?",
    "choices": [
      "Store product data only in S3 Glacier to reduce DB load",
      "Enable RDS Multi-AZ and send reads to the standby",
      "Cache hot items in ElastiCache and apply an appropriate cache invalidation/TTL strategy",
      "Increase EBS volume size on the database instance"
    ],
    "answer": 2,
    "explanation": "ElastiCache provides low-latency caching for hot data, reducing repetitive reads to the database and improving performance during spikes. Multi-AZ improves availability but doesn’t offload reads in typical configurations.",
    "difficulty": "Hard"
  },
  {
    "id": "SAA-184",
    "domainId": "D4",
    "domain": "Design Cost-Optimized Architectures",
    "section": "S3",
    "question": "A company stores confidential build artifacts in S3 and wants to “never worry about capacity.” For the first 30 days, all artifacts are accessed frequently. After 30 days, most artifacts are rarely accessed, and retrieval time is not strict for developers.\nHowever, objects under the prefix /finance-fast/ are used by an automated post-processing pipeline that requires millisecond retrieval at any time.\nWhich lifecycle approach is MOST cost-effective while meeting the access requirements?",
    "choices": [
      "Enable S3 Intelligent-Tiering for the entire bucket and disable any archive tiers",
      "Keep everything in S3 Standard and rely on compression to reduce cost",
      "Transition the entire bucket to S3 Glacier Deep Archive after 30 days",
      "Use lifecycle rules to transition most objects to Glacier Flexible Retrieval after 30 days, but transition /finance-fast/ objects to S3 Standard-IA (or keep in Standard) to maintain millisecond retrieval"
    ],
    "answer": 3,
    "explanation": "Most artifacts can move to an archive tier (like Glacier Flexible Retrieval) after the frequent-access window because developers have no strict retrieval latency requirement. The /finance-fast/ prefix must stay in a millisecond-access class (Standard or Standard-IA). Prefix-based lifecycle rules meet both requirements at lowest cost.",
    "difficulty": "Hard"
  },
  {
    "id": "SAA-185",
    "domainId": "D4",
    "domain": "Design Cost-Optimized Architectures",
    "section": "EC2",
    "question": "A company has a mixed compute fleet:\n- A baseline set of instances runs 24/7 year-round\n- Additional instances run only during occasional peak campaigns\nThey want to minimize cost while keeping flexibility for peaks.\nWhich purchasing strategy is MOST cost-effective?",
    "choices": [
      "Use Spot Instances for the baseline steady-state because it is cheapest",
      "Use Savings Plans or Reserved Instances for the baseline, and use On-Demand or Spot (where appropriate) for the variable peak capacity",
      "Use On-Demand for everything to keep flexibility",
      "Use Dedicated Hosts for all instances to reduce cost"
    ],
    "answer": 1,
    "explanation": "A blended strategy is typically optimal: commit discounts (RI/Savings Plans) for steady usage, and use flexible capacity (On-Demand or Spot for fault-tolerant workloads) for peaks. Spot for baseline is risky due to interruptions.",
    "difficulty": "Hard"
  },
  {
    "id": "SAA-186",
    "domainId": "D4",
    "domain": "Design Cost-Optimized Architectures",
    "section": "RDS/Aurora",
    "question": "A startup is building an application with an unpredictable traffic pattern. They need a relational database but want to minimize operational overhead and avoid paying for unused capacity during idle periods.\nWhich option is MOST cost-effective and operationally simple?",
    "choices": [
      "Run MySQL on a large EC2 instance and scale it manually",
      "Use Redshift because it is serverless",
      "Use Aurora Serverless (where supported) to automatically scale capacity based on demand",
      "Use a multi-node self-managed PostgreSQL cluster on EC2 for high availability"
    ],
    "answer": 2,
    "explanation": "Aurora Serverless is designed for variable and unpredictable workloads, automatically scaling capacity and reducing the need to overprovision. Managing databases on EC2 generally increases operational overhead and can be less cost-effective for spiky usage.",
    "difficulty": "Hard"
  },
  {
    "id": "SAA-187",
    "domainId": "D4",
    "domain": "Design Cost-Optimized Architectures",
    "section": "NAT/VPC",
    "question": "A company has workloads in three AZs. Each private subnet routes outbound internet traffic through a single NAT Gateway. Costs are high and throughput is occasionally constrained.\nThey also want to be resilient to an AZ outage.\nWhich design best optimizes BOTH cost and resilience?",
    "choices": [
      "Move all instances to public subnets to avoid NAT cost",
      "Replace NAT Gateway with an Internet Gateway in private subnets",
      "Keep one NAT Gateway and increase its size",
      "Deploy one NAT Gateway per AZ and route each private subnet to the NAT Gateway in the same AZ; add VPC endpoints for high-volume AWS services like S3/DynamoDB to reduce NAT usage"
    ],
    "answer": 3,
    "explanation": "One NAT per AZ avoids a single-AZ dependency, improving resilience. Adding VPC endpoints for high-volume AWS services reduces NAT data processing charges and can improve throughput, optimizing overall cost and performance.",
    "difficulty": "Hard"
  },
  {
    "id": "SAA-188",
    "domainId": "D4",
    "domain": "Design Cost-Optimized Architectures",
    "section": "DynamoDB",
    "question": "A company uses DynamoDB for an API with a predictable daily traffic pattern: low at night, very high during business hours. They want to minimize cost while avoiding throttling.\nWhich configuration is MOST suitable?",
    "choices": [
      "Move the API data to S3 Standard to reduce costs",
      "Use provisioned capacity with auto scaling (and scheduled scaling if needed) to match predictable peaks and troughs",
      "Fix provisioned capacity at the peak level 24/7",
      "Use on-demand capacity because it is always cheapest"
    ],
    "answer": 1,
    "explanation": "Provisioned capacity with auto scaling (and optionally scheduled scaling) is well suited for predictable patterns, reducing cost during low periods while scaling up during known peaks. On-demand is simpler but may be more expensive for predictable steady usage.",
    "difficulty": "Hard"
  },
  {
    "id": "SAA-189",
    "domainId": "D4",
    "domain": "Design Cost-Optimized Architectures",
    "section": "S3",
    "question": "A data lake stores raw data in S3. The analytics team needs frequent queries on recent data (last 7 days) and rarely queries older data, but when they do, queries must still work without manual restores.\nThey want to reduce storage cost without breaking analytics workflows.\nWhich S3 storage strategy is MOST appropriate?",
    "choices": [
      "Store all data in EBS volumes attached to an EC2 instance",
      "Delete all data older than 7 days and rely on backups",
      "Move all older data to Glacier Deep Archive after 7 days",
      "Keep recent data in S3 Standard and transition older data to S3 Intelligent-Tiering (with archive tiers if retrieval latency is acceptable) so access remains transparent"
    ],
    "answer": 3,
    "explanation": "Intelligent-Tiering can automatically move objects between access tiers while keeping access transparent to applications, which helps when older data is occasionally queried without requiring manual restore steps (depending on selected tiers and retrieval expectations).",
    "difficulty": "Hard"
  },
  {
    "id": "SAA-190",
    "domainId": "D4",
    "domain": "Design Cost-Optimized Architectures",
    "section": "CloudFront",
    "question": "A company has a global customer base and serves large downloadable installers from an S3 bucket in one region. They pay high data transfer charges from S3 and users far from the region have slow downloads.\nThey want to improve download performance and reduce origin load, with minimal changes.\nWhich solution is MOST suitable?",
    "choices": [
      "Use an ALB in front of S3 to reduce transfer charges",
      "Move the installers to Glacier Deep Archive to reduce cost",
      "Use CloudFront in front of the S3 bucket and cache the installers at edge locations; set appropriate TTLs and enable compression if applicable",
      "Use a NAT Gateway to speed up downloads"
    ],
    "answer": 2,
    "explanation": "CloudFront caches large files at edge locations, improving download performance globally and reducing repeated origin fetches. This can reduce S3 request load and may lower overall cost depending on traffic patterns.",
    "difficulty": "Hard"
  },
  {
    "id": "SAA-191",
    "domainId": "D4",
    "domain": "Design Cost-Optimized Architectures",
    "section": "EFS",
    "question": "A company uses Amazon EFS for shared storage. Most files are read only a few times after creation, but must remain instantly accessible when needed.\nThey want to reduce ongoing storage costs without changing the application.\nWhich EFS feature should they use?",
    "choices": [
      "Transition files to S3 Glacier Deep Archive automatically",
      "Disable encryption on EFS to reduce cost",
      "Mount the EFS file system only during business hours",
      "Enable EFS lifecycle management to transition files to EFS Infrequent Access (EFS IA) after a defined period"
    ],
    "answer": 3,
    "explanation": "EFS lifecycle management can move infrequently accessed files into EFS IA automatically, reducing storage cost while keeping the same file system interface and immediate access when needed.",
    "difficulty": "Hard"
  },
  {
    "id": "SAA-192",
    "domainId": "D4",
    "domain": "Design Cost-Optimized Architectures",
    "section": "RDS",
    "question": "A company’s RDS database storage keeps growing. They store large audit records that are never updated and are queried only a few times per year. The production database must stay fast and cost-effective.\nWhich approach is MOST cost-effective long term?",
    "choices": [
      "Store audit records in EC2 instance store for low cost",
      "Archive historical audit records to S3 (for example, in Parquet) and query them with Athena when needed, keeping only recent/hot data in RDS",
      "Keep all audit records in RDS and increase storage indefinitely",
      "Move the entire database to a larger RDS instance type"
    ],
    "answer": 1,
    "explanation": "Keeping rarely accessed historical data in RDS increases cost and can impact performance. Archiving cold data to S3 and querying with Athena is typically more cost-effective for infrequent access while keeping the production database lean.",
    "difficulty": "Hard"
  },
  {
    "id": "SAA-193",
    "domainId": "D4",
    "domain": "Design Cost-Optimized Architectures",
    "section": "Messaging",
    "question": "A company needs to process images uploaded by users. Processing is bursty: huge spikes during events and almost none at other times.\nThey want to minimize cost while ensuring the system can handle spikes without losing requests.\nWhich architecture is MOST cost-effective?",
    "choices": [
      "Run a fixed fleet of EC2 workers 24/7 sized for peak load",
      "Process images synchronously in the upload request path",
      "Use S3 event notifications to an SQS queue and scale workers (Lambda or ECS) based on queue depth; use DLQ for failures",
      "Write all uploads to EBS and poll the disk every minute"
    ],
    "answer": 2,
    "explanation": "Queue-based buffering decouples ingestion from processing, allowing cost-efficient scale-out during spikes and scale-in when idle. A fixed peak-sized fleet wastes money during idle periods, and synchronous processing increases latency and failure risk.",
    "difficulty": "Hard"
  },
  {
    "id": "SAA-194",
    "domainId": "D4",
    "domain": "Design Cost-Optimized Architectures",
    "section": "Compute",
    "question": "A company runs CI jobs that compile code for 10–20 minutes and then terminate. Jobs are fault-tolerant and can be retried. The team wants the lowest possible compute cost.\nWhich option is MOST suitable?",
    "choices": [
      "Use On-Demand instances only",
      "Use Spot Instances (or Spot capacity in a managed service) with retry handling",
      "Use Dedicated Hosts to get discounts on short jobs",
      "Use 3-year Reserved Instances for all CI jobs"
    ],
    "answer": 1,
    "explanation": "Short-lived, fault-tolerant workloads are ideal for Spot, which can offer deep discounts. Retries handle interruptions. Reserved Instances and Dedicated Hosts are less suitable for highly variable short jobs.",
    "difficulty": "Hard"
  },
  {
    "id": "SAA-195",
    "domainId": "D4",
    "domain": "Design Cost-Optimized Architectures",
    "section": "S3",
    "question": "A company must keep a large volume of documents for 7 years for compliance. During the first 90 days, documents are accessed infrequently but must be retrieved in milliseconds. After 90 days, documents are almost never accessed and retrieval can take hours.\nThey want the most cost-effective S3 lifecycle plan.\nWhich option BEST meets the requirements?",
    "choices": [
      "Store in S3 One Zone-IA for 90 days then delete",
      "Store in S3 Intelligent-Tiering only and disable archive tiers",
      "Store in S3 Glacier Deep Archive immediately",
      "Store in S3 Standard initially, transition to S3 Standard-IA shortly after creation, and transition to S3 Glacier Deep Archive after 90 days"
    ],
    "answer": 3,
    "explanation": "Standard-IA provides millisecond retrieval for infrequent access during the first 90 days. After 90 days, Deep Archive minimizes cost when hours-level retrieval is acceptable. This lifecycle aligns storage class to access and latency needs over time.",
    "difficulty": "Hard"
  },
  {
    "id": "SAA-196",
    "domainId": "D3",
    "domain": "Design High-Performing Architectures",
    "section": "EC2",
    "question": "In the instance name m5.2xlarge, what does the “5” represent?",
    "choices": [
      "Network speed tier",
      "Storage type",
      "Instance size",
      "Generation"
    ],
    "answer": 3,
    "explanation": "In EC2 instance naming, the number indicates the instance generation (e.g., m5 is 5th-generation general purpose).",
    "difficulty": "Easy"
  },
  {
    "id": "SAA-197",
    "domainId": "D3",
    "domain": "Design High-Performing Architectures",
    "section": "EC2",
    "question": "What is an AMI mainly used for?",
    "choices": [
      "Scaling traffic across instances",
      "Attaching a second ENI",
      "Preconfigured image to launch EC2s with OS/software",
      "Long-term object storage"
    ],
    "answer": 2,
    "explanation": "An AMI (Amazon Machine Image) is a template used to launch EC2 instances with a predefined OS and optional software/configuration.",
    "difficulty": "Easy"
  },
  {
    "id": "SAA-198",
    "domainId": "D3",
    "domain": "Design High-Performing Architectures",
    "section": "EBS",
    "question": "What happens to a root EBS volume on instance termination by default?",
    "choices": [
      "Moved to another AZ",
      "Snapshotted automatically",
      "Deleted by default",
      "Always kept"
    ],
    "answer": 2,
    "explanation": "By default, the root EBS volume has DeleteOnTermination=true, so it is deleted when the instance is terminated (unless you change that setting).",
    "difficulty": "Easy"
  },
  {
    "id": "SAA-199",
    "domainId": "D4",
    "domain": "Design Cost-Optimized Architectures",
    "section": "EC2 Pricing",
    "question": "Which purchase option is best for short, unpredictable workloads?",
    "choices": [
      "Savings Plans",
      "Dedicated Hosts",
      "On-Demand",
      "Reserved Instances"
    ],
    "answer": 2,
    "explanation": "On-Demand is best for short-term, spiky, or unpredictable usage because it requires no commitment and you pay only for what you use.",
    "difficulty": "Easy"
  },
  {
    "id": "SAA-200",
    "domainId": "D1",
    "domain": "Design Secure Architectures",
    "section": "IAM",
    "question": "In which ways can a user access AWS?",
    "choices": [
      "SSH, CLI, SDK",
      "AWS Console, SSH, FTP",
      "AWS Console, CLI, SDK",
      "Console only"
    ],
    "answer": 2,
    "explanation": "Users access AWS via the Management Console, AWS CLI, and AWS SDKs/APIs. SSH/FTP are used to access servers (like EC2), not to access AWS services directly.",
    "difficulty": "Easy"
  },
  {
    "id": "SAA-201",
    "domainId": "D1",
    "domain": "Design Secure Architectures",
    "section": "IAM",
    "question": "In IAM, where do you usually attach permissions for many users at once?",
    "choices": [
      "To S3 buckets",
      "To passwords",
      "To groups with policies",
      "To VPCs"
    ],
    "answer": 2,
    "explanation": "Best practice is to attach policies to IAM groups (or roles) and then add users to groups, so you manage permissions at scale.",
    "difficulty": "Easy"
  },
  {
    "id": "SAA-202",
    "domainId": "D1",
    "domain": "Design Secure Architectures",
    "section": "VPC",
    "question": "By default, a Security Group allows:",
    "choices": [
      "All inbound and all outbound",
      "Blocks all inbound and outbound",
      "Blocks all inbound and allows all outbound",
      "All inbound and blocks all outbound"
    ],
    "answer": 2,
    "explanation": "A new security group starts with no inbound rules (so inbound is blocked) and an allow-all outbound rule (so outbound is allowed).",
    "difficulty": "Easy"
  },
  {
    "id": "SAA-203",
    "domainId": "D3",
    "domain": "Design High-Performing Architectures",
    "section": "EC2 Networking",
    "question": "Your EC2 public IP keeps changing after stop/start. What’s the simple AWS feature to keep a fixed public IPv4?",
    "choices": [
      "Private IP",
      "Elastic IP",
      "Route 53 Alias",
      "NAT Gateway"
    ],
    "answer": 1,
    "explanation": "An Elastic IP (EIP) is a static public IPv4 address you can allocate and associate to an instance (or other resources). It stays the same across stop/start as long as it remains allocated to you.",
    "difficulty": "Easy"
  },
  {
    "id": "SAA-204",
    "domainId": "D3",
    "domain": "Design High-Performing Architectures",
    "section": "Storage",
    "question": "EBS vs EFS — which pairing is MOST accurate?",
    "choices": [
      "EBS: single instance / AZ-scoped; EFS: multi-AZ, many instances",
      "Both are multi-AZ, many instances",
      "EBS: multi-AZ, many instances; EFS: single instance only",
      "Both are single-instance only"
    ],
    "answer": 0,
    "explanation": "EBS is block storage that is scoped to a single Availability Zone and typically attached to one instance (with limited exceptions like Multi-Attach within the same AZ). EFS is a regional, multi-AZ file system that can be mounted by many instances concurrently.",
    "difficulty": "Medium"
  },
  {
    "id": "SAA-205",
    "domainId": "D3",
    "domain": "Design High-Performing Architectures",
    "section": "EC2",
    "question": "EC2 User Data scripts run…",
    "choices": [
      "Every hour",
      "Every time the instance reboots",
      "After the instance is terminated",
      "Once, at the first start of the instance"
    ],
    "answer": 3,
    "explanation": "By default, EC2 user data runs only on the first boot/first launch of the instance (unless you build custom logic to run it again).",
    "difficulty": "Easy"
  },
  {
    "id": "SAA-206",
    "domainId": "D3",
    "domain": "Design High-Performing Architectures",
    "section": "ELB",
    "question": "Your application runs on EC2 instances in two AZs. You need a managed service to distribute incoming HTTP/HTTPS traffic across all instances. What should you use?",
    "choices": [
      "Application Load Balancer",
      "Amazon Route 53",
      "Classic Load Balancer",
      "Network Load Balancer"
    ],
    "answer": 0,
    "explanation": "An Application Load Balancer (ALB) is designed for HTTP/HTTPS (Layer 7) traffic, supports advanced routing (host/path rules), and can distribute requests across targets in multiple AZs.",
    "difficulty": "Easy"
  },
  {
    "id": "SAA-207",
    "domainId": "D2",
    "domain": "Design Resilient Architectures",
    "section": "ELB",
    "question": "You have an ALB with targets in multiple AZs. One instance fails its health checks. What will the ALB do?",
    "choices": [
      "Terminate the instance and launch a new one",
      "Continue sending some traffic until all instances are unhealthy",
      "Automatically resize the instance type",
      "Stop sending traffic to the unhealthy instance"
    ],
    "answer": 3,
    "explanation": "An ALB uses health checks to determine target health. If a target becomes unhealthy, the ALB stops routing traffic to it. (Replacing/terminating instances is the job of Auto Scaling, not the ALB.)",
    "difficulty": "Easy"
  },
  {
    "id": "SAA-208",
    "domainId": "D2",
    "domain": "Design Resilient Architectures",
    "section": "Auto Scaling",
    "question": "Which option BEST describes how an Auto Scaling Group (ASG) works?",
    "choices": [
      "Manually starts EC2 instances on a fixed schedule only",
      "Is used only with Spot Instances",
      "Only replaces unhealthy instances but never changes capacity",
      "Automatically adds or removes EC2 instances based on policies and health checks"
    ],
    "answer": 3,
    "explanation": "An Auto Scaling Group maintains desired capacity and can scale out/in automatically using scaling policies (for example, CPU-based) and can also replace unhealthy instances based on health checks.",
    "difficulty": "Easy"
  },
  {
    "id": "SAA-209",
    "domainId": "D2",
    "domain": "Design Resilient Architectures",
    "section": "Auto Scaling",
    "question": "You configure an ASG with Min=2, Max=6, Desired=3. A scaling policy adds 2 instances when CPU > 70%. What happens on the first scale-out event?",
    "choices": [
      "ASG will have 6 instances",
      "ASG will have 4 instances",
      "ASG will have 5 instances",
      "ASG will have 3 instances"
    ],
    "answer": 2,
    "explanation": "The ASG starts at Desired=3. On the first scale-out event, the policy adds 2 instances, bringing it to 5 total. This is within Max=6, so it scales to 5.",
    "difficulty": "Easy"
  },
  {
    "id": "SAA-210",
    "domainId": "D3",
    "domain": "Design High-Performing Architectures",
    "section": "ELB",
    "question": "You need extremely high performance TCP traffic handling with static IPs per AZ. Which load balancer should you choose?",
    "choices": [
      "Network Load Balancer",
      "Classic Load Balancer",
      "Application Load Balancer",
      "Gateway Load Balancer"
    ],
    "answer": 0,
    "explanation": "A Network Load Balancer (NLB) operates at Layer 4 (TCP/UDP/TLS), supports very high throughput and low latency, and provides static IP addresses per Availability Zone (or you can use Elastic IPs).",
    "difficulty": "Medium"
  },
  {
    "id": "SAA-211",
    "domainId": "D2",
    "domain": "Design Resilient Architectures",
    "section": "RDS",
    "question": "Your production MySQL database on RDS must have automatic failover to another AZ with minimal changes to your application endpoint. What should you enable?",
    "choices": [
      "RDS Multi-AZ deployment",
      "RDS Read Replica in the same AZ",
      "Store data only on EBS attached to EC2",
      "RDS snapshot every hour"
    ],
    "answer": 0,
    "explanation": "RDS Multi-AZ provides synchronous replication to a standby in a different AZ and supports automatic failover. The DB endpoint remains the same, so application changes are minimal. Read replicas are mainly for read scaling and are not the primary HA/failover mechanism.",
    "difficulty": "Medium"
  },
  {
    "id": "SAA-212",
    "domainId": "D2",
    "domain": "Design Resilient Architectures",
    "section": "Aurora",
    "question": "Which statement about Amazon Aurora is MOST accurate?",
    "choices": [
      "Aurora automatically replicates data across multiple AZs",
      "Aurora has no separation between writer and reader",
      "Aurora supports only one AZ",
      "Aurora is only for key-value workloads"
    ],
    "answer": 0,
    "explanation": "Amazon Aurora is a relational database compatible with MySQL/PostgreSQL and is designed for high availability by replicating data across multiple Availability Zones in a region. It supports a writer instance and multiple reader instances for read scaling.",
    "difficulty": "Medium"
  },
  {
    "id": "SAA-213",
    "domainId": "D3",
    "domain": "Design High-Performing Architectures",
    "section": "ElastiCache",
    "question": "You want to reduce read load on your RDS database by caching frequently accessed session data in memory. Which AWS service is the BEST fit?",
    "choices": [
      "Amazon S3",
      "AWS Lambda",
      "Amazon EFS",
      "Amazon ElastiCache"
    ],
    "answer": 3,
    "explanation": "Amazon ElastiCache (Redis or Memcached) is an in-memory caching service that reduces database load and improves latency for frequently accessed data like sessions, tokens, or hot reads.",
    "difficulty": "Easy"
  },
  {
    "id": "SAA-214",
    "domainId": "D3",
    "domain": "Design High-Performing Architectures",
    "section": "ElastiCache",
    "question": "You need a simple in-memory cache with multiple nodes, no persistence, and easy horizontal scaling. Which ElastiCache engine is MOST suitable?",
    "choices": [
      "Amazon Aurora MySQL",
      "Redis",
      "Amazon DynamoDB",
      "Memcached"
    ],
    "answer": 3,
    "explanation": "Memcached is a simple, distributed in-memory cache designed for ease of horizontal scaling and does not provide persistence. Redis supports more advanced data structures and can provide persistence/replication, but for a simple non-persistent cache, Memcached is the better fit.",
    "difficulty": "Medium"
  },
  {
    "id": "SAA-215",
    "domainId": "D2",
    "domain": "Design Resilient Architectures",
    "section": "Architecture",
    "question": "An app runs behind an ALB with an ASG and uses RDS Multi-AZ plus ElastiCache. Which statement BEST describes this architecture?",
    "choices": [
      "It guarantees zero downtime in all failure scenarios",
      "It only improves security, not availability",
      "It removes the need for backups",
      "It is designed for high availability and scalability"
    ],
    "answer": 3,
    "explanation": "ALB + ASG provides scalable and fault-tolerant compute across AZs. RDS Multi-AZ adds database high availability with automatic failover. ElastiCache improves read performance and can reduce DB load. Together this architecture is designed for high availability and scalability, but it doesn’t guarantee zero downtime in every scenario and it does not eliminate the need for backups.",
    "difficulty": "Medium"
  },
  {
    "id": "SAA-216",
    "domainId": "D2",
    "domain": "Design Resilient Architectures",
    "section": "Route 53",
    "question": "You need to map the root domain example.com to an Application Load Balancer. What should you create in Route 53?",
    "choices": [
      "Alias A record pointing to the ALB",
      "CNAME record pointing to the ALB DNS name",
      "NS record pointing to the ALB",
      "Simple routing policy with the ALB’s IPs"
    ],
    "answer": 0,
    "explanation": "Route 53 does not allow a CNAME at the zone apex (root domain). To point example.com to an ALB, you create an Alias A record to the ALB DNS name. Alias records work at the apex and don’t require hardcoding IPs.",
    "difficulty": "Medium"
  },
  {
    "id": "SAA-217",
    "domainId": "D2",
    "domain": "Design Resilient Architectures",
    "section": "Route 53",
    "question": "You want to send 20% of traffic to a new version and 80% to the old one, both behind different target groups. Which policy fits best?",
    "choices": [
      "Geolocation",
      "Simple",
      "Weighted",
      "Latency-based"
    ],
    "answer": 2,
    "explanation": "Weighted routing lets you split traffic across multiple records by percentage using weights (for example, 20/80). This is commonly used for gradual rollouts and A/B testing.",
    "difficulty": "Medium"
  },
  {
    "id": "SAA-218",
    "domainId": "D2",
    "domain": "Design Resilient Architectures",
    "section": "Route 53",
    "question": "You run active–passive across two endpoints. If the primary fails health checks, traffic must move to standby automatically. What should you use?",
    "choices": [
      "Failover routing with health checks",
      "Geoproximity routing",
      "Latency-based routing",
      "Multi-Value Answer"
    ],
    "answer": 0,
    "explanation": "Failover routing is built for active-passive setups. You configure primary and secondary records and associate health checks so Route 53 routes traffic to the secondary endpoint when the primary fails.",
    "difficulty": "Medium"
  },
  {
    "id": "SAA-219",
    "domainId": "D2",
    "domain": "Design Resilient Architectures",
    "section": "Route 53",
    "question": "You want EU visitors routed to eu-west-1 even if another region is currently lower latency for some users. Which policy?",
    "choices": [
      "Latency-based",
      "Geolocation",
      "Multi-Value Answer",
      "Weighted"
    ],
    "answer": 1,
    "explanation": "Geolocation routing routes users based on the geographic location of their DNS resolvers (for example, Europe to eu-west-1). It is chosen when you want location-based control, not “best latency.”",
    "difficulty": "Medium"
  },
  {
    "id": "SAA-220",
    "domainId": "D2",
    "domain": "Design Resilient Architectures",
    "section": "Route 53",
    "question": "Your app runs on several EC2 instances with public IPs. You don’t need L7 features, just simple DNS returning several healthy IPs. Which policy?",
    "choices": [
      "Latency-based",
      "Geoproximity",
      "Failover",
      "Multi-Value Answer"
    ],
    "answer": 3,
    "explanation": "Multi-Value Answer routing returns multiple values (IPs) for a record and can be associated with health checks to return only healthy endpoints. It’s a simple way to do basic DNS-based load distribution without advanced routing logic.",
    "difficulty": "Medium"
  },
  {
    "id": "SAA-221",
    "domainId": "D3",
    "domain": "Design High-Performing Architectures",
    "section": "Route 53",
    "question": "You’re hosting a static website directly on S3 and want example.com to resolve to it. What Route 53 record do you need?",
    "choices": [
      "AAAA record to the bucket",
      "Alias A record to the ALB",
      "Alias A record to the S3 website endpoint",
      "CNAME to the S3 REST endpoint"
    ],
    "answer": 2,
    "explanation": "For an S3 static website, you use the S3 **website endpoint** (not the REST endpoint). To map the root domain (example.com), create an Alias A record pointing to the S3 website endpoint so it works at the zone apex.",
    "difficulty": "Medium"
  },
  {
    "id": "SAA-222",
    "domainId": "D2",
    "domain": "Design Resilient Architectures",
    "section": "S3",
    "question": "Which statement about S3 Versioning is most accurate?",
    "choices": [
      "It automatically replicates objects across regions",
      "It’s required only for Glacier usage",
      "It can be turned on and fully turned off with all old versions deleted automatically",
      "It can be enabled and later suspended; past versions remain, helping recover deletes/overwrites."
    ],
    "answer": 3,
    "explanation": "S3 versioning can be enabled and later suspended, but it cannot be fully “disabled” back to a never-versioned state. Existing versions remain and help recover from accidental deletes/overwrites. Replication across regions is a separate feature (CRR).",
    "difficulty": "Medium"
  },
  {
    "id": "SAA-223",
    "domainId": "D2",
    "domain": "Design Resilient Architectures",
    "section": "S3",
    "question": "You need Cross-Region Replication (CRR) from us-east-1 to eu-west-1. What is a hard prerequisite?",
    "choices": [
      "A lifecycle rule to transition objects to IA",
      "Versioning enabled on both source and destination",
      "Object Lock enabled on both buckets",
      "Default bucket encryption enabled"
    ],
    "answer": 1,
    "explanation": "Cross-Region Replication requires versioning to be enabled on both the source and destination buckets. Without versioning, CRR cannot replicate objects.",
    "difficulty": "Medium"
  },
  {
    "id": "SAA-224",
    "domainId": "D4",
    "domain": "Design Cost-Optimized Architectures",
    "section": "S3",
    "question": "You store objects that are rarely accessed but must be retrieved in milliseconds when needed. You are ok with a single AZ to cut costs. Which storage class?",
    "choices": [
      "S3 Glacier Instant Retrieval",
      "S3 One Zone-IA",
      "S3 Standard",
      "S3 Standard-IA"
    ],
    "answer": 1,
    "explanation": "S3 One Zone-IA is designed for infrequently accessed data with millisecond access, stored in a single Availability Zone at a lower cost than Standard-IA. This matches the requirement for rare access, millisecond retrieval, and cost savings by using one AZ.",
    "difficulty": "Medium"
  },
  {
    "id": "SAA-225",
    "domainId": "D4",
    "domain": "Design Cost-Optimized Architectures",
    "section": "S3",
    "question": "You have tens of millions of objects with unpredictable access patterns. You want automatic cost optimization without changing the app, millisecond retrieval when accessed again, and no retrieval fees. Which storage class is best?",
    "choices": [
      "S3 Glacier Instant Retrieval",
      "S3 One Zone-IA",
      "S3 Intelligent-Tiering",
      "S3 Standard-IA"
    ],
    "answer": 2,
    "explanation": "S3 Intelligent-Tiering automatically moves objects between access tiers based on usage, requires no application changes, keeps millisecond retrieval, and does not charge retrieval fees (it charges a small monitoring/automation fee). This matches the requirements for unpredictable access at very large scale.",
    "difficulty": "Hard"
  },
  {
    "id": "SAA-226",
    "domainId": "D4",
    "domain": "Design Cost-Optimized Architectures",
    "section": "S3",
    "question": "You host a public dataset in S3 and want downloaders to pay request and data-transfer costs while you continue paying for storage. What should you enable?",
    "choices": [
      "S3 Transfer Acceleration",
      "S3 Access Points with VPC restriction",
      "Bucket ACLs granting Everyone: READ",
      "Requester Pays"
    ],
    "answer": 3,
    "explanation": "Enable S3 Requester Pays so the requester (downloader) is charged for request and data transfer costs, while the bucket owner continues to pay for storage.",
    "difficulty": "Medium"
  },
  {
    "id": "SAA-227",
    "domainId": "D3",
    "domain": "Design High-Performing Architectures",
    "section": "S3",
    "question": "You must apply a new tag to 50 million existing objects across several buckets, and get a progress report. what is the easiest native option?",
    "choices": [
      "S3 Batch Operations with a manifest",
      "S3 Storage Lens",
      "AWS Glue crawler + Lambda per object",
      "Parallel PutObjectTagging from a custom script"
    ],
    "answer": 0,
    "explanation": "S3 Batch Operations is designed for large-scale object operations (like tagging) across millions or billions of objects. You provide a manifest of objects and get a job progress/completion report. This is the most native and operationally simple option compared to running custom scripts.",
    "difficulty": "Hard"
  },
  {
    "id": "SAA-228",
    "domainId": "D1",
    "domain": "Design Secure Architectures",
    "section": "S3",
    "question": "Security requires all new objects be encrypted with your KMS CMK. How do you enforce it?",
    "choices": [
      "Turn on default encryption SSE-S3",
      "Use ACLs to deny unencrypted uploads",
      "Enable Object Lock in Compliance mode",
      "Bucket policy that allows s3:PutObject only when s3:x-amz-server-side-encryption = aws:kms and s3:x-amz-server-side-encryption-aws-kms-key-id = your CMK"
    ],
    "answer": 3,
    "explanation": "Default encryption helps, but enforcement is done with a bucket policy. You can require that PutObject requests specify SSE-KMS and the exact KMS key ID (your CMK). If the request doesn't include these headers/values, the upload is denied, guaranteeing all new objects use your CMK.",
    "difficulty": "Hard"
  },
  {
    "id": "SAA-229",
    "domainId": "D1",
    "domain": "Design Secure Architectures",
    "section": "S3",
    "question": "A web app at https://app.example.com must use JavaScript to PUT/GET objects in https://my-bucket.s3.amazonaws.com. Requests are blocked by the browser. What must you configure?",
    "choices": [
      "CloudTrail data events",
      "Bucket ACLs for Everyone: WRITE",
      "S3 CORS rules allowing the app origin and required methods/headers",
      "Pre-signed URLs only"
    ],
    "answer": 2,
    "explanation": "Browser-based cross-origin requests require the bucket to allow the origin and HTTP methods via CORS. Configure S3 CORS to allow https://app.example.com and the required methods (GET/PUT) and headers so the browser permits the requests.",
    "difficulty": "Medium"
  },
  {
    "id": "SAA-230",
    "domainId": "D1",
    "domain": "Design Secure Architectures",
    "section": "S3",
    "question": "Your records must be immutable for 7 years to meet regulatory WORM requirements and prevent privileged users from deletion or alteration. Which feature can handle this requirement?",
    "choices": [
      "S3 Lifecycle with Glacier Deep Archive",
      "S3 Object Lock in Compliance mode",
      "Glacier Vault Lock only",
      "S3 Versioning alone"
    ],
    "answer": 1,
    "explanation": "S3 Object Lock in Compliance mode enforces WORM retention so objects cannot be deleted or overwritten until the retention period expires, even by root or administrators. Versioning alone does not prevent deletion, and lifecycle policies are for transitions/expiration, not enforcement of immutability.",
    "difficulty": "Hard"
  },
  {
    "id": "SAA-231",
    "domainId": "D1",
    "domain": "Design Secure Architectures",
    "section": "CloudFront",
    "question": "Your streaming service must block viewers from specific countries due to licensing. How can you enforce this at the edge?",
    "choices": [
      "Security groups on the origin",
      "Route 53 geolocation routing",
      "Signed cookies",
      "CloudFront geo restriction"
    ],
    "answer": 3,
    "explanation": "CloudFront geo restriction allows you to whitelist or blacklist specific countries at edge locations. This blocks requests before they reach your origin. Route 53 geolocation influences DNS responses but does not enforce blocking; origin security groups do not filter by country; signed cookies control who can access, not location-based blocking.",
    "difficulty": "Medium"
  },
  {
    "id": "SAA-232",
    "domainId": "D2",
    "domain": "Design Resilient Architectures",
    "section": "DataSync",
    "question": "You must migrate 300 TB from an on-prem NFS server to Amazon EFS, keeping metadata, with scheduling, verification, and incremental syncs. What is the best service?",
    "choices": [
      "AWS Transfer Family",
      "AWS DataSync",
      "Snowball Edge Storage Optimized",
      "AWS Backup"
    ],
    "answer": 1,
    "explanation": "AWS DataSync is built for large-scale data transfer to AWS storage services (EFS, S3, FSx) and supports metadata preservation, scheduled runs, verification, and incremental syncs after the initial copy.",
    "difficulty": "Hard"
  },
  {
    "id": "SAA-233",
    "domainId": "D2",
    "domain": "Design Resilient Architectures",
    "section": "Storage Gateway",
    "question": "Your backup software expects an iSCSI virtual tape library and you want to retire physical tapes while keeping long-term retention in S3/Glacier. Which gateway should you use?",
    "choices": [
      "Volume Gateway – Stored",
      "File Gateway",
      "Tape Gateway",
      "Volume Gateway – Cached"
    ],
    "answer": 2,
    "explanation": "Storage Gateway Tape Gateway provides a virtual tape library (VTL) interface over iSCSI for existing backup software, while storing virtual tapes in S3 and archiving them to Glacier for long-term retention.",
    "difficulty": "Hard"
  },
  {
    "id": "SAA-234",
    "domainId": "D3",
    "domain": "Design High-Performing Architectures",
    "section": "FSx",
    "question": "A Linux HPC workload needs a POSIX file system with sub-millisecond latencies and the ability to link a dataset in S3 so compute nodes can process it as a file system. Which service?",
    "choices": [
      "FSx for Windows File Server",
      "Storage Gateway – File Gateway",
      "FSx for Lustre",
      "S3 + Transfer Acceleration"
    ],
    "answer": 2,
    "explanation": "FSx for Lustre is designed for HPC workloads with very low latencies and high throughput. It integrates with S3 so you can link S3 data to a Lustre file system for high-performance processing by compute nodes.",
    "difficulty": "Hard"
  },
  {
    "id": "SAA-235",
    "domainId": "D2",
    "domain": "Design Resilient Architectures",
    "section": "Snow Family",
    "question": "Your company must collect and migrate ~300 TB of data from 8 remote plants that have no high-bandwidth network. You also need to run lightweight validation scripts at the edge before shipment, and require KMS encryption and chain-of-custody tracking. Which device should you choose?",
    "choices": [
      "AWS Snowball Edge Storage Optimized",
      "AWS Snowmobile",
      "AWS Snowcone",
      "AWS DataSync"
    ],
    "answer": 0,
    "explanation": "Snowball Edge Storage Optimized is designed for large offline data transfers (hundreds of TB), supports encryption with KMS, includes chain-of-custody tracking, and provides onboard compute capabilities to run lightweight processing/validation at the edge. Snowcone is for much smaller datasets, and Snowmobile is for exabyte-scale transfers.",
    "difficulty": "Hard"
  },
  {
    "id": "SAA-236",
    "domainId": "D2",
    "domain": "Design Resilient Architectures",
    "section": "SQS",
    "question": "Your SQS-triggered Lambda sometimes takes 8–10 minutes to process a message. After ~5 minutes, the same message is delivered again to another Lambda instance, causing duplicate work. Which configuration should you use to prevent this duplicate processing?",
    "choices": [
      "Reduce Lambda timeout to 5 minutes",
      "Increase the SQS visibility timeout to be greater than the maximum Lambda processing time",
      "Enable SQS long polling at 20 seconds",
      "Enable FIFO on the queue"
    ],
    "answer": 1,
    "explanation": "If the visibility timeout expires before processing finishes, SQS makes the message visible again and it can be received by another Lambda invocation. Set the visibility timeout longer than the maximum end-to-end processing time (and include buffer). Long polling and FIFO do not solve visibility-timeout re-delivery by themselves.",
    "difficulty": "Medium"
  },
  {
    "id": "SAA-237",
    "domainId": "D3",
    "domain": "Design High-Performing Architectures",
    "section": "SNS",
    "question": "You must fan out each event to multiple consumers while preserving strict ordering and exactly-once semantics. Which architecture should you choose?",
    "choices": [
      "Kinesis Data Firehose with multiple destinations",
      "SNS standard topic → SQS standard queues",
      "SNS FIFO topic → SQS FIFO subscriptions using Message Group IDs",
      "SQS standard queue with multiple consumers"
    ],
    "answer": 2,
    "explanation": "To preserve ordering and get FIFO exactly-once processing semantics, you need FIFO end-to-end. Use an SNS FIFO topic fan-out to multiple SQS FIFO queues, and use Message Group IDs to control ordering per group. Standard SNS/SQS do not provide strict ordering, and Firehose is for delivery to destinations (not ordered fan-out to multiple independent consumers).",
    "difficulty": "Hard"
  },
  {
    "id": "SAA-238",
    "domainId": "D2",
    "domain": "Design Resilient Architectures",
    "section": "Lambda",
    "question": "An SQS-triggered Lambda scales up quickly and overwhelms RDS during traffic spikes. You want to throttle how many Lambdas run in parallel for this queue. Which configuration should you use?",
    "choices": [
      "Use SNS instead of SQS",
      "Set a Reserved Concurrency on the Lambda function to cap parallel executions",
      "Increase batch size",
      "Increase visibility timeout"
    ],
    "answer": 1,
    "explanation": "Reserved Concurrency caps the maximum number of concurrent Lambda executions, which throttles how fast SQS messages can be processed and protects downstream systems like RDS. Batch size changes how many messages each invocation receives, but it doesn’t directly cap concurrency; visibility timeout doesn’t limit concurrency either.",
    "difficulty": "Medium"
  },
  {
    "id": "SAA-239",
    "domainId": "D3",
    "domain": "Design High-Performing Architectures",
    "section": "Lambda",
    "question": "You have a Java 11 Lambda that experiences spiky, unpredictable traffic. You must minimize cold-start latency when requests arrive but avoid paying for pre-warmed capacity when idle. Which feature should you choose?",
    "choices": [
      "Lambda Provisioned Concurrency",
      "Increase the function memory size only",
      "Lambda SnapStart for Java",
      "Lambda@Edge"
    ],
    "answer": 2,
    "explanation": "SnapStart reduces cold-start latency for Java functions without needing to keep provisioned instances warm during idle periods. Provisioned Concurrency minimizes cold starts too, but you pay for pre-warmed capacity even when there’s no traffic. Memory can help performance but does not reliably eliminate cold starts.",
    "difficulty": "Hard"
  },
  {
    "id": "SAA-240",
    "domainId": "D3",
    "domain": "Design High-Performing Architectures",
    "section": "EKS",
    "question": "Your platform team mandates Kubernetes APIs and wants a managed control plane with optional managed node groups and integration with VPC CNI. Which service should you choose?",
    "choices": [
      "Amazon EKS",
      "AWS Lambda",
      "Amazon ECS Fargate",
      "Docker on EC2 with an ALB"
    ],
    "answer": 0,
    "explanation": "Amazon EKS provides a managed Kubernetes control plane and supports managed node groups and AWS VPC CNI integration for pod networking.",
    "difficulty": "Easy"
  },
  {
    "id": "SAA-241",
    "domainId": "D3",
    "domain": "Design High-Performing Architectures",
    "section": "ECS",
    "question": "You need to run a long-running, HTTP microservice in containers with no server management, integrate with an ALB, and run in private subnets. Which service should you choose?",
    "choices": [
      "AWS App Runner on Git repo",
      "Amazon ECS on Fargate launch type",
      "Amazon ECS on EC2 launch type",
      "Amazon EKS with self-managed nodes"
    ],
    "answer": 1,
    "explanation": "ECS on Fargate lets you run containers without managing EC2 instances, supports ALB integration, and can run tasks in private subnets. ECS on EC2 requires server management, and EKS with self-managed nodes also increases operational overhead.",
    "difficulty": "Medium"
  },
  {
    "id": "SAA-242",
    "domainId": "D4",
    "domain": "Design Cost-Optimized Architectures",
    "section": "DynamoDB",
    "question": "Your DynamoDB workload has unpredictable spikes, and you don’t want to plan read/write capacity or manage auto scaling. Which capacity mode should you choose?",
    "choices": [
      "Global tables with provisioned capacity",
      "On-demand capacity mode",
      "Provisioned with auto scaling",
      "DAX with provisioned capacity"
    ],
    "answer": 1,
    "explanation": "On-demand capacity automatically accommodates unpredictable traffic without you having to plan RCUs/WCUs or configure auto scaling. Provisioned + auto scaling still requires capacity planning and tuning; DAX is a caching layer and doesn’t replace capacity mode.",
    "difficulty": "Medium"
  },
  {
    "id": "SAA-243",
    "domainId": "D1",
    "domain": "Design Secure Architectures",
    "section": "CloudFront",
    "question": "Your distribution must authenticate viewers at the edge by calling an external authorization API, then add/remove headers and possibly return a 302 redirect before the request reaches the origin. Which feature should you choose?",
    "choices": [
      "AWS WAF rate-based rule",
      "CloudFront Functions",
      "ALB listener rules behind CloudFront",
      "Lambda@Edge"
    ],
    "answer": 3,
    "explanation": "Lambda@Edge can run at CloudFront viewer request, call external authorization endpoints, and then modify headers or generate responses (including redirects) before forwarding to the origin. CloudFront Functions are lightweight and fast but cannot make network calls to external APIs. WAF rate rules don’t perform custom auth logic.",
    "difficulty": "Hard"
  },
  {
    "id": "SAA-244",
    "domainId": "D3",
    "domain": "Design High-Performing Architectures",
    "section": "Kinesis",
    "question": "Your team needs to ingest real-time clickstream events at high throughput, process them with sub-second latency, allow multiple independent consumers (analytics + fraud), and be able to replay data from the last 24–72 hours to reprocess if logic changes. Which service should you choose?",
    "choices": [
      "Amazon Kinesis Data Streams",
      "Amazon SNS",
      "Amazon Kinesis Data Firehose",
      "Amazon SQS"
    ],
    "answer": 0,
    "explanation": "Kinesis Data Streams supports high-throughput streaming ingestion, multiple consumer applications (enhanced fan-out if needed), low-latency processing, and data retention for replay (for example 24–72 hours or longer depending on configuration). Firehose is primarily for delivery to storage/analytics destinations with limited replay semantics.",
    "difficulty": "Hard"
  },
  {
    "id": "SAA-245",
    "domainId": "D4",
    "domain": "Design Cost-Optimized Architectures",
    "section": "Batch",
    "question": "Your company has a nightly automation script that takes 2–3 hours to complete. They prefer a fully managed, serverless option. Which service should you choose?",
    "choices": [
      "AWS Lambda orchestrated by Step Functions looping for hours",
      "AWS Lambda with Provisioned Concurrency",
      "AWS Batch with a Fargate compute environment",
      "AWS Lambda with the timeout increased to 3 hours"
    ],
    "answer": 2,
    "explanation": "Lambda can’t run for hours (maximum execution time is much lower), so options D and B are not suitable. Provisioned Concurrency doesn’t change Lambda’s max runtime. AWS Batch can run long jobs, and with a Fargate compute environment you avoid managing servers while still running multi-hour workloads reliably on a schedule.",
    "difficulty": "Hard"
  },
  {
    "id": "SAA-246",
    "domainId": "D3",
    "domain": "Design High-Performing Architectures",
    "section": "Neptune",
    "question": "Your company is building a knowledge graph to support features like friend-of-friend, shortest path, and fraud rings. You need a fully managed graph database that supports Gremlin and SPARQL, offers high availability across AZs, and integrates with IAM/KMS for security. Which service should you choose?",
    "choices": [
      "Amazon DocumentDB",
      "Amazon DynamoDB",
      "Amazon Neptune",
      "Amazon RDS for PostgreSQL"
    ],
    "answer": 2,
    "explanation": "Amazon Neptune is a fully managed graph database service that supports Gremlin and SPARQL, provides high availability, and integrates with IAM/KMS for access control and encryption.",
    "difficulty": "Medium"
  },
  {
    "id": "SAA-247",
    "domainId": "D3",
    "domain": "Design High-Performing Architectures",
    "section": "DocumentDB",
    "question": "A legacy microservice uses MongoDB drivers and stores schema-flexible JSON. You want a drop-in managed replacement with automatic backups, VPC isolation, and no manual sharding/patching. Which service should you choose?",
    "choices": [
      "Amazon ElastiCache for Redis",
      "Amazon DocumentDB",
      "Amazon Aurora MySQL",
      "Amazon DynamoDB"
    ],
    "answer": 1,
    "explanation": "Amazon DocumentDB is MongoDB-compatible, fully managed, supports VPC isolation and automated backups, and removes the operational overhead of running MongoDB yourself.",
    "difficulty": "Medium"
  },
  {
    "id": "SAA-248",
    "domainId": "D3",
    "domain": "Design High-Performing Architectures",
    "section": "ElastiCache",
    "question": "Your web tier stores ephemeral session state, needs sub-millisecond latency, TTL eviction, and optional pub/sub. Data must live in memory and offload reads from your primary database. Which service should you choose?",
    "choices": [
      "Amazon S3 Standard",
      "Amazon EFS",
      "Amazon ElastiCache for Redis",
      "Amazon RDS for MySQL"
    ],
    "answer": 2,
    "explanation": "ElastiCache for Redis provides in-memory storage with sub-millisecond latency, supports TTL eviction, and supports pub/sub, making it ideal for session state and offloading reads from databases.",
    "difficulty": "Medium"
  },
  {
    "id": "SAA-249",
    "domainId": "D4",
    "domain": "Design Cost-Optimized Architectures",
    "section": "Athena",
    "question": "Analysts keep CSV/Parquet in Amazon S3 and need to run one-off SQL and join datasets without provisioning clusters. Results should be billed per query and use the Glue Data Catalog for schemas. Which service should you choose?",
    "choices": [
      "Amazon Athena",
      "Amazon EMR",
      "AWS Glue",
      "Amazon Redshift"
    ],
    "answer": 0,
    "explanation": "Amazon Athena is serverless SQL on S3, billed per query, and integrates with the AWS Glue Data Catalog for table definitions and schemas.",
    "difficulty": "Medium"
  },
  {
    "id": "SAA-250",
    "domainId": "D3",
    "domain": "Design High-Performing Architectures",
    "section": "Redshift",
    "question": "BI teams require a columnar, massively parallel SQL engine with concurrency scaling, materialized views, and integration with QuickSight. Data loads from S3 and operational stores nightly. Which service should you choose?",
    "choices": [
      "AWS Glue",
      "Amazon Redshift",
      "Amazon QuickSight",
      "Amazon Athena"
    ],
    "answer": 1,
    "explanation": "Amazon Redshift is a columnar, MPP data warehouse that supports features like concurrency scaling and materialized views and integrates well with BI tools like QuickSight.",
    "difficulty": "Medium"
  },
  {
    "id": "SAA-251",
    "domainId": "D3",
    "domain": "Design High-Performing Architectures",
    "section": "Glue",
    "question": "Nightly jobs must crawl S3, infer/update table schemas, run Spark transformations from CSV → Parquet, and load curated data to Redshift with minimal ops. Which service should you choose?",
    "choices": [
      "AWS Data Pipeline",
      "Amazon EMR with long-running clusters",
      "Amazon Athena CTAS queries only",
      "AWS Glue"
    ],
    "answer": 3,
    "explanation": "AWS Glue provides crawlers to infer schemas and update the Data Catalog, and managed Spark ETL jobs to transform data (CSV to Parquet) and load curated outputs to targets like Redshift with low operational overhead.",
    "difficulty": "Medium"
  },
  {
    "id": "SAA-252",
    "domainId": "D3",
    "domain": "Design High-Performing Architectures",
    "section": "Rekognition",
    "question": "Your app must detect objects and faces in images and return labels with confidence scores through a managed API. Which service should you choose?",
    "choices": [
      "Transcribe",
      "Comprehend",
      "Polly",
      "Rekognition"
    ],
    "answer": 3,
    "explanation": "Amazon Rekognition provides managed image/video analysis APIs to detect objects, scenes, and faces and returns labels with confidence scores.",
    "difficulty": "Easy"
  },
  {
    "id": "SAA-253",
    "domainId": "D3",
    "domain": "Design High-Performing Architectures",
    "section": "Polly",
    "question": "Marketing needs to turn blog posts into audio using lifelike voices via an API. Which service should you choose?",
    "choices": [
      "Polly",
      "Lex",
      "Transcribe",
      "Comprehend"
    ],
    "answer": 0,
    "explanation": "Amazon Polly converts text to lifelike speech using a managed API (text-to-speech).",
    "difficulty": "Easy"
  },
  {
    "id": "SAA-254",
    "domainId": "D1",
    "domain": "Design Secure Architectures",
    "section": "CloudTrail",
    "question": "Yesterday a production outage was traced to a security group rule change. You need to answer, “Which principal made the API call, from which IP, and at what exact time?” Which service should you choose?",
    "choices": [
      "Amazon CloudWatch Metrics",
      "AWS Systems Manager",
      "AWS Config conformance packs",
      "AWS CloudTrail"
    ],
    "answer": 3,
    "explanation": "AWS CloudTrail records API activity and includes who made the call (principal), source IP, request details, and timestamps—ideal for auditing and forensics.",
    "difficulty": "Medium"
  },
  {
    "id": "SAA-255",
    "domainId": "D1",
    "domain": "Design Secure Architectures",
    "section": "Organizations",
    "question": "Your company uses AWS Organizations with Control Tower. At the Root, an SCP is attached that denies ec2:TerminateInstances on all resources. An admin in a member account (with AdministratorAccess) tries to terminate an EC2 instance in any region. What does this SCP mean for the attached accounts?",
    "choices": [
      "The action is allowed only if the instance has a certain tag",
      "The action is denied for all principals in all attached accounts in all regions, regardless of IAM permissions",
      "The action is denied only when called from the console, not the CLI",
      "The action is allowed because AdministratorAccess overrides the SCP at the account level"
    ],
    "answer": 1,
    "explanation": "SCPs set the maximum permissions for accounts/OUs. An explicit Deny in an SCP cannot be overridden by IAM permissions, so ec2:TerminateInstances is denied for all principals in all attached accounts in all regions.",
    "difficulty": "Hard"
  },
  {
    "id": "SAA-256",
    "domainId": "D1",
    "domain": "Design Secure Architectures",
    "section": "KMS",
    "question": "Your app writes data in us-east-1 and replicates the ciphertext to eu-west-1. You need to decrypt in both Regions without re-encrypting and keep keys cryptographically equivalent across Regions. Which KMS feature should you choose?",
    "choices": [
      "Customer-managed alias pointing to different keys per Region",
      "A single-Region KMS key shared to eu-west-1",
      "KMS multi-Region keys",
      "SSE-S3 without KMS"
    ],
    "answer": 2,
    "explanation": "KMS multi-Region keys create linked, cryptographically equivalent keys in multiple Regions so ciphertext encrypted in one Region can be decrypted in another without re-encrypting.",
    "difficulty": "Hard"
  },
  {
    "id": "SAA-257",
    "domainId": "D1",
    "domain": "Design Secure Architectures",
    "section": "S3",
    "question": "You enable S3 Cross-Region Replication for a bucket using SSE-KMS. Replication fails with an access error on the destination key. Which change should you implement so the replicas are encrypted at the destination?",
    "choices": [
      "Create a VPC endpoint for S3",
      "Turn off KMS on the source bucket",
      "Use SSE-S3 on the destination only",
      "Update the destination KMS key policy to allow the source bucket’s replication role to use kms:Encrypt"
    ],
    "answer": 3,
    "explanation": "For CRR with SSE-KMS, the replication IAM role must be permitted by the destination KMS key policy to encrypt (and typically generate data keys). Grant the replication role the required KMS permissions on the destination key.",
    "difficulty": "Hard"
  },
  {
    "id": "SAA-258",
    "domainId": "D1",
    "domain": "Design Secure Architectures",
    "section": "EC2",
    "question": "You must share an EBS-backed AMI encrypted with your CMK so another AWS account can launch it. Which steps should you choose?",
    "choices": [
      "Share only the AMI",
      "Share the AMI and its encrypted snapshot, and grant the other account kms:Decrypt on the CMK (or let them copy the snapshot to their CMK)",
      "Copy the AMI to S3 and send a link",
      "Share just the snapshot"
    ],
    "answer": 1,
    "explanation": "For an encrypted EBS-backed AMI, you must share the AMI and the underlying encrypted snapshot and also allow the target account to use the KMS key (or have them copy the snapshot/AMI using their own CMK). Sharing only the AMI is not sufficient.",
    "difficulty": "Hard"
  },
  {
    "id": "SAA-259",
    "domainId": "D1",
    "domain": "Design Secure Architectures",
    "section": "Secrets Manager",
    "question": "You store database credentials and must rotate them automatically every 30 days, with built-in rotation workflows and audit. Which service should you choose?",
    "choices": [
      "SSM Parameter Store",
      "IAM Roles Anywhere",
      "AWS Secrets Manager",
      "S3 with SSE-KMS"
    ],
    "answer": 2,
    "explanation": "AWS Secrets Manager provides managed secret storage with built-in rotation workflows (via Lambda), scheduled rotation, and auditing/integration with IAM and CloudTrail.",
    "difficulty": "Medium"
  },
  {
    "id": "SAA-260",
    "domainId": "D1",
    "domain": "Design Secure Architectures",
    "section": "ACM",
    "question": "You will expose a web app through an Application Load Balancer at app.example.com. You want a public TLS certificate managed by AWS with easy renewals. Which approach should you choose?",
    "choices": [
      "Issue a private ACM cert from a Private CA",
      "Upload a self-signed cert to the ALB",
      "Use CloudFront to auto-create a cert",
      "Request a public certificate in AWS Certificate Manager and validate via DNS in Route 53"
    ],
    "answer": 3,
    "explanation": "ACM public certificates are AWS-managed and renew automatically (when DNS validation remains in place). You then attach the ACM cert to the ALB HTTPS listener.",
    "difficulty": "Medium"
  },
  {
    "id": "SAA-261",
    "domainId": "D1",
    "domain": "Design Secure Architectures",
    "section": "Firewall Manager",
    "question": "Your org needs to enforce WAF rules and Shield protections across dozens of accounts and ALBs/CloudFront from a central place using AWS Organizations. Which service should you choose?",
    "choices": [
      "Amazon GuardDuty",
      "AWS Shield Advanced alone",
      "AWS Firewall Manager",
      "AWS Network Firewall"
    ],
    "answer": 2,
    "explanation": "AWS Firewall Manager is the AWS Organizations-integrated service for centrally configuring and enforcing AWS WAF rules and Shield Advanced protections across multiple accounts and resources.",
    "difficulty": "Hard"
  },
  {
    "id": "SAA-262",
    "domainId": "D1",
    "domain": "Design Secure Architectures",
    "section": "GuardDuty",
    "question": "Security wants managed threat detection that analyzes CloudTrail, VPC Flow Logs, and DNS logs to alert on anomalous IAM activity and known malicious IPs. Which service should you choose?",
    "choices": [
      "Amazon Inspector",
      "Amazon GuardDuty",
      "AWS CloudTrail",
      "AWS Config"
    ],
    "answer": 1,
    "explanation": "Amazon GuardDuty is a managed threat detection service that analyzes CloudTrail events, VPC Flow Logs, and DNS logs to generate security findings.",
    "difficulty": "Medium"
  },
  {
    "id": "SAA-263",
    "domainId": "D1",
    "domain": "Design Secure Architectures",
    "section": "VPC",
    "question": "You place workloads in IPv6-only private subnets and they must reach public Internet services while remaining non-routable from the Internet. Which gateway should you choose?",
    "choices": [
      "Transit Gateway",
      "Egress-Only Internet Gateway",
      "NAT Gateway",
      "Internet Gateway"
    ],
    "answer": 1,
    "explanation": "An Egress-Only Internet Gateway allows outbound-only IPv6 access to the internet while preventing inbound connections initiated from the internet.",
    "difficulty": "Medium"
  },
  {
    "id": "SAA-264",
    "domainId": "D4",
    "domain": "Design Cost-Optimized Architectures",
    "section": "VPC Endpoints",
    "question": "Instances in private subnets must access S3 without using a NAT Gateway to minimize cost and keep traffic off the Internet. Which integration should you choose?",
    "choices": [
      "Gateway VPC endpoint for S3",
      "Interface VPC endpoint for S3",
      "Public S3 with bucket policy Allow *",
      "VPC peering to the S3 VPC"
    ],
    "answer": 0,
    "explanation": "A Gateway VPC endpoint for S3 routes S3 traffic privately over the AWS network without a NAT Gateway, reducing cost and keeping traffic off the public internet.",
    "difficulty": "Medium"
  },
  {
    "id": "SAA-265",
    "domainId": "D2",
    "domain": "Design Resilient Architectures",
    "section": "Transit Gateway",
    "question": "You need to connect dozens of VPCs and on-prem networks in a hub-and-spoke topology with route propagation and centralized control, avoiding complex peering meshes. Which service should you choose?",
    "choices": [
      "AWS Transit Gateway",
      "VPC Peering",
      "Site-to-Site VPN per VPC",
      "AWS Direct Connect only"
    ],
    "answer": 0,
    "explanation": "AWS Transit Gateway provides hub-and-spoke connectivity for many VPCs and on-prem networks with centralized routing and route propagation, avoiding a complex full mesh of VPC peering connections.",
    "difficulty": "Medium"
  },
  {
    "id": "SAA-266",
    "domainId": "D2",
    "domain": "Design Resilient Architectures",
    "section": "Disaster Recovery",
    "question": "A payments platform needs minutes-level RTO and low data loss across two Regions but wants to avoid the full cost of active/active. It will keep a scaled-down copy of the app and database warm in the secondary Region and scale up on failover. Which DR strategy should you choose?",
    "choices": [
      "Multi-Region Active/Active",
      "Pilot Light",
      "Backup & Restore",
      "Warm Standby"
    ],
    "answer": 3,
    "explanation": "Warm Standby keeps a scaled-down but fully functional environment running in the secondary Region (app + database) and scales up on failover, providing minutes-level RTO with lower cost than active/active.",
    "difficulty": "Medium"
  },
  {
    "id": "SAA-267",
    "domainId": "D2",
    "domain": "Design Resilient Architectures",
    "section": "DMS",
    "question": "You must move an on-prem Oracle OLTP database to Amazon Aurora PostgreSQL with minutes of cutover downtime. The target schema needs conversion, and you want ongoing change data capture (CDC) until the cutover. Which approach should you choose?",
    "choices": [
      "AWS Schema Conversion Tool (SCT) + AWS DMS replication task with CDC",
      "Export/import with Data Pump only",
      "Snapshot/restore to Aurora",
      "Glue ETL jobs into Aurora"
    ],
    "answer": 0,
    "explanation": "SCT handles heterogeneous schema conversion (Oracle → Aurora PostgreSQL). DMS can do full load plus CDC replication so you keep the target nearly in sync and perform a short cutover window.",
    "difficulty": "Hard"
  },
  {
    "id": "SAA-268",
    "domainId": "D2",
    "domain": "Design Resilient Architectures",
    "section": "RDS",
    "question": "You’re upgrading RDS MySQL to a new major version and need a very short, controlled cutover with automatic replica synchronization and quick rollback if needed. Which feature should you choose?",
    "choices": [
      "Cross-Region read replica and manual promotion",
      "DMS full load only",
      "RDS Blue/Green Deployments",
      "Multi-AZ failover"
    ],
    "answer": 2,
    "explanation": "RDS Blue/Green Deployments lets you create a synchronized staging (green) environment, perform the upgrade there, and then switch over with a controlled cutover. It also supports rolling back by switching back if needed (depending on the situation).",
    "difficulty": "Hard"
  },
  {
    "id": "SAA-269",
    "domainId": "D2",
    "domain": "Design Resilient Architectures",
    "section": "Outposts",
    "question": "A factory site requires local, single-digit-ms latency and wants to run native AWS services (EC2, EBS, EKS, RDS) on-prem with AWS-managed hardware and the same APIs/console. Which service should you choose?",
    "choices": [
      "AWS Snowball Edge",
      "AWS Outposts",
      "VMware Cloud on AWS",
      "AWS Local Zones"
    ],
    "answer": 1,
    "explanation": "AWS Outposts brings AWS-managed hardware and many AWS services into your on-prem site, using the same AWS APIs/console and providing very low-latency local access.",
    "difficulty": "Medium"
  },
  {
    "id": "SAA-270",
    "domainId": "D2",
    "domain": "Design Resilient Architectures",
    "section": "AWS Backup",
    "question": "You need central policy-based backups for RDS, EFS, DynamoDB, EC2/EBS across multiple accounts and Regions with cross-account copy and backup vaults. Which service should you choose?",
    "choices": [
      "CloudFormation custom resources",
      "EBS snapshots with custom scripts",
      "Systems Manager Automation documents",
      "AWS Backup with Backup Policies via AWS Organizations"
    ],
    "answer": 3,
    "explanation": "AWS Backup provides a centralized managed backup service for multiple AWS data sources and supports backup vaults, cross-account copy, and policy-based backup management via AWS Organizations.",
    "difficulty": "Medium"
  },
  {
    "id": "SAA-271",
    "domainId": "D1",
    "domain": "Design Secure Architectures",
    "section": "CloudFormation",
    "question": "Security wants to ensure a stack can only create certain resources (for example, EC2 within specific subnets) even if the template is modified. Which configuration should you use?",
    "choices": [
      "Give CloudFormation full AdministratorAccess",
      "Use stack termination protection only",
      "Attach a dedicated CloudFormation service role with a least-privilege IAM policy",
      "Rely on drift detection"
    ],
    "answer": 2,
    "explanation": "A CloudFormation service role with least-privilege permissions enforces what the stack can create/update, even if someone modifies the template. Termination protection and drift detection don’t restrict what resources can be created.",
    "difficulty": "Medium"
  },
  {
    "id": "SAA-272",
    "domainId": "D3",
    "domain": "Design High-Performing Architectures",
    "section": "Pinpoint",
    "question": "Product needs to send bulk marketing campaigns with segmentation, A/B testing, and analytics dashboards across email and SMS, while engineering will keep transactional emails simple. Which service should you choose for the marketing use case?",
    "choices": [
      "Amazon SES only",
      "SQS",
      "Amazon Pinpoint",
      "SNS"
    ],
    "answer": 2,
    "explanation": "Amazon Pinpoint is designed for marketing engagement at scale (segmentation, campaigns, A/B testing, analytics) across channels like email and SMS. SES alone is better suited for transactional email sending without the marketing campaign features.",
    "difficulty": "Medium"
  },
  {
    "id": "SAA-273",
    "domainId": "D1",
    "domain": "Design Secure Architectures",
    "section": "Systems Manager",
    "question": "Your EC2 instances are in private subnets with no inbound rules. Ops needs interactive shell and port-forwarding for troubleshooting with full audit logs and no bastion hosts. Which service should you choose?",
    "choices": [
      "A public bastion with SSH keys",
      "AWS Systems Manager Session Manager",
      "Direct Connect",
      "EC2 Instance Connect"
    ],
    "answer": 1,
    "explanation": "SSM Session Manager provides interactive shell access and port forwarding without opening inbound SSH/RDP, and it can log sessions for auditing. This removes the need for bastion hosts.",
    "difficulty": "Medium"
  },
  {
    "id": "SAA-274",
    "domainId": "D4",
    "domain": "Design Cost-Optimized Architectures",
    "section": "Billing",
    "question": "Finance wants automatic detection of unusual daily spend and alerts without maintaining per-service thresholds. Which service should you choose?",
    "choices": [
      "AWS Cost Anomaly Detection with monitors and SNS notifications",
      "AWS Budgets with fixed thresholds",
      "Trusted Advisor",
      "Cost Explorer saved reports"
    ],
    "answer": 0,
    "explanation": "AWS Cost Anomaly Detection uses machine learning to detect unusual spend patterns and can alert via monitors (often routed through SNS) without you defining manual per-service thresholds.",
    "difficulty": "Medium"
  },
  {
    "id": "SAA-275",
    "domainId": "D2",
    "domain": "Design Resilient Architectures",
    "section": "MGN",
    "question": "You must migrate hundreds of on-prem VMs to AWS with block-level continuous replication, test cutovers, and a short final cutover window to EC2. Which service should you choose?",
    "choices": [
      "AWS Application Migration Service (MGN)",
      "AWS Database Migration Service",
      "AWS DataSync",
      "VMware Cloud on AWS"
    ],
    "answer": 0,
    "explanation": "AWS Application Migration Service (MGN) performs block-level continuous replication of servers to AWS, supports test cutovers, and enables a short final cutover to EC2. DMS is for databases, and DataSync is file/object transfer (not VM lift-and-shift).",
    "difficulty": "Hard"
  },
  {
    "id": "SAA-276",
    "domainId": "D1",
    "domain": "Design Secure Architectures",
    "section": "ACM",
    "question": "You are exposing https://app.example.com through an Application Load Balancer (ALB). You want a publicly trusted TLS certificate with automatic renewal and the least operational overhead. Which TWO actions should you take? (Choose TWO.)",
    "choices": [
      "Create a self-signed certificate and upload it to the ALB listener",
      "Create a private certificate using ACM Private CA and attach it to the public ALB",
      "Store the certificate in S3 and configure the ALB to fetch it on startup",
      "Request a public certificate in AWS Certificate Manager (ACM)",
      "Validate the ACM certificate using DNS validation in Route 53"
    ],
    "answer": [
      3,
      4
    ],
    "explanation": "Use ACM public certificates for publicly trusted TLS with managed renewals, and validate via Route 53 DNS. Self-signed and private CA certs are not publicly trusted by default, and ALB does not pull certs from S3.",
    "difficulty": "Easy"
  },
  {
    "id": "SAA-277",
    "domainId": "D1",
    "domain": "Design Secure Architectures",
    "section": "IAM",
    "question": "A security team wants to reduce risk by ensuring engineers do not attach permissions directly to individual IAM users, and instead manage permissions at scale. Which TWO practices best meet this goal? (Choose TWO.)",
    "choices": [
      "Store access keys in Parameter Store and share them across users",
      "Use IAM roles for applications and workloads instead of long-term user keys",
      "Enable S3 versioning on all buckets",
      "Use IAM groups with managed policies and add users to groups",
      "Attach policies directly to each IAM user for better visibility"
    ],
    "answer": [
      1,
      3
    ],
    "explanation": "Groups + policies scale permission management for many users. Roles reduce long-term credentials for workloads. The other options do not address scalable user permission management.",
    "difficulty": "Easy"
  },
  {
    "id": "SAA-278",
    "domainId": "D2",
    "domain": "Design Resilient Architectures",
    "section": "Route 53",
    "question": "You run two endpoints in an active-passive setup. If the primary endpoint fails, traffic must automatically shift to the standby. Which TWO Route 53 components do you configure? (Choose TWO.)",
    "choices": [
      "Weighted routing policy",
      "Latency-based routing policy",
      "Geoproximity routing policy",
      "Failover routing policy",
      "A Route 53 health check for the primary endpoint"
    ],
    "answer": [
      3,
      4
    ],
    "explanation": "Failover routing + health checks provide automated primary/secondary DNS failover. Weighted/latency/geoproximity are for different routing goals.",
    "difficulty": "Easy"
  },
  {
    "id": "SAA-279",
    "domainId": "D3",
    "domain": "Design High-Performing Architectures",
    "section": "ELB",
    "question": "A gaming service uses UDP for client-to-server communication and needs a load balancer that supports UDP and can scale to very high throughput. Which TWO AWS services together form the best front-door solution? (Choose TWO.)",
    "choices": [
      "Amazon Route 53",
      "Network Load Balancer",
      "Gateway Load Balancer",
      "Application Load Balancer",
      "AWS Global Accelerator"
    ],
    "answer": [
      1,
      4
    ],
    "explanation": "NLB supports UDP at Layer 4. Global Accelerator can improve global performance and provides static anycast IPs in front of the NLB for worldwide users.",
    "difficulty": "Easy"
  },
  {
    "id": "SAA-280",
    "domainId": "D4",
    "domain": "Design Cost-Optimized Architectures",
    "section": "S3",
    "question": "You store data that is frequently accessed for 30 days, then rarely accessed but still needs millisecond retrieval afterward. Which TWO storage classes best match this requirement over time? (Choose TWO.)",
    "choices": [
      "S3 Glacier Flexible Retrieval",
      "S3 One Zone-IA",
      "S3 Standard",
      "S3 Standard-IA",
      "S3 Glacier Deep Archive"
    ],
    "answer": [
      2,
      3
    ],
    "explanation": "S3 Standard fits frequent access; S3 Standard-IA fits infrequent access with millisecond retrieval. Glacier classes have longer retrieval times; One Zone-IA is single-AZ and only fits if you accept reduced resilience.",
    "difficulty": "Easy"
  },
  {
    "id": "SAA-281",
    "domainId": "D2",
    "domain": "Design Resilient Architectures",
    "section": "Auto Scaling",
    "question": "A web application must remain available during an AZ failure and automatically replace unhealthy instances. Which TWO AWS components should you implement? (Choose TWO.)",
    "choices": [
      "Run instances in a single AZ with a larger instance type",
      "A local database on instance store",
      "An Application Load Balancer across multiple AZs",
      "An Auto Scaling Group spanning at least two AZs",
      "A single EC2 instance with an Elastic IP"
    ],
    "answer": [
      2,
      3
    ],
    "explanation": "ASG across multiple AZs replaces unhealthy instances and maintains capacity. An ALB across AZs distributes traffic and stops routing to unhealthy targets.",
    "difficulty": "Easy"
  },
  {
    "id": "SAA-282",
    "domainId": "D1",
    "domain": "Design Secure Architectures",
    "section": "VPC Endpoints",
    "question": "Instances in private subnets must access Amazon S3 without traversing the public internet and without using a NAT Gateway. Which TWO configuration elements are required? (Choose TWO.)",
    "choices": [
      "A Site-to-Site VPN",
      "An Internet Gateway attached to the VPC",
      "A public Elastic IP on each instance",
      "A Gateway VPC endpoint for S3",
      "A route table entry targeting the S3 Gateway endpoint"
    ],
    "answer": [
      3,
      4
    ],
    "explanation": "Use an S3 Gateway VPC endpoint and add the endpoint route to the private subnet route tables. Internet gateways/EIPs are not needed for private S3 access through the endpoint.",
    "difficulty": "Easy"
  },
  {
    "id": "SAA-283",
    "domainId": "D1",
    "domain": "Design Secure Architectures",
    "section": "CloudTrail",
    "question": "After an incident, you must identify who changed a security group rule, from which IP, and the exact time. Which TWO AWS services/features should be used to capture and retain this information? (Choose TWO.)",
    "choices": [
      "CloudTrail log file delivery to an S3 bucket",
      "AWS CloudTrail management events",
      "AWS WAF logs",
      "Amazon CloudWatch Metrics only",
      "Amazon S3 access logs"
    ],
    "answer": [
      0,
      1
    ],
    "explanation": "CloudTrail management events record the API caller, source IP, and timestamp. Delivering CloudTrail logs to S3 retains the audit history.",
    "difficulty": "Easy"
  },
  {
    "id": "SAA-284",
    "domainId": "D3",
    "domain": "Design High-Performing Architectures",
    "section": "ElastiCache",
    "question": "A web tier needs an in-memory cache for session data with sub-millisecond latency and TTL eviction. Which TWO options are valid managed caching solutions on AWS? (Choose TWO.)",
    "choices": [
      "Amazon S3 Glacier Instant Retrieval",
      "Amazon RDS Multi-AZ",
      "Amazon ElastiCache for Redis",
      "Amazon EFS",
      "Amazon ElastiCache for Memcached"
    ],
    "answer": [
      2,
      4
    ],
    "explanation": "ElastiCache Redis and Memcached are managed in-memory caches. The other services are storage or databases, not in-memory cache engines.",
    "difficulty": "Easy"
  },
  {
    "id": "SAA-285",
    "domainId": "D4",
    "domain": "Design Cost-Optimized Architectures",
    "section": "EC2 Pricing",
    "question": "A team runs a steady baseline of EC2 usage 24/7 but also has unpredictable spikes. Which TWO purchasing models best minimize cost while handling both patterns? (Choose TWO.)",
    "choices": [
      "Dedicated Hosts for spikes",
      "Spot Instances for the baseline with no interruptions",
      "On-Demand Instances for the baseline",
      "Reserved Instances or Savings Plans for the baseline",
      "On-Demand Instances for spikes"
    ],
    "answer": [
      3,
      4
    ],
    "explanation": "Commitments (RI/Savings Plans) reduce baseline cost. On-Demand handles unpredictable spikes without commitment. Spot for baseline risks interruption; Dedicated Hosts increase cost.",
    "difficulty": "Easy"
  },
  {
    "id": "SAA-286",
    "domainId": "D1",
    "domain": "Design Secure Architectures",
    "section": "S3",
    "question": "A bucket must enforce encryption using a specific customer-managed KMS key (CMK). Developers sometimes upload objects without specifying encryption headers. Which TWO controls best enforce the requirement? (Choose TWO.)",
    "choices": [
      "Add a bucket policy condition that requires the specific KMS key ID",
      "Enable default encryption with SSE-S3 only",
      "Enable S3 Transfer Acceleration",
      "Enable default encryption with SSE-KMS using the CMK",
      "Add a bucket policy that denies PutObject unless s3:x-amz-server-side-encryption is aws:kms"
    ],
    "answer": [
      0,
      4
    ],
    "explanation": "Default encryption helps, but enforcement is best done by denying uploads that don’t use SSE-KMS and the required key ID via bucket policy conditions.",
    "difficulty": "Medium"
  },
  {
    "id": "SAA-287",
    "domainId": "D2",
    "domain": "Design Resilient Architectures",
    "section": "RDS",
    "question": "An OLTP application uses Amazon RDS MySQL. Analytics users need to run heavy read queries without impacting production performance. Which TWO options meet the requirement with the best fit? (Choose TWO.)",
    "choices": [
      "Offload analytics to an Amazon Redshift cluster (ETL/ELT pipeline)",
      "Enable RDS Multi-AZ and route analytics reads to the standby",
      "Use Amazon ElastiCache to cache all analytics queries",
      "Increase the production DB instance size only",
      "Create an RDS Read Replica and route analytics reads to it"
    ],
    "answer": [
      0,
      4
    ],
    "explanation": "Read replicas offload read traffic from the primary. Redshift is purpose-built for analytics and can be a better long-term warehouse. Multi-AZ standby isn’t for reads, and resizing alone doesn’t prevent contention.",
    "difficulty": "Medium"
  },
  {
    "id": "SAA-288",
    "domainId": "D2",
    "domain": "Design Resilient Architectures",
    "section": "SQS",
    "question": "Your SQS-triggered Lambda sometimes processes messages for up to 12 minutes. You want to prevent duplicate processing and also control concurrency so downstream RDS is not overwhelmed. Which TWO configurations should you apply? (Choose TWO.)",
    "choices": [
      "Set SQS visibility timeout greater than the maximum processing time",
      "Switch to an SNS topic instead of SQS",
      "Increase Lambda memory to maximum",
      "Enable SQS long polling at 20 seconds",
      "Set a Reserved Concurrency limit on the Lambda function"
    ],
    "answer": [
      0,
      4
    ],
    "explanation": "Visibility timeout prevents re-delivery during processing. Reserved Concurrency caps parallel executions and protects RDS. Long polling reduces empty receives but doesn’t stop duplicates or throttle concurrency.",
    "difficulty": "Medium"
  },
  {
    "id": "SAA-289",
    "domainId": "D3",
    "domain": "Design High-Performing Architectures",
    "section": "CloudFront",
    "question": "A global website serves mostly cacheable content. The company wants lower latency worldwide and reduced origin load. Which TWO services should be used together to meet this goal? (Choose TWO.)",
    "choices": [
      "Amazon CloudFront",
      "AWS Storage Gateway",
      "Amazon Route 53 Resolver inbound endpoints",
      "An Application Load Balancer as the origin",
      "AWS Global Accelerator only (no CDN)"
    ],
    "answer": [
      0,
      3
    ],
    "explanation": "CloudFront caches content at edge locations. ALB can serve as a scalable origin (routing to multiple targets) for dynamic and cacheable content.",
    "difficulty": "Medium"
  },
  {
    "id": "SAA-290",
    "domainId": "D4",
    "domain": "Design Cost-Optimized Architectures",
    "section": "S3",
    "question": "You have tens of millions of objects with unpredictable access patterns. You want automatic tiering without app changes and millisecond access when requested. Which TWO S3 options can satisfy this pattern? (Choose TWO.)",
    "choices": [
      "S3 Intelligent-Tiering",
      "S3 Standard-IA only",
      "S3 Glacier Deep Archive",
      "S3 One Zone-IA only",
      "S3 Lifecycle rules transitioning between Standard and Standard-IA"
    ],
    "answer": [
      0,
      4
    ],
    "explanation": "Intelligent-Tiering automatically optimizes based on access. Lifecycle transitions (Standard ↔ IA patterns) can reduce cost without app changes, though they’re rule-based rather than automatic learning. Deep Archive won’t meet millisecond access.",
    "difficulty": "Medium"
  },
  {
    "id": "SAA-291",
    "domainId": "D1",
    "domain": "Design Secure Architectures",
    "section": "Organizations",
    "question": "A company wants to centrally enforce that no account in an OU can disable CloudTrail or stop log delivery. Which TWO mechanisms are most appropriate? (Choose TWO.)",
    "choices": [
      "Service Control Policies (SCPs) denying cloudtrail:StopLogging and s3:PutBucketPolicy changes",
      "Security groups denying outbound HTTPS",
      "CloudFront Functions",
      "IAM inline policies on each developer user",
      "AWS Control Tower guardrails (detective/preventive) where applicable"
    ],
    "answer": [
      0,
      4
    ],
    "explanation": "SCPs set maximum permissions for accounts and can prevent disabling CloudTrail. Control Tower guardrails help enforce and monitor required configurations at scale.",
    "difficulty": "Medium"
  },
  {
    "id": "SAA-292",
    "domainId": "D2",
    "domain": "Design Resilient Architectures",
    "section": "DataSync",
    "question": "You need to migrate 150 TB from an on-prem NFS server to Amazon EFS with metadata preservation, scheduling, and incremental sync. Which TWO components are required? (Choose TWO.)",
    "choices": [
      "AWS DataSync agent deployed on-prem",
      "Amazon EBS snapshots of the NFS server",
      "AWS Transfer Family SFTP server in AWS",
      "Amazon CloudFront distribution",
      "An AWS DataSync task configured from NFS to EFS"
    ],
    "answer": [
      0,
      4
    ],
    "explanation": "DataSync uses an on-prem agent plus a configured DataSync task to move data from NFS to EFS with scheduling and verification.",
    "difficulty": "Medium"
  },
  {
    "id": "SAA-293",
    "domainId": "D3",
    "domain": "Design High-Performing Architectures",
    "section": "Kinesis",
    "question": "A team needs near real-time ingestion of clickstream events with multiple independent consumers and replay capability for 48 hours. Which TWO statements about the correct service are true? (Choose TWO.)",
    "choices": [
      "Amazon SNS provides ordered replay for 48 hours by default",
      "Amazon Kinesis Data Streams is suited for low-latency stream processing",
      "Amazon Kinesis Data Streams supports multiple consumers and configurable retention for replay",
      "Amazon Kinesis Data Firehose is best for sub-second consumer processing with replay",
      "Amazon SQS Standard guarantees strict ordering for all messages"
    ],
    "answer": [
      1,
      2
    ],
    "explanation": "Kinesis Data Streams supports low-latency processing, multiple consumers, and retention for replay. Firehose is optimized for delivery to destinations, not multi-consumer replay-first patterns.",
    "difficulty": "Medium"
  },
  {
    "id": "SAA-294",
    "domainId": "D1",
    "domain": "Design Secure Architectures",
    "section": "VPC",
    "question": "Workloads are IPv6-only in private subnets and must reach the internet outbound, but must not be reachable inbound from the internet. Which TWO items are part of the correct solution? (Choose TWO.)",
    "choices": [
      "VPC peering to a public VPC",
      "Routes in private subnet route tables to the egress-only internet gateway for ::/0",
      "Internet Gateway with inbound security group rules opened",
      "Egress-only Internet Gateway",
      "NAT Gateway"
    ],
    "answer": [
      1,
      3
    ],
    "explanation": "For IPv6 outbound-only internet, use an egress-only IGW and add ::/0 routes to it from private subnets. NAT Gateway is for IPv4.",
    "difficulty": "Medium"
  },
  {
    "id": "SAA-295",
    "domainId": "D4",
    "domain": "Design Cost-Optimized Architectures",
    "section": "Compute",
    "question": "A containerized batch job runs nightly for 2 hours and is not time-sensitive. The team wants to minimize cost and avoid managing servers. Which TWO compute options are the best fit? (Choose TWO.)",
    "choices": [
      "AWS Lambda with a 3-hour timeout",
      "Amazon EC2 Dedicated Hosts",
      "AWS Batch with a Fargate compute environment",
      "Amazon ECS on Fargate with scheduled tasks",
      "Amazon EKS with self-managed nodes kept running 24/7"
    ],
    "answer": [
      2,
      3
    ],
    "explanation": "Batch on Fargate or ECS Fargate scheduled tasks meet serverless container execution and reduce idle costs. Lambda cannot run for hours, and always-on node fleets increase cost.",
    "difficulty": "Medium"
  },
  {
    "id": "SAA-296",
    "domainId": "D1",
    "domain": "Design Secure Architectures",
    "section": "KMS",
    "question": "A company replicates encrypted objects from us-east-1 to eu-west-1. They must decrypt in both Regions without re-encrypting and ensure keys remain cryptographically equivalent. Which TWO KMS actions/features should be used? (Choose TWO.)",
    "choices": [
      "Use a single-region key and share it directly into eu-west-1",
      "Create a replica key in eu-west-1 for the multi-Region key",
      "Use unrelated CMKs in each Region but keep the same alias name",
      "Create a KMS multi-Region primary key in us-east-1",
      "Use SSE-S3 because it decrypts cross-Region automatically"
    ],
    "answer": [
      1,
      3
    ],
    "explanation": "Multi-Region keys are designed for cross-Region encrypt/decrypt without re-encryption by using linked primary + replica keys that are cryptographically equivalent.",
    "difficulty": "Hard"
  },
  {
    "id": "SAA-297",
    "domainId": "D1",
    "domain": "Design Secure Architectures",
    "section": "S3",
    "question": "S3 Cross-Region Replication is enabled for a source bucket using SSE-KMS. Replication fails due to access errors on the destination KMS key. Which TWO changes are most likely required to fix it while keeping destination objects SSE-KMS encrypted? (Choose TWO.)",
    "choices": [
      "Ensure the replication IAM role has permissions to replicate objects to the destination bucket (s3:ReplicateObject, s3:ReplicateDelete, etc.)",
      "Turn off SSE-KMS on the source bucket",
      "Disable versioning on the destination bucket to reduce complexity",
      "Create an S3 Transfer Acceleration endpoint",
      "Update the destination KMS key policy to allow the replication IAM role to use kms:Encrypt and kms:GenerateDataKey"
    ],
    "answer": [
      0,
      4
    ],
    "explanation": "CRR with SSE-KMS needs (1) S3 permissions for replication and (2) KMS key policy permissions on the destination CMK so the replication role can encrypt (and generate data keys).",
    "difficulty": "Hard"
  },
  {
    "id": "SAA-298",
    "domainId": "D1",
    "domain": "Design Secure Architectures",
    "section": "Organizations",
    "question": "A security team wants to ensure that even admins in member accounts cannot create internet-facing load balancers and cannot disable GuardDuty. The company uses AWS Organizations. Which TWO controls best enforce these requirements at scale? (Choose TWO.)",
    "choices": [
      "IAM policies on each admin user, manually maintained per account",
      "Security groups that block 0.0.0.0/0",
      "Permission boundaries attached to every IAM role in every account",
      "AWS Config rules only, with email notifications",
      "SCPs that explicitly deny elasticloadbalancing:CreateLoadBalancer with scheme=internet-facing and guardduty:DeleteDetector/StopMonitoringMembers"
    ],
    "answer": [
      2,
      4
    ],
    "explanation": "SCPs enforce maximum permissions across accounts. Permission boundaries further constrain what IAM roles/users can do even when admins try to expand permissions. Config alone is detective, not preventive.",
    "difficulty": "Hard"
  },
  {
    "id": "SAA-299",
    "domainId": "D2",
    "domain": "Design Resilient Architectures",
    "section": "Disaster Recovery",
    "question": "A critical payments platform requires minutes-level RTO and low RPO across two Regions, but cannot justify active/active cost. The secondary Region should run a scaled-down environment that can rapidly scale during failover. Which TWO elements best describe the correct approach? (Choose TWO.)",
    "choices": [
      "Backup and restore strategy",
      "Keep only backups in S3 Glacier Deep Archive and restore during disaster",
      "Warm Standby strategy",
      "Keep a minimal but running copy of the application stack in the secondary Region",
      "Multi-Region active/active with continuous traffic splitting"
    ],
    "answer": [
      2,
      3
    ],
    "explanation": "Warm standby keeps a reduced-capacity but running environment in the secondary Region and scales up on failover, providing minutes-level RTO with lower cost than active/active.",
    "difficulty": "Hard"
  },
  {
    "id": "SAA-300",
    "domainId": "D3",
    "domain": "Design High-Performing Architectures",
    "section": "CloudFront",
    "question": "A CloudFront distribution must run lightweight JavaScript code to modify requests and responses at the edge with sub-millisecond latency. What is the BEST solution?",
    "choices": [
      "Lambda@Edge functions",
      "CloudFront Functions",
      "API Gateway with Lambda",
      "AWS AppSync"
    ],
    "answer": 1,
    "explanation": "CloudFront Functions are designed for lightweight, sub-millisecond latency JavaScript execution at the edge. They are ideal for simple request/response transformations like header manipulation, URL rewrites, and authorization. Lambda@Edge is better for more complex operations but has higher latency.",
    "difficulty": "Hard"
  },
  {
    "id": "SAA-301",
    "domainId": "D2",
    "domain": "Design Resilient Architectures",
    "section": "Networking",
    "question": "A company needs to connect dozens of VPCs across accounts plus on-prem networks in a hub-and-spoke topology, with centralized routing, route propagation, and minimal operational overhead. Which TWO statements describe the best solution? (Choose TWO.)",
    "choices": [
      "A separate Site-to-Site VPN per VPC is the simplest at large scale",
      "VPC Peering is preferred because it automatically provides transitive routing",
      "AWS Transit Gateway provides hub-and-spoke connectivity and centralized route tables",
      "Transit Gateway attachments simplify connecting many VPCs without a full mesh",
      "Direct Connect alone automatically connects VPC-to-VPC routing without a hub"
    ],
    "answer": [
      2,
      3
    ],
    "explanation": "Transit Gateway is built for centralized connectivity and avoids complex peering meshes. VPC peering is non-transitive and becomes operationally complex at scale.",
    "difficulty": "Hard"
  },
  {
    "id": "SAA-302",
    "domainId": "D1",
    "domain": "Design Secure Architectures",
    "section": "EKS",
    "question": "An EKS cluster runs workloads that must access DynamoDB securely without storing long-term AWS keys in pods. The solution must use IAM policies and be least privilege. Which TWO actions should you take? (Choose TWO.)",
    "choices": [
      "Store AWS access keys in a ConfigMap and mount it into pods",
      "Enable IAM Roles for Service Accounts (IRSA) and map a Kubernetes service account to an IAM role",
      "Expose DynamoDB through a public ALB and use basic auth",
      "Assign AdministratorAccess to the node instance role so pods inherit it",
      "Attach a least-privilege IAM policy to the IRSA IAM role allowing required DynamoDB actions"
    ],
    "answer": [
      1,
      4
    ],
    "explanation": "IRSA provides short-lived credentials to pods via an IAM role bound to a service account. Attach only the required DynamoDB permissions to that role for least privilege.",
    "difficulty": "Hard"
  },
  {
    "id": "SAA-303",
    "domainId": "D2",
    "domain": "Design Resilient Architectures",
    "section": "RDS",
    "question": "A company needs a very short, controlled database upgrade cutover and the ability to quickly roll back if issues occur. They are using Amazon RDS for MySQL and upgrading a major version. Which TWO steps/features best match this requirement? (Choose TWO.)",
    "choices": [
      "Switch over to the green environment during a controlled maintenance window",
      "Rely on Multi-AZ failover to downgrade automatically",
      "Use RDS Blue/Green Deployments to create a synchronized green environment",
      "Use S3 Lifecycle policies to archive old database logs",
      "Perform the major upgrade directly on the production instance during business hours"
    ],
    "answer": [
      0,
      2
    ],
    "explanation": "Blue/Green provides a synchronized staging environment to upgrade safely, then switch over with a short cutover. Multi-AZ is HA, not version rollback.",
    "difficulty": "Hard"
  },
  {
    "id": "SAA-304",
    "domainId": "D4",
    "domain": "Design Cost-Optimized Architectures",
    "section": "S3",
    "question": "You must update tags on 50 million objects across multiple S3 buckets and you need progress reporting with minimal custom code. Which TWO items form the most native, operationally simple solution? (Choose TWO.)",
    "choices": [
      "Provide an S3 Batch Operations manifest listing objects to update",
      "Use S3 Transfer Acceleration to speed up tagging API calls",
      "Use S3 Batch Operations to run a PutObjectTagging job",
      "Use S3 Storage Lens to apply tags",
      "Write a custom script with thousands of parallel threads and no job tracking"
    ],
    "answer": [
      0,
      2
    ],
    "explanation": "S3 Batch Operations is built for massive-scale object actions and provides job tracking/reporting. A manifest is the standard way to define the object set for the batch job.",
    "difficulty": "Hard"
  },
  {
    "id": "SAA-305",
    "domainId": "D2",
    "domain": "Design Resilient Architectures",
    "section": "Migration",
    "question": "You must migrate hundreds of on-prem VMs to AWS with block-level continuous replication, support test cutovers, and keep the final cutover window short. Which TWO statements describe the correct service/approach? (Choose TWO.)",
    "choices": [
      "S3 Batch Operations is used to replicate running VM disks",
      "AWS DMS is the primary service for lift-and-shift VM replication to EC2",
      "AWS Application Migration Service (MGN) performs block-level replication for server migrations",
      "AWS DataSync is designed for VM block-level replication and cutover orchestration",
      "MGN supports launching test instances in AWS before final cutover"
    ],
    "answer": [
      2,
      4
    ],
    "explanation": "MGN is purpose-built for lift-and-shift server migrations with continuous block-level replication and test cutovers. DataSync is for file transfers; DMS is for databases.",
    "difficulty": "Hard"
  },
  {
    "id": "SAA-306",
    "domainId": "D1",
    "domain": "Design Secure Architectures",
    "section": "IAM",
    "question": "A new AWS account was created for production. Which TWO best practices should be applied to the root user right away? (Choose TWO.)",
    "choices": [
      "Enable MFA on the root user",
      "Share the root password with the DevOps team for emergencies",
      "Use the root user only for tasks that specifically require it",
      "Attach AdministratorAccess to all IAM users instead of using the root user",
      "Create access keys for the root user for daily CLI use"
    ],
    "answer": [
      0,
      2
    ],
    "explanation": "Enable MFA on the root user and avoid using it for day-to-day operations; use it only when required.",
    "difficulty": "Easy"
  },
  {
    "id": "SAA-308",
    "domainId": "D1",
    "domain": "Design Secure Architectures",
    "section": "Networking",
    "question": "Your EC2 instances are in private subnets and must download patches from the internet without being directly reachable from the internet. Which TWO components are typically required? (Choose TWO.)",
    "choices": [
      "Route table in the private subnet pointing 0.0.0.0/0 to the NAT Gateway",
      "VPC peering to a public VPC owned by AWS",
      "Internet Gateway attached to the VPC",
      "NAT Gateway in a public subnet",
      "An ALB in front of the instances to provide outbound internet"
    ],
    "answer": [
      0,
      3
    ],
    "explanation": "Private subnets use a NAT Gateway for outbound internet access, plus a route to the NAT in the private route table.",
    "difficulty": "Easy"
  },
  {
    "id": "SAA-309",
    "domainId": "D2",
    "domain": "Design Resilient Architectures",
    "section": "EC2",
    "question": "By default, what happens to an EC2 instance’s root EBS volume when the instance is terminated?",
    "choices": [
      "It is deleted by default",
      "It is automatically snapshotted",
      "It is moved to another AZ",
      "It is always kept"
    ],
    "answer": 0,
    "explanation": "The default behavior is to delete the root EBS volume on termination (unless you change the DeleteOnTermination flag).",
    "difficulty": "Easy"
  },
  {
    "id": "SAA-310",
    "domainId": "D3",
    "domain": "Design High-Performing Architectures",
    "section": "Access",
    "question": "Which TWO are valid ways to access AWS services programmatically? (Choose TWO.)",
    "choices": [
      "AWS SDKs",
      "Remote Desktop Protocol (RDP) to the AWS Console",
      "FTP client",
      "AWS CLI",
      "Telnet"
    ],
    "answer": [
      0,
      3
    ],
    "explanation": "Programmatic access is typically done using the AWS CLI or AWS SDKs (which call AWS APIs).",
    "difficulty": "Easy"
  },
  {
    "id": "SAA-311",
    "domainId": "D3",
    "domain": "Design High-Performing Architectures",
    "section": "ELB",
    "question": "Which load balancer is best suited for HTTP/HTTPS traffic with features like host-based and path-based routing?",
    "choices": [
      "Application Load Balancer (ALB)",
      "Network Load Balancer (NLB)",
      "Gateway Load Balancer (GWLB)",
      "Classic Load Balancer (CLB) only"
    ],
    "answer": 0,
    "explanation": "ALB is Layer 7 and supports routing features like host-based and path-based rules.",
    "difficulty": "Easy"
  },
  {
    "id": "SAA-312",
    "domainId": "D2",
    "domain": "Design Resilient Architectures",
    "section": "Auto Scaling",
    "question": "You want your application to automatically add EC2 instances during high load and replace unhealthy instances. Which TWO AWS components are the standard solution? (Choose TWO.)",
    "choices": [
      "Auto Scaling Group (ASG)",
      "AWS Snowball Edge",
      "Amazon Route 53 private hosted zone only",
      "Application Load Balancer (ALB)",
      "Amazon S3 lifecycle policies"
    ],
    "answer": [
      0,
      3
    ],
    "explanation": "An ASG handles scaling and health-based replacement, while an ALB distributes traffic and removes unhealthy targets.",
    "difficulty": "Easy"
  },
  {
    "id": "SAA-313",
    "domainId": "D4",
    "domain": "Design Cost-Optimized Architectures",
    "section": "EC2 Pricing",
    "question": "Which EC2 purchase option is typically best for short, unpredictable workloads with no long-term commitment?",
    "choices": [
      "Reserved Instances (3-year)",
      "Dedicated Hosts",
      "Savings Plans (3-year)",
      "On-Demand Instances"
    ],
    "answer": 3,
    "explanation": "On-Demand is best for short, unpredictable workloads because it has no long-term commitment.",
    "difficulty": "Easy"
  },
  {
    "id": "SAA-314",
    "domainId": "D3",
    "domain": "Design High-Performing Architectures",
    "section": "Storage",
    "question": "Which TWO statements accurately describe Amazon EBS vs Amazon EFS? (Choose TWO.)",
    "choices": [
      "EFS is a managed NFS file system that can be mounted by many instances across AZs",
      "EFS is object storage for static websites",
      "EBS automatically replicates across Regions by default",
      "EBS can be mounted by unlimited instances across multiple AZs by default",
      "EBS is block storage attached to a single EC2 instance (AZ-scoped)"
    ],
    "answer": [
      0,
      4
    ],
    "explanation": "EBS is AZ-scoped block storage for a single instance (typical use). EFS is shared file storage (NFS) across multiple instances and AZs.",
    "difficulty": "Easy"
  },
  {
    "id": "SAA-316",
    "domainId": "D1",
    "domain": "Design Secure Architectures",
    "section": "Security Groups",
    "question": "By default, which TWO statements about a new Security Group are correct? (Choose TWO.)",
    "choices": [
      "It blocks all outbound traffic by default",
      "It is stateless like a Network ACL",
      "It allows all inbound traffic by default",
      "It allows all outbound traffic by default",
      "It blocks all inbound traffic until you add inbound rules"
    ],
    "answer": [
      3,
      4
    ],
    "explanation": "Default security group behavior is: inbound denied (no inbound rules) and outbound allowed (allow all outbound).",
    "difficulty": "Easy"
  },
  {
    "id": "SAA-317",
    "domainId": "D2",
    "domain": "Design Resilient Architectures",
    "section": "RDS",
    "question": "Which RDS feature provides automatic failover to another AZ with minimal application changes (same endpoint)?",
    "choices": [
      "RDS snapshot",
      "RDS Multi-AZ deployment",
      "RDS Read Replica",
      "RDS Performance Insights"
    ],
    "answer": 1,
    "explanation": "Multi-AZ provides a standby in another AZ and automatic failover with the same endpoint.",
    "difficulty": "Easy"
  },
  {
    "id": "SAA-318",
    "domainId": "D4",
    "domain": "Design Cost-Optimized Architectures",
    "section": "S3",
    "question": "You need to host a public dataset in S3 and want downloaders to pay request and data-transfer costs while you keep paying for storage. Which TWO statements are true? (Choose TWO.)",
    "choices": [
      "Enable Requester Pays on the bucket",
      "You must enable S3 Transfer Acceleration for Requester Pays to work",
      "Requester Pays prevents public access automatically",
      "Requesters are charged for requests and data transfer when Requester Pays is enabled",
      "Requester Pays makes the bucket owner pay for all requests"
    ],
    "answer": [
      0,
      3
    ],
    "explanation": "Requester Pays shifts request and transfer charges to the requester; the bucket owner still pays for storage.",
    "difficulty": "Easy"
  },
  {
    "id": "SAA-319",
    "domainId": "D1",
    "domain": "Design Secure Architectures",
    "section": "S3",
    "question": "A browser-based web app at https://app.example.com needs to call GET/PUT on an S3 bucket. Requests are blocked by the browser. What must be configured?",
    "choices": [
      "S3 Transfer Acceleration",
      "CloudTrail data events only",
      "S3 CORS configuration allowing the origin and required methods/headers",
      "S3 Object Lock"
    ],
    "answer": 2,
    "explanation": "Cross-origin browser requests require S3 CORS rules allowing the web app origin and the needed HTTP methods/headers.",
    "difficulty": "Easy"
  },
  {
    "id": "SAA-320",
    "domainId": "D2",
    "domain": "Design Resilient Architectures",
    "section": "Route 53",
    "question": "You want to split traffic between two endpoints: 80% to the old version and 20% to the new version. Which TWO Route 53 concepts are used? (Choose TWO.)",
    "choices": [
      "Geolocation routing policy",
      "Failover routing policy",
      "Two records (one per endpoint) with different weights",
      "Multi-Value Answer routing policy",
      "Weighted routing policy"
    ],
    "answer": [
      2,
      4
    ],
    "explanation": "Weighted routing uses multiple records with weights to control traffic percentage between endpoints.",
    "difficulty": "Easy"
  },
  {
    "id": "SAA-321",
    "domainId": "D2",
    "domain": "Design Resilient Architectures",
    "section": "Route 53",
    "question": "You need to map the zone apex (example.com) to an Application Load Balancer. Which Route 53 record type should you use?",
    "choices": [
      "CNAME record to the ALB DNS name",
      "Alias A record to the ALB",
      "NS record to the ALB",
      "TXT record containing the ALB name"
    ],
    "answer": 1,
    "explanation": "At the zone apex you use an Alias A record (CNAME isn’t allowed at the root in Route 53).",
    "difficulty": "Easy"
  },
  {
    "id": "SAA-322",
    "domainId": "D1",
    "domain": "Design Secure Architectures",
    "section": "CloudTrail",
    "question": "A security team needs to know who made AWS API calls, from which IP, and when. Which TWO steps/services provide this auditing capability? (Choose TWO.)",
    "choices": [
      "Deliver CloudTrail logs to an S3 bucket",
      "Enable Amazon GuardDuty only",
      "Enable S3 Transfer Acceleration",
      "Enable AWS Budgets",
      "Enable AWS CloudTrail management events"
    ],
    "answer": [
      0,
      4
    ],
    "explanation": "CloudTrail records API calls (identity, source IP, time), and delivering logs to S3 retains them for auditing.",
    "difficulty": "Easy"
  },
  {
    "id": "SAA-323",
    "domainId": "D3",
    "domain": "Design High-Performing Architectures",
    "section": "Lambda",
    "question": "What is the maximum duration a single AWS Lambda invocation can run before it times out (assuming you set it to the maximum)?",
    "choices": [
      "5 minutes",
      "15 minutes",
      "30 seconds",
      "1 hour"
    ],
    "answer": 1,
    "explanation": "Lambda has a maximum timeout of 15 minutes per invocation.",
    "difficulty": "Easy"
  },
  {
    "id": "SAA-324",
    "domainId": "D2",
    "domain": "Design Resilient Architectures",
    "section": "SQS",
    "question": "An SQS-triggered Lambda is processing a message and you don’t want SQS to deliver the same message again while processing is still in progress. Which TWO settings should be aligned? (Choose TWO.)",
    "choices": [
      "SQS visibility timeout should be greater than the maximum processing time",
      "SQS long polling must be set to 20 seconds",
      "Enable S3 Versioning",
      "Lambda function timeout should be less than or equal to the SQS visibility timeout",
      "Enable FIFO to automatically prevent all duplicates"
    ],
    "answer": [
      0,
      3
    ],
    "explanation": "Visibility timeout must cover processing time, and Lambda timeout should fit within that window to reduce duplicate deliveries.",
    "difficulty": "Easy"
  },
  {
    "id": "SAA-325",
    "domainId": "D3",
    "domain": "Design High-Performing Architectures",
    "section": "DynamoDB",
    "question": "Your DynamoDB table has unpredictable traffic patterns and you want to automatically scale capacity without manual intervention. What capacity mode should you use?",
    "choices": [
      "Provisioned capacity with Auto Scaling",
      "On-Demand capacity mode",
      "Reserved capacity",
      "Provisioned capacity without Auto Scaling"
    ],
    "answer": 1,
    "explanation": "On-Demand capacity mode automatically scales to accommodate workload demands without capacity planning. It is ideal for unpredictable traffic patterns as it instantly accommodates workloads as they ramp up or down, charging only for the read and write requests consumed.",
    "difficulty": "Easy"
  },
  {
    "id": "SAA-326",
    "domainId": "D1",
    "domain": "Design Secure Architectures",
    "section": "Secrets Manager",
    "question": "You store database credentials and need automatic rotation every 30 days with managed workflows. Which TWO capabilities/services should you use? (Choose TWO.)",
    "choices": [
      "AWS Secrets Manager",
      "Route 53 health checks",
      "Secrets Manager rotation (uses a Lambda rotation function)",
      "S3 bucket policies",
      "EBS snapshots"
    ],
    "answer": [
      0,
      2
    ],
    "explanation": "Secrets Manager stores secrets and supports automatic rotation via a rotation Lambda function on a schedule.",
    "difficulty": "Easy"
  },
  {
    "id": "SAA-327",
    "domainId": "D1",
    "domain": "Design Secure Architectures",
    "section": "KMS",
    "question": "Which AWS service is used to create and manage encryption keys for services like S3, EBS, and RDS (SSE-KMS)?",
    "choices": [
      "AWS Secrets Manager",
      "AWS Key Management Service (KMS)",
      "Amazon Cognito",
      "AWS Certificate Manager (ACM)"
    ],
    "answer": 1,
    "explanation": "KMS manages encryption keys used by many AWS services for server-side encryption and cryptographic operations.",
    "difficulty": "Easy"
  },
  {
    "id": "SAA-328",
    "domainId": "D3",
    "domain": "Design High-Performing Architectures",
    "section": "CloudFront",
    "question": "You want to block viewers from specific countries from accessing your content at the edge. Which TWO CloudFront features can directly help? (Choose TWO.)",
    "choices": [
      "Security groups on the origin only",
      "CloudFront geo restriction",
      "Route 53 weighted routing",
      "S3 Object Lock",
      "CloudFront signed URLs or signed cookies"
    ],
    "answer": [
      1,
      4
    ],
    "explanation": "Geo restriction blocks by country at the edge, and signed URLs/cookies restrict access to authorized viewers.",
    "difficulty": "Easy"
  },
  {
    "id": "SAA-329",
    "domainId": "D3",
    "domain": "Design High-Performing Architectures",
    "section": "ECS",
    "question": "You want to run containers without managing EC2 instances. Which ECS launch type should you use?",
    "choices": [
      "EC2 launch type",
      "Fargate launch type",
      "On-premises launch type",
      "Dedicated Host launch type"
    ],
    "answer": 1,
    "explanation": "ECS on Fargate removes the need to manage EC2 instances for container workloads.",
    "difficulty": "Easy"
  },
  {
    "id": "SAA-330",
    "domainId": "D1",
    "domain": "Design Secure Architectures",
    "section": "VPC Endpoints",
    "question": "You want private subnets to reach Amazon S3 without using a NAT Gateway and without sending traffic over the public internet. Which TWO actions achieve this? (Choose TWO.)",
    "choices": [
      "Update the private subnet route table to target the S3 Gateway endpoint",
      "Create an Interface VPC endpoint for S3 and disable private DNS",
      "Assign Elastic IPs to the instances",
      "Attach an Internet Gateway to the private subnet",
      "Create a Gateway VPC endpoint for S3"
    ],
    "answer": [
      0,
      4
    ],
    "explanation": "Use an S3 Gateway VPC endpoint and add the endpoint route to the private route table.",
    "difficulty": "Easy"
  },
  {
    "id": "SAA-331",
    "domainId": "D2",
    "domain": "Design Resilient Architectures",
    "section": "S3",
    "question": "What is a hard prerequisite for enabling S3 Cross-Region Replication (CRR) between two buckets?",
    "choices": [
      "S3 Object Lock enabled on both buckets",
      "S3 Transfer Acceleration enabled on both buckets",
      "The buckets must be in the same Region",
      "Versioning enabled on both source and destination buckets"
    ],
    "answer": 3,
    "explanation": "CRR requires versioning enabled on both buckets.",
    "difficulty": "Easy"
  },
  {
    "id": "SAA-332",
    "domainId": "D3",
    "domain": "Design High-Performing Architectures",
    "section": "CloudWatch",
    "question": "You want to be alerted when an EC2 instance’s CPU utilization stays above 80% for 5 minutes. Which TWO services/features do you use? (Choose TWO.)",
    "choices": [
      "Amazon CloudWatch alarm",
      "Amazon Athena",
      "Amazon CloudWatch metric (CPUUtilization)",
      "AWS Config",
      "AWS CloudTrail"
    ],
    "answer": [
      0,
      2
    ],
    "explanation": "CloudWatch metrics provide CPUUtilization and CloudWatch alarms evaluate the threshold and trigger notifications/actions.",
    "difficulty": "Easy"
  },
  {
    "id": "SAA-333",
    "domainId": "D2",
    "domain": "Design Resilient Architectures",
    "section": "EBS",
    "question": "What is the primary purpose of an EBS snapshot?",
    "choices": [
      "To create a point-in-time backup of an EBS volume",
      "To encrypt a KMS key",
      "To store objects for static website hosting",
      "To distribute HTTP traffic across instances"
    ],
    "answer": 0,
    "explanation": "An EBS snapshot is a point-in-time backup of an EBS volume.",
    "difficulty": "Easy"
  },
  {
    "id": "SAA-334",
    "domainId": "D1",
    "domain": "Design Secure Architectures",
    "section": "ACM",
    "question": "You need a publicly trusted TLS certificate for an ALB and want AWS-managed renewals. What should you do?",
    "choices": [
      "Request a public certificate in ACM and validate it (DNS or email)",
      "Use S3 to host the certificate and reference it from the ALB",
      "Use a self-signed certificate and import it into ACM",
      "Create a certificate in Secrets Manager"
    ],
    "answer": 0,
    "explanation": "ACM public certificates are managed by AWS and support automatic renewal when validation remains in place.",
    "difficulty": "Easy"
  },
  {
    "id": "SAA-335",
    "domainId": "D4",
    "domain": "Design Cost-Optimized Architectures",
    "section": "S3",
    "question": "You store compliance archives that are rarely accessed but must be retained for 10 years with retrieval times of up to 12 hours acceptable. What is the MOST cost-effective S3 storage class?",
    "choices": [
      "S3 Standard",
      "S3 Standard-IA",
      "S3 Glacier Flexible Retrieval",
      "S3 Glacier Deep Archive"
    ],
    "answer": 3,
    "explanation": "S3 Glacier Deep Archive is the most cost-effective storage class for long-term archives that are rarely accessed. It offers the lowest storage costs and supports retrieval times of up to 12 hours, making it ideal for compliance archives with 7-10 year retention requirements.",
    "difficulty": "Easy"
  },
  {
    "id": "SAA-336",
    "domainId": "D3",
    "domain": "Design High-Performing Architectures",
    "section": "Athena",
    "question": "You want to run ad-hoc SQL queries directly against files in S3 without provisioning servers. Which service should you use?",
    "choices": [
      "Amazon Athena",
      "Amazon RDS",
      "Amazon ElastiCache",
      "Amazon EC2"
    ],
    "answer": 0,
    "explanation": "Athena is serverless SQL for querying data in S3.",
    "difficulty": "Easy"
  },
  {
    "id": "SAA-337",
    "domainId": "D2",
    "domain": "Design Resilient Architectures",
    "section": "Disaster Recovery",
    "question": "Which disaster recovery strategy has the lowest cost but typically the highest RTO/RPO among common DR patterns?",
    "choices": [
      "Pilot Light",
      "Backup & Restore",
      "Warm Standby",
      "Multi-Region Active/Active"
    ],
    "answer": 1,
    "explanation": "Backup & Restore is usually the lowest cost, but it has longer recovery time and potentially more data loss compared to warm standby or active/active.",
    "difficulty": "Easy"
  },
  {
    "id": "SAA-338",
    "domainId": "D1",
    "domain": "Design Secure Architectures",
    "section": "Organizations",
    "question": "What is the main purpose of an AWS Organizations Service Control Policy (SCP)?",
    "choices": [
      "Set the maximum permissions for member accounts/OUs (guardrails)",
      "Encrypt data at rest for all services",
      "Grant permissions to IAM users in an account",
      "Provide DDoS protection for CloudFront"
    ],
    "answer": 0,
    "explanation": "SCPs define the permission boundaries (maximum allowed) for accounts in an organization; they do not grant permissions by themselves.",
    "difficulty": "Easy"
  },
  {
    "id": "SAA-339",
    "domainId": "D2",
    "domain": "Design Resilient Architectures",
    "section": "AWS Backup",
    "question": "You want a centralized managed service to back up resources like EBS, RDS, DynamoDB, and EFS using policies. Which service should you use?",
    "choices": [
      "Amazon CloudFront",
      "AWS Glue",
      "AWS Backup",
      "AWS DataSync"
    ],
    "answer": 2,
    "explanation": "AWS Backup is the managed centralized service for policy-based backups across multiple AWS services.",
    "difficulty": "Easy"
  },
  {
    "id": "SAA-340",
    "domainId": "D1",
    "domain": "Design Secure Architectures",
    "section": "WAF",
    "question": "A company uses CloudFront in front of multiple ALBs across several AWS accounts. Security wants to centrally enforce a baseline set of WAF rules across all accounts using AWS Organizations. Which service should be used?",
    "choices": [
      "AWS Shield Standard",
      "AWS Firewall Manager",
      "Amazon GuardDuty",
      "AWS Network Firewall"
    ],
    "answer": 1,
    "explanation": "AWS Firewall Manager integrates with AWS Organizations to centrally manage and enforce AWS WAF (and Shield Advanced) policies across multiple accounts and resources.",
    "difficulty": "Medium"
  },
  {
    "id": "SAA-341",
    "domainId": "D2",
    "domain": "Design Resilient Architectures",
    "section": "RDS",
    "question": "A production MySQL database runs on Amazon RDS. The analytics team must run heavy read queries without impacting the application’s performance. Which solution is the MOST suitable and cost-effective?",
    "choices": [
      "Export data nightly to S3 and query with Athena only",
      "Create an RDS Read Replica and direct analytics queries to the replica",
      "Increase the DB instance size and keep analytics on the primary",
      "Enable RDS Multi-AZ and direct analytics queries to the standby instance"
    ],
    "answer": 1,
    "explanation": "Read replicas offload read traffic from the primary DB, preventing analytics queries from impacting the production workload. Multi-AZ standby is not used for reads.",
    "difficulty": "Medium"
  },
  {
    "id": "SAA-342",
    "domainId": "D4",
    "domain": "Design Cost-Optimized Architectures",
    "section": "S3",
    "question": "A team stores large objects in S3. Objects are heavily accessed for the first 14 days, then rarely accessed for the next 60 days but must still be retrieved immediately (milliseconds). After that, the data is kept for compliance and can take hours to retrieve. Which lifecycle approach best meets the requirements at the lowest cost?",
    "choices": [
      "S3 Standard (14 days) → S3 Glacier Deep Archive (after day 14)",
      "S3 One Zone-IA (14 days) → S3 Standard-IA (day 14–74) → S3 Glacier Deep Archive (after day 74)",
      "S3 Intelligent-Tiering (14 days) → S3 One Zone-IA (day 14–74) → S3 Glacier Instant Retrieval (after day 74)",
      "S3 Standard (14 days) → S3 Standard-IA (day 14–74) → S3 Glacier Flexible Retrieval (after day 74)"
    ],
    "answer": 3,
    "explanation": "Standard fits frequent access, Standard-IA supports infrequent access with millisecond retrieval, and Glacier Flexible Retrieval supports long-term archiving with hour-level retrieval time.",
    "difficulty": "Medium"
  },
  {
    "id": "SAA-343",
    "domainId": "D1",
    "domain": "Design Secure Architectures",
    "section": "KMS",
    "question": "An S3 bucket uses SSE-KMS. A replication job to another Region fails with an error related to the destination KMS key. Which change is most likely required to allow replication to encrypt objects in the destination bucket?",
    "choices": [
      "Add permissions to the destination KMS key policy for the replication role to use kms:Encrypt and kms:GenerateDataKey",
      "Disable bucket versioning on the source bucket",
      "Enable MFA delete on the destination bucket",
      "Enable S3 Transfer Acceleration on the destination bucket"
    ],
    "answer": 0,
    "explanation": "For SSE-KMS replication, the replication IAM role must be allowed by the destination KMS key policy to perform encryption-related KMS actions (such as Encrypt and GenerateDataKey).",
    "difficulty": "Medium"
  },
  {
    "id": "SAA-344",
    "domainId": "D2",
    "domain": "Design Resilient Architectures",
    "section": "Disaster Recovery",
    "question": "A web platform must meet an RTO of under 30 minutes and an RPO of near zero for a regional disaster. The company can’t afford full active/active but can keep the secondary environment running at reduced capacity and scale it on failover. Which DR strategy is the best fit?",
    "choices": [
      "Pilot Light",
      "Multi-Region Active/Active",
      "Backup and Restore",
      "Warm Standby"
    ],
    "answer": 3,
    "explanation": "Warm standby keeps a scaled-down, fully functional environment running in the secondary Region and scales up during failover, meeting moderate RTO/RPO without active/active cost.",
    "difficulty": "Medium"
  },
  {
    "id": "SAA-345",
    "domainId": "D3",
    "domain": "Design High-Performing Architectures",
    "section": "Kinesis",
    "question": "A company needs to ingest clickstream events at high throughput with multiple consumer applications (analytics, fraud detection). Consumers must be able to replay events from the last 48 hours if processing logic changes. Which service best meets these requirements?",
    "choices": [
      "Amazon Kinesis Data Firehose",
      "Amazon SQS Standard",
      "Amazon SNS",
      "Amazon Kinesis Data Streams"
    ],
    "answer": 3,
    "explanation": "Kinesis Data Streams supports multiple consumers, low-latency processing, and configurable retention for replaying data (e.g., 48 hours).",
    "difficulty": "Medium"
  },
  {
    "id": "SAA-346",
    "domainId": "D1",
    "domain": "Design Secure Architectures",
    "section": "VPC Endpoints",
    "question": "EC2 instances in private subnets must access S3 without routing traffic through a NAT Gateway to reduce costs. What solution should you use?",
    "choices": [
      "VPC endpoint for S3",
      "Internet Gateway",
      "AWS PrivateLink",
      "VPN connection"
    ],
    "answer": 0,
    "explanation": "A VPC endpoint for S3 (Gateway endpoint) allows instances in private subnets to access S3 directly without requiring a NAT Gateway, Internet Gateway, or VPN connection. This eliminates NAT Gateway data transfer costs and provides better performance.",
    "difficulty": "Medium"
  },
  {
    "id": "SAA-347",
    "domainId": "D2",
    "domain": "Design Resilient Architectures",
    "section": "Outposts",
    "question": "A manufacturing site needs to run AWS services (EC2, EBS, EKS) on-premises with the same AWS APIs and console while achieving very low local latency. Which service is the BEST choice?",
    "choices": [
      "VMware Cloud on AWS",
      "AWS Local Zones",
      "AWS Outposts",
      "AWS Snowball Edge"
    ],
    "answer": 2,
    "explanation": "AWS Outposts brings AWS-managed infrastructure on-prem and supports native AWS services with consistent APIs and console experience.",
    "difficulty": "Medium"
  },
  {
    "id": "SAA-348",
    "domainId": "D4",
    "domain": "Design Cost-Optimized Architectures",
    "section": "Compute",
    "question": "A batch workload runs in containers for about 90 minutes each night. It is not time-sensitive and the team wants a serverless option without managing EC2 instances. Which solution is the MOST cost-effective?",
    "choices": [
      "Amazon EC2 On-Demand instances running 24/7",
      "Amazon ECS on Fargate with a scheduled task",
      "Amazon EKS with always-on managed node groups",
      "AWS Lambda with the timeout increased to 2 hours"
    ],
    "answer": 1,
    "explanation": "ECS Fargate supports serverless containers and can run scheduled tasks without managing servers. Lambda can’t run that long, and always-on nodes increase cost.",
    "difficulty": "Medium"
  },
  {
    "id": "SAA-349",
    "domainId": "D3",
    "domain": "Design High-Performing Architectures",
    "section": "ElastiCache",
    "question": "A web app is experiencing high read pressure on its RDS database due to frequently accessed session and user profile data. The data must be served with sub-millisecond latency and expire automatically. Which service is the BEST fit?",
    "choices": [
      "Amazon ElastiCache for Redis",
      "Amazon Athena",
      "Amazon EFS",
      "Amazon S3 Standard"
    ],
    "answer": 0,
    "explanation": "ElastiCache for Redis provides in-memory caching with very low latency and TTL expiration, reducing read load on RDS.",
    "difficulty": "Medium"
  },
  {
    "id": "SAA-350",
    "domainId": "D1",
    "domain": "Design Secure Architectures",
    "section": "Systems Manager",
    "question": "EC2 instances are in private subnets with no inbound access allowed. The operations team needs interactive shell access and port forwarding for troubleshooting without using bastion hosts, and all activity must be logged. Which service should be used?",
    "choices": [
      "AWS Systems Manager Session Manager",
      "Amazon Inspector",
      "Direct Connect",
      "EC2 Instance Connect"
    ],
    "answer": 0,
    "explanation": "SSM Session Manager provides interactive access without inbound SSH and supports logging/auditing to CloudWatch Logs/S3.",
    "difficulty": "Medium"
  },
  {
    "id": "SAA-351",
    "domainId": "D2",
    "domain": "Design Resilient Architectures",
    "section": "Networking",
    "question": "You need to connect dozens of VPCs and multiple on-premises networks in a hub-and-spoke design with centralized routing and route propagation. Which TWO services could be used to meet this requirement? (Choose TWO.)",
    "choices": [
      "AWS Site-to-Site VPN",
      "AWS Transit Gateway",
      "AWS Direct Connect",
      "VPC Peering",
      "Amazon Route 53 Resolver endpoints"
    ],
    "answer": [
      1,
      2
    ],
    "explanation": "Transit Gateway provides the hub for many VPCs and on-prem connections. Direct Connect can connect on-prem to AWS and can attach to Transit Gateway for centralized routing. (Site-to-Site VPN can also attach, but the question asks for TWO.)",
    "difficulty": "Medium"
  },
  {
    "id": "SAA-352",
    "domainId": "D3",
    "domain": "Design High-Performing Architectures",
    "section": "Global Accelerator",
    "question": "A global gaming app uses UDP and needs static anycast IPs and improved latency for worldwide users while balancing traffic to AWS endpoints. Which TWO AWS services should be used together? (Choose TWO.)",
    "choices": [
      "Network Load Balancer",
      "AWS Global Accelerator",
      "AWS WAF",
      "Application Load Balancer",
      "Amazon CloudFront"
    ],
    "answer": [
      0,
      1
    ],
    "explanation": "Global Accelerator provides static anycast IPs and optimized network paths for global users. Network Load Balancer supports UDP at Layer 4 and can serve as the regional endpoint.",
    "difficulty": "Medium"
  },
  {
    "id": "SAA-353",
    "domainId": "D1",
    "domain": "Design Secure Architectures",
    "section": "CloudFront",
    "question": "A company serves a global web app through Amazon CloudFront with an ALB origin. Security requires an authorization step at the edge: before any request reaches the origin, CloudFront must call an external authorization API, then either add/remove headers or return a redirect when access is denied. Which solution will meet these requirements with the LEAST operational overhead?",
    "choices": [
      "Move authorization to the origin and enforce it only in the application code",
      "Use CloudFront Functions to call the external authorization API before forwarding to the origin",
      "Use Lambda@Edge on viewer request to call the authorization API and rewrite headers or return redirects",
      "Attach AWS WAF to CloudFront and configure WAF to call the external authorization API"
    ],
    "answer": 2,
    "explanation": "Lambda@Edge can run on viewer request, perform external network calls (within limits), modify headers, and return custom responses. CloudFront Functions cannot call external services, and WAF cannot call arbitrary external authorization APIs.",
    "difficulty": "Hard"
  },
  {
    "id": "SAA-354",
    "domainId": "D2",
    "domain": "Design Resilient Architectures",
    "section": "RDS",
    "question": "A retail company runs a mission-critical RDS for MySQL database. They must upgrade to a new major version with a very short, controlled cutover and want an easy rollback if issues are found after the change. Which approach can be used to fulfill this requirement?",
    "choices": [
      "Export to S3, restore into a new DB, and repoint clients",
      "Use RDS Blue/Green Deployments and switch over when validation is complete",
      "Perform an in-place major version upgrade and rely on Multi-AZ failover for rollback",
      "Create a read replica, upgrade it, and promote it during cutover"
    ],
    "answer": 1,
    "explanation": "RDS Blue/Green Deployments supports safer, controlled upgrades with minimal downtime by keeping a synchronized staging environment and performing a switch-over when ready, with a practical rollback path.",
    "difficulty": "Hard"
  },
  {
    "id": "SAA-355",
    "domainId": "D1",
    "domain": "Design Secure Architectures",
    "section": "S3",
    "question": "A finance team stores monthly statements in Amazon S3. Regulations require WORM immutability for 7 years and protection against deletion by privileged users. Which combination of actions best satisfies the requirements while being the most cost-effective? (Choose TWO.)",
    "choices": [
      "Enable CloudTrail Insights",
      "Enable S3 Object Lock in Compliance mode with a 7-year retention",
      "Enable S3 Transfer Acceleration",
      "Enable default encryption with SSE-S3",
      "Enable S3 Versioning"
    ],
    "answer": [
      1,
      4
    ],
    "explanation": "Object Lock (Compliance) provides WORM enforcement that cannot be bypassed and requires versioning. Together they satisfy immutability and retention requirements.",
    "difficulty": "Hard"
  },
  {
    "id": "SAA-356",
    "domainId": "D3",
    "domain": "Design High-Performing Architectures",
    "section": "DynamoDB",
    "question": "A SaaS platform serves users in North America and Europe. The app needs single-digit-millisecond reads in both Regions and must continue operating through a full regional outage. Writes must be accepted in either Region. Which solution will meet these requirements with the LEAST operational overhead?",
    "choices": [
      "ElastiCache Global Datastore only",
      "DynamoDB Global Tables",
      "S3 Cross-Region Replication plus Athena queries",
      "Aurora read replicas in each Region with manual failover"
    ],
    "answer": 1,
    "explanation": "DynamoDB Global Tables provide active-active, multi-Region replication with local low-latency reads and multi-Region writes, minimizing operational overhead for this pattern.",
    "difficulty": "Hard"
  },
  {
    "id": "SAA-357",
    "domainId": "D4",
    "domain": "Design Cost-Optimized Architectures",
    "section": "S3",
    "question": "A company stores project artifacts in S3. For 30 days objects are frequently accessed. After day 30, most objects are rarely accessed and can tolerate minutes-to-hours retrieval. However, objects under s3://bucket/hotfix/ must still be retrievable in milliseconds after day 30. Which solution is MOST cost-effective?",
    "choices": [
      "Keep all objects in S3 Standard indefinitely",
      "Enable Intelligent-Tiering and disable lifecycle rules",
      "Use lifecycle rules: hotfix/ to S3 Standard-IA after 30 days, and the rest to S3 Glacier Flexible Retrieval",
      "Move the entire bucket to S3 One Zone-IA after 30 days"
    ],
    "answer": 2,
    "explanation": "Standard-IA provides millisecond retrieval for infrequently accessed objects at lower cost than Standard, while Glacier Flexible Retrieval lowers cost for the rest with acceptable retrieval latency.",
    "difficulty": "Hard"
  },
  {
    "id": "SAA-358",
    "domainId": "D1",
    "domain": "Design Secure Architectures",
    "section": "Organizations",
    "question": "An OU has an SCP that denies s3:PutBucketPolicy. A developer in a member account has AdministratorAccess but cannot update a bucket policy for a valid business use case. How will the Architect fix this issue while keeping strong guardrails?",
    "choices": [
      "Remove the SCP and rely on IAM permissions in each account",
      "Enable ACLs and stop using bucket policies for cross-account access",
      "Use a separate AWS account with no SCPs and migrate the bucket there",
      "Refine the SCP to allow s3:PutBucketPolicy only under controlled conditions (for example, using tags/conditions)"
    ],
    "answer": 3,
    "explanation": "SCPs apply regardless of IAM AdministratorAccess. The correct approach is to adjust the guardrail to allow the action only when it meets defined constraints.",
    "difficulty": "Hard"
  },
  {
    "id": "SAA-359",
    "domainId": "D2",
    "domain": "Design Resilient Architectures",
    "section": "Disaster Recovery",
    "question": "A payments platform needs minutes-level RTO and low data loss across two Regions, but wants to avoid full active/active cost. It will keep a reduced-capacity environment running in the secondary Region and scale up on failover. Which DR strategy should you choose?",
    "choices": [
      "Cold Standby",
      "Pilot Light",
      "Warm Standby",
      "Backup & Restore"
    ],
    "answer": 2,
    "explanation": "Warm Standby keeps a scaled-down but running environment in the secondary Region and can scale quickly during failover, meeting tighter RTO/RPO than backup/restore or pilot light.",
    "difficulty": "Hard"
  },
  {
    "id": "SAA-360",
    "domainId": "D1",
    "domain": "Design Secure Architectures",
    "section": "EKS",
    "question": "A platform team runs workloads on Amazon EKS. Pods must call DynamoDB without storing long-term keys. Access must be least privilege per workload. Which combination of actions best satisfies the requirement while being the most cost-effective? (Choose TWO.)",
    "choices": [
      "Use CloudFront signed URLs to DynamoDB",
      "Store access keys in Kubernetes Secrets and rotate monthly",
      "Give the node instance role AdministratorAccess",
      "Attach least-privilege DynamoDB permissions to the IAM role used by IRSA",
      "Enable IAM Roles for Service Accounts (IRSA)"
    ],
    "answer": [
      3,
      4
    ],
    "explanation": "IRSA provides short-lived credentials to pods, and attaching a least-privilege policy to the mapped IAM role ensures per-workload access without long-term keys.",
    "difficulty": "Hard"
  },
  {
    "id": "SAA-361",
    "domainId": "D3",
    "domain": "Design High-Performing Architectures",
    "section": "FSx",
    "question": "A research team runs HPC jobs that need a POSIX file system with very low latency and high throughput. The dataset is stored in S3 and must be processed as a mounted file system without manual copy steps. Which solution will meet these requirements with the LEAST operational overhead?",
    "choices": [
      "AWS Storage Gateway File Gateway",
      "Amazon FSx for Lustre linked to the S3 dataset",
      "S3 Glacier Instant Retrieval mounted via NFS",
      "Amazon EFS with lifecycle policies"
    ],
    "answer": 1,
    "explanation": "FSx for Lustre is optimized for HPC and can link to S3, presenting data as a high-performance file system with minimal operational effort.",
    "difficulty": "Hard"
  },
  {
    "id": "SAA-362",
    "domainId": "D4",
    "domain": "Design Cost-Optimized Architectures",
    "section": "Compute",
    "question": "A containerized microservice requires a steady compute baseline 24/7, but also has unpredictable spikes. The company wants to lower cost while avoiding capacity risk during spikes. Which combination best satisfies the requirements?",
    "choices": [
      "Spot for baseline usage and Spot for spikes",
      "Dedicated Hosts for baseline and On-Demand for spikes",
      "Savings Plans for baseline usage and On-Demand for spikes",
      "Only On-Demand so scaling is always flexible"
    ],
    "answer": 2,
    "explanation": "Savings Plans reduce cost for steady usage. On-Demand covers spikes without interruption risk or capacity constraints typical of Spot.",
    "difficulty": "Hard"
  },
  {
    "id": "SAA-363",
    "domainId": "D2",
    "domain": "Design Resilient Architectures",
    "section": "SQS",
    "question": "An order-processing system uses SQS with a Lambda consumer. During spikes, Lambda scales too aggressively and overwhelms the downstream database. How will the Architect fix this issue?",
    "choices": [
      "Increase SQS long polling to 20 seconds",
      "Enable FIFO so Lambda cannot scale out",
      "Decrease visibility timeout to reduce retries",
      "Set Reserved Concurrency on the Lambda function and tune batch size"
    ],
    "answer": 3,
    "explanation": "Reserved Concurrency caps parallel executions, throttling throughput. Batch size tuning further controls processing rate without changing producers.",
    "difficulty": "Hard"
  },
  {
    "id": "SAA-364",
    "domainId": "D1",
    "domain": "Design Secure Architectures",
    "section": "VPC Endpoints",
    "question": "Instances in private subnets must access S3 without using NAT and the security team wants to allow access only to a single bucket from those subnets. Which solution will meet these requirements with the LEAST operational overhead?",
    "choices": [
      "Use an Internet Gateway and Network ACLs to block inbound traffic",
      "Use VPC peering to an S3 VPC and restrict routes",
      "Create an S3 Gateway VPC endpoint and restrict the bucket policy to the endpoint",
      "Use a NAT Gateway and restrict the bucket policy to the NAT public IP"
    ],
    "answer": 2,
    "explanation": "Gateway endpoints keep traffic on the AWS network without NAT. Bucket policy conditions can restrict access to requests coming via a specific VPC endpoint.",
    "difficulty": "Hard"
  },
  {
    "id": "SAA-365",
    "domainId": "D1",
    "domain": "Design Secure Architectures",
    "section": "Secrets Manager",
    "question": "A company stores database credentials in AWS Secrets Manager. Auditors require proof of which IAM principal retrieved secret values and from which IP address. Which approach best meets the requirement?",
    "choices": [
      "Enable CloudWatch metrics for Secrets Manager and export them",
      "Enable CloudTrail and review Secrets Manager API events",
      "Enable VPC Flow Logs and search for AWS endpoint connections",
      "Enable AWS Config to record changes to secret rotation schedule"
    ],
    "answer": 1,
    "explanation": "CloudTrail logs Secrets Manager API calls (including GetSecretValue), capturing identity and source IP, which is what auditors need.",
    "difficulty": "Hard"
  },
  {
    "id": "SAA-366",
    "domainId": "D1",
    "domain": "Design Secure Architectures",
    "section": "KMS",
    "question": "You enable S3 Cross-Region Replication on a bucket that uses SSE-KMS. Replication fails due to an access error on the destination KMS key. Which of the following must be implemented in the current architecture to satisfy the new requirement?",
    "choices": [
      "Update the destination KMS key policy to allow the replication role to use KMS encryption actions",
      "Disable versioning on the destination bucket",
      "Enable S3 Transfer Acceleration on both buckets",
      "Disable SSE-KMS on the source bucket and switch to SSE-S3"
    ],
    "answer": 0,
    "explanation": "For SSE-KMS replication, the replication role must be allowed by the destination key policy to perform encrypt/data key actions so replicas can be encrypted at the destination.",
    "difficulty": "Hard"
  },
  {
    "id": "SAA-367",
    "domainId": "D3",
    "domain": "Design High-Performing Architectures",
    "section": "Kinesis",
    "question": "A company ingests telemetry at high throughput. Multiple consumers need sub-second processing and the ability to replay 72 hours of events after code changes. Which service should you choose?",
    "choices": [
      "Amazon Kinesis Data Streams",
      "Amazon SQS standard queue",
      "Amazon Kinesis Data Firehose only",
      "Amazon SNS standard topic"
    ],
    "answer": 0,
    "explanation": "Kinesis Data Streams supports multiple consumers and configurable retention for replay. SNS/SQS don’t provide the same stream replay pattern, and Firehose is delivery-focused without consumer replay semantics.",
    "difficulty": "Hard"
  },
  {
    "id": "SAA-368",
    "domainId": "D3",
    "domain": "Design High-Performing Architectures",
    "section": "Global Accelerator",
    "question": "A multiplayer game uses UDP and needs static anycast IPs and improved performance for global users to AWS endpoints. Which combination of actions best satisfies the requirements while being the most cost-effective? (Choose TWO.)",
    "choices": [
      "Use CloudFront as the entrypoint for UDP",
      "Use Application Load Balancer as the regional endpoint",
      "Use AWS Global Accelerator for the entrypoint",
      "Use S3 Transfer Acceleration for game packets",
      "Use Network Load Balancer as the regional endpoint"
    ],
    "answer": [
      2,
      4
    ],
    "explanation": "Global Accelerator provides static anycast IPs and optimized routing. NLB supports UDP and high throughput as a regional endpoint.",
    "difficulty": "Hard"
  },
  {
    "id": "SAA-369",
    "domainId": "D3",
    "domain": "Design High-Performing Architectures",
    "section": "Aurora",
    "question": "A read-heavy application uses Aurora MySQL. The team wants to scale read capacity with minimal changes and ensure fast writer failover. Which solution best meets these requirements?",
    "choices": [
      "Use periodic snapshots to improve read performance",
      "Move reads into S3 Select",
      "Add Aurora Replicas and use the reader endpoint for reads",
      "Increase the writer instance size only"
    ],
    "answer": 2,
    "explanation": "Aurora Replicas increase read capacity, and the reader endpoint distributes read traffic. Aurora managed failover improves resilience without complex application changes.",
    "difficulty": "Hard"
  },
  {
    "id": "SAA-370",
    "domainId": "D1",
    "domain": "Design Secure Architectures",
    "section": "KMS",
    "question": "A company encrypts data in us-east-1 and replicates ciphertext to eu-west-1. They must decrypt in both Regions without re-encrypting and want AWS-managed equivalent keys. Which approach should you choose?",
    "choices": [
      "Use one single-Region key and share it to the other Region",
      "Use SSE-S3 so decryption works anywhere",
      "Use KMS multi-Region keys with a replica key in the second Region",
      "Use two unrelated CMKs and keep the alias name identical"
    ],
    "answer": 2,
    "explanation": "KMS multi-Region keys are designed to provide cryptographically related keys across Regions so ciphertext can be decrypted in either Region without re-encryption.",
    "difficulty": "Hard"
  },
  {
    "id": "SAA-371",
    "domainId": "D2",
    "domain": "Design Resilient Architectures",
    "section": "Migration",
    "question": "A company must migrate hundreds of on-prem VMs to AWS. They require continuous block-level replication, the ability to launch test cutovers, and a short final cutover window. Which combination of actions best satisfies the given set of requirements while being the most cost-effective? (Choose TWO.)",
    "choices": [
      "Use AWS Application Migration Service (MGN) for replication",
      "Use AWS DMS to replicate VM blocks",
      "Use AWS DataSync for continuous block replication",
      "Perform test cutovers by launching test instances from replicated data",
      "Use S3 Batch Operations to import VM images"
    ],
    "answer": [
      0,
      3
    ],
    "explanation": "MGN provides continuous block-level replication and supports test cutovers by launching test instances, enabling a short final cutover window.",
    "difficulty": "Hard"
  },
  {
    "id": "SAA-372",
    "domainId": "D4",
    "domain": "Design Cost-Optimized Architectures",
    "section": "EFS",
    "question": "A pipeline stores temporary processing files on Amazon EFS. Files are heavily used for 7 days, then rarely accessed but must remain available for 90 days. The team wants to reduce storage cost without changing the app. Which solution should you implement?",
    "choices": [
      "Enable EFS lifecycle management to transition to EFS Infrequent Access after 7 days",
      "Move files to EBS gp3 after 7 days via cron jobs",
      "Replicate EFS to another Region and delete the primary copy",
      "Replace EFS with instance store to reduce cost"
    ],
    "answer": 0,
    "explanation": "EFS lifecycle management automatically transitions infrequently accessed files to EFS IA, lowering cost while keeping the same file system interface.",
    "difficulty": "Hard"
  },
  {
    "id": "SAA-373",
    "domainId": "D1",
    "domain": "Design Secure Architectures",
    "section": "IAM",
    "question": "A company must allow a third-party auditor to review CloudWatch logs and CloudTrail events in a dedicated audit account without giving write permissions. The auditor should not need long-term access keys. Which solution will meet these requirements with the LEAST operational overhead?",
    "choices": [
      "Attach AdministratorAccess to an auditor IAM user to avoid missing permissions",
      "Create an IAM user in the audit account and email the access keys to the auditor",
      "Create a root user in the audit account and enable MFA, then share the credentials",
      "Create an IAM role in the audit account and allow the auditor’s AWS account to assume it with read-only permissions"
    ],
    "answer": 3,
    "explanation": "Cross-account role assumption is the standard pattern for third-party access without distributing long-term keys. You can scope the role to read-only access.",
    "difficulty": "Hard"
  },
  {
    "id": "SAA-374",
    "domainId": "D2",
    "domain": "Design Resilient Architectures",
    "section": "Route 53",
    "question": "A company runs active-passive endpoints in two Regions. If the primary endpoint fails health checks, traffic must move to standby automatically, then return to primary when healthy. Which solution should be used?",
    "choices": [
      "CloudFront geo restriction",
      "Route 53 failover routing with health checks",
      "Route 53 weighted routing without health checks",
      "An ALB spanning both Regions"
    ],
    "answer": 1,
    "explanation": "Route 53 failover routing uses health checks to shift traffic to a secondary endpoint when the primary is unhealthy and can restore traffic when it becomes healthy again.",
    "difficulty": "Hard"
  },
  {
    "id": "SAA-375",
    "domainId": "D1",
    "domain": "Design Secure Architectures",
    "section": "ACM",
    "question": "A company has dozens of internet-facing ALBs in multiple accounts. Each ALB requires a publicly trusted TLS certificate with automatic renewal, and operations wants minimal per-application work. Which approach can be used to fulfill this requirement?",
    "choices": [
      "Use AWS Certificate Manager public certificates and validate using DNS in Route 53 hosted zones",
      "Use ACM Private CA so browsers trust certificates automatically",
      "Use OpenSSL on EC2 and copy certificates to each ALB manually",
      "Use self-signed certificates and rotate them quarterly"
    ],
    "answer": 0,
    "explanation": "ACM public certificates are publicly trusted and support managed renewal when DNS validation is kept in place, minimizing operational overhead compared with manual certificate creation and rotation.",
    "difficulty": "Hard"
  },
  {
    "id": "SAA-376",
    "domainId": "D3",
    "domain": "Design High-Performing Architectures",
    "section": "S3",
    "question": "A data lake stores tens of millions of objects in S3 with highly unpredictable access. The team wants automatic cost optimization with millisecond retrieval when accessed and no retrieval fees. Which storage class should be used?",
    "choices": [
      "S3 Standard-IA",
      "S3 Intelligent-Tiering",
      "S3 One Zone-IA",
      "S3 Glacier Instant Retrieval"
    ],
    "answer": 1,
    "explanation": "S3 Intelligent-Tiering automatically moves objects between access tiers based on usage patterns while maintaining millisecond retrieval and avoiding retrieval fees for access tiers.",
    "difficulty": "Hard"
  },
  {
    "id": "SAA-377",
    "domainId": "D4",
    "domain": "Design Cost-Optimized Architectures",
    "section": "Cost Management",
    "question": "Finance wants to categorize AWS costs by project and department for detailed cost tracking. What is the BEST approach?",
    "choices": [
      "Use AWS Budgets to set spending limits per project",
      "Create separate AWS accounts for each project",
      "Use cost allocation tags and enable them in the Billing console",
      "Export billing data to S3 and use Athena for analysis"
    ],
    "answer": 2,
    "explanation": "Cost allocation tags allow you to categorize and track AWS costs by project, department, or any custom dimension. After applying tags to resources and enabling them in the Billing console, you can view costs broken down by tag in Cost Explorer and billing reports.",
    "difficulty": "Hard"
  },
  {
    "id": "SAA-378",
    "domainId": "D1",
    "domain": "Design Secure Architectures",
    "section": "Networking",
    "question": "A global company has two VPCs in different AWS Regions: one for HR and one for Finance. The departments must be able to access each other’s resources. Security also mandates in-line inspection to actively block malicious traffic patterns between the VPCs. Which network architecture design should the Solutions Architect set up to satisfy these requirements?",
    "choices": [
      "Create Amazon Route 53 traffic policies between the VPCs and enable Route 53 Resolver DNS Firewall to inspect and block inter-VPC traffic",
      "Connect the VPCs using VPC peering across Regions, then use security groups to inspect and block vulnerability exploits in transit",
      "Deploy an AWS Transit Gateway with inter-Region peering, attach both VPCs, and use AWS Network Firewall in a dedicated inspection VPC to enforce in-line traffic inspection and blocking",
      "Build an AWS Direct Connect Gateway with VPC associations, then enable AWS Security Hub to inspect and block traffic between the VPCs"
    ],
    "answer": 2,
    "explanation": "Transit Gateway supports scalable hub-and-spoke connectivity, including inter-Region TGW peering. AWS Network Firewall provides stateful, in-line inspection and blocking. Route 53/DNS Firewall is DNS-focused, Security Hub is posture management, and security groups are not an IPS for in-line inspection.",
    "difficulty": "Hard"
  },
  {
    "id": "SAA-379",
    "domainId": "D2",
    "domain": "Design Resilient Architectures",
    "section": "S3",
    "question": "A company stores critical documents in Amazon S3 in us-east-1. The compliance team requires that the same data exist in eu-west-1 for disaster recovery. Only objects under the prefix legal/ should replicate, and replicated objects must remain encrypted using SSE-KMS with a destination KMS key. Which solution best meets these requirements with the LEAST operational overhead?",
    "choices": [
      "Enable S3 Transfer Acceleration on both buckets and configure a bucket policy to copy new objects to the destination bucket automatically",
      "Enable S3 Cross-Region Replication with a replication rule filtered to legal/, keep versioning enabled, and update the destination KMS key policy to allow the replication role to encrypt with the destination key",
      "Create a Lambda function triggered by S3 events to copy objects across Regions and use KMS decrypt/encrypt calls inside the function for each object",
      "Run a nightly AWS DataSync task to move objects from the source bucket to the destination bucket and enable default encryption on the destination"
    ],
    "answer": 1,
    "explanation": "CRR supports prefix filters, requires versioning, and works with SSE-KMS when the destination key policy allows the replication role to encrypt. It is the lowest-ops native solution compared with custom Lambda or scheduled copy jobs.",
    "difficulty": "Hard"
  },
  {
    "id": "SAA-380",
    "domainId": "D3",
    "domain": "Design High-Performing Architectures",
    "section": "ECS",
    "question": "A company runs an internal API on Amazon ECS using the Fargate launch type behind an ALB. During deployments, traffic spikes and some containers are terminated while still handling requests, causing a burst of 5xx errors. The team wants a solution that reduces deployment errors without changing application code. Which approach should the Solutions Architect recommend?",
    "choices": [
      "Configure ECS service deployment to use a higher desired count and enable deployment circuit breaker with automatic rollback, ensuring tasks are drained properly before termination",
      "Switch from ALB to NLB so that connections are preserved and tasks are never terminated during deployments",
      "Enable S3 static website hosting for the API endpoints and route traffic through CloudFront to avoid container termination issues",
      "Move the API to Lambda@Edge so scaling is global and deployments never cause any 5xx responses"
    ],
    "answer": 0,
    "explanation": "ECS deployment settings (including deployment configuration and circuit breaker) help reduce failed deployments and roll back automatically. Proper draining/health checks and controlled deployment behavior mitigate 5xx spikes without changing code.",
    "difficulty": "Hard"
  },
  {
    "id": "SAA-381",
    "domainId": "D4",
    "domain": "Design Cost-Optimized Architectures",
    "section": "EC2 Pricing",
    "question": "A data processing workload runs 24/7 on EC2 and is expected to remain steady for at least 2 years. The company wants to reduce compute cost but must be able to change instance families if needed later. Which purchasing option provides the best balance of savings and flexibility?",
    "choices": [
      "Purchase Standard Reserved Instances for a specific instance family and size for 2 years to maximize discount",
      "Use Spot Instances for the entire workload and rely on instance interruption handling for cost savings",
      "Use Compute Savings Plans to cover the baseline usage while retaining flexibility across instance families and Regions",
      "Use Dedicated Hosts so the workload qualifies for the biggest discount while keeping full flexibility"
    ],
    "answer": 2,
    "explanation": "Compute Savings Plans provide discounts for steady usage while remaining flexible across instance families, sizes, and Regions compared with Standard RIs. Spot is risky for 24/7 steady workloads, and Dedicated Hosts are for compliance/licensing needs, not general cost optimization.",
    "difficulty": "Hard"
  },
  {
    "id": "SAA-382",
    "domainId": "D2",
    "domain": "Design Resilient Architectures",
    "section": "Route 53",
    "question": "A company has an application deployed in two Regions. Users should normally go to the closest Region, but if one Region becomes unhealthy, all traffic must fail over to the healthy Region automatically. Which Route 53 configuration best meets the requirements?",
    "choices": [
      "Geolocation routing so users are forced to specific Regions based on country and never fail over automatically",
      "Weighted routing set to 50/50 so both Regions receive traffic equally, and remove health checks to avoid DNS flapping",
      "Latency-based routing combined with health checks on both endpoints to route to the lowest-latency healthy Region",
      "Multi-Value Answer routing with a long TTL so clients cache answers and reduce Route 53 query costs"
    ],
    "answer": 2,
    "explanation": "Latency-based routing directs users to the lowest-latency endpoint and, with health checks, removes unhealthy endpoints from DNS responses for automatic failover behavior.",
    "difficulty": "Hard"
  },
  {
    "id": "SAA-383",
    "domainId": "D1",
    "domain": "Design Secure Architectures",
    "section": "IAM",
    "question": "A company wants developers to access production resources only through federated SSO and must avoid long-term IAM user access keys. Access should be granted temporarily and audited. Which approach best satisfies these requirements with the LEAST operational overhead?",
    "choices": [
      "Create IAM users for each developer and rotate access keys every 30 days using an internal script",
      "Use IAM roles with AWS IAM Identity Center (AWS SSO) so developers obtain short-lived credentials through federation",
      "Store AWS access keys in AWS Secrets Manager and issue them to developers only when needed",
      "Share a single IAM user among all developers and enforce MFA to prevent misuse"
    ],
    "answer": 1,
    "explanation": "Identity Center (SSO) with IAM roles provides federated access with temporary credentials and centralized auditing. It eliminates long-term keys and reduces operational burden compared with rotating user keys.",
    "difficulty": "Hard"
  },
  {
    "id": "SAA-384",
    "domainId": "D3",
    "domain": "Design High-Performing Architectures",
    "section": "CloudFront",
    "question": "A company serves large downloadable files globally from an S3 origin behind CloudFront. Security requires that only paid subscribers can download files, and the access mechanism must work even if the S3 bucket is private. Which solution will meet these requirements?",
    "choices": [
      "Use Route 53 weighted routing to send subscribers to a different S3 bucket",
      "Enable S3 Transfer Acceleration and require users to authenticate with IAM user access keys",
      "Use CloudFront signed URLs or signed cookies and restrict S3 access to CloudFront using an origin access control (OAC) or similar mechanism",
      "Make the S3 bucket public-read and rely on application-side authentication only"
    ],
    "answer": 2,
    "explanation": "Signed URLs/cookies enforce viewer authorization at CloudFront, and OAC/OAI-style access ensures the S3 bucket remains private and only CloudFront can fetch objects.",
    "difficulty": "Hard"
  },
  {
    "id": "SAA-385",
    "domainId": "D2",
    "domain": "Design Resilient Architectures",
    "section": "SQS",
    "question": "A payment pipeline uses standard SQS and a Lambda consumer. The business now requires strict ordering for events per customer and exactly-once processing semantics to avoid double-charging. Which solution best meets the requirement with minimal redesign?",
    "choices": [
      "Keep the standard queue and increase the visibility timeout so messages are processed only once",
      "Migrate to an SQS FIFO queue and use Message Group IDs per customer along with deduplication",
      "Use Kinesis Data Firehose to deliver data into S3 and process it from there in order",
      "Use an SNS standard topic to broadcast messages and rely on retries for ordering"
    ],
    "answer": 1,
    "explanation": "SQS FIFO supports ordering and deduplication features (exactly-once processing semantics within FIFO constraints), and Message Group IDs maintain ordering per customer.",
    "difficulty": "Hard"
  },
  {
    "id": "SAA-386",
    "domainId": "D1",
    "domain": "Design Secure Architectures",
    "section": "Network Firewall",
    "question": "A company centralizes outbound internet access from multiple VPCs using a shared egress VPC. Security now requires stateful inspection, domain-based allow/deny controls, and centralized logging for all egress traffic. Which solution should be implemented?",
    "choices": [
      "Enable VPC Flow Logs and block domains by adding route table blackhole entries",
      "Deploy AWS Network Firewall in the egress VPC and route traffic through firewall endpoints with centralized logging",
      "Attach AWS WAF to the NAT Gateway so it can inspect and block outbound requests",
      "Use security groups with outbound rules to inspect and block domain names at Layer 7"
    ],
    "answer": 1,
    "explanation": "AWS Network Firewall provides stateful inspection and filtering with centralized logging for VPC traffic. Security groups and WAF don’t provide the required in-line egress inspection for arbitrary outbound traffic.",
    "difficulty": "Hard"
  },
  {
    "id": "SAA-388",
    "domainId": "D3",
    "domain": "Design High-Performing Architectures",
    "section": "S3",
    "question": "Which S3 feature allows uploading large objects by splitting them into parts that can be retried independently?",
    "choices": [
      "S3 Inventory",
      "S3 Multipart Upload",
      "S3 Event Notifications",
      "S3 Object Lock"
    ],
    "answer": 1,
    "explanation": "Multipart Upload breaks an object into parts, enabling parallel upload and independent retries.",
    "difficulty": "Easy"
  },
  {
    "id": "SAA-389",
    "domainId": "D2",
    "domain": "Design Resilient Architectures",
    "section": "ELB",
    "question": "Which AWS service distributes incoming HTTP/HTTPS traffic across targets and supports path-based routing?",
    "choices": [
      "Gateway Load Balancer",
      "AWS Direct Connect",
      "Network Load Balancer",
      "Application Load Balancer"
    ],
    "answer": 3,
    "explanation": "An Application Load Balancer operates at Layer 7 and supports routing features like path-based rules.",
    "difficulty": "Easy"
  },
  {
    "id": "SAA-390",
    "domainId": "D4",
    "domain": "Design Cost-Optimized Architectures",
    "section": "EC2 Pricing",
    "question": "Which EC2 pricing model provides the biggest discounts but can be interrupted with little notice?",
    "choices": [
      "Spot Instances",
      "On-Demand Instances",
      "Dedicated Hosts",
      "Reserved Instances"
    ],
    "answer": 0,
    "explanation": "Spot Instances offer deep discounts but can be interrupted when AWS needs the capacity back.",
    "difficulty": "Easy"
  },
  {
    "id": "SAA-391",
    "domainId": "D1",
    "domain": "Design Secure Architectures",
    "section": "IAM",
    "question": "A company wants to ensure that IAM users cannot accidentally expose their AWS credentials in application code. What is the AWS best practice for granting applications running on EC2 instances access to AWS services?",
    "choices": [
      "Store IAM user access keys in environment variables on the EC2 instance",
      "Attach an IAM role to the EC2 instance",
      "Embed access keys directly in the application code",
      "Share a single set of IAM user credentials across all EC2 instances"
    ],
    "answer": 1,
    "explanation": "IAM roles provide temporary credentials to EC2 instances without requiring long-term access keys, following AWS security best practices.",
    "difficulty": "Easy"
  },
  {
    "id": "SAA-392",
    "domainId": "D1",
    "domain": "Design Secure Architectures",
    "section": "KMS",
    "question": "A company needs to encrypt data at rest in an Amazon S3 bucket. Which AWS service should they use to manage the encryption keys?",
    "choices": [
      "AWS Systems Manager",
      "AWS Secrets Manager",
      "AWS Certificate Manager",
      "AWS Key Management Service (KMS)"
    ],
    "answer": 3,
    "explanation": "AWS KMS is specifically designed for creating and managing cryptographic keys for encryption, including S3 server-side encryption.",
    "difficulty": "Easy"
  },
  {
    "id": "SAA-393",
    "domainId": "D1",
    "domain": "Design Secure Architectures",
    "section": "Security Groups",
    "question": "A developer needs to allow inbound SSH access to an EC2 instance only from their company's office IP address. Which AWS feature should they configure?",
    "choices": [
      "Network ACL with a deny rule for all other IPs",
      "Security group with an inbound rule allowing port 22 from the office IP",
      "IAM policy restricting SSH access",
      "VPC route table entry"
    ],
    "answer": 1,
    "explanation": "Security groups act as virtual firewalls and can restrict inbound SSH (port 22) access to specific IP addresses.",
    "difficulty": "Easy"
  },
  {
    "id": "SAA-394",
    "domainId": "D2",
    "domain": "Design Resilient Architectures",
    "section": "Multi-AZ",
    "question": "A company wants to ensure their RDS database remains available if an Availability Zone fails. What feature should they enable?",
    "choices": [
      "RDS Read Replicas",
      "Multi-AZ deployment",
      "RDS snapshots",
      "Enhanced monitoring"
    ],
    "answer": 1,
    "explanation": "Multi-AZ deployment automatically provisions and maintains a synchronous standby replica in a different AZ for high availability and automatic failover.",
    "difficulty": "Easy"
  },
  {
    "id": "SAA-395",
    "domainId": "D2",
    "domain": "Design Resilient Architectures",
    "section": "ELB",
    "question": "An application running on multiple EC2 instances needs to distribute incoming traffic evenly across all healthy instances. Which AWS service should be used?",
    "choices": [
      "Amazon Route 53",
      "AWS Auto Scaling",
      "Elastic Load Balancer",
      "Amazon CloudFront"
    ],
    "answer": 2,
    "explanation": "Elastic Load Balancer automatically distributes incoming application traffic across multiple targets and performs health checks.",
    "difficulty": "Easy"
  },
  {
    "id": "SAA-396",
    "domainId": "D3",
    "domain": "Design High-Performing Architectures",
    "section": "CloudFront",
    "question": "A company serves static content to users worldwide and wants to reduce latency for global users. Which AWS service should they use?",
    "choices": [
      "AWS Global Accelerator",
      "Amazon Route 53",
      "Amazon CloudFront",
      "Amazon S3 Transfer Acceleration"
    ],
    "answer": 2,
    "explanation": "CloudFront is a CDN that caches content at edge locations worldwide, reducing latency for global users accessing static content.",
    "difficulty": "Easy"
  },
  {
    "id": "SAA-397",
    "domainId": "D3",
    "domain": "Design High-Performing Architectures",
    "section": "ElastiCache",
    "question": "An application frequently reads the same data from a relational database, causing high database load. Which service can help reduce database read load by caching frequently accessed data?",
    "choices": [
      "Amazon ElastiCache",
      "Amazon DynamoDB",
      "AWS Lambda",
      "Amazon SQS"
    ],
    "answer": 0,
    "explanation": "ElastiCache provides in-memory caching (Redis or Memcached) to store frequently accessed data, reducing database read operations.",
    "difficulty": "Easy"
  },
  {
    "id": "SAA-398",
    "domainId": "D3",
    "domain": "Design High-Performing Architectures",
    "section": "EBS",
    "question": "A database application requires consistent low-latency disk performance with high IOPS. Which EBS volume type is best suited for this workload?",
    "choices": [
      "EBS Provisioned IOPS SSD (io2)",
      "EBS Throughput Optimized HDD (st1)",
      "EBS Cold HDD (sc1)",
      "EBS General Purpose SSD (gp3)"
    ],
    "answer": 0,
    "explanation": "Provisioned IOPS SSD volumes are designed for I/O intensive workloads requiring sustained high IOPS and consistent low-latency performance.",
    "difficulty": "Easy"
  },
  {
    "id": "SAA-399",
    "domainId": "D4",
    "domain": "Design Cost-Optimized Architectures",
    "section": "S3",
    "question": "A company has log files in S3 that are frequently accessed for 30 days, then rarely accessed but must be retained for compliance. Which approach optimizes storage costs?",
    "choices": [
      "Keep all logs in S3 Standard indefinitely",
      "Use S3 Lifecycle policies to transition logs to S3 Glacier after 30 days",
      "Delete logs after 30 days and recreate them if needed",
      "Move logs to EBS volumes after 30 days"
    ],
    "answer": 1,
    "explanation": "S3 Lifecycle policies can automatically transition objects to lower-cost storage classes like Glacier for long-term archival, reducing costs while maintaining compliance.",
    "difficulty": "Easy"
  },
  {
    "id": "SAA-400",
    "domainId": "D4",
    "domain": "Design Cost-Optimized Architectures",
    "section": "EC2 Pricing",
    "question": "A company runs batch processing jobs that can be interrupted and resumed without issues. Which EC2 pricing model would be most cost-effective?",
    "choices": [
      "On-Demand Instances",
      "Reserved Instances",
      "Spot Instances",
      "Dedicated Hosts"
    ],
    "answer": 2,
    "explanation": "Spot Instances offer up to 90% discount compared to On-Demand pricing and are ideal for fault-tolerant, flexible workloads that can handle interruptions.",
    "difficulty": "Easy"
  },
  {
    "id": "SAA-401",
    "domainId": "D1",
    "domain": "Design Secure Architectures",
    "section": "IAM",
    "question": "A company needs to grant a third-party vendor temporary access to specific S3 buckets in their AWS account for auditing purposes. The vendor has their own AWS account and should not require long-term credentials. The solution must follow the principle of least privilege and allow the company to revoke access at any time.\nWhat is the MOST secure approach?",
    "choices": [
      "Create an IAM user with programmatic access in the company's account and share the access keys with the vendor via encrypted email",
      "Configure an IAM role with a trust policy allowing the vendor's AWS account to assume it, with permissions scoped to only the required S3 buckets",
      "Enable public access on the S3 buckets and provide the vendor with pre-signed URLs that expire after 24 hours",
      "Create an IAM group with the necessary S3 permissions and add the vendor's IAM users to the group using cross-account IAM group membership"
    ],
    "answer": 1,
    "explanation": "Cross-account IAM roles with trust policies allow secure temporary access without sharing long-term credentials. The company maintains control and can modify or revoke the role at any time. Pre-signed URLs are time-limited but don't provide the same level of control, and sharing access keys violates security best practices. Cross-account IAM group membership is not supported in AWS.",
    "difficulty": "Medium"
  },
  {
    "id": "SAA-402",
    "domainId": "D1",
    "domain": "Design Secure Architectures",
    "section": "VPC",
    "question": "An application running in a private subnet needs to access Amazon S3 and DynamoDB without traversing the public internet, while also preventing any internet-bound traffic from the instances. The security team requires that all network traffic remain within the AWS network.\nWhich combination of VPC components achieves this requirement with the LEAST operational overhead?",
    "choices": [
      "Deploy NAT Gateway in a public subnet and configure route tables to route S3 and DynamoDB traffic through the NAT Gateway",
      "Create VPC endpoints for S3 (Gateway endpoint) and DynamoDB (Gateway endpoint) and update route tables accordingly",
      "Establish AWS Direct Connect to route all traffic through the corporate data center firewall before reaching AWS services",
      "Deploy AWS PrivateLink endpoints for both S3 and DynamoDB in each private subnet"
    ],
    "answer": 1,
    "explanation": "Gateway VPC endpoints for S3 and DynamoDB allow private connectivity without internet access and incur no additional charges. NAT Gateway would route traffic through the internet and incurs costs. Direct Connect is unnecessary for AWS service access and adds complexity. While PrivateLink works for many services, S3 and DynamoDB use Gateway endpoints which are simpler and more cost-effective.",
    "difficulty": "Medium"
  },
  {
    "id": "SAA-403",
    "domainId": "D1",
    "domain": "Design Secure Architectures",
    "section": "KMS",
    "question": "A financial services company must encrypt all data at rest in their RDS database and S3 buckets using customer-managed keys. They need to implement automatic key rotation annually and maintain an audit trail of all key usage. Compliance requirements mandate that the company must be able to immediately revoke access to encrypted data if a security breach is detected.\nWhich solution meets all these requirements?",
    "choices": [
      "Use AWS KMS customer managed keys (CMK) with automatic key rotation enabled, CloudTrail logging, and key policies that allow immediate key disablement",
      "Use S3 and RDS default encryption with AWS managed keys and rely on service-level access controls",
      "Implement client-side encryption using keys stored in AWS Secrets Manager with custom rotation Lambda functions",
      "Use AWS KMS with imported key material and manually rotate keys annually using custom scripts"
    ],
    "answer": 0,
    "explanation": "AWS KMS customer managed keys support automatic annual rotation, integrate with CloudTrail for audit logging, and can be immediately disabled via key policies to revoke access. AWS managed keys don't allow immediate disabling by customers. Client-side encryption adds complexity and doesn't integrate as seamlessly. Imported key material requires manual rotation and doesn't support automatic rotation.",
    "difficulty": "Medium"
  },
  {
    "id": "SAA-404",
    "domainId": "D2",
    "domain": "Design Resilient Architectures",
    "section": "Route 53",
    "question": "A global e-commerce application is deployed in both us-east-1 and eu-west-1 regions. The company needs to implement automatic failover to the secondary region if the primary region becomes unavailable, with a Recovery Time Objective (RTO) of less than 1 minute. Health checks must validate application functionality, not just endpoint availability.\nWhat is the MOST appropriate Route 53 configuration?",
    "choices": [
      "Configure Route 53 geolocation routing policy to route users to the nearest region based on their geographic location",
      "Use Route 53 weighted routing policy with 100% traffic to the primary region and 0% to secondary, manually updating weights during failover",
      "Implement Route 53 failover routing policy with health checks configured to monitor application-specific endpoints in each region",
      "Deploy Route 53 latency-based routing to automatically direct users to the lowest latency region"
    ],
    "answer": 2,
    "explanation": "Failover routing with application-level health checks provides automatic failover based on application health, not just network latency or geography. Health checks can be configured to test application functionality (HTTP status, response time) to ensure true availability. Geolocation and latency-based routing don't provide automatic failover. Weighted routing requires manual intervention, failing to meet the RTO requirement.",
    "difficulty": "Medium"
  },
  {
    "id": "SAA-405",
    "domainId": "D2",
    "domain": "Design Resilient Architectures",
    "section": "Backup",
    "question": "A company runs critical databases on Amazon RDS and EC2 instances with attached EBS volumes across multiple Availability Zones. They need a backup strategy that provides cross-region disaster recovery with a Recovery Point Objective (RPO) of 15 minutes and centralized backup management and compliance reporting.\nWhich solution best meets these requirements?",
    "choices": [
      "Create manual EBS snapshots and RDS snapshots every 15 minutes using CloudWatch Events and Lambda, then copy snapshots to a secondary region",
      "Use AWS Backup to create backup plans with 15-minute backup frequency, enable cross-region copy, and use AWS Backup Vault Lock for compliance",
      "Configure RDS automated backups with 15-minute backup windows and use custom scripts to replicate EBS volumes to another region",
      "Implement third-party backup software on EC2 instances to manage all backups and replicate data to S3 in another region"
    ],
    "answer": 1,
    "explanation": "AWS Backup provides centralized backup management across RDS and EBS with policy-based backup plans, automated cross-region copy, and compliance reporting through Backup Vault Lock. It supports the 15-minute RPO requirement and reduces operational overhead. Manual snapshots with Lambda require custom development and lack centralized management. RDS automated backups don't support 15-minute RPO. Third-party solutions add cost and complexity.",
    "difficulty": "Medium"
  },
  {
    "id": "SAA-406",
    "domainId": "D3",
    "domain": "Design High-Performing Architectures",
    "section": "RDS/Aurora",
    "question": "An online analytics platform experiences read-heavy database workloads with millions of queries per day. The application requires sub-10ms read latency for frequently accessed data and can tolerate slightly stale data (up to 30 seconds old) for read queries. The database is currently running on RDS MySQL and experiencing performance bottlenecks during peak hours.\nWhat combination of services would BEST improve read performance while minimizing infrastructure changes?",
    "choices": [
      "Migrate to Amazon Aurora and add up to 15 Aurora read replicas to distribute read traffic",
      "Implement Amazon ElastiCache for Redis in front of the RDS database to cache frequent queries, with a TTL of 30 seconds",
      "Vertically scale the RDS instance to a larger instance type with more CPU and memory resources",
      "Create multiple RDS read replicas and use Route 53 weighted routing to distribute queries across replicas"
    ],
    "answer": 1,
    "explanation": "ElastiCache for Redis provides sub-millisecond read latency for cached data and is ideal for read-heavy workloads with tolerable data staleness. The 30-second TTL matches the application's tolerance. While Aurora read replicas improve scalability, they still involve database queries with higher latency than cache. Vertical scaling has limits and doesn't address the read-heavy pattern. RDS read replicas help but don't provide the sub-10ms latency that cache delivers.",
    "difficulty": "Medium"
  },
  {
    "id": "SAA-407",
    "domainId": "D3",
    "domain": "Design High-Performing Architectures",
    "section": "CloudFront",
    "question": "A media streaming company serves video content to users globally from an S3 bucket in us-east-1. Users in Asia and Europe experience high latency and buffering issues. The company needs to reduce latency for global users while minimizing data transfer costs from S3. Video files are large (500MB-2GB) and content is updated weekly.\nWhat is the MOST cost-effective solution to improve performance?",
    "choices": [
      "Enable S3 Transfer Acceleration to speed up uploads and downloads for global users accessing the S3 bucket directly",
      "Create additional S3 buckets in ap-southeast-1 and eu-west-1 regions and use Route 53 geolocation routing to direct users to the nearest bucket",
      "Configure Amazon CloudFront distribution with the S3 bucket as the origin, enabling caching at edge locations worldwide",
      "Deploy an Application Load Balancer in each region with EC2 instances that stream content from the S3 bucket"
    ],
    "answer": 2,
    "explanation": "CloudFront caches content at edge locations globally, providing low-latency access for users worldwide and reducing S3 data transfer costs since cached content is served from edge locations. Transfer Acceleration helps with uploads but not the primary use case of downloads. Multiple S3 buckets require replication costs and complexity. ALB with EC2 adds unnecessary infrastructure costs and complexity compared to CloudFront's managed CDN.",
    "difficulty": "Medium"
  },
  {
    "id": "SAA-408",
    "domainId": "D3",
    "domain": "Design High-Performing Architectures",
    "section": "DynamoDB",
    "question": "An IoT application writes sensor data from 100,000 devices every second to a DynamoDB table. Each write is approximately 1KB in size. The application experiences throttling errors during peak traffic periods. The data has a time-series pattern where recent data (last 7 days) is frequently queried, while older data is rarely accessed but must be retained for 2 years for compliance.\nWhich solution provides the MOST cost-effective performance improvement?",
    "choices": [
      "Increase provisioned write capacity units (WCUs) to handle peak load and enable DynamoDB auto scaling",
      "Switch to DynamoDB on-demand pricing mode to automatically handle variable workload patterns",
      "Implement DynamoDB write sharding using multiple partition keys and use DynamoDB Time to Live (TTL) to archive old data to S3",
      "Partition data by time range into separate tables (daily tables) and use DynamoDB global tables for replication"
    ],
    "answer": 2,
    "explanation": "Write sharding distributes writes across multiple partitions to avoid hot partition throttling, while TTL automatically archives old data to reduce storage costs. This addresses both performance and cost optimization. On-demand mode is more expensive for predictable high-volume workloads. Simply increasing WCUs is costly and doesn't optimize for the time-series access pattern. Daily tables add operational complexity and don't address the core throttling issue.",
    "difficulty": "Medium"
  },
  {
    "id": "SAA-409",
    "domainId": "D4",
    "domain": "Design Cost-Optimized Architectures",
    "section": "S3",
    "question": "A data analytics company stores 500TB of raw log data in S3 Standard. Analysis shows that 80% of the data is accessed only during the first 30 days after upload, 15% is accessed occasionally between 30-90 days, and 5% is rarely accessed after 90 days but must be retained for 7 years for compliance. Objects vary in size from 1KB to 100MB.\nWhich S3 storage strategy provides the GREATEST cost savings while meeting access requirements?",
    "choices": [
      "Use S3 Intelligent-Tiering for all objects to automatically move data between access tiers based on usage patterns",
      "Implement S3 Lifecycle policies to transition objects to S3 Standard-IA after 30 days, S3 Glacier Flexible Retrieval after 90 days, and S3 Glacier Deep Archive after 1 year",
      "Store all data in S3 One Zone-IA to reduce costs with acceptable availability for log data",
      "Migrate all data to S3 Glacier Flexible Retrieval immediately and use expedited retrieval when access is needed"
    ],
    "answer": 1,
    "explanation": "Lifecycle policies with tiered transitions match the described access patterns precisely, maximizing cost savings. Standard for 30 days handles frequent access, Standard-IA for occasional access (30-90 days), and Glacier tiers for long-term archival provide the lowest cost. Intelligent-Tiering has monitoring fees that may not be cost-effective for predictable patterns. One Zone-IA doesn't optimize for the multi-phase access pattern. Immediate Glacier storage prevents efficient access during the first 30 days when data is frequently used.",
    "difficulty": "Medium"
  },
  {
    "id": "SAA-410",
    "domainId": "D4",
    "domain": "Design Cost-Optimized Architectures",
    "section": "EC2 Pricing",
    "question": "A company runs a web application on EC2 instances that experiences predictable traffic patterns: baseline load requires 10 instances 24/7, with peak periods (4 hours daily during business hours) requiring 50 additional instances. The application has been running for over a year with consistent patterns and will continue for at least 2 more years. The company wants to minimize compute costs.\nWhat EC2 purchasing strategy provides the LOWEST cost?",
    "choices": [
      "Purchase 60 Reserved Instances with 1-year all upfront payment to cover maximum load",
      "Use 10 Reserved Instances for baseline load with 3-year all upfront payment, and On-Demand Instances for peak load",
      "Purchase 10 Reserved Instances for baseline with 3-year all upfront payment, and use Spot Instances with On-Demand as fallback for peak load",
      "Use 60 Spot Instances for all workload with On-Demand instances as fallback when Spot is unavailable"
    ],
    "answer": 2,
    "explanation": "Combining Reserved Instances for predictable baseline load (maximum discount with 3-year all upfront) with Spot Instances for flexible peak load provides optimal cost savings. Spot Instances can save up to 90% for interruptible workloads, with On-Demand as fallback ensures availability. Reserving 60 instances wastes money on idle capacity. Using only RIs with On-Demand for peaks misses Spot savings. Full Spot usage risks availability for baseline workload that requires 24/7 operation.",
    "difficulty": "Medium"
  },
  {
    "id": "SAA-411",
    "domainId": "D1",
    "domain": "Design Secure Architectures",
    "section": "Organizations",
    "question": "A large financial services corporation operates over 200 AWS accounts across multiple business units. The company must enforce strict compliance requirements including: mandatory encryption for all S3 buckets and RDS instances, prevent any account from disabling CloudTrail logging, restrict deployment to only approved AWS regions (us-east-1, us-west-2, eu-west-1), and maintain centralized audit logging. The security team needs to implement these controls with minimal ongoing operational overhead while allowing individual teams autonomy for their application deployments.\nWhich solution BEST meets all these requirements?",
    "choices": [
      "Implement AWS Config rules in each account with AWS Lambda remediation functions, use CloudFormation StackSets to deploy the rules across all accounts, and configure Amazon EventBridge to centralize audit logs in a master account.",
      "Use AWS Organizations with Service Control Policies (SCPs) to enforce encryption, CloudTrail, and region restrictions at the organizational unit level, enable AWS Control Tower for governance, and configure AWS CloudTrail Organization Trail for centralized logging.",
      "Deploy AWS Systems Manager State Manager across all accounts to enforce compliance configurations, use AWS Config Conformance Packs to validate requirements, and replicate CloudTrail logs to a central S3 bucket using cross-account replication.",
      "Create IAM policies in each account restricting user permissions, implement AWS Security Hub to monitor compliance, use Amazon GuardDuty for threat detection, and manually audit CloudTrail logs quarterly."
    ],
    "answer": 1,
    "explanation": "AWS Organizations with SCPs provides centralized, preventive controls that cannot be overridden by individual accounts, making them ideal for mandatory compliance requirements. Control Tower automates best practice guardrails and account provisioning. Organization Trail automatically aggregates CloudTrail logs from all accounts with minimal overhead. Config rules are detective controls requiring remediation rather than prevention. Systems Manager requires agents and ongoing management. Manual IAM policies in each account lack centralization and are prone to configuration drift.",
    "difficulty": "Hard"
  },
  {
    "id": "SAA-412",
    "domainId": "D1",
    "domain": "Design Secure Architectures",
    "section": "VPC",
    "question": "A healthcare technology company runs HIPAA-compliant applications across three VPCs in the same region: a shared services VPC with Active Directory and monitoring tools, a production VPC with patient data processing applications, and a development VPC. The company needs to enable private connectivity between all VPCs while ensuring: traffic between development and production VPCs is completely blocked, all inter-VPC traffic must be inspected by a centralized firewall for compliance logging, the solution must support adding 20 more VPCs over the next year without re-architecting, and minimize data transfer costs between VPCs.\nWhich architecture would BEST satisfy these requirements?",
    "choices": [
      "Create VPC peering connections between each VPC pair, configure route tables to prevent development-production routing, deploy AWS Network Firewall in each VPC, and use VPC Flow Logs for compliance logging.",
      "Implement AWS Transit Gateway with separate route tables for production and development environments, deploy AWS Network Firewall in an inspection VPC, configure Transit Gateway route tables to route all inter-VPC traffic through the firewall, and enable VPC Flow Logs.",
      "Use AWS PrivateLink to create endpoint services in each VPC, implement Network Load Balancers for routing, deploy third-party firewall appliances in each VPC, and centralize logs using CloudWatch Logs.",
      "Deploy a hub-and-spoke architecture with VPN connections, place firewall appliances in the hub VPC, use static routing to control traffic flow, and configure Security Groups to block development-production traffic."
    ],
    "answer": 1,
    "explanation": "Transit Gateway with separate route tables provides scalable VPC connectivity with centralized routing control, easily accommodating future VPC additions. The inspection VPC architecture allows all inter-VPC traffic to be routed through AWS Network Firewall for centralized inspection and logging while maintaining network segmentation. Transit Gateway supports thousands of VPCs and reduces data transfer costs compared to VPC peering. VPC peering doesn't scale well and can't provide centralized traffic inspection without complex routing. PrivateLink is designed for service exposure, not general VPC connectivity. VPN connections add latency and complexity for intra-region communication.",
    "difficulty": "Hard"
  },
  {
    "id": "SAA-413",
    "domainId": "D1",
    "domain": "Design Secure Architectures",
    "section": "KMS",
    "question": "A multinational corporation processes sensitive financial data in AWS across multiple regions (us-east-1, eu-west-1, ap-southeast-1). Regulatory requirements mandate that: encryption keys must be managed by the customer with the ability to immediately revoke access, all cryptographic operations must be performed in FIPS 140-2 Level 3 validated hardware security modules, encryption keys for EU data must never leave the EU region due to GDPR, the company must maintain complete audit trails of all key usage, and the solution must support automatic key rotation. The company is currently using AWS managed keys and needs to migrate to a compliant solution.\nWhich solution would NOT be suitable for meeting these requirements?",
    "choices": [
      "Implement AWS KMS with customer managed keys in each region, enable automatic key rotation, use CloudTrail for audit logging, create key policies allowing immediate disablement, and configure cross-region encrypted snapshots using regional KMS keys.",
      "Deploy AWS CloudHSM clusters in each region with FIPS 140-2 Level 3 validated HSMs, implement custom key management using CloudHSM client SDK, configure CloudTrail for audit logging, and build custom key rotation logic using Lambda functions.",
      "Use AWS KMS with imported key material from an on-premises HSM, configure regional KMS keys for each geography, enable CloudTrail logging, manually rotate keys by importing new key material periodically, and use key policies for access control.",
      "Continue using AWS managed keys but enable CloudTrail logging, implement AWS Config rules to monitor key usage, use Service Control Policies to restrict key access, and configure AWS Backup to ensure keys are replicated across regions."
    ],
    "answer": 3,
    "explanation": "AWS managed keys do not provide customer control over key management, cannot be immediately disabled by customers, do not support FIPS 140-2 Level 3 (AWS KMS uses Level 2), and cannot meet the requirement for customer-managed keys. Cross-region key replication would violate GDPR data residency requirements. KMS customer managed keys with CloudTrail meet most requirements and support automatic rotation. CloudHSM provides FIPS 140-2 Level 3 compliance and full customer control. Imported key material allows external key management with regional isolation, though rotation is manual.",
    "difficulty": "Hard"
  },
  {
    "id": "SAA-414",
    "domainId": "D2",
    "domain": "Design Resilient Architectures",
    "section": "DR",
    "question": "A SaaS platform provider hosts a business-critical application processing real-time financial transactions in us-east-1. The application uses a three-tier architecture with Application Load Balancer, Amazon ECS on EC2 for compute, and Amazon Aurora PostgreSQL for the database. The company's disaster recovery requirements specify: Recovery Time Objective (RTO) of 5 minutes, Recovery Point Objective (RPO) of 30 seconds, the DR solution must be in a different AWS region (us-west-2), the solution must support automated failover without manual intervention, and minimize infrastructure costs during normal operations while maintaining DR readiness.\nWhich disaster recovery strategy would BEST meet these requirements?",
    "choices": [
      "Configure Aurora Global Database with us-east-1 as primary and us-west-2 as secondary region, use AWS Global Accelerator for automatic traffic routing during failover, maintain warm standby ECS cluster in us-west-2 with 25% capacity, and use Auto Scaling to scale up during failover.",
      "Implement Aurora read replicas in us-west-2, use Route 53 health checks with failover routing policy, deploy full production capacity ECS cluster in us-west-2 as hot standby, and configure automated database promotion scripts using Lambda.",
      "Deploy pilot light architecture with Aurora snapshots replicated to us-west-2 every 30 minutes, use CloudFormation templates to rebuild infrastructure during disaster, implement Route 53 failover routing, and maintain AMIs of application servers in both regions.",
      "Use AWS Backup to copy Aurora backups to us-west-2 daily, maintain infrastructure-as-code templates for quick deployment, implement manual failover procedures documented in runbooks, and use Route 53 to manually redirect traffic during disaster."
    ],
    "answer": 0,
    "explanation": "Aurora Global Database provides sub-second data replication to meet the 30-second RPO and supports automated failover capabilities. Global Accelerator provides automatic traffic redirection based on health checks. The warm standby approach with 25% capacity balances cost optimization with the ability to meet 5-minute RTO through auto-scaling. Full hot standby exceeds requirements and doubles infrastructure costs unnecessarily. Pilot light with 30-minute snapshots cannot meet the 30-second RPO, and infrastructure rebuild would exceed 5-minute RTO. Daily backups and manual procedures fail both RTO and RPO requirements and lack automation.",
    "difficulty": "Hard"
  },
  {
    "id": "SAA-415",
    "domainId": "D2",
    "domain": "Design Resilient Architectures",
    "section": "Auto Scaling",
    "question": "An e-learning platform experiences highly variable traffic patterns: baseline load of 100 concurrent users growing to 10,000 users during scheduled class sessions (known 24 hours in advance), plus unpredictable traffic spikes of up to 5,000 users when popular courses launch. The application runs on EC2 instances behind an Application Load Balancer. The company needs a scaling solution that: responds within 60 seconds to unpredictable spikes, minimizes costs during low-usage periods, pre-warms capacity for scheduled sessions to ensure performance, maintains exactly 2 instances minimum for high availability, and avoids over-provisioning during predictable events.\nWhich combination of Auto Scaling configurations would MOST effectively meet these requirements?",
    "choices": [
      "Use target tracking scaling policy based on ALB request count per target with 60-second evaluation periods, configure scheduled scaling actions for known class sessions, set minimum capacity to 2 instances, and enable predictive scaling with 24-hour forecasting.",
      "Implement step scaling policies with CloudWatch alarms on CPU utilization at 60-second intervals, use scheduled scaling for class sessions, configure warm pool with pre-initialized instances, set minimum capacity to 2, and enable instance protection on baseline instances.",
      "Deploy simple scaling policy based on ALB target response time, create scheduled scaling actions for class sessions with 15-minute warmup, maintain minimum 2 instances, enable mixed instances policy with Spot and On-Demand, and use lifecycle hooks for health checks.",
      "Use AWS Application Auto Scaling with custom CloudWatch metrics measuring concurrent users, implement scheduled scaling with predictive scaling override, configure minimum 2 instances, enable capacity rebalancing for mixed instance types, and use cooldown periods of 120 seconds."
    ],
    "answer": 0,
    "explanation": "Target tracking scaling policy provides fast, responsive scaling based on ALB request count per target, which directly correlates with user load and can respond within 60 seconds. Scheduled scaling handles known class sessions efficiently without over-provisioning. Predictive scaling with 24-hour forecasting learns traffic patterns to optimize capacity for scheduled events. The minimum capacity of 2 ensures high availability. Step scaling with CPU may not respond fast enough to rapid user growth. Simple scaling based on response time is reactive rather than proactive. Custom metrics add complexity and may have delayed responses compared to ALB metrics.",
    "difficulty": "Hard"
  },
  {
    "id": "SAA-416",
    "domainId": "D3",
    "domain": "Design High-Performing Architectures",
    "section": "FSx",
    "question": "A visual effects studio is migrating their render farm to AWS for processing high-resolution video content. The workload requires a parallel file system that can: deliver sustained throughput of 10 GB/s for reading source video files, support concurrent access from 500 EC2 instances running rendering software, provide sub-millisecond latencies for metadata operations, persist data long-term (multi-year retention) for completed projects, integrate with their existing on-premises NFS storage for active project files during migration, and minimize storage costs for archived completed projects.\nWhich storage solution would BEST meet all these requirements?",
    "choices": [
      "Deploy Amazon FSx for Lustre with Persistent file system deployment type, configure data repository association with S3 for long-term storage, enable automatic export of completed renders to S3 Glacier Deep Archive using lifecycle policies, and use AWS DataSync for on-premises integration.",
      "Implement Amazon EFS with Max I/O performance mode and Elastic throughput, configure EFS-to-EFS replication for disaster recovery, use EFS Lifecycle Management to transition infrequently accessed files to Infrequent Access storage class, and connect on-premises storage via AWS Direct Connect with NFS mounts.",
      "Use Amazon FSx for NetApp ONTAP with Multi-AZ deployment, configure FlexCache for performance optimization, implement SnapMirror for on-premises replication, use cloud tiering to S3 for archive storage, and enable NFS protocol for compatibility.",
      "Deploy Amazon File Cache with on-premises NFS as the data source, use Amazon S3 with S3 Glacier for archival, configure multiple cache instances for scale, and access cache via NFS from EC2 rendering instances."
    ],
    "answer": 0,
    "explanation": "FSx for Lustre is purpose-built for high-performance computing workloads and can easily deliver 10+ GB/s throughput with sub-millisecond latencies. Persistent deployment type ensures data durability for long-term storage. Data repository association with S3 enables seamless archiving to Glacier for cost optimization. AWS DataSync provides efficient data transfer from on-premises NFS during migration. EFS Max I/O doesn't provide the extreme performance levels required for HPC rendering workloads. FSx for NetApp ONTAP is designed for enterprise file shares, not HPC parallel file systems. Amazon File Cache is designed for temporary caching scenarios, not long-term data persistence and retention.",
    "difficulty": "Hard"
  },
  {
    "id": "SAA-417",
    "domainId": "D3",
    "domain": "Design High-Performing Architectures",
    "section": "DynamoDB",
    "question": "A global gaming company operates a leaderboard system that must handle: 50,000 writes per second during peak gaming hours (4 hours daily), 500,000 reads per second for real-time leaderboard queries globally, single-digit millisecond read latencies in all geographic regions, the ability to perform complex queries ranking players by multiple attributes (score, level, region), strong consistency for write operations to prevent score manipulation, and minimize database costs during off-peak hours (20 hours daily with 10% of peak traffic).\nWhich database architecture would MOST cost-effectively meet these performance requirements?",
    "choices": [
      "Use Amazon DynamoDB with on-demand capacity mode, implement DynamoDB Global Tables for multi-region deployment, create Global Secondary Indexes for ranking queries, enable DynamoDB Accelerator (DAX) for read caching in each region, and use strongly consistent reads.",
      "Deploy Amazon Aurora Global Database with write forwarding enabled, implement read replicas in five regions, use Aurora's auto-scaling for capacity management, create indexes for ranking queries, and enable Aurora's query cache for frequently accessed leaderboards.",
      "Implement DynamoDB with provisioned capacity mode and auto-scaling, deploy Global Tables across regions, use ElastiCache for Redis in front of DynamoDB for read caching, implement sorted sets in Redis for ranking operations, and use DynamoDB Streams for cache invalidation.",
      "Use Amazon DocumentDB with global clusters, implement custom sharding logic for write distribution, deploy read replicas globally, create compound indexes for ranking, and use Amazon ElastiCache for Memcached for read optimization."
    ],
    "answer": 2,
    "explanation": "DynamoDB provisioned capacity with auto-scaling is more cost-effective than on-demand for predictable traffic patterns with 20 hours of low usage. Global Tables provide multi-region replication with strong consistency. ElastiCache for Redis with sorted sets is specifically designed for leaderboard use cases and can handle complex ranking queries efficiently while reducing DynamoDB read load. DynamoDB Streams enables real-time cache updates. On-demand mode would be more expensive given the predictable traffic pattern. Aurora cannot match DynamoDB's write scalability of 50K writes/second without significant over-provisioning. DocumentDB lacks the extreme scalability and global distribution capabilities required for this use case.",
    "difficulty": "Hard"
  },
  {
    "id": "SAA-418",
    "domainId": "D3",
    "domain": "Design High-Performing Architectures",
    "section": "ECS",
    "question": "A fintech startup is building a microservices-based trading platform that must meet the following requirements: deploy 50+ containerized microservices with independent scaling policies, support blue/green deployments with automated rollback on failures, maintain service mesh capabilities for inter-service communication and observability, ensure developers can deploy supplemental infrastructure components (caches, queues) alongside their services, auto-scale container tasks based on custom business metrics (trades per second), and minimize operational overhead for infrastructure management while maintaining control over service configurations.\nWhich solution would BEST address these requirements?",
    "choices": [
      "Deploy containers using Amazon ECS on AWS Fargate with Application Load Balancer, implement AWS App Mesh for service mesh, use AWS CodeDeploy for blue/green deployments, configure Auto Scaling using CloudWatch custom metrics for trades per second, and enable ECS Service Discovery.",
      "Use Amazon Elastic Kubernetes Service (EKS) with managed node groups, implement Istio service mesh, configure Argo Rollouts for progressive delivery, use Horizontal Pod Autoscaler with custom metrics from CloudWatch Container Insights, and deploy Helm charts for infrastructure components.",
      "Implement AWS Proton for standardized service templates, deploy containers on ECS with EC2 launch type, use AWS App Mesh for service communication, configure CodeDeploy for deployment automation, enable ECS Auto Scaling with target tracking policies, and allow developers to add components through Proton.",
      "Deploy Amazon EKS Anywhere on EC2 instances for full control, use Linkerd for service mesh, implement Flux for GitOps-based deployments, configure custom autoscaling with KEDA using trading metrics, and use Kubernetes operators for infrastructure provisioning."
    ],
    "answer": 2,
    "explanation": "AWS Proton is specifically designed to enable standardized infrastructure templates while allowing developers to add supplemental components, directly addressing the requirement for infrastructure flexibility. ECS with App Mesh provides service mesh capabilities with less operational overhead than Kubernetes. CodeDeploy supports blue/green deployments with automatic rollback. ECS Auto Scaling integrates well with CloudWatch custom metrics. While EKS with Istio is powerful, it adds significant operational complexity compared to the managed Proton approach. ECS on Fargate lacks the component extensibility that Proton provides. EKS Anywhere on EC2 maximizes operational overhead rather than minimizing it.",
    "difficulty": "Hard"
  },
  {
    "id": "SAA-419",
    "domainId": "D4",
    "domain": "Design Cost-Optimized Architectures",
    "section": "Compute",
    "question": "A data analytics company runs three distinct compute workloads on AWS: batch data processing jobs that run nightly for 6 hours (interruptible, can restart from checkpoints), a web application requiring 20 instances continuously (24/7 with consistent load), and machine learning training jobs that run unpredictably 2-3 times per week for 12-hour periods (stateful, cannot be interrupted). The company has committed to AWS for the next 3 years and wants to minimize total compute costs while ensuring workload reliability. Current spend is $150,000 annually using all On-Demand instances.\nWhich EC2 purchasing strategy would provide the GREATEST cost savings while meeting workload requirements?",
    "choices": [
      "Purchase 20 Standard 3-year Reserved Instances with all-upfront payment for web application, use Spot Instances with Spot Fleet for batch processing with automatic fallback to On-Demand, and use On-Demand Instances for ML training jobs to ensure completion.",
      "Buy 20 Convertible 3-year Reserved Instances for web servers, use Spot Instances with maximum price limit for batch jobs, purchase 3-year Compute Savings Plans to cover ML training at any instance type, and use Spot block instances for predictable 12-hour ML sessions.",
      "Implement 20 Standard 3-year Reserved Instances with all-upfront for web tier, use EC2 Spot Instances with checkpointing for batch processing, use On-Demand Instances for ML training, and purchase EC2 Instance Savings Plans (3-year) to cover unexpected ML compute needs.",
      "Use Compute Savings Plans (3-year) to cover baseline web application instances, supplement with On-Demand during any unexpected growth, use Spot Fleet with diversified instance types for batch processing, and use Reserved Instances for ML training workloads based on historical usage patterns."
    ],
    "answer": 0,
    "explanation": "Standard 3-year RIs with all-upfront provide maximum discount (up to 72%) for the predictable 24/7 web workload. Spot Instances are ideal for interruptible batch jobs and offer up to 90% savings with checkpoint recovery. ML training's unpredictable schedule and stateful nature makes On-Demand most reliable despite higher cost, but represents small portion of total compute. Convertible RIs are more expensive than Standard for known stable workloads. Spot blocks are deprecated. Compute Savings Plans are less optimal than Standard RIs when instance requirements are well-defined. Reserved Instances for unpredictable ML workloads risk underutilization and waste.",
    "difficulty": "Hard"
  },
  {
    "id": "SAA-420",
    "domainId": "D4",
    "domain": "Design Cost-Optimized Architectures",
    "section": "S3",
    "question": "A media company stores 5 PB of video content in Amazon S3 with the following access patterns: new uploads are frequently accessed for transcoding and initial editing (first 7 days), videos are occasionally accessed for re-editing between 7-90 days, content older than 90 days is rarely accessed but must be available within 12 hours when needed, videos must be retained for 10 years for licensing compliance, object sizes range from 100 MB to 50 GB, and the company receives frequent requests to retrieve videos uploaded 2-3 years ago. Monthly storage costs are currently $120,000 using S3 Standard for all content.\nWhich storage optimization strategy would provide the GREATEST cost reduction while meeting access requirements?",
    "choices": [
      "Implement S3 Intelligent-Tiering for all objects to automatically optimize storage costs based on access patterns, configure Archive Instant Access tier for objects not accessed in 90 days, and use S3 Lifecycle policies to delete objects after 10 years.",
      "Use S3 Lifecycle policies to transition objects to S3 Standard-IA after 7 days, transition to S3 Glacier Flexible Retrieval after 90 days, transition to S3 Glacier Deep Archive after 1 year, and configure retrieval expedited mode for urgent access needs.",
      "Store new uploads in S3 Standard, use lifecycle policies to move to S3 One Zone-IA after 7 days, transition to S3 Intelligent-Tiering after 90 days, move to S3 Glacier Deep Archive after 2 years, and restore to S3 Standard when accessed.",
      "Keep objects in S3 Standard for 7 days, transition to S3 Standard-IA for 7-90 days, move to S3 Glacier Instant Retrieval after 90 days for frequently requested archived content, transition to S3 Glacier Deep Archive after 3 years for final long-term archival."
    ],
    "answer": 3,
    "explanation": "This strategy optimizes for the specific access patterns: S3 Standard for active use (7 days), Standard-IA for occasional access (7-90 days at lower cost), Glacier Instant Retrieval for archived content with frequent retrieval needs (provides millisecond access matching the 2-3 year retrieval pattern), and Deep Archive for truly cold data (lowest cost at $1/TB/month). Intelligent-Tiering has monitoring fees that may exceed savings for predictable patterns, and Archive Instant Access doesn't provide the immediate retrieval needed. Glacier Flexible Retrieval's 12-hour retrieval meets requirements but costs more than Instant Retrieval given frequent access to 2-3 year old content. One Zone-IA lacks durability guarantees needed for 10-year retention requirements.",
    "difficulty": "Hard"
  },
  {
    "id": "SAA-421",
    "domainId": "D1",
    "domain": "Design Secure Architectures",
    "section": "IAM",
    "question": "Which AWS service allows you to create and manage user permissions and access to AWS resources?",
    "choices": [
      "AWS Organizations",
      "AWS IAM",
      "AWS Directory Service",
      "AWS Single Sign-On"
    ],
    "answer": 1,
    "explanation": "AWS IAM (Identity and Access Management) is the service used to create and manage user permissions and access control for AWS resources.",
    "difficulty": "Easy"
  },
  {
    "id": "SAA-422",
    "domainId": "D1",
    "domain": "Design Secure Architectures",
    "section": "S3",
    "question": "Which S3 feature should be enabled to prevent accidental deletion of objects?",
    "choices": [
      "S3 Versioning",
      "S3 Replication",
      "S3 Transfer Acceleration",
      "S3 Inventory"
    ],
    "answer": 0,
    "explanation": "S3 Versioning preserves multiple versions of an object, allowing recovery from accidental deletions or overwrites.",
    "difficulty": "Easy"
  },
  {
    "id": "SAA-423",
    "domainId": "D1",
    "domain": "Design Secure Architectures",
    "section": "VPC",
    "question": "What AWS service provides a logically isolated section of the AWS Cloud where you can launch resources in a virtual network?",
    "choices": [
      "AWS Direct Connect",
      "Amazon VPC",
      "AWS Transit Gateway",
      "AWS PrivateLink"
    ],
    "answer": 1,
    "explanation": "Amazon VPC (Virtual Private Cloud) provides an isolated virtual network environment within AWS where you can launch and manage resources.",
    "difficulty": "Easy"
  },
  {
    "id": "SAA-424",
    "domainId": "D1",
    "domain": "Design Secure Architectures",
    "section": "CloudTrail",
    "question": "Which AWS service records API calls made in your AWS account for auditing and compliance?",
    "choices": [
      "AWS Config",
      "Amazon CloudWatch",
      "AWS CloudTrail",
      "AWS X-Ray"
    ],
    "answer": 2,
    "explanation": "AWS CloudTrail records all API calls and actions in your AWS account, providing an audit trail for security analysis and compliance.",
    "difficulty": "Easy"
  },
  {
    "id": "SAA-425",
    "domainId": "D1",
    "domain": "Design Secure Architectures",
    "section": "KMS",
    "question": "What is the purpose of AWS KMS?",
    "choices": [
      "To monitor application performance",
      "To create and manage encryption keys",
      "To manage user identities",
      "To distribute content globally"
    ],
    "answer": 1,
    "explanation": "AWS KMS (Key Management Service) is used to create and control encryption keys for securing data.",
    "difficulty": "Easy"
  },
  {
    "id": "SAA-426",
    "domainId": "D1",
    "domain": "Design Secure Architectures",
    "section": "Secrets Manager",
    "question": "Which service helps you rotate, manage, and retrieve database credentials, API keys, and other secrets?",
    "choices": [
      "AWS Secrets Manager",
      "AWS Systems Manager Parameter Store",
      "AWS KMS",
      "AWS Certificate Manager"
    ],
    "answer": 0,
    "explanation": "AWS Secrets Manager helps manage, rotate, and retrieve secrets like database credentials and API keys with automatic rotation capabilities.",
    "difficulty": "Easy"
  },
  {
    "id": "SAA-427",
    "domainId": "D1",
    "domain": "Design Secure Architectures",
    "section": "WAF",
    "question": "Which AWS service protects web applications from common web exploits like SQL injection and cross-site scripting?",
    "choices": [
      "AWS Shield",
      "AWS WAF",
      "AWS GuardDuty",
      "Amazon Inspector"
    ],
    "answer": 1,
    "explanation": "AWS WAF (Web Application Firewall) protects web applications from common web exploits and attacks at the application layer.",
    "difficulty": "Easy"
  },
  {
    "id": "SAA-428",
    "domainId": "D1",
    "domain": "Design Secure Architectures",
    "section": "Security Groups",
    "question": "What type of firewall is a security group in AWS?",
    "choices": [
      "Network-level firewall",
      "Stateful firewall at the instance level",
      "Stateless firewall at the subnet level",
      "Application-level firewall"
    ],
    "answer": 1,
    "explanation": "Security groups act as stateful firewalls at the EC2 instance level, controlling inbound and outbound traffic.",
    "difficulty": "Easy"
  },
  {
    "id": "SAA-429",
    "domainId": "D1",
    "domain": "Design Secure Architectures",
    "section": "IAM",
    "question": "What is an IAM policy?",
    "choices": [
      "A JSON document that defines permissions",
      "A user authentication mechanism",
      "A network access control list",
      "An encryption key"
    ],
    "answer": 0,
    "explanation": "An IAM policy is a JSON document that explicitly defines permissions for users, groups, or roles to access AWS resources.",
    "difficulty": "Easy"
  },
  {
    "id": "SAA-430",
    "domainId": "D1",
    "domain": "Design Secure Architectures",
    "section": "S3",
    "question": "Which S3 feature encrypts data at rest using server-side encryption?",
    "choices": [
      "S3 SSE (Server-Side Encryption)",
      "S3 CRR (Cross-Region Replication)",
      "S3 Transfer Acceleration",
      "S3 Intelligent-Tiering"
    ],
    "answer": 0,
    "explanation": "S3 Server-Side Encryption (SSE) automatically encrypts objects at rest in S3 buckets using various key management options.",
    "difficulty": "Easy"
  },
  {
    "id": "SAA-431",
    "domainId": "D1",
    "domain": "Design Secure Architectures",
    "section": "VPC",
    "question": "What component allows private subnet instances to access the internet without exposing their private IP addresses?",
    "choices": [
      "Internet Gateway",
      "NAT Gateway",
      "VPC Peering",
      "VPN Connection"
    ],
    "answer": 1,
    "explanation": "A NAT Gateway enables instances in private subnets to initiate outbound internet traffic while preventing inbound connections from the internet.",
    "difficulty": "Easy"
  },
  {
    "id": "SAA-432",
    "domainId": "D1",
    "domain": "Design Secure Architectures",
    "section": "IAM",
    "question": "What is the AWS best practice for granting permissions to applications running on EC2 instances?",
    "choices": [
      "Embed access keys in the application code",
      "Use IAM roles attached to the EC2 instance",
      "Store credentials in a configuration file on the instance",
      "Use root account credentials"
    ],
    "answer": 1,
    "explanation": "IAM roles provide temporary security credentials to EC2 instances without requiring long-term access keys, following security best practices.",
    "difficulty": "Easy"
  },
  {
    "id": "SAA-433",
    "domainId": "D1",
    "domain": "Design Secure Architectures",
    "section": "GuardDuty",
    "question": "Which AWS service provides intelligent threat detection by analyzing VPC Flow Logs, CloudTrail logs, and DNS logs?",
    "choices": [
      "Amazon Inspector",
      "AWS GuardDuty",
      "AWS Security Hub",
      "AWS Macie"
    ],
    "answer": 1,
    "explanation": "AWS GuardDuty is a threat detection service that continuously monitors and analyzes AWS account activity and network traffic for malicious behavior.",
    "difficulty": "Easy"
  },
  {
    "id": "SAA-434",
    "domainId": "D1",
    "domain": "Design Secure Architectures",
    "section": "IAM",
    "question": "A company needs to grant temporary access to AWS resources for users from a corporate directory. They also want to ensure users can access multiple AWS services with a single set of credentials. Which TWO AWS services should they use together? (Choose TWO.)",
    "choices": [
      "AWS IAM Identity Center (formerly AWS SSO)",
      "AWS Directory Service",
      "AWS Cognito",
      "AWS Organizations",
      "AWS KMS"
    ],
    "answer": [
      0,
      1
    ],
    "explanation": "AWS IAM Identity Center provides single sign-on access to multiple AWS accounts and applications. AWS Directory Service integrates with corporate directories like Active Directory to enable centralized user management and authentication.",
    "difficulty": "Easy"
  },
  {
    "id": "SAA-435",
    "domainId": "D2",
    "domain": "Design Resilient Architectures",
    "section": "ELB",
    "question": "Which type of load balancer operates at the application layer (Layer 7) and can route requests based on content?",
    "choices": [
      "Network Load Balancer",
      "Application Load Balancer",
      "Classic Load Balancer",
      "Gateway Load Balancer"
    ],
    "answer": 1,
    "explanation": "Application Load Balancer operates at Layer 7 and can route HTTP/HTTPS traffic based on URL paths, hostnames, and other request content.",
    "difficulty": "Easy"
  },
  {
    "id": "SAA-436",
    "domainId": "D2",
    "domain": "Design Resilient Architectures",
    "section": "RDS",
    "question": "What RDS feature automatically replicates your database to a standby instance in a different Availability Zone?",
    "choices": [
      "Read Replicas",
      "Multi-AZ deployment",
      "Automated backups",
      "Database snapshots"
    ],
    "answer": 1,
    "explanation": "Multi-AZ deployment automatically maintains a synchronous standby replica in another AZ, providing high availability and automatic failover.",
    "difficulty": "Easy"
  },
  {
    "id": "SAA-437",
    "domainId": "D2",
    "domain": "Design Resilient Architectures",
    "section": "S3",
    "question": "Which S3 storage class is designed for long-term archival with retrieval times of hours?",
    "choices": [
      "S3 Standard",
      "S3 Standard-IA",
      "S3 Glacier Flexible Retrieval",
      "S3 One Zone-IA"
    ],
    "answer": 2,
    "explanation": "S3 Glacier Flexible Retrieval (formerly S3 Glacier) is designed for long-term archive storage with retrieval times ranging from minutes to hours.",
    "difficulty": "Easy"
  },
  {
    "id": "SAA-438",
    "domainId": "D2",
    "domain": "Design Resilient Architectures",
    "section": "Route 53",
    "question": "Which Route 53 routing policy routes traffic to multiple resources and returns all healthy resource records?",
    "choices": [
      "Simple routing",
      "Weighted routing",
      "Multivalue answer routing",
      "Failover routing"
    ],
    "answer": 2,
    "explanation": "Multivalue answer routing returns multiple healthy IP addresses for a query, allowing Route 53 to perform basic load distribution and health checking.",
    "difficulty": "Easy"
  },
  {
    "id": "SAA-439",
    "domainId": "D2",
    "domain": "Design Resilient Architectures",
    "section": "Auto Scaling",
    "question": "What is the primary benefit of using Auto Scaling groups?",
    "choices": [
      "Reduces costs by using smaller instances",
      "Automatically adjusts capacity to maintain performance and availability",
      "Provides faster network connectivity",
      "Encrypts data at rest"
    ],
    "answer": 1,
    "explanation": "Auto Scaling automatically adjusts the number of EC2 instances based on demand, maintaining application performance and availability while optimizing costs.",
    "difficulty": "Easy"
  },
  {
    "id": "SAA-440",
    "domainId": "D2",
    "domain": "Design Resilient Architectures",
    "section": "SQS",
    "question": "Which AWS service provides a fully managed message queuing service for decoupling application components?",
    "choices": [
      "Amazon SNS",
      "Amazon SQS",
      "Amazon Kinesis",
      "AWS Step Functions"
    ],
    "answer": 1,
    "explanation": "Amazon SQS (Simple Queue Service) is a fully managed message queue service that enables decoupling and scaling of distributed systems.",
    "difficulty": "Easy"
  },
  {
    "id": "SAA-441",
    "domainId": "D2",
    "domain": "Design Resilient Architectures",
    "section": "CloudFront",
    "question": "What is the primary purpose of Amazon CloudFront?",
    "choices": [
      "Database replication",
      "Content delivery network (CDN)",
      "Server monitoring",
      "Identity management"
    ],
    "answer": 1,
    "explanation": "Amazon CloudFront is a CDN service that delivers content to users with low latency by caching at edge locations worldwide.",
    "difficulty": "Easy"
  },
  {
    "id": "SAA-442",
    "domainId": "D2",
    "domain": "Design Resilient Architectures",
    "section": "ELB",
    "question": "Which load balancer type is best suited for routing TCP traffic with ultra-high performance and low latency?",
    "choices": [
      "Application Load Balancer",
      "Classic Load Balancer",
      "Network Load Balancer",
      "Gateway Load Balancer"
    ],
    "answer": 2,
    "explanation": "Network Load Balancer operates at Layer 4 (TCP) and can handle millions of requests per second with ultra-low latency.",
    "difficulty": "Easy"
  },
  {
    "id": "SAA-443",
    "domainId": "D2",
    "domain": "Design Resilient Architectures",
    "section": "RDS",
    "question": "What is the primary technical benefit of using RDS Read Replicas?",
    "choices": [
      "Automatic failover for high availability",
      "Offload read traffic from the primary database to improve performance",
      "Enable cross-region disaster recovery",
      "Reduce storage costs by sharing data"
    ],
    "answer": 1,
    "explanation": "RDS Read Replicas offload read traffic from the primary database, improving overall performance for read-heavy workloads. They use asynchronous replication and are primarily used for scaling read operations, not for automatic failover (which requires Multi-AZ).",
    "difficulty": "Easy"
  },
  {
    "id": "SAA-444",
    "domainId": "D2",
    "domain": "Design Resilient Architectures",
    "section": "S3",
    "question": "Which feature automatically replicates S3 objects to a different AWS region?",
    "choices": [
      "S3 Versioning",
      "S3 Cross-Region Replication (CRR)",
      "S3 Lifecycle policies",
      "S3 Transfer Acceleration"
    ],
    "answer": 1,
    "explanation": "S3 Cross-Region Replication automatically copies objects across S3 buckets in different AWS regions for disaster recovery and compliance.",
    "difficulty": "Easy"
  },
  {
    "id": "SAA-445",
    "domainId": "D2",
    "domain": "Design Resilient Architectures",
    "section": "SNS",
    "question": "What type of messaging pattern does Amazon SNS provide?",
    "choices": [
      "Point-to-point",
      "Publish-subscribe",
      "Request-response",
      "Peer-to-peer"
    ],
    "answer": 1,
    "explanation": "Amazon SNS (Simple Notification Service) follows a publish-subscribe pattern, allowing messages to be sent to multiple subscribers.",
    "difficulty": "Easy"
  },
  {
    "id": "SAA-446",
    "domainId": "D2",
    "domain": "Design Resilient Architectures",
    "section": "Lambda",
    "question": "What is AWS Lambda primarily used for?",
    "choices": [
      "Running containerized applications",
      "Running serverless code in response to events",
      "Managing virtual machines",
      "Creating VPN connections"
    ],
    "answer": 1,
    "explanation": "AWS Lambda is a serverless compute service that runs code in response to events without provisioning or managing servers.",
    "difficulty": "Easy"
  },
  {
    "id": "SAA-447",
    "domainId": "D2",
    "domain": "Design Resilient Architectures",
    "section": "EBS",
    "question": "What happens to data on an instance store volume when an EC2 instance is stopped or terminated?",
    "choices": [
      "Data persists and can be reattached",
      "Data is lost",
      "Data is automatically backed up to S3",
      "Data is moved to EBS"
    ],
    "answer": 1,
    "explanation": "Instance store volumes provide temporary block-level storage that is lost when the instance is stopped or terminated.",
    "difficulty": "Easy"
  },
  {
    "id": "SAA-448",
    "domainId": "D2",
    "domain": "Design Resilient Architectures",
    "section": "Route 53",
    "question": "A web application needs high availability across multiple regions. The application should automatically route traffic to healthy endpoints and minimize downtime during failures. Which TWO Route 53 features should be used? (Choose TWO.)",
    "choices": [
      "Health checks",
      "Failover routing policy",
      "Private hosted zones",
      "DNSSEC",
      "Alias records for S3 buckets"
    ],
    "answer": [
      0,
      1
    ],
    "explanation": "Route 53 health checks monitor endpoint health, and failover routing automatically redirects traffic to healthy resources when primary endpoints fail, ensuring high availability.",
    "difficulty": "Easy"
  },
  {
    "id": "SAA-449",
    "domainId": "D3",
    "domain": "Design High-Performing Architectures",
    "section": "ElastiCache",
    "question": "Which AWS service provides in-memory caching to improve application performance?",
    "choices": [
      "Amazon RDS",
      "Amazon ElastiCache",
      "Amazon DynamoDB",
      "Amazon Aurora"
    ],
    "answer": 1,
    "explanation": "Amazon ElastiCache provides in-memory caching using Redis or Memcached to improve application performance by reducing database load.",
    "difficulty": "Easy"
  },
  {
    "id": "SAA-450",
    "domainId": "D3",
    "domain": "Design High-Performing Architectures",
    "section": "EBS",
    "question": "Which EBS volume type provides the highest IOPS performance for mission-critical applications?",
    "choices": [
      "General Purpose SSD (gp3)",
      "Provisioned IOPS SSD (io2)",
      "Throughput Optimized HDD (st1)",
      "Cold HDD (sc1)"
    ],
    "answer": 1,
    "explanation": "Provisioned IOPS SSD (io2/io1) volumes deliver the highest performance with up to 64,000 IOPS for I/O intensive workloads.",
    "difficulty": "Easy"
  },
  {
    "id": "SAA-451",
    "domainId": "D3",
    "domain": "Design High-Performing Architectures",
    "section": "CloudFront",
    "question": "How does CloudFront improve content delivery performance?",
    "choices": [
      "By increasing server capacity",
      "By caching content at edge locations closer to users",
      "By compressing all files",
      "By upgrading network bandwidth"
    ],
    "answer": 1,
    "explanation": "CloudFront caches content at edge locations around the world, reducing latency by serving content from locations closest to end users.",
    "difficulty": "Easy"
  },
  {
    "id": "SAA-452",
    "domainId": "D3",
    "domain": "Design High-Performing Architectures",
    "section": "DynamoDB",
    "question": "What type of database is Amazon DynamoDB?",
    "choices": [
      "Relational database",
      "NoSQL key-value and document database",
      "Graph database",
      "Time-series database"
    ],
    "answer": 1,
    "explanation": "DynamoDB is a fully managed NoSQL database that provides fast and predictable performance with seamless scalability.",
    "difficulty": "Easy"
  },
  {
    "id": "SAA-453",
    "domainId": "D3",
    "domain": "Design High-Performing Architectures",
    "section": "Aurora",
    "question": "What is Amazon Aurora?",
    "choices": [
      "A NoSQL database service",
      "A MySQL and PostgreSQL-compatible relational database",
      "A data warehouse service",
      "A caching service"
    ],
    "answer": 1,
    "explanation": "Amazon Aurora is a MySQL and PostgreSQL-compatible relational database that offers high performance and availability with cloud-native architecture.",
    "difficulty": "Easy"
  },
  {
    "id": "SAA-454",
    "domainId": "D3",
    "domain": "Design High-Performing Architectures",
    "section": "S3",
    "question": "Which S3 feature accelerates uploads and downloads of large files over long distances?",
    "choices": [
      "S3 Versioning",
      "S3 Transfer Acceleration",
      "S3 Replication",
      "S3 Lifecycle policies"
    ],
    "answer": 1,
    "explanation": "S3 Transfer Acceleration uses CloudFront edge locations to accelerate uploads and downloads of large objects over long distances.",
    "difficulty": "Easy"
  },
  {
    "id": "SAA-455",
    "domainId": "D3",
    "domain": "Design High-Performing Architectures",
    "section": "EBS",
    "question": "What is the advantage of using EBS-optimized instances?",
    "choices": [
      "Lower cost",
      "Dedicated bandwidth for EBS I/O",
      "Larger storage capacity",
      "Automatic backups"
    ],
    "answer": 1,
    "explanation": "EBS-optimized instances provide dedicated network bandwidth for EBS volumes, ensuring consistent I/O performance.",
    "difficulty": "Easy"
  },
  {
    "id": "SAA-456",
    "domainId": "D3",
    "domain": "Design High-Performing Architectures",
    "section": "RDS",
    "question": "Which AWS database service is best for online transaction processing (OLTP) workloads?",
    "choices": [
      "Amazon Redshift",
      "Amazon RDS",
      "Amazon EMR",
      "Amazon Athena"
    ],
    "answer": 1,
    "explanation": "Amazon RDS is optimized for OLTP workloads requiring fast, consistent transaction processing with ACID compliance.",
    "difficulty": "Easy"
  },
  {
    "id": "SAA-457",
    "domainId": "D3",
    "domain": "Design High-Performing Architectures",
    "section": "Lambda",
    "question": "What is the maximum execution time for a single AWS Lambda function?",
    "choices": [
      "5 minutes",
      "15 minutes",
      "30 minutes",
      "1 hour"
    ],
    "answer": 1,
    "explanation": "AWS Lambda functions can run for a maximum of 15 minutes per execution.",
    "difficulty": "Easy"
  },
  {
    "id": "SAA-458",
    "domainId": "D3",
    "domain": "Design High-Performing Architectures",
    "section": "EFS",
    "question": "Which storage service provides a scalable file system that can be mounted by multiple EC2 instances concurrently?",
    "choices": [
      "Amazon EBS",
      "Amazon S3",
      "Amazon EFS",
      "Instance Store"
    ],
    "answer": 2,
    "explanation": "Amazon EFS (Elastic File System) provides a scalable, shared file system that can be mounted by multiple EC2 instances simultaneously.",
    "difficulty": "Easy"
  },
  {
    "id": "SAA-459",
    "domainId": "D3",
    "domain": "Design High-Performing Architectures",
    "section": "DynamoDB",
    "question": "Which DynamoDB feature provides microsecond read latency for frequently accessed data?",
    "choices": [
      "DynamoDB Streams",
      "DynamoDB Accelerator (DAX)",
      "Global Tables",
      "Point-in-time recovery"
    ],
    "answer": 1,
    "explanation": "DynamoDB Accelerator (DAX) is an in-memory cache that provides microsecond response times for read-heavy workloads.",
    "difficulty": "Easy"
  },
  {
    "id": "SAA-460",
    "domainId": "D3",
    "domain": "Design High-Performing Architectures",
    "section": "Global Accelerator",
    "question": "What is the primary benefit of AWS Global Accelerator?",
    "choices": [
      "Reduces storage costs",
      "Improves application availability and performance using the AWS global network",
      "Provides database replication",
      "Manages user authentication"
    ],
    "answer": 1,
    "explanation": "AWS Global Accelerator improves application availability and performance by routing traffic through the AWS global network to optimal endpoints.",
    "difficulty": "Easy"
  },
  {
    "id": "SAA-461",
    "domainId": "D3",
    "domain": "Design High-Performing Architectures",
    "section": "Redshift",
    "question": "Which AWS service is designed for data warehousing and analytics on large datasets?",
    "choices": [
      "Amazon RDS",
      "Amazon DynamoDB",
      "Amazon Redshift",
      "Amazon Aurora"
    ],
    "answer": 2,
    "explanation": "Amazon Redshift is a fast, fully managed data warehouse service designed for analytics on petabyte-scale data.",
    "difficulty": "Easy"
  },
  {
    "id": "SAA-462",
    "domainId": "D3",
    "domain": "Design High-Performing Architectures",
    "section": "CloudFront",
    "question": "A media company needs to deliver video content to users worldwide with low latency. They also want to reduce the load on their origin servers by caching content closer to users. Which TWO AWS services should they use? (Choose TWO.)",
    "choices": [
      "Amazon CloudFront",
      "Amazon S3",
      "AWS Direct Connect",
      "Amazon Route 53",
      "AWS Global Accelerator"
    ],
    "answer": [
      0,
      1
    ],
    "explanation": "CloudFront caches and delivers content from edge locations for low latency. S3 serves as the origin for storing and serving the video content to CloudFront.",
    "difficulty": "Easy"
  },
  {
    "id": "SAA-463",
    "domainId": "D4",
    "domain": "Design Cost-Optimized Architectures",
    "section": "S3",
    "question": "Which S3 storage class offers the lowest storage cost for rarely accessed data?",
    "choices": [
      "S3 Standard",
      "S3 Standard-IA",
      "S3 Glacier Deep Archive",
      "S3 One Zone-IA"
    ],
    "answer": 2,
    "explanation": "S3 Glacier Deep Archive provides the lowest storage cost for long-term archival data that is rarely accessed.",
    "difficulty": "Easy"
  },
  {
    "id": "SAA-464",
    "domainId": "D4",
    "domain": "Design Cost-Optimized Architectures",
    "section": "EC2 Pricing",
    "question": "Which EC2 purchasing option offers the largest discount for workloads with predictable usage?",
    "choices": [
      "On-Demand Instances",
      "Spot Instances",
      "Reserved Instances",
      "Dedicated Hosts"
    ],
    "answer": 2,
    "explanation": "Reserved Instances provide up to 72% discount compared to On-Demand pricing for predictable, steady-state workloads with 1 or 3-year commitments.",
    "difficulty": "Easy"
  },
  {
    "id": "SAA-465",
    "domainId": "D4",
    "domain": "Design Cost-Optimized Architectures",
    "section": "EC2 Pricing",
    "question": "Which EC2 pricing model is best for fault-tolerant workloads that can handle interruptions?",
    "choices": [
      "On-Demand Instances",
      "Reserved Instances",
      "Spot Instances",
      "Savings Plans"
    ],
    "answer": 2,
    "explanation": "Spot Instances offer up to 90% discount but can be interrupted by AWS, making them ideal for fault-tolerant, flexible workloads.",
    "difficulty": "Easy"
  },
  {
    "id": "SAA-466",
    "domainId": "D4",
    "domain": "Design Cost-Optimized Architectures",
    "section": "CloudWatch",
    "question": "Which AWS service helps you monitor and analyze resource utilization to identify cost optimization opportunities?",
    "choices": [
      "AWS Cost Explorer",
      "AWS Budgets",
      "Amazon CloudWatch",
      "AWS Trusted Advisor"
    ],
    "answer": 2,
    "explanation": "Amazon CloudWatch monitors resource utilization metrics, helping identify underutilized resources for cost optimization.",
    "difficulty": "Easy"
  },
  {
    "id": "SAA-467",
    "domainId": "D4",
    "domain": "Design Cost-Optimized Architectures",
    "section": "S3",
    "question": "What S3 feature automatically transitions objects between storage classes based on access patterns?",
    "choices": [
      "S3 Lifecycle policies",
      "S3 Intelligent-Tiering",
      "S3 Object Lock",
      "S3 Versioning"
    ],
    "answer": 1,
    "explanation": "S3 Intelligent-Tiering automatically moves objects between access tiers based on changing access patterns without performance impact or operational overhead. While Lifecycle policies can transition objects, they require manual configuration of rules rather than automatic pattern detection.",
    "difficulty": "Easy"
  },
  {
    "id": "SAA-468",
    "domainId": "D4",
    "domain": "Design Cost-Optimized Architectures",
    "section": "Cost Management",
    "question": "Which AWS tool provides recommendations for cost optimization based on your usage patterns?",
    "choices": [
      "AWS Billing Dashboard",
      "AWS Cost and Usage Report",
      "AWS Trusted Advisor",
      "AWS Price List API"
    ],
    "answer": 2,
    "explanation": "AWS Trusted Advisor provides cost optimization recommendations including idle resources, Reserved Instance opportunities, and right-sizing suggestions.",
    "difficulty": "Easy"
  },
  {
    "id": "SAA-469",
    "domainId": "D4",
    "domain": "Design Cost-Optimized Architectures",
    "section": "Auto Scaling",
    "question": "How does Auto Scaling help with cost optimization?",
    "choices": [
      "By using cheaper instance types",
      "By automatically adjusting capacity based on demand",
      "By negotiating better pricing with AWS",
      "By consolidating workloads"
    ],
    "answer": 1,
    "explanation": "Auto Scaling automatically adds or removes instances based on demand, ensuring you only pay for the capacity you need.",
    "difficulty": "Easy"
  },
  {
    "id": "SAA-470",
    "domainId": "D4",
    "domain": "Design Cost-Optimized Architectures",
    "section": "EBS",
    "question": "Which EBS volume type provides the lowest cost per GB for throughput-intensive workloads?",
    "choices": [
      "General Purpose SSD (gp3)",
      "Provisioned IOPS SSD (io2)",
      "Throughput Optimized HDD (st1)",
      "Cold HDD (sc1)"
    ],
    "answer": 2,
    "explanation": "Throughput Optimized HDD (st1) provides low-cost magnetic storage designed for frequently accessed, throughput-intensive workloads.",
    "difficulty": "Easy"
  },
  {
    "id": "SAA-471",
    "domainId": "D4",
    "domain": "Design Cost-Optimized Architectures",
    "section": "RDS",
    "question": "What RDS feature can help reduce costs for development and test environments?",
    "choices": [
      "Multi-AZ deployment",
      "Automated backups",
      "Stop and start DB instances",
      "Encryption at rest"
    ],
    "answer": 2,
    "explanation": "Stopping RDS instances when not in use (e.g., during non-business hours for dev/test) reduces costs as you only pay for storage, not compute.",
    "difficulty": "Easy"
  },
  {
    "id": "SAA-472",
    "domainId": "D4",
    "domain": "Design Cost-Optimized Architectures",
    "section": "Lambda",
    "question": "How are you charged for AWS Lambda usage?",
    "choices": [
      "Per hour of function deployment",
      "Based on number of requests and compute time",
      "Fixed monthly fee",
      "Per GB of code uploaded"
    ],
    "answer": 1,
    "explanation": "Lambda charges based on the number of requests and the duration/memory consumed during code execution, with no charges when code isn't running.",
    "difficulty": "Easy"
  },
  {
    "id": "SAA-473",
    "domainId": "D4",
    "domain": "Design Cost-Optimized Architectures",
    "section": "S3",
    "question": "Which S3 storage class automatically moves data between access tiers based on changing access patterns?",
    "choices": [
      "S3 Standard",
      "S3 Intelligent-Tiering",
      "S3 Glacier",
      "S3 One Zone-IA"
    ],
    "answer": 1,
    "explanation": "S3 Intelligent-Tiering automatically moves objects between access tiers based on usage patterns, optimizing costs without performance impact.",
    "difficulty": "Easy"
  },
  {
    "id": "SAA-474",
    "domainId": "D4",
    "domain": "Design Cost-Optimized Architectures",
    "section": "Cost Management",
    "question": "A company wants to receive alerts when their AWS spending exceeds a certain threshold. They also want to forecast future costs based on current usage. Which TWO AWS services should they use? (Choose TWO.)",
    "choices": [
      "AWS Budgets",
      "AWS Cost Explorer",
      "Amazon CloudWatch",
      "AWS Config",
      "AWS Systems Manager"
    ],
    "answer": [
      0,
      1
    ],
    "explanation": "AWS Budgets allows setting custom cost and usage budgets with alerts. AWS Cost Explorer provides cost forecasting and analysis tools to understand spending patterns.",
    "difficulty": "Easy"
  },
  {
    "id": "SAA-475",
    "domainId": "D4",
    "domain": "Design Cost-Optimized Architectures",
    "section": "EC2 Pricing",
    "question": "A development team runs EC2 instances 24/7 for testing but only actively uses them during business hours (8 hours daily). They need a solution that minimizes costs while maintaining the ability to quickly resume work. Which TWO actions would be MOST cost-effective? (Choose TWO.)",
    "choices": [
      "Use Reserved Instances for all development instances",
      "Stop instances during non-business hours",
      "Use Auto Scaling to reduce instance count during off-hours",
      "Migrate to Spot Instances",
      "Use larger instance types with burstable performance"
    ],
    "answer": [
      1,
      2
    ],
    "explanation": "Stopping instances during non-business hours eliminates compute charges while preserving instance state. Auto Scaling can reduce the number of running instances during low-usage periods, both optimizing costs for variable usage patterns.",
    "difficulty": "Easy"
  },
  {
    "id": "SAA-476",
    "domainId": "D1",
    "domain": "Design Secure Architectures",
    "section": "IAM",
    "question": "A team wants an EC2-hosted application to call AWS APIs without storing long-term credentials on the instance. The security team also wants the permissions to be tightly scoped to only what the app needs.\nWhich approach should the Solutions Architect implement?",
    "choices": [
      "Create an IAM user and store access keys in the application configuration file",
      "Attach an IAM role to the EC2 instance with a least-privilege policy",
      "Store IAM user access keys in AWS Systems Manager Run Command documents",
      "Generate temporary credentials using AWS STS from a shared IAM user"
    ],
    "answer": 1,
    "explanation": "An IAM role attached to the EC2 instance provides temporary credentials via the instance metadata service and supports least-privilege permissions without storing long-term keys.",
    "difficulty": "Medium"
  },
  {
    "id": "SAA-477",
    "domainId": "D1",
    "domain": "Design Secure Architectures",
    "section": "S3",
    "question": "A company hosts a static website in an S3 bucket behind CloudFront. Security requirements state that the S3 bucket must not be publicly accessible, and only CloudFront should be able to read objects.\nWhat should you do?",
    "choices": [
      "Enable S3 static website hosting and restrict access using a bucket ACL",
      "Use an Origin Access Control (OAC) or Origin Access Identity (OAI) and a bucket policy that allows only CloudFront",
      "Allow public read on the bucket and restrict CloudFront by signed cookies only",
      "Put the bucket in a private subnet and access it through a NAT Gateway"
    ],
    "answer": 1,
    "explanation": "Using CloudFront OAC/OAI with a restrictive bucket policy keeps the bucket private while allowing CloudFront to fetch content securely.",
    "difficulty": "Medium"
  },
  {
    "id": "SAA-478",
    "domainId": "D1",
    "domain": "Design Secure Architectures",
    "section": "KMS",
    "question": "A company must encrypt objects in S3 using customer-managed keys and must be able to immediately revoke access to the encrypted data if a breach is detected.\nWhich solution meets this requirement?",
    "choices": [
      "Use SSE-S3 and remove the bucket policy during a breach",
      "Use SSE-KMS with a customer managed key and disable the KMS key if needed",
      "Use client-side encryption and store the key in an EC2 instance user-data script",
      "Use SSE-C and rotate the customer-provided key daily"
    ],
    "answer": 1,
    "explanation": "SSE-KMS with a customer managed key allows immediate revocation by disabling the key (or tightening the key policy), preventing further decrypt operations.",
    "difficulty": "Medium"
  },
  {
    "id": "SAA-479",
    "domainId": "D1",
    "domain": "Design Secure Architectures",
    "section": "VPC",
    "question": "Instances in a private subnet must call DynamoDB without using the public internet. The company wants the simplest approach with minimal ongoing management.\nWhat should you configure?",
    "choices": [
      "A NAT Gateway in a public subnet and route DynamoDB traffic through it",
      "A gateway VPC endpoint for DynamoDB and update the route tables",
      "A VPC peering connection to a VPC that has internet access",
      "AWS Direct Connect to DynamoDB public endpoints"
    ],
    "answer": 1,
    "explanation": "A DynamoDB gateway endpoint keeps traffic on the AWS network and avoids internet egress and NAT costs/management.",
    "difficulty": "Medium"
  },
  {
    "id": "SAA-480",
    "domainId": "D1",
    "domain": "Design Secure Architectures",
    "section": "Security Groups",
    "question": "A workload has a public ALB and private EC2 instances in an Auto Scaling group. Only the ALB should be able to reach the instances on port 443.\nHow should the instance security group be configured?",
    "choices": [
      "Allow inbound 443 from 0.0.0.0/0",
      "Allow inbound 443 from the ALB security group",
      "Allow inbound 443 from the ALB subnet CIDR blocks only",
      "Allow inbound 443 from the VPC CIDR block"
    ],
    "answer": 1,
    "explanation": "Referencing the ALB security group in the instance security group rule ensures only the ALB can connect, even if ALB IPs change.",
    "difficulty": "Medium"
  },
  {
    "id": "SAA-481",
    "domainId": "D1",
    "domain": "Design Secure Architectures",
    "section": "CloudTrail",
    "question": "A company needs an immutable audit trail of API activity for all accounts in an AWS Organization. They also want to prevent member accounts from turning off logging.\nWhat should you implement?",
    "choices": [
      "Enable CloudTrail in each account and restrict it with IAM policies",
      "Create an Organization trail in the management account and use SCPs to prevent CloudTrail changes",
      "Enable VPC Flow Logs and store them in an encrypted S3 bucket",
      "Enable AWS Config and send configuration changes to a central account"
    ],
    "answer": 1,
    "explanation": "An Organization trail centralizes logging across accounts, and SCPs can prevent disabling or tampering with CloudTrail configuration in member accounts.",
    "difficulty": "Medium"
  },
  {
    "id": "SAA-482",
    "domainId": "D1",
    "domain": "Design Secure Architectures",
    "section": "Secrets Manager",
    "question": "A Lambda function must connect to an RDS database. The database password must be rotated automatically without changing application code.\nWhich solution is best?",
    "choices": [
      "Store the password in Lambda environment variables and update them manually",
      "Store the password in Secrets Manager and enable automatic rotation",
      "Store the password in Parameter Store Standard tier and rotate it with a cron job on EC2",
      "Store the password in an encrypted S3 object and download it on each invocation"
    ],
    "answer": 1,
    "explanation": "Secrets Manager supports managed secret rotation workflows and integrates well with Lambda/RDS patterns.",
    "difficulty": "Medium"
  },
  {
    "id": "SAA-483",
    "domainId": "D1",
    "domain": "Design Secure Architectures",
    "section": "Organizations",
    "question": "A company must ensure developers can only deploy resources in approved regions. This must be enforced centrally and must not rely on users remembering to apply IAM policies.\nWhat should the company use?",
    "choices": [
      "IAM permission boundaries in each account",
      "Service Control Policies (SCPs) in AWS Organizations",
      "Security groups that block outbound traffic to other regions",
      "AWS Config rules with auto-remediation"
    ],
    "answer": 1,
    "explanation": "SCPs provide preventive, organization-level guardrails that apply regardless of IAM permissions inside member accounts.",
    "difficulty": "Medium"
  },
  {
    "id": "SAA-484",
    "domainId": "D1",
    "domain": "Design Secure Architectures",
    "section": "WAF",
    "question": "A public API behind an ALB is being hit with common web exploits (SQLi/XSS) and needs basic rate limiting by client IP. The team wants a managed approach.\nWhich solution should be used?",
    "choices": [
      "Deploy AWS Shield Advanced only",
      "Use AWS WAF on the ALB with managed rules and a rate-based rule",
      "Add NACL rules to block all IPs except known customers",
      "Use IAM policies to deny requests with suspicious headers"
    ],
    "answer": 1,
    "explanation": "AWS WAF supports managed rule groups for common exploits and rate-based rules to throttle abusive IPs at the edge/ALB.",
    "difficulty": "Medium"
  },
  {
    "id": "SAA-485",
    "domainId": "D1",
    "domain": "Design Secure Architectures",
    "section": "VPC",
    "question": "A company wants to privately access an internal service running on an NLB in another account, without opening inbound access from the entire VPC CIDR and without VPC peering.\nWhich solution meets this requirement?",
    "choices": [
      "VPC peering and security group rules between accounts",
      "AWS PrivateLink (interface VPC endpoints) to the NLB endpoint service",
      "A Transit Gateway with a shared route table",
      "A public ALB with IP allowlists"
    ],
    "answer": 1,
    "explanation": "PrivateLink exposes a service privately via interface endpoints without broad network connectivity and is ideal for cross-account service consumption.",
    "difficulty": "Medium"
  },
  {
    "id": "SAA-486",
    "domainId": "D1",
    "domain": "Design Secure Architectures",
    "section": "IAM (Select TWO)",
    "question": "A company wants to reduce the risk of credential exposure for workloads running on EC2 and ECS. They also want an approach that minimizes long-term secrets.\nWhich TWO actions should be taken? (Choose TWO.)",
    "choices": [
      "Use IAM roles for EC2 instances and ECS task roles for containers",
      "Store access keys in an encrypted S3 bucket and fetch them at startup",
      "Use AWS STS-issued temporary credentials instead of long-lived access keys",
      "Hardcode credentials in the container image and restrict access to the ECR repo",
      "Share one IAM user across multiple services to simplify key rotation"
    ],
    "answer": [
      0,
      2
    ],
    "explanation": "IAM roles (including ECS task roles) and STS temporary credentials reduce reliance on long-lived secrets and follow AWS best practices for workload identity.",
    "difficulty": "Medium"
  },
  {
    "id": "SAA-487",
    "domainId": "D2",
    "domain": "Design Resilient Architectures",
    "section": "RDS",
    "question": "A production database on RDS MySQL must remain available during an AZ outage with automatic failover. Read scaling is not the primary requirement.\nWhat should be enabled?",
    "choices": [
      "RDS Read Replica in the same AZ",
      "RDS Multi-AZ deployment",
      "Manual snapshots every hour",
      "Amazon ElastiCache in front of the database"
    ],
    "answer": 1,
    "explanation": "Multi-AZ provides synchronous standby and automatic failover for high availability during AZ failures.",
    "difficulty": "Medium"
  },
  {
    "id": "SAA-488",
    "domainId": "D2",
    "domain": "Design Resilient Architectures",
    "section": "SQS",
    "question": "An application must process messages at least once and can tolerate duplicate processing. The team wants to decouple components and buffer traffic spikes.\nWhich messaging service configuration fits best?",
    "choices": [
      "SQS Standard queue with idempotent consumer logic",
      "SQS FIFO queue with content-based deduplication disabled",
      "SNS topic with email subscriptions only",
      "Kinesis Data Streams with 1 shard and no consumer retry"
    ],
    "answer": 0,
    "explanation": "SQS Standard provides high throughput and at-least-once delivery; duplicates are handled by making consumers idempotent.",
    "difficulty": "Medium"
  },
  {
    "id": "SAA-489",
    "domainId": "D2",
    "domain": "Design Resilient Architectures",
    "section": "Route 53",
    "question": "An application is deployed in two regions. The company needs automatic DNS failover when the primary region becomes unhealthy. Health checks must validate an application URL (not just TCP).\nWhich Route 53 routing policy should be used?",
    "choices": [
      "Latency-based routing",
      "Failover routing with health checks",
      "Geolocation routing",
      "Multivalue answer routing without health checks"
    ],
    "answer": 1,
    "explanation": "Failover routing uses Route 53 health checks to direct traffic to the secondary endpoint when the primary fails application-level checks.",
    "difficulty": "Medium"
  },
  {
    "id": "SAA-490",
    "domainId": "D2",
    "domain": "Design Resilient Architectures",
    "section": "Auto Scaling",
    "question": "A web app behind an ALB has predictable daily peaks at 09:00 and 18:00, and also occasional unexpected spikes. The company wants cost-efficient scaling with minimal manual intervention.\nWhich combination is most appropriate?",
    "choices": [
      "Scheduled scaling for predictable peaks and target tracking for unexpected spikes",
      "Only scheduled scaling with large buffers",
      "Only step scaling based on CPU at 5-minute intervals",
      "Disable scaling and buy Reserved Instances for maximum load"
    ],
    "answer": 0,
    "explanation": "Scheduled scaling handles known peaks proactively, while target tracking reacts to unexpected demand with automatic adjustments.",
    "difficulty": "Medium"
  },
  {
    "id": "SAA-491",
    "domainId": "D2",
    "domain": "Design Resilient Architectures",
    "section": "ECS",
    "question": "A service runs on ECS and must support deployments without downtime. If the new version fails health checks, traffic must automatically roll back.\nWhich deployment strategy best meets this requirement?",
    "choices": [
      "In-place deployment with a manual rollback runbook",
      "Blue/green deployments using AWS CodeDeploy for ECS",
      "Recreate all tasks at once with a larger desired count",
      "Deploy to a single task and gradually increase desired count without health checks"
    ],
    "answer": 1,
    "explanation": "CodeDeploy blue/green for ECS shifts traffic between target groups and supports automatic rollback on failed health checks.",
    "difficulty": "Medium"
  },
  {
    "id": "SAA-492",
    "domainId": "D2",
    "domain": "Design Resilient Architectures",
    "section": "S3",
    "question": "A company stores critical documents in S3 and wants protection against accidental deletion or overwrite, while still allowing normal writes.\nWhich solution is most appropriate?",
    "choices": [
      "Enable S3 Transfer Acceleration",
      "Enable S3 Versioning and optionally MFA Delete for additional protection",
      "Use a public bucket policy with CloudFront caching",
      "Enable S3 Intelligent-Tiering"
    ],
    "answer": 1,
    "explanation": "Versioning preserves prior object versions and protects against accidental deletes/overwrites; MFA Delete adds protection for delete operations.",
    "difficulty": "Medium"
  },
  {
    "id": "SAA-493",
    "domainId": "D2",
    "domain": "Design Resilient Architectures",
    "section": "Backup",
    "question": "A company needs centralized backup policies for EC2 (EBS volumes) and RDS with cross-region copy and compliance reporting.\nWhich service should be used?",
    "choices": [
      "AWS Backup with backup plans and cross-region copy",
      "CloudWatch Logs with retention policies",
      "AWS Snowball scheduled exports",
      "Manual snapshots with local scripts on EC2"
    ],
    "answer": 0,
    "explanation": "AWS Backup provides centralized, policy-based backups across services with vaults, reporting, and cross-region copy options.",
    "difficulty": "Medium"
  },
  {
    "id": "SAA-494",
    "domainId": "D2",
    "domain": "Design Resilient Architectures",
    "section": "ELB",
    "question": "A company needs a load balancer that supports HTTP/HTTPS features like host-based routing, path-based routing, and WebSocket support.\nWhich load balancer should they choose?",
    "choices": [
      "Network Load Balancer",
      "Application Load Balancer",
      "Gateway Load Balancer",
      "Classic Load Balancer (for new workloads)"
    ],
    "answer": 1,
    "explanation": "ALB is Layer 7 and supports host/path-based routing and modern HTTP features like WebSockets.",
    "difficulty": "Medium"
  },
  {
    "id": "SAA-495",
    "domainId": "D2",
    "domain": "Design Resilient Architectures",
    "section": "Aurora",
    "question": "A company uses Aurora and needs fast regional disaster recovery with low RPO using cross-region replication that is designed for Aurora.\nWhich feature should they use?",
    "choices": [
      "Aurora Global Database",
      "Aurora Serverless v1 only",
      "Manual snapshots copied weekly",
      "Read replicas in the same AZ"
    ],
    "answer": 0,
    "explanation": "Aurora Global Database provides cross-region replication with low-latency replication and supports DR scenarios with low RPO.",
    "difficulty": "Medium"
  },
  {
    "id": "SAA-496",
    "domainId": "D2",
    "domain": "Design Resilient Architectures",
    "section": "Lambda",
    "question": "A Lambda function is triggered by SQS. During outages downstream, messages should not be lost and should be retried without blocking the entire queue indefinitely.\nWhich configuration helps isolate poison messages?",
    "choices": [
      "Increase the Lambda timeout to the maximum",
      "Configure a dead-letter queue (DLQ) or redrive policy with a max receive count",
      "Disable visibility timeout",
      "Use a FIFO queue with no deduplication"
    ],
    "answer": 1,
    "explanation": "A redrive policy moves repeatedly failing messages to a DLQ after max receives, preventing stuck processing while preserving data.",
    "difficulty": "Medium"
  },
  {
    "id": "SAA-497",
    "domainId": "D2",
    "domain": "Design Resilient Architectures",
    "section": "Multi-Region",
    "question": "A global app needs a static anycast entry point that can route users to the nearest healthy regional endpoint and fail over quickly if a region is down.\nWhich AWS service is most appropriate?",
    "choices": [
      "Amazon CloudFront only",
      "AWS Global Accelerator",
      "AWS Direct Connect",
      "Amazon VPC Lattice"
    ],
    "answer": 1,
    "explanation": "Global Accelerator provides anycast IPs and health-based routing to optimal regional endpoints with fast failover.",
    "difficulty": "Medium"
  },
  {
    "id": "SAA-498",
    "domainId": "D2",
    "domain": "Design Resilient Architectures",
    "section": "EBS",
    "question": "An EC2 instance with an EBS volume fails. The volume must be attached to a replacement instance as quickly as possible with the same data.\nWhich approach is best?",
    "choices": [
      "Use an EBS snapshot, then create a new volume and attach it",
      "Detach the existing EBS volume and attach it to the new instance in the same AZ",
      "Copy the data from S3 Glacier and rehydrate it",
      "Use an AMI only; AMIs always include the latest data"
    ],
    "answer": 1,
    "explanation": "EBS volumes are AZ-scoped; detaching and reattaching the same volume in the same AZ is the fastest way to preserve data and restore service.",
    "difficulty": "Medium"
  },
  {
    "id": "SAA-499",
    "domainId": "D2",
    "domain": "Design Resilient Architectures",
    "section": "DR (Select TWO)",
    "question": "A workload requires a regional disaster recovery plan with reduced downtime and frequent data replication, but the company wants to avoid paying for full production capacity in the secondary region.\nWhich TWO DR approaches generally align with these goals? (Choose TWO.)",
    "choices": [
      "Warm standby",
      "Backup and restore only",
      "Pilot light",
      "Active/active in both regions at full scale",
      "Run everything in a single AZ with Multi-AZ disabled"
    ],
    "answer": [
      0,
      2
    ],
    "explanation": "Warm standby and pilot light reduce cost compared to full active/active while maintaining better RTO/RPO than backup-and-restore alone.",
    "difficulty": "Medium"
  },
  {
    "id": "SAA-500",
    "domainId": "D2",
    "domain": "Design Resilient Architectures",
    "section": "Elastic Beanstalk",
    "question": "A team wants an easy way to deploy a web application with built-in health checks, rolling deployments, and Auto Scaling without managing most underlying infrastructure.\nWhich service is best?",
    "choices": [
      "AWS Elastic Beanstalk",
      "Amazon EMR",
      "Amazon WorkSpaces",
      "AWS Batch"
    ],
    "answer": 0,
    "explanation": "Elastic Beanstalk provides a managed application deployment experience that can provision ALB, Auto Scaling, and health monitoring with minimal overhead.",
    "difficulty": "Medium"
  },
  {
    "id": "SAA-501",
    "domainId": "D3",
    "domain": "Design High-Performing Architectures",
    "section": "CloudFront",
    "question": "A website serves static assets from S3 to a global audience. The company wants lower latency and reduced load on the origin.\nWhich solution should be used?",
    "choices": [
      "Add more S3 buckets and manually sync content",
      "Use Amazon CloudFront with the S3 bucket as origin and enable caching",
      "Use an NLB in front of S3",
      "Use Route 53 weighted routing to S3"
    ],
    "answer": 1,
    "explanation": "CloudFront caches content at edge locations, reducing latency for users and decreasing requests to the S3 origin.",
    "difficulty": "Medium"
  },
  {
    "id": "SAA-502",
    "domainId": "D3",
    "domain": "Design High-Performing Architectures",
    "section": "ElastiCache",
    "question": "A read-heavy application needs sub-millisecond access to frequently requested items and can tolerate data being up to 30 seconds stale.\nWhat should the Solutions Architect implement?",
    "choices": [
      "Increase RDS storage size",
      "Add ElastiCache (Redis) with a suitable TTL and cache-aside pattern",
      "Move the application to a larger EC2 instance type",
      "Enable S3 Transfer Acceleration"
    ],
    "answer": 1,
    "explanation": "Redis caching can serve hot data with very low latency and reduce database read load; TTL supports acceptable staleness.",
    "difficulty": "Medium"
  },
  {
    "id": "SAA-503",
    "domainId": "D3",
    "domain": "Design High-Performing Architectures",
    "section": "EBS",
    "question": "A transactional database needs sustained high IOPS and consistent low latency. The team is choosing between gp3 and io2.\nWhich option is most appropriate for the highest, most consistent I/O performance?",
    "choices": [
      "st1",
      "sc1",
      "io2",
      "Magnetic (standard)"
    ],
    "answer": 2,
    "explanation": "io2 Provisioned IOPS SSD is built for I/O-intensive workloads requiring sustained high IOPS and consistent low latency.",
    "difficulty": "Medium"
  },
  {
    "id": "SAA-504",
    "domainId": "D3",
    "domain": "Design High-Performing Architectures",
    "section": "Lambda",
    "question": "A Lambda function is experiencing timeouts because it needs to call an external API that sometimes responds slowly. The team wants better performance and fewer cold starts.\nWhich change is most likely to help?",
    "choices": [
      "Decrease the function memory size",
      "Enable Provisioned Concurrency for the function",
      "Disable retries for asynchronous invocations",
      "Move the code to a smaller deployment package"
    ],
    "answer": 1,
    "explanation": "Provisioned Concurrency keeps functions initialized, reducing cold start latency and improving responsiveness under load.",
    "difficulty": "Medium"
  },
  {
    "id": "SAA-505",
    "domainId": "D3",
    "domain": "Design High-Performing Architectures",
    "section": "DynamoDB",
    "question": "A DynamoDB table receives heavy writes to a small set of partition keys, causing throttling. The workload must keep using DynamoDB.\nWhat is the best way to reduce throttling caused by hot partitions?",
    "choices": [
      "Use a smaller item size",
      "Enable DynamoDB Streams",
      "Add write sharding by expanding the partition key space",
      "Turn on strongly consistent reads"
    ],
    "answer": 2,
    "explanation": "Write sharding spreads traffic across more partitions by increasing key cardinality, reducing hot partition throttling.",
    "difficulty": "Medium"
  },
  {
    "id": "SAA-506",
    "domainId": "D3",
    "domain": "Design High-Performing Architectures",
    "section": "Kinesis",
    "question": "A company ingests clickstream events and needs near-real-time processing by multiple consumers. They expect sustained high throughput and want ordered processing per partition.\nWhich service is most appropriate?",
    "choices": [
      "Amazon SQS Standard",
      "Amazon Kinesis Data Streams",
      "AWS Step Functions Standard",
      "Amazon SNS"
    ],
    "answer": 1,
    "explanation": "Kinesis Data Streams supports high-throughput streaming with multiple consumers and ordering within shards (partitions).",
    "difficulty": "Medium"
  },
  {
    "id": "SAA-507",
    "domainId": "D3",
    "domain": "Design High-Performing Architectures",
    "section": "Caching (Select TWO)",
    "question": "A company wants to reduce latency and origin load for a global web application serving dynamic and static content.\nWhich TWO approaches are most effective? (Choose TWO.)",
    "choices": [
      "Use CloudFront to cache static content close to users",
      "Use ElastiCache to cache frequently accessed database/query results",
      "Store all dynamic content in S3 Glacier Deep Archive",
      "Increase DNS TTL to 24 hours to improve application performance",
      "Disable compression to reduce CPU usage on clients"
    ],
    "answer": [
      0,
      1
    ],
    "explanation": "CloudFront helps with edge caching for static/edge-eligible content, and ElastiCache reduces backend latency by caching hot data and query results.",
    "difficulty": "Medium"
  },
  {
    "id": "SAA-508",
    "domainId": "D3",
    "domain": "Design High-Performing Architectures",
    "section": "EFS",
    "question": "Multiple EC2 instances across different AZs need a shared POSIX file system for application content. The team wants a managed service that scales automatically.\nWhich storage service should be used?",
    "choices": [
      "Amazon EFS",
      "Amazon EBS Multi-Attach only",
      "Instance Store",
      "Amazon S3 Glacier"
    ],
    "answer": 0,
    "explanation": "EFS is a managed NFS file system that can be mounted by many instances across AZs and scales automatically.",
    "difficulty": "Medium"
  },
  {
    "id": "SAA-509",
    "domainId": "D3",
    "domain": "Design High-Performing Architectures",
    "section": "RDS",
    "question": "A MySQL workload is read-heavy and needs to scale reads without changing the application significantly. Writes must remain on the primary.\nWhat is the best option?",
    "choices": [
      "Add RDS read replicas and direct read traffic to them",
      "Enable Multi-AZ for read scaling",
      "Move the database to S3",
      "Use AWS Backup to copy the database"
    ],
    "answer": 0,
    "explanation": "RDS read replicas offload read traffic and help scale read throughput while keeping writes on the primary instance.",
    "difficulty": "Medium"
  },
  {
    "id": "SAA-510",
    "domainId": "D3",
    "domain": "Design High-Performing Architectures",
    "section": "CloudWatch",
    "question": "An application needs to scale based on business metrics (orders per minute) rather than CPU. The team wants an AWS-native approach.\nWhat should they do?",
    "choices": [
      "Use CloudWatch custom metrics and target tracking scaling policies",
      "Use only EC2 scheduled scaling",
      "Use CloudTrail events to trigger scaling actions",
      "Use S3 event notifications to scale EC2"
    ],
    "answer": 0,
    "explanation": "Publishing custom metrics to CloudWatch enables Auto Scaling to scale based on business KPIs using target tracking or step policies.",
    "difficulty": "Medium"
  },
  {
    "id": "SAA-511",
    "domainId": "D3",
    "domain": "Design High-Performing Architectures",
    "section": "S3",
    "question": "A global user base frequently downloads large files stored in S3. The company wants to improve download performance without duplicating data to multiple buckets.\nWhich solution is most appropriate?",
    "choices": [
      "Use CloudFront in front of S3",
      "Use EBS snapshots and share them publicly",
      "Use Amazon EFS and mount it globally",
      "Use AWS Backup to accelerate downloads"
    ],
    "answer": 0,
    "explanation": "CloudFront improves download performance by caching at edge locations and optimizing delivery from the S3 origin.",
    "difficulty": "Medium"
  },
  {
    "id": "SAA-512",
    "domainId": "D3",
    "domain": "Design High-Performing Architectures",
    "section": "Networking",
    "question": "A latency-sensitive TCP application requires a static IP and very high throughput load balancing. The application does not need Layer 7 routing features.\nWhich load balancer is best?",
    "choices": [
      "Application Load Balancer",
      "Network Load Balancer",
      "Gateway Load Balancer",
      "Classic Load Balancer"
    ],
    "answer": 1,
    "explanation": "NLB provides high performance for TCP/UDP and supports static IPs (or Elastic IPs) and low latency.",
    "difficulty": "Medium"
  },
  {
    "id": "SAA-513",
    "domainId": "D3",
    "domain": "Design High-Performing Architectures",
    "section": "Aurora",
    "question": "A company wants better read scalability and faster failover than standard RDS MySQL, while staying MySQL-compatible.\nWhich database choice is most appropriate?",
    "choices": [
      "Amazon Aurora MySQL-Compatible",
      "Amazon Neptune",
      "Amazon Redshift",
      "Amazon DocumentDB"
    ],
    "answer": 0,
    "explanation": "Aurora MySQL offers higher performance, improved replication, and faster failover while maintaining MySQL compatibility.",
    "difficulty": "Medium"
  },
  {
    "id": "SAA-514",
    "domainId": "D3",
    "domain": "Design High-Performing Architectures",
    "section": "DynamoDB",
    "question": "An application needs consistent single-digit millisecond reads and writes at massive scale, and the data model is key-value with predictable access patterns.\nWhich database is best?",
    "choices": [
      "Amazon DynamoDB",
      "Amazon RDS PostgreSQL",
      "Amazon OpenSearch Service",
      "Amazon Athena"
    ],
    "answer": 0,
    "explanation": "DynamoDB is designed for low-latency key-value access at scale, making it ideal for predictable key-based access patterns.",
    "difficulty": "Medium"
  },
  {
    "id": "SAA-515",
    "domainId": "D4",
    "domain": "Design Cost-Optimized Architectures",
    "section": "S3",
    "question": "A company stores access logs in S3. Logs are queried frequently for the first 14 days, then rarely accessed but must be retained for 1 year.\nWhich cost-optimized approach is best?",
    "choices": [
      "Keep logs in S3 Standard for the full year",
      "Use S3 Lifecycle to transition to S3 Standard-IA after 14 days",
      "Move logs to EBS volumes after 14 days",
      "Move logs to S3 One Zone-IA immediately"
    ],
    "answer": 1,
    "explanation": "Standard-IA reduces storage cost for infrequently accessed data while keeping it quickly retrievable; lifecycle rules automate transitions.",
    "difficulty": "Medium"
  },
  {
    "id": "SAA-516",
    "domainId": "D4",
    "domain": "Design Cost-Optimized Architectures",
    "section": "EC2 Pricing",
    "question": "A service needs 20 EC2 instances running 24/7 for the next 3 years with a stable instance type. The company wants the lowest compute cost.\nWhat should they purchase?",
    "choices": [
      "On-Demand Instances only",
      "Spot Instances only",
      "Standard Reserved Instances (3-year) or a 3-year Savings Plan covering the baseline",
      "Dedicated Hosts"
    ],
    "answer": 2,
    "explanation": "For steady-state workloads, 3-year commitment discounts (Standard RIs or Savings Plans) typically provide the best cost reduction.",
    "difficulty": "Medium"
  },
  {
    "id": "SAA-517",
    "domainId": "D4",
    "domain": "Design Cost-Optimized Architectures",
    "section": "EBS",
    "question": "A team is paying for large gp3 volumes with more provisioned IOPS than needed. They want to reduce costs while keeping performance adequate.\nWhat should they do first?",
    "choices": [
      "Switch all volumes to io2",
      "Right-size EBS volume size and provisioned IOPS/throughput based on actual metrics",
      "Move the workload to instance store",
      "Disable CloudWatch monitoring"
    ],
    "answer": 1,
    "explanation": "Right-sizing gp3 capacity, IOPS, and throughput to match real usage is a direct way to reduce EBS spend without sacrificing required performance.",
    "difficulty": "Medium"
  },
  {
    "id": "SAA-518",
    "domainId": "D4",
    "domain": "Design Cost-Optimized Architectures",
    "section": "Compute (Select TWO)",
    "question": "A company runs nightly batch jobs that can be interrupted and restarted. They want to minimize cost while keeping completion time reasonable.\nWhich TWO options are most cost-effective? (Choose TWO.)",
    "choices": [
      "Use EC2 Spot Instances with checkpointing",
      "Use AWS Batch with Spot capacity enabled",
      "Use Dedicated Hosts to reserve capacity",
      "Use On-Demand Instances only",
      "Use 3-year Standard Reserved Instances for the batch fleet"
    ],
    "answer": [
      0,
      1
    ],
    "explanation": "Spot is ideal for interruptible workloads. AWS Batch can manage job queues and leverage Spot capacity automatically while handling retries and scaling.",
    "difficulty": "Medium"
  },
  {
    "id": "SAA-519",
    "domainId": "D4",
    "domain": "Design Cost-Optimized Architectures",
    "section": "RDS",
    "question": "A company runs a dev/test RDS database that is only needed during business hours. They want to reduce cost while keeping the same DB engine.\nWhat should they do?",
    "choices": [
      "Enable Multi-AZ to reduce costs",
      "Stop the RDS instance outside business hours (where supported) or use Aurora Serverless v2 for variable usage",
      "Move the database to an EC2 instance store volume",
      "Enable CloudFront caching"
    ],
    "answer": 1,
    "explanation": "Stopping non-production databases during off-hours (or using an auto-scaling serverless option where appropriate) reduces compute costs significantly.",
    "difficulty": "Medium"
  },
  {
    "id": "SAA-520",
    "domainId": "D4",
    "domain": "Design Cost-Optimized Architectures",
    "section": "S3",
    "question": "A dataset has unpredictable access patterns. The team wants to reduce storage costs without manually creating complex lifecycle rules and without impacting retrieval for frequently accessed objects.\nWhich S3 storage class is most appropriate?",
    "choices": [
      "S3 Glacier Deep Archive",
      "S3 Intelligent-Tiering",
      "S3 One Zone-IA",
      "S3 Reduced Redundancy Storage (RRS)"
    ],
    "answer": 1,
    "explanation": "Intelligent-Tiering automatically moves objects between tiers based on access while keeping retrieval seamless for frequently accessed data.",
    "difficulty": "Medium"
  },
  {
    "id": "SAA-521",
    "domainId": "D4",
    "domain": "Design Cost-Optimized Architectures",
    "section": "Data Transfer",
    "question": "A workload moves large amounts of data between two EC2 instances in the same AZ. The company wants to minimize data transfer costs.\nWhich placement is most cost-effective?",
    "choices": [
      "Place the instances in different regions",
      "Place the instances in different AZs in the same region",
      "Place the instances in the same AZ (and same VPC) when possible",
      "Route traffic through the internet gateway"
    ],
    "answer": 2,
    "explanation": "Keeping traffic within the same AZ generally reduces cross-AZ data transfer charges and can improve latency.",
    "difficulty": "Medium"
  },
  {
    "id": "SAA-522",
    "domainId": "D4",
    "domain": "Design Cost-Optimized Architectures",
    "section": "Logging",
    "question": "A company stores application logs in CloudWatch Logs indefinitely and costs are growing. Logs are only needed for search for 30 days, but must be retained for 1 year for compliance.\nWhat is the best cost-optimized approach?",
    "choices": [
      "Reduce the log level and keep indefinite retention",
      "Set CloudWatch Logs retention to 30 days and export/archive logs to S3 for long-term retention",
      "Disable logging to reduce cost",
      "Store logs only on EC2 instance disks"
    ],
    "answer": 1,
    "explanation": "CloudWatch Logs retention limits ongoing ingestion/storage costs, while S3 provides cheaper long-term retention for compliance.",
    "difficulty": "Medium"
  },
  {
    "id": "SAA-523",
    "domainId": "D4",
    "domain": "Design Cost-Optimized Architectures",
    "section": "Compute",
    "question": "A workload runs on multiple EC2 instance families and sizes, but has a consistent monthly spend pattern. The company wants flexible discounts without locking to a single instance type.\nWhat should they use?",
    "choices": [
      "Dedicated Hosts",
      "Compute Savings Plans",
      "Spot Instances only",
      "On-Demand Capacity Reservations"
    ],
    "answer": 1,
    "explanation": "Compute Savings Plans offer flexible discounts across instance families and regions (within terms) compared to instance-specific reservations.",
    "difficulty": "Medium"
  },
  {
    "id": "SAA-524",
    "domainId": "D4",
    "domain": "Design Cost-Optimized Architectures",
    "section": "DynamoDB",
    "question": "A DynamoDB table has highly variable traffic: very high on weekends and low during weekdays. The team wants to avoid capacity planning while keeping costs reasonable for spiky usage.\nWhich capacity mode is most suitable?",
    "choices": [
      "Provisioned capacity with auto scaling disabled",
      "Provisioned capacity with a fixed high WCU/RCU",
      "On-demand capacity mode",
      "Local secondary indexes only"
    ],
    "answer": 2,
    "explanation": "On-demand automatically scales with workload spikes and removes the need for capacity planning, which fits highly variable usage patterns.",
    "difficulty": "Medium"
  },
  {
    "id": "SAA-525",
    "domainId": "D1",
    "domain": "Design Secure Architectures",
    "section": "Cognito",
    "question": "A web app needs user sign-up/sign-in and should receive temporary AWS credentials to access S3 with least privilege. The company wants a managed user directory.\nWhich solution is best?",
    "choices": [
      "IAM users for every customer",
      "Amazon Cognito User Pools with an Identity Pool for AWS credentials",
      "Store usernames/passwords in DynamoDB and create STS sessions manually",
      "Use EC2 instance profiles for end users"
    ],
    "answer": 1,
    "explanation": "User Pools manage identities and authentication; Identity Pools can exchange tokens for temporary AWS credentials scoped via IAM roles.",
    "difficulty": "Medium"
  },
  {
    "id": "SAA-526",
    "domainId": "D1",
    "domain": "Design Secure Architectures",
    "section": "NACL",
    "question": "A security team wants to explicitly block traffic from a known malicious IP range at the subnet boundary for a public subnet. They want a stateless rule that can deny traffic.\nWhat should they use?",
    "choices": [
      "Security group deny rules",
      "Network ACL deny rules",
      "Route table blackhole routes for the IP range",
      "IAM policies"
    ],
    "answer": 1,
    "explanation": "NACLs are stateless and support explicit allow and deny rules, making them suitable for subnet-level IP blocking.",
    "difficulty": "Medium"
  },
  {
    "id": "SAA-527",
    "domainId": "D2",
    "domain": "Design Resilient Architectures",
    "section": "SQS/SNS",
    "question": "An event-driven system must deliver the same event to multiple independent consumers (email, SMS, and a processing service). The company wants loose coupling.\nWhich solution is most appropriate?",
    "choices": [
      "Send all events directly to each consumer from the producer",
      "Use SNS to publish events and have multiple subscriptions (including SQS for processing)",
      "Use a single SQS queue and have all consumers compete for messages",
      "Use EBS snapshots to store events"
    ],
    "answer": 1,
    "explanation": "SNS provides pub/sub fanout. SQS subscriptions allow durable processing by services while other subscribers can use different protocols.",
    "difficulty": "Medium"
  },
  {
    "id": "SAA-528",
    "domainId": "D3",
    "domain": "Design High-Performing Architectures",
    "section": "S3 Performance",
    "question": "A workload uploads many large objects to S3 from a single client and wants faster upload throughput while also enabling retries of parts.\nWhich approach should be used?",
    "choices": [
      "Use S3 Select",
      "Use multipart upload",
      "Use Glacier Deep Archive for faster ingest",
      "Use S3 bucket ACLs"
    ],
    "answer": 1,
    "explanation": "Multipart upload increases throughput by uploading parts in parallel and improves resiliency by retrying only failed parts.",
    "difficulty": "Medium"
  },
  {
    "id": "SAA-529",
    "domainId": "D1",
    "domain": "Design Secure Architectures",
    "section": "Monitoring (Select TWO)",
    "question": "A company wants to detect suspicious API activity and potential credential compromise in AWS accounts.\nWhich TWO services are best suited for this? (Choose TWO.)",
    "choices": [
      "Amazon GuardDuty",
      "AWS CloudTrail",
      "Amazon CloudFront",
      "AWS Snowcone",
      "Amazon EFS"
    ],
    "answer": [
      0,
      1
    ],
    "explanation": "CloudTrail records API activity, and GuardDuty analyzes logs (including CloudTrail) for threats like anomalous access patterns and compromised credentials.",
    "difficulty": "Medium"
  },
  {
    "id": "SAA-530",
    "domainId": "D4",
    "domain": "Design Cost-Optimized Architectures",
    "section": "Auto Scaling Costs",
    "question": "A service scales out during peak, but scale-in is slow and costs are higher than expected. The team wants to reduce cost without impacting availability.\nWhat should they adjust first?",
    "choices": [
      "Increase the minimum desired capacity permanently",
      "Review cooldowns and scale-in policies (including target tracking settings) to allow faster scale-in",
      "Switch all instances to Dedicated Hosts",
      "Disable health checks to prevent replacements"
    ],
    "answer": 1,
    "explanation": "Overly conservative cooldowns and scale-in settings can keep extra instances running longer than needed. Tuning them reduces cost while preserving availability.",
    "difficulty": "Medium"
  },
  {
    "id": "SAA-531",
    "domainId": "D1",
    "domain": "Design Secure Architectures",
    "section": "IAM",
    "question": "A company is moving to an attribute-based access control (ABAC) model across 60 AWS accounts. Each developer assumes a role from a central identity provider and receives session tags such as Department, Project, and Environment. The security team requires that users can create and manage EC2 resources only when the resource tags match their session tags, and they must not be able to bypass tagging restrictions by changing tags after creation.\nWhich solution BEST enforces these requirements?",
    "choices": [
      "Use a permission boundary that allows ec2:* but relies on developers to apply correct tags",
      "Use IAM policies with aws:RequestTag and aws:ResourceTag conditions, and explicitly deny tag changes that would break ABAC rules",
      "Use AWS Config rules to detect incorrect tags and remediate after the fact with Lambda",
      "Use security groups and NACLs to restrict who can manage EC2 instances"
    ],
    "answer": 1,
    "explanation": "ABAC is enforced with IAM conditions on request tags and resource tags. Adding explicit deny conditions for tag mutations prevents users from creating resources with compliant tags and later changing them to bypass access controls.",
    "difficulty": "Hard"
  },
  {
    "id": "SAA-532",
    "domainId": "D1",
    "domain": "Design Secure Architectures",
    "section": "S3 / Organizations",
    "question": "A security team must ensure that no team in any account can upload objects to any S3 bucket unless the objects are encrypted with SSE-KMS using a specific customer managed key. The control must be preventive across the AWS Organization and must remain effective even if a team changes IAM policies in their account.\nWhich approach BEST meets this requirement?",
    "choices": [
      "Enable S3 default encryption with SSE-S3 on all buckets and rely on developers to follow guidance",
      "Apply an SCP that denies s3:PutObject unless the correct SSE-KMS headers are present, and enforce a bucket policy requiring the specific KMS key",
      "Use AWS Config managed rules to detect unencrypted objects and delete them automatically",
      "Use CloudTrail alerts to notify security when an unencrypted upload occurs"
    ],
    "answer": 1,
    "explanation": "SCPs provide org-wide preventive guardrails that cannot be overridden by member account IAM. Combining SCP enforcement with bucket policy conditions ensures uploads are rejected unless the required SSE-KMS settings and key are used.",
    "difficulty": "Hard"
  },
  {
    "id": "SAA-533",
    "domainId": "D1",
    "domain": "Design Secure Architectures",
    "section": "VPC Endpoints",
    "question": "An ECS cluster runs entirely in private subnets. The workloads must pull images from Amazon ECR, write logs to CloudWatch Logs, and read configuration from AWS Systems Manager Parameter Store. The security team prohibits any internet egress and does not allow NAT Gateways.\nWhich solution enables the workloads to function while meeting the constraints?",
    "choices": [
      "Create a NAT instance in a public subnet and route all outbound traffic through it",
      "Create interface VPC endpoints for ECR (api and dkr), CloudWatch Logs, Systems Manager/SSM Messages, and a gateway endpoint for S3 if required by ECR",
      "Use an Internet Gateway with restrictive security group egress rules to block most destinations",
      "Use VPC peering to a shared services VPC that has a NAT Gateway"
    ],
    "answer": 1,
    "explanation": "Private connectivity to AWS services without internet egress is achieved using VPC endpoints. ECR commonly requires interface endpoints (and often S3 gateway endpoint for image layer retrieval). CloudWatch Logs and SSM also require interface endpoints.",
    "difficulty": "Hard"
  },
  {
    "id": "SAA-534",
    "domainId": "D1",
    "domain": "Design Secure Architectures",
    "section": "CloudTrail",
    "question": "A company must keep an immutable audit record of all management events for 7 years. Requirements: centralized logging for all accounts, encryption with customer managed keys, and protection against log deletion or overwrite even by administrators in member accounts.\nWhich solution BEST satisfies these requirements?",
    "choices": [
      "Enable CloudTrail in each account and store logs in local S3 buckets with bucket versioning",
      "Create an organization CloudTrail trail to a central S3 bucket, enable S3 Object Lock in compliance mode, and encrypt using SSE-KMS with restricted key policies",
      "Store CloudTrail logs in CloudWatch Logs with infinite retention and restrict deletion using IAM policies",
      "Use VPC Flow Logs instead of CloudTrail and archive to Glacier Deep Archive"
    ],
    "answer": 1,
    "explanation": "An organization trail centralizes CloudTrail across accounts. S3 Object Lock (compliance mode) and SSE-KMS provide immutability and encryption. Proper key and bucket policies prevent tampering by member accounts.",
    "difficulty": "Hard"
  },
  {
    "id": "SAA-535",
    "domainId": "D1",
    "domain": "Design Secure Architectures",
    "section": "WAF / Shield",
    "question": "A public application is fronted by CloudFront with an ALB as origin. The company is experiencing both large volumetric attacks and application-layer attacks (SQLi, XSS, and high-rate bot traffic). Requirements: managed protection with minimal custom code, centralized visibility, and the ability to quickly block abusive IPs.\nWhich combination provides the BEST protection?",
    "choices": [
      "Enable AWS Shield Standard only and rely on ALB security groups",
      "Use AWS Shield Advanced and AWS WAF on CloudFront with managed rule groups and rate-based rules",
      "Move the application to private subnets and remove CloudFront",
      "Use NACL deny rules and manually update them on every incident"
    ],
    "answer": 1,
    "explanation": "Shield Advanced improves DDoS protections and response, while AWS WAF at CloudFront provides managed L7 protections (SQLi/XSS) plus rate limiting and centralized management/visibility.",
    "difficulty": "Hard"
  },
  {
    "id": "SAA-536",
    "domainId": "D1",
    "domain": "Design Secure Architectures",
    "section": "Secrets Manager / RDS Proxy",
    "question": "A serverless application uses Lambda to connect to an RDS MySQL database. During traffic spikes, the database hits connection limits and credentials must be rotated automatically without redeploying the Lambdas. The solution must minimize downtime during credential rotation.\nWhich solution BEST meets these requirements?",
    "choices": [
      "Store credentials in Lambda environment variables and rotate them manually on a schedule",
      "Store credentials in Secrets Manager with rotation enabled and use RDS Proxy to manage database connections",
      "Store credentials in Parameter Store Standard and rotate them weekly using an EC2 cron job",
      "Use IAM database authentication and disable Secrets Manager"
    ],
    "answer": 1,
    "explanation": "Secrets Manager provides managed rotation workflows, and RDS Proxy reduces connection storms and allows smoother credential rotation with fewer failed connections during spikes.",
    "difficulty": "Hard"
  },
  {
    "id": "SAA-537",
    "domainId": "D1",
    "domain": "Design Secure Architectures",
    "section": "ACM / TLS",
    "question": "A company runs internal microservices accessed only from private subnets. They require mutual TLS between services and want certificate issuance, renewal, and revocation managed centrally. The certificates must be private (not publicly trusted).\nWhich solution BEST satisfies these requirements with minimal operational overhead?",
    "choices": [
      "Use public ACM certificates on all internal services and manually distribute private keys",
      "Use ACM Private CA to issue private certificates and integrate services to automatically renew certificates",
      "Use self-signed certificates generated on each EC2 instance and rotate them manually",
      "Store certificates in S3 and rotate by copying new files to every host"
    ],
    "answer": 1,
    "explanation": "ACM Private CA enables private certificate issuance and lifecycle management (including renewal) without needing public trust, reducing manual certificate handling and operational burden.",
    "difficulty": "Hard"
  },
  {
    "id": "SAA-538",
    "domainId": "D1",
    "domain": "Design Secure Architectures",
    "section": "PrivateLink",
    "question": "A platform team provides an internal API hosted behind an NLB in a shared services account. Over the next year, 40 application accounts must consume the API from their own VPCs without opening broad network connectivity. The consumers must not be able to reach any other resources in the provider VPC.\nWhich solution BEST meets these requirements?",
    "choices": [
      "Use VPC peering between every consumer VPC and the provider VPC",
      "Use AWS PrivateLink with an endpoint service on the provider NLB and interface endpoints in each consumer VPC",
      "Use a Transit Gateway shared with all accounts and a single route table for all traffic",
      "Expose the API through a public ALB and restrict access by source IP"
    ],
    "answer": 1,
    "explanation": "PrivateLink provides private, service-level connectivity across accounts without broad VPC-to-VPC routing. Consumers can access only the exposed endpoint service, not other provider VPC resources.",
    "difficulty": "Hard"
  },
  {
    "id": "SAA-539",
    "domainId": "D1",
    "domain": "Design Secure Architectures",
    "section": "Governance (Select TWO)",
    "question": "A company wants to prevent accidental public exposure of S3 data across all accounts while also ensuring security can detect and remediate misconfigurations that slip through. The solution must scale to hundreds of accounts with minimal manual work.\nWhich TWO actions BEST meet these requirements? (Choose TWO.)",
    "choices": [
      "Enable S3 Block Public Access at the account level for all accounts via organizations controls",
      "Rely on bucket ACLs because they are simpler than policies",
      "Deploy AWS Config rules for S3 public access settings and use auto-remediation to fix noncompliant buckets",
      "Allow public access by default and require teams to request exceptions through tickets",
      "Disable CloudTrail data events to reduce cost"
    ],
    "answer": [
      0,
      2
    ],
    "explanation": "Account-level S3 Block Public Access provides preventive guardrails, while AWS Config with auto-remediation provides detective controls and automated correction at scale.",
    "difficulty": "Hard"
  },
  {
    "id": "SAA-540",
    "domainId": "D2",
    "domain": "Design Resilient Architectures",
    "section": "Multi-Region",
    "question": "A global application stores user profile data in DynamoDB and serves images from S3. Requirements: regional failover with minimal downtime, low RPO for profile updates, and global read performance. Operations wants a solution that keeps the architecture mostly serverless.\nWhich solution BEST meets these requirements?",
    "choices": [
      "Use DynamoDB Global Tables for profiles and S3 Cross-Region Replication for images, with Route 53 failover routing",
      "Use a single DynamoDB table in one region and back it up daily to S3 in another region",
      "Use S3 Transfer Acceleration for images and keep DynamoDB single-region",
      "Use CloudFront for images and keep profiles in an RDS database with manual snapshots"
    ],
    "answer": 0,
    "explanation": "Global Tables provide multi-region replication and low RPO for DynamoDB writes. S3 CRR keeps objects replicated. Route 53 failover can direct clients to the healthy region with minimal downtime.",
    "difficulty": "Hard"
  },
  {
    "id": "SAA-541",
    "domainId": "D2",
    "domain": "Design Resilient Architectures",
    "section": "RDS DR",
    "question": "A company runs an RDS PostgreSQL database in eu-west-1. DR requirements: fail over to eu-central-1 within 15 minutes and lose no more than 5 minutes of data. The company wants to avoid maintaining a full active/active database setup.\nWhich design BEST meets these requirements?",
    "choices": [
      "Take manual snapshots every hour and copy them to eu-central-1",
      "Create a cross-region read replica in eu-central-1 and promote it during failover, using automated runbooks and Route 53 failover",
      "Use Multi-AZ in eu-west-1 only",
      "Use AWS Backup daily backups with cross-region copy"
    ],
    "answer": 1,
    "explanation": "A cross-region read replica provides near-real-time replication that can meet a 5-minute RPO and can be promoted to become primary, achieving a faster RTO than snapshot-based restore while avoiding full active/active.",
    "difficulty": "Hard"
  },
  {
    "id": "SAA-542",
    "domainId": "D2",
    "domain": "Design Resilient Architectures",
    "section": "EFS Backup",
    "question": "A company uses Amazon EFS for shared application content. Compliance requires centralized backup policies, retention for 5 years, and protection against backup deletion. They also want cross-region copy for disaster recovery.\nWhich solution BEST satisfies these requirements?",
    "choices": [
      "Use EFS replication only; replication replaces the need for backups",
      "Use AWS Backup to back up EFS with cross-region copy and enable Backup Vault Lock for retention enforcement",
      "Create a cron job on EC2 to rsync EFS to an S3 bucket",
      "Create EFS snapshots manually every week"
    ],
    "answer": 1,
    "explanation": "AWS Backup supports EFS backups with centralized policies, cross-region copy, and Vault Lock to enforce retention and prevent deletion, aligning with compliance needs.",
    "difficulty": "Hard"
  },
  {
    "id": "SAA-543",
    "domainId": "D2",
    "domain": "Design Resilient Architectures",
    "section": "SQS FIFO",
    "question": "A payment processing pipeline must preserve strict ordering per customer and avoid duplicate processing of charge events. Throughput is high but can be partitioned by customer ID. The system must provide exactly-once processing semantics at the queue level.\nWhich solution BEST meets these requirements?",
    "choices": [
      "SQS Standard queue with a single consumer instance",
      "SQS FIFO queue using MessageGroupId = customer ID and content-based deduplication or a DeduplicationId",
      "SNS topic with multiple HTTP subscriptions",
      "Kinesis Data Firehose with S3 destination"
    ],
    "answer": 1,
    "explanation": "SQS FIFO provides ordering within a message group and supports exactly-once processing at the queue level with deduplication features, fitting payment events partitioned by customer.",
    "difficulty": "Hard"
  },
  {
    "id": "SAA-544",
    "domainId": "D2",
    "domain": "Design Resilient Architectures",
    "section": "Deployments",
    "question": "A production service runs on EC2 in an Auto Scaling group behind an ALB. During deployments, the company must avoid dropping in-flight requests and ensure instances are replaced gradually with automatic rollback if health checks fail.\nWhich approach BEST meets these requirements?",
    "choices": [
      "Terminate all instances at once and let Auto Scaling replace them quickly",
      "Use an Auto Scaling Instance Refresh with a minimum healthy percentage, ALB health checks, and a sufficient deregistration delay",
      "Use a single large EC2 instance to avoid deployment complexity",
      "Disable ALB health checks during deployments to prevent replacements"
    ],
    "answer": 1,
    "explanation": "Instance Refresh performs controlled, rolling replacements with health validation. ALB deregistration delay helps drain connections to avoid dropped requests, and failed health checks can stop/rollback the refresh.",
    "difficulty": "Hard"
  },
  {
    "id": "SAA-545",
    "domainId": "D2",
    "domain": "Design Resilient Architectures",
    "section": "Centralized Logging",
    "question": "A company must centralize VPC Flow Logs from 90 accounts to a dedicated security account. They want near-real-time delivery, durable storage, and the ability to query logs later. Teams must not be able to modify or delete the centralized logs.\nWhich solution BEST meets these requirements?",
    "choices": [
      "Send VPC Flow Logs to CloudWatch Logs in each account and rely on cross-account IAM to read them",
      "Publish VPC Flow Logs to a centralized Kinesis Data Firehose delivery stream in the security account and store in an S3 bucket with restrictive policies and optional Object Lock",
      "Export Flow Logs to local EBS volumes and copy them weekly to the security account",
      "Use AWS Config to collect Flow Logs automatically into a central bucket"
    ],
    "answer": 1,
    "explanation": "Kinesis Data Firehose can deliver near-real-time log data to S3 in a central account. Restrictive bucket policies (and Object Lock if needed) prevent member accounts from tampering with centralized logs.",
    "difficulty": "Hard"
  },
  {
    "id": "SAA-546",
    "domainId": "D2",
    "domain": "Design Resilient Architectures",
    "section": "EventBridge",
    "question": "Security findings from multiple AWS accounts must be routed to a central account for automated response. The central team wants to keep rules in one place and avoid deploying identical rules into every account.\nWhich design BEST meets these requirements?",
    "choices": [
      "Create CloudWatch alarms in every account and email the security team",
      "Use EventBridge with a centralized event bus in the security account and add resource policies to allow member accounts to put events to it",
      "Use SQS queues in every account and have the security team poll them continuously",
      "Use VPC Flow Logs to detect security findings and forward them to SNS"
    ],
    "answer": 1,
    "explanation": "A centralized EventBridge event bus with appropriate permissions allows multi-account event ingestion and centralized rule management for automated response workflows.",
    "difficulty": "Hard"
  },
  {
    "id": "SAA-547",
    "domainId": "D2",
    "domain": "Design Resilient Architectures",
    "section": "Step Functions",
    "question": "An order workflow triggers multiple microservices: reserve inventory, charge payment, and schedule shipment. Failures require compensating actions (refund payment or release inventory). The company needs built-in retries, timeouts, and clear execution history for audits.\nWhich solution BEST meets these requirements?",
    "choices": [
      "Use a single Lambda function that calls all services sequentially",
      "Use AWS Step Functions to orchestrate the workflow with retries, catch/compensation steps, and execution history",
      "Use an S3 bucket as a state store and a cron job that checks status",
      "Use an EC2 instance running a custom workflow engine"
    ],
    "answer": 1,
    "explanation": "Step Functions provides native orchestration, retries, timeouts, error handling with compensations, and a full execution history suitable for audits and operational visibility.",
    "difficulty": "Hard"
  },
  {
    "id": "SAA-548",
    "domainId": "D2",
    "domain": "Design Resilient Architectures",
    "section": "EKS",
    "question": "A company runs a critical service on Amazon EKS. Requirements: survive an AZ failure, minimize downtime during node replacements, and ensure workloads are spread across AZs without manual pod placement. The company wants a managed approach.\nWhich design BEST meets these requirements?",
    "choices": [
      "Run a single node group in one AZ and scale vertically for reliability",
      "Use managed node groups spanning multiple AZs, configure multiple replicas, and define Pod Disruption Budgets to control voluntary disruptions",
      "Use self-managed nodes only and disable cluster autoscaler to prevent changes",
      "Run the service on Fargate only and pin all pods to the same subnet"
    ],
    "answer": 1,
    "explanation": "Multi-AZ managed node groups, replicated workloads, and Pod Disruption Budgets improve resiliency and control disruptions during maintenance/replacements in a managed, scalable way.",
    "difficulty": "Hard"
  },
  {
    "id": "SAA-549",
    "domainId": "D2",
    "domain": "Design Resilient Architectures",
    "section": "S3 Replication",
    "question": "A company must replicate critical documents to a second region. The destination copy must be tamper-resistant (including protection from deletions) and retained for at least 1 year even if the source is deleted or encrypted key access is revoked.\nWhich solution BEST meets these requirements?",
    "choices": [
      "Enable S3 Cross-Region Replication to a destination bucket with S3 Object Lock enabled in compliance mode and a retention period of 1 year",
      "Enable S3 Transfer Acceleration and upload the objects twice",
      "Use S3 Lifecycle to move objects to Glacier in the same bucket after 30 days",
      "Use CloudFront caching to keep copies at edge locations"
    ],
    "answer": 0,
    "explanation": "CRR replicates objects to another region. S3 Object Lock in compliance mode enforces retention and prevents deletion/overwrite in the destination during the retention period.",
    "difficulty": "Hard"
  },
  {
    "id": "SAA-550",
    "domainId": "D2",
    "domain": "Design Resilient Architectures",
    "section": "CloudFront",
    "question": "A company serves static content through CloudFront. They store the same content in two S3 buckets in different regions. Requirements: CloudFront must automatically fail over to the secondary bucket if the primary bucket becomes unavailable, and the solution must not require DNS changes during an outage.\nWhich configuration BEST meets these requirements?",
    "choices": [
      "Use Route 53 weighted routing between the two S3 buckets",
      "Use a CloudFront origin group with primary and secondary origins and configure origin failover criteria",
      "Use S3 Transfer Acceleration and rely on faster routing",
      "Create an ALB in front of S3 and configure health checks"
    ],
    "answer": 1,
    "explanation": "CloudFront origin groups support origin failover from primary to secondary based on configured failover criteria, without DNS changes during incidents.",
    "difficulty": "Hard"
  },
  {
    "id": "SAA-551",
    "domainId": "D2",
    "domain": "Design Resilient Architectures",
    "section": "Auto Scaling (Select TWO)",
    "question": "A workload has predictable daily traffic spikes at known times and also random flash spikes. Requirements: pre-provision capacity for known spikes, react quickly to random spikes, and reduce unnecessary spend when traffic drops.\nWhich TWO Auto Scaling features should be used together? (Choose TWO.)",
    "choices": [
      "Scheduled scaling actions for predictable spikes",
      "Target tracking scaling based on ALB request count per target",
      "Disable scale-in to avoid churn",
      "Use a fixed desired capacity and manually adjust weekly",
      "Use only CPU-based step scaling with 10-minute evaluation periods"
    ],
    "answer": [
      0,
      1
    ],
    "explanation": "Scheduled scaling prepares capacity for known events, while target tracking reacts quickly to unexpected demand and scales back when traffic drops, optimizing both performance and cost.",
    "difficulty": "Hard"
  },
  {
    "id": "SAA-552",
    "domainId": "D3",
    "domain": "Design High-Performing Architectures",
    "section": "DynamoDB / DAX",
    "question": "A gaming API uses DynamoDB for player sessions and receives extremely read-heavy traffic with strict low-latency requirements. The application can tolerate eventually consistent reads for session lookups, and the team wants a managed caching layer that integrates directly with DynamoDB without rewriting the data model.\nWhich solution BEST improves read performance?",
    "choices": [
      "Add DynamoDB Streams to speed up reads",
      "Use DynamoDB Accelerator (DAX) in front of the table for cached reads",
      "Move the session store to S3 and cache with CloudFront",
      "Use RDS read replicas and migrate the session table to MySQL"
    ],
    "answer": 1,
    "explanation": "DAX is a managed, DynamoDB-compatible cache that improves read performance significantly with minimal application changes, especially for read-heavy, eventually consistent access patterns.",
    "difficulty": "Hard"
  },
  {
    "id": "SAA-553",
    "domainId": "D3",
    "domain": "Design High-Performing Architectures",
    "section": "Kinesis",
    "question": "A real-time analytics platform uses Kinesis Data Streams and has 15 independent consumer applications that all need sub-second access to the same data. The current shared throughput per shard is causing consumer lag.\nWhich option BEST reduces consumer contention while keeping low latency?",
    "choices": [
      "Reduce the number of shards to concentrate throughput",
      "Enable enhanced fan-out for the consumer applications",
      "Switch to SQS Standard queues and have each consumer poll",
      "Write the stream directly to S3 and query with Athena"
    ],
    "answer": 1,
    "explanation": "Enhanced fan-out provides dedicated read throughput per consumer and improves parallel consumption performance while maintaining low latency.",
    "difficulty": "Hard"
  },
  {
    "id": "SAA-554",
    "domainId": "D3",
    "domain": "Design High-Performing Architectures",
    "section": "S3 Transfer",
    "question": "A mobile app uploads large videos from users around the world into a single S3 bucket in us-east-1. Upload performance is inconsistent for users far from the region. The company wants the simplest managed solution to accelerate uploads without deploying additional servers.\nWhich solution BEST meets these requirements?",
    "choices": [
      "Enable S3 Transfer Acceleration for the bucket",
      "Enable CloudFront with the bucket as origin and use signed cookies",
      "Create multiple buckets in different regions and build custom routing logic",
      "Use Amazon EFS mounted in multiple regions"
    ],
    "answer": 0,
    "explanation": "S3 Transfer Acceleration uses AWS edge locations to speed up long-distance uploads to a single bucket without extra infrastructure.",
    "difficulty": "Hard"
  },
  {
    "id": "SAA-555",
    "domainId": "D3",
    "domain": "Design High-Performing Architectures",
    "section": "FSx",
    "question": "A company migrates Windows file shares used by hundreds of users. They require SMB support, Windows ACLs, Multi-AZ high availability, and integrated backups/snapshots. They also want to minimize operational effort and keep a familiar file-server experience.\nWhich solution BEST meets these requirements?",
    "choices": [
      "Amazon EFS with Max I/O mode",
      "Amazon FSx for Windows File Server with Multi-AZ deployment",
      "Amazon S3 with static website hosting",
      "Amazon FSx for Lustre with scratch deployment"
    ],
    "answer": 1,
    "explanation": "FSx for Windows File Server is purpose-built for SMB shares with Windows permissions and supports Multi-AZ and native integration for backups and availability.",
    "difficulty": "Hard"
  },
  {
    "id": "SAA-556",
    "domainId": "D3",
    "domain": "Design High-Performing Architectures",
    "section": "Load Balancing",
    "question": "A microservice uses gRPC over HTTP/2 and requires Layer 7 routing based on host/path while maintaining end-to-end TLS. The team wants managed routing features rather than building them in the service.\nWhich load balancer BEST meets these requirements?",
    "choices": [
      "Application Load Balancer",
      "Network Load Balancer",
      "Gateway Load Balancer",
      "Classic Load Balancer"
    ],
    "answer": 0,
    "explanation": "ALB supports Layer 7 routing and gRPC over HTTP/2, enabling host/path routing and managed request handling capabilities.",
    "difficulty": "Hard"
  },
  {
    "id": "SAA-557",
    "domainId": "D3",
    "domain": "Design High-Performing Architectures",
    "section": "EBS",
    "question": "A big data workload performs large sequential reads and writes and is sensitive to throughput rather than random IOPS. The data does not require the low-latency characteristics of SSD. The team wants the most suitable EBS volume type for sustained throughput.\nWhich volume type is BEST?",
    "choices": [
      "io2",
      "gp3",
      "st1",
      "sc1"
    ],
    "answer": 2,
    "explanation": "st1 (Throughput Optimized HDD) is designed for frequently accessed, throughput-intensive workloads with large sequential I/O patterns.",
    "difficulty": "Hard"
  },
  {
    "id": "SAA-558",
    "domainId": "D3",
    "domain": "Design High-Performing Architectures",
    "section": "RDS",
    "question": "A serverless API experiences sudden bursts of traffic and opens thousands of database connections to an RDS PostgreSQL instance. The database frequently reaches max connections, causing errors. The team wants a managed solution that reduces connection overhead without rewriting the application significantly.\nWhich solution BEST addresses this issue?",
    "choices": [
      "Increase the RDS instance storage size",
      "Use RDS Proxy to pool and manage connections",
      "Enable Multi-AZ to increase max connections automatically",
      "Move the database to an EC2 instance store volume"
    ],
    "answer": 1,
    "explanation": "RDS Proxy pools and multiplexes connections to reduce connection storms and improves database availability during traffic spikes with minimal application changes.",
    "difficulty": "Hard"
  },
  {
    "id": "SAA-559",
    "domainId": "D3",
    "domain": "Design High-Performing Architectures",
    "section": "CloudFront Security",
    "question": "A media company sells premium downloadable content. Files are stored privately in S3 and delivered through CloudFront. Requirements: prevent direct S3 access, ensure only paying users can download, and allow access to expire after a short period. The company also wants to reduce origin load.\nWhich solution BEST meets these requirements?",
    "choices": [
      "Make the S3 bucket public and rely on obscurity of object keys",
      "Use CloudFront signed URLs or signed cookies with an Origin Access Control (OAC) to a private S3 bucket",
      "Use S3 static website hosting with basic auth",
      "Use Route 53 geolocation routing to restrict access"
    ],
    "answer": 1,
    "explanation": "CloudFront signed URLs/cookies enforce time-bound access for authorized users, while OAC keeps S3 private and prevents direct access. CloudFront caching reduces origin load.",
    "difficulty": "Hard"
  },
  {
    "id": "SAA-560",
    "domainId": "D3",
    "domain": "Design High-Performing Architectures",
    "section": "DynamoDB",
    "question": "A fintech service needs to update multiple items in DynamoDB as part of a single operation (debit one account, credit another, and write an audit record). Partial updates are not allowed, and the system must guarantee all-or-nothing behavior.\nWhich DynamoDB feature BEST meets this requirement?",
    "choices": [
      "DynamoDB Streams",
      "DynamoDB Transactions",
      "Global Secondary Indexes",
      "Time to Live (TTL)"
    ],
    "answer": 1,
    "explanation": "DynamoDB transactions provide atomic, all-or-nothing updates across multiple items and tables, preventing partial writes in financial transfer scenarios.",
    "difficulty": "Hard"
  },
  {
    "id": "SAA-561",
    "domainId": "D3",
    "domain": "Design High-Performing Architectures",
    "section": "ECS",
    "question": "A stateless service on ECS must scale rapidly and minimize cost using Spot where possible, but it also needs a guaranteed baseline capacity to avoid outages when Spot capacity is reclaimed. The team wants ECS to manage placement and scaling automatically.\nWhich solution BEST meets these requirements?",
    "choices": [
      "Run everything on On-Demand only",
      "Use ECS capacity providers with a base capacity on On-Demand and additional capacity on Spot",
      "Use a single EC2 instance with Docker Compose",
      "Use Lambda for all workloads including long-running services"
    ],
    "answer": 1,
    "explanation": "ECS capacity providers can define baseline On-Demand capacity with additional Spot capacity for cost savings while maintaining availability during Spot interruptions.",
    "difficulty": "Hard"
  },
  {
    "id": "SAA-562",
    "domainId": "D3",
    "domain": "Design High-Performing Architectures",
    "section": "Global Networking",
    "question": "A real-time multiplayer game uses UDP and requires consistently low latency for players worldwide. The game servers run in multiple regions and the company wants fast regional failover without relying on DNS TTL.\nWhich AWS service BEST meets these requirements?",
    "choices": [
      "Amazon CloudFront",
      "AWS Global Accelerator",
      "Amazon Route 53 weighted routing only",
      "AWS Direct Connect"
    ],
    "answer": 1,
    "explanation": "Global Accelerator provides static anycast IPs, routes users to the nearest healthy regional endpoint over the AWS global network, supports TCP/UDP, and enables fast health-based failover without DNS delays.",
    "difficulty": "Hard"
  },
  {
    "id": "SAA-563",
    "domainId": "D3",
    "domain": "Design High-Performing Architectures",
    "section": "Multi-Region Performance (Select TWO)",
    "question": "A global API is deployed active/active in two regions. Requirements: users should automatically reach the nearest healthy region, failover must be fast (no long DNS caching delays), and the solution must work well for both HTTP and non-HTTP protocols.\nWhich TWO solutions BEST meet these requirements? (Choose TWO.)",
    "choices": [
      "AWS Global Accelerator with health checks and endpoint weights",
      "Route 53 latency-based routing with health checks",
      "CloudFront only, without any origin health-based routing",
      "Manual DNS updates during incidents",
      "Using a single regional endpoint and scaling vertically"
    ],
    "answer": [
      0,
      1
    ],
    "explanation": "Global Accelerator provides fast, anycast-based routing and failover for multiple protocols. Route 53 latency routing with health checks is also appropriate for directing users to the nearest healthy region for DNS-based clients.",
    "difficulty": "Hard"
  },
  {
    "id": "SAA-564",
    "domainId": "D4",
    "domain": "Design Cost-Optimized Architectures",
    "section": "S3 Lifecycle",
    "question": "A company stores compliance archives in S3. Data is frequently accessed for the first 45 days, occasionally accessed for the next 6 months, and then rarely accessed but must be retrievable within 24 hours for 7 years. The company wants maximum cost savings while meeting access SLAs.\nWhich storage strategy BEST fits these requirements?",
    "choices": [
      "Keep everything in S3 Standard for 7 years",
      "Use lifecycle transitions: S3 Standard (45 days) -> S3 Standard-IA (6 months) -> S3 Glacier Flexible Retrieval for long-term retention",
      "Move everything directly to S3 Glacier Deep Archive after 45 days",
      "Use S3 One Zone-IA for all objects to reduce cost"
    ],
    "answer": 1,
    "explanation": "The lifecycle strategy aligns storage tiers with access frequency while meeting the 24-hour retrieval requirement using Glacier Flexible Retrieval for long-term archival.",
    "difficulty": "Hard"
  },
  {
    "id": "SAA-565",
    "domainId": "D4",
    "domain": "Design Cost-Optimized Architectures",
    "section": "Savings Plans",
    "question": "A company runs a large fleet of EC2 instances across multiple instance families and plans to continue for at least 3 years. They frequently change instance types as they optimize performance, but overall compute spend is stable. They want the best discount without being locked to a single instance family.\nWhich option provides the BEST fit?",
    "choices": [
      "Standard Reserved Instances for a single instance type",
      "Compute Savings Plans for a 3-year term",
      "Spot Instances only for all workloads",
      "Dedicated Hosts with 3-year commitments"
    ],
    "answer": 1,
    "explanation": "Compute Savings Plans provide flexible discounts across instance families and sizes, matching stable spend while allowing frequent instance type changes.",
    "difficulty": "Hard"
  },
  {
    "id": "SAA-566",
    "domainId": "D4",
    "domain": "Design Cost-Optimized Architectures",
    "section": "NAT Cost Optimization",
    "question": "A workload in private subnets generates high monthly NAT Gateway charges. Most traffic is to S3 and DynamoDB, and the security team prefers traffic stay on the AWS network. The company wants to reduce cost without changing the application.\nWhich change provides the MOST cost-effective improvement?",
    "choices": [
      "Replace NAT Gateway with a NAT instance",
      "Create gateway VPC endpoints for S3 and DynamoDB and update route tables",
      "Add more NAT Gateways (one per AZ) to distribute traffic",
      "Move the instances to public subnets"
    ],
    "answer": 1,
    "explanation": "Gateway endpoints keep S3 and DynamoDB traffic off NAT, reducing data processing charges and keeping traffic private on the AWS network.",
    "difficulty": "Hard"
  },
  {
    "id": "SAA-567",
    "domainId": "D4",
    "domain": "Design Cost-Optimized Architectures",
    "section": "Analytics",
    "question": "A team stores 200 TB of logs in S3 and needs to run occasional ad hoc SQL queries without managing servers or clusters. Most queries scan only a few columns and the team wants to minimize cost.\nWhich service is MOST appropriate?",
    "choices": [
      "Amazon Redshift provisioned cluster",
      "Amazon Athena querying data in S3",
      "Amazon RDS MySQL with the logs imported into tables",
      "Amazon OpenSearch with all logs indexed immediately"
    ],
    "answer": 1,
    "explanation": "Athena is serverless and cost-effective for ad hoc SQL over data in S3, especially when using columnar formats and partitioning to reduce scanned data.",
    "difficulty": "Hard"
  },
  {
    "id": "SAA-568",
    "domainId": "D4",
    "domain": "Design Cost-Optimized Architectures",
    "section": "CloudFront Pricing",
    "question": "A company distributes content mostly to Europe and North America. They want CloudFront but want to reduce costs by limiting edge locations used while still serving these regions well.\nWhich configuration BEST meets this requirement?",
    "choices": [
      "Enable S3 Transfer Acceleration",
      "Set CloudFront to use a restricted Price Class that includes only the needed regions",
      "Disable caching and forward all requests to the origin",
      "Use Route 53 geolocation routing instead of CloudFront"
    ],
    "answer": 1,
    "explanation": "CloudFront Price Classes restrict edge locations to a subset of regions, reducing cost while still providing good performance in targeted geographies.",
    "difficulty": "Hard"
  },
  {
    "id": "SAA-569",
    "domainId": "D4",
    "domain": "Design Cost-Optimized Architectures",
    "section": "EBS Optimization",
    "question": "A company uses gp2 volumes and sees unpredictable performance and growing costs. Metrics show they need consistent baseline performance with occasional bursts. They also want the ability to tune IOPS and throughput independently.\nWhich change is MOST cost-effective?",
    "choices": [
      "Migrate all volumes to io2",
      "Migrate to gp3 and right-size IOPS and throughput to match observed metrics",
      "Switch volumes to sc1 for lower cost",
      "Move the data to instance store only"
    ],
    "answer": 1,
    "explanation": "gp3 provides predictable performance and separates volume size from IOPS/throughput settings, enabling cost-effective right-sizing compared to gp2 and avoiding io2 overkill.",
    "difficulty": "Hard"
  },
  {
    "id": "SAA-570",
    "domainId": "D4",
    "domain": "Design Cost-Optimized Architectures",
    "section": "Spot / Mixed Instances",
    "question": "A stateless web tier runs behind an ALB with Auto Scaling. The company wants to reduce cost using Spot but must keep a guaranteed minimum capacity and automatically replace interrupted instances without downtime.\nWhich solution BEST meets these requirements?",
    "choices": [
      "Use Spot Instances only with no On-Demand",
      "Use an Auto Scaling group with a mixed instances policy: On-Demand base capacity and Spot for the remainder, with capacity rebalance enabled",
      "Use Dedicated Hosts for all instances",
      "Use Reserved Instances for peak capacity and On-Demand for baseline"
    ],
    "answer": 1,
    "explanation": "Mixed instances with an On-Demand base ensures availability, while Spot reduces costs for additional capacity. Capacity rebalance helps proactively replace Spot instances when interruption risk rises.",
    "difficulty": "Hard"
  },
  {
    "id": "SAA-571",
    "domainId": "D4",
    "domain": "Design Cost-Optimized Architectures",
    "section": "Databases",
    "question": "A development environment database is used intermittently, with heavy usage during daytime and almost no usage at night. The team wants to reduce costs while keeping the same relational engine and minimizing operational effort.\nWhich option BEST meets these requirements?",
    "choices": [
      "Enable Multi-AZ to reduce cost during off hours",
      "Automate start/stop schedules for the database where supported, or use an auto-scaling serverless relational option for variable usage",
      "Move the database to a larger instance to finish daytime work faster",
      "Store the database files in S3 and mount them from EC2"
    ],
    "answer": 1,
    "explanation": "Stopping nonproduction databases during idle hours or using a serverless relational option for variable demand reduces compute spend with minimal operational complexity.",
    "difficulty": "Hard"
  },
  {
    "id": "SAA-572",
    "domainId": "D4",
    "domain": "Design Cost-Optimized Architectures",
    "section": "Data Transfer",
    "question": "A service has two tightly coupled tiers with high east-west traffic. They are deployed across multiple AZs and data transfer charges are unexpectedly high. The system must remain highly available, but the company wants to reduce cross-AZ transfer costs.\nWhich design change BEST reduces cost without eliminating high availability?",
    "choices": [
      "Pin both tiers to a single AZ and remove Multi-AZ for the service",
      "Use zonal awareness: keep paired components in the same AZ where possible, and use an ALB with cross-zone load balancing disabled while maintaining instances in multiple AZs",
      "Move the service to a single EC2 instance and scale vertically",
      "Route all traffic through a NAT Gateway to simplify networking"
    ],
    "answer": 1,
    "explanation": "Keeping chatty traffic within the same AZ reduces cross-AZ data transfer while maintaining multi-AZ capacity. Disabling cross-zone load balancing can help keep traffic zonal depending on the architecture and client flow.",
    "difficulty": "Hard"
  },
  {
    "id": "SAA-573",
    "domainId": "D4",
    "domain": "Design Cost-Optimized Architectures",
    "section": "S3",
    "question": "A dataset has unpredictable access patterns across millions of objects. The team does not want to constantly tune lifecycle policies, but they do want to minimize storage cost while keeping retrieval straightforward for frequently accessed data.\nWhich S3 option BEST meets these requirements?",
    "choices": [
      "S3 Glacier Deep Archive",
      "S3 Intelligent-Tiering",
      "S3 One Zone-IA",
      "S3 Standard only"
    ],
    "answer": 1,
    "explanation": "Intelligent-Tiering automatically moves objects between access tiers based on usage while keeping retrieval seamless, reducing the need for complex lifecycle tuning.",
    "difficulty": "Hard"
  },
  {
    "id": "SAA-574",
    "domainId": "D4",
    "domain": "Design Cost-Optimized Architectures",
    "section": "EFS",
    "question": "A company stores large amounts of shared files on EFS. Analysis shows most files are rarely accessed after 30 days, but they must remain available immediately. The company wants to reduce storage cost automatically.\nWhich option BEST meets these requirements?",
    "choices": [
      "Enable EFS Lifecycle Management to move files to EFS Infrequent Access after 30 days",
      "Move the entire file system to S3 Glacier Deep Archive",
      "Disable backups to reduce cost",
      "Switch to Provisioned IOPS SSD volumes on EBS"
    ],
    "answer": 0,
    "explanation": "EFS Lifecycle Management transitions files to EFS Infrequent Access automatically based on last access, reducing cost while keeping immediate availability.",
    "difficulty": "Hard"
  },
  {
    "id": "SAA-575",
    "domainId": "D4",
    "domain": "Design Cost-Optimized Architectures",
    "section": "Compute Strategy (Select TWO)",
    "question": "A company runs three workloads: (1) a 24/7 web tier with steady demand, (2) nightly batch processing that can be interrupted and resumes from checkpoints, and (3) a stateful workload that must complete once started and runs a few times per week. The company wants the greatest cost savings while maintaining reliability.\nWhich TWO purchasing approaches BEST match these requirements? (Choose TWO.)",
    "choices": [
      "Use 3-year commitment discounts (Savings Plans or Standard RIs) for the steady 24/7 web tier",
      "Use Spot Instances for the interruptible batch jobs with checkpointing",
      "Use Spot Instances only for the stateful workload that cannot be interrupted",
      "Use Dedicated Hosts for all workloads to maximize discounts",
      "Use On-Demand only for all workloads to avoid commitments"
    ],
    "answer": [
      0,
      1
    ],
    "explanation": "Committed discounts are best for predictable 24/7 usage, and Spot is ideal for interruptible batch workloads with checkpointing. Stateful jobs that cannot be interrupted generally need On-Demand or committed capacity, not Spot-only.",
    "difficulty": "Hard"
  },
  {
    "id": "SAA-576",
    "domainId": "D1",
    "domain": "Design Secure Architectures",
    "section": "Egress Filtering",
    "question": "A company must enforce outbound web access controls for workloads in private subnets: only allow traffic to approved domains, log all DNS queries, and block known malicious domains. The solution must be managed and require minimal custom infrastructure.\nWhich solution BEST meets these requirements?",
    "choices": [
      "Use only security groups with destination CIDR allowlists",
      "Use Route 53 Resolver DNS Firewall for domain blocking and logging, and route outbound traffic through a controlled egress point",
      "Use S3 bucket policies to restrict outbound traffic",
      "Use IAM policies to deny access to the internet"
    ],
    "answer": 1,
    "explanation": "Route 53 Resolver DNS Firewall supports managed domain allow/deny lists and DNS query logging. Combined with controlled egress, it enforces outbound domain policies without heavy custom infrastructure.",
    "difficulty": "Hard"
  },
  {
    "id": "SAA-577",
    "domainId": "D1",
    "domain": "Design Secure Architectures",
    "section": "Systems Manager",
    "question": "A company forbids inbound SSH/RDP to production instances. Administrators must still access instances for troubleshooting, sessions must be logged, and access must be controlled via IAM with MFA. The solution must work in private subnets.\nWhich solution BEST meets these requirements?",
    "choices": [
      "Open port 22 to the corporate IP range and log sessions locally",
      "Use AWS Systems Manager Session Manager with IAM-based access control and session logging to CloudWatch Logs or S3",
      "Use a bastion host in a public subnet and allow SSH from 0.0.0.0/0",
      "Use EC2 serial console and share the credentials across the team"
    ],
    "answer": 1,
    "explanation": "Session Manager provides agent-based access without inbound ports, supports IAM controls (including MFA via federation), and can log sessions to CloudWatch Logs/S3 for auditing.",
    "difficulty": "Hard"
  },
  {
    "id": "SAA-578",
    "domainId": "D1",
    "domain": "Design Secure Architectures",
    "section": "Certificate Management",
    "question": "A company operates multiple internal APIs and wants end-to-end TLS with privately trusted certificates. They also require centralized issuance and automated renewal without manual distribution of private keys.\nWhich solution BEST meets these requirements?",
    "choices": [
      "Use public ACM certificates for internal endpoints",
      "Use ACM Private CA to issue private certificates and integrate renewal with the services",
      "Use self-signed certs and store them in S3 for manual updates",
      "Use AWS Secrets Manager to store certificates and rotate them weekly"
    ],
    "answer": 1,
    "explanation": "ACM Private CA provides centralized issuance of private certificates with managed lifecycle features, enabling automated renewals without manual key distribution workflows.",
    "difficulty": "Hard"
  },
  {
    "id": "SAA-579",
    "domainId": "D2",
    "domain": "Design Resilient Architectures",
    "section": "DR Automation",
    "question": "A company uses a cross-region RDS read replica for disaster recovery. They want automated failover that promotes the replica when the primary region fails, updates application endpoints, and avoids human intervention. The company is fine with DNS-based client routing.\nWhich approach BEST meets these requirements?",
    "choices": [
      "Write a manual runbook and have on-call engineers promote the replica and update DNS",
      "Use Route 53 failover records with health checks plus automation (Lambda/SSM) to promote the replica and update records if needed",
      "Use S3 Transfer Acceleration to improve database replication speed",
      "Enable Multi-AZ only and rely on it for regional failover"
    ],
    "answer": 1,
    "explanation": "Route 53 health-based failover can switch endpoints, while automation can promote the replica to primary. Multi-AZ does not provide cross-region failover, and manual runbooks do not meet the automation requirement.",
    "difficulty": "Hard"
  },
  {
    "id": "SAA-580",
    "domainId": "D2",
    "domain": "Design Resilient Architectures",
    "section": "DynamoDB Recovery",
    "question": "A company must protect a DynamoDB table from accidental writes and deletes. They require the ability to restore the table to any point within the last 35 days and also need periodic retained backups for long-term retention beyond that window.\nWhich solution BEST meets these requirements?",
    "choices": [
      "Enable DynamoDB Streams and replay events for 35 days",
      "Enable DynamoDB Point-in-Time Recovery (PITR) and also create on-demand backups for long-term retention",
      "Export the table to S3 daily and delete the table after each export",
      "Use TTL to remove items and treat that as backup"
    ],
    "answer": 1,
    "explanation": "PITR enables point-in-time restore within the retention window. On-demand backups can be retained for longer periods to satisfy long-term retention requirements.",
    "difficulty": "Hard"
  },
  {
    "id": "SAA-581",
    "domainId": "D3",
    "domain": "Design High-Performing Architectures",
    "section": "S3 Select",
    "question": "A data pipeline stores large CSV objects in S3. A downstream job frequently needs only a few columns and a subset of rows. The company wants to reduce data transfer and speed up processing without building a separate database.\nWhich solution BEST meets these requirements?",
    "choices": [
      "Use S3 Select to retrieve only required columns/rows from objects",
      "Enable S3 Object Lock to speed up reads",
      "Use CloudFront to cache the entire CSV files",
      "Move the data to EBS volumes and run queries locally"
    ],
    "answer": 0,
    "explanation": "S3 Select allows querying and retrieving a subset of data within an object, reducing both transferred bytes and processing time for selective reads.",
    "difficulty": "Hard"
  },
  {
    "id": "SAA-582",
    "domainId": "D3",
    "domain": "Design High-Performing Architectures",
    "section": "HPC Storage",
    "question": "A scientific simulation workload runs on hundreds of Linux instances and needs a shared file system with extremely high aggregate throughput and low-latency metadata operations. Data must be staged from and persisted to S3 for long-term storage, while the compute phase needs high-speed POSIX access.\nWhich solution BEST meets these requirements?",
    "choices": [
      "Amazon EFS with Elastic throughput only",
      "Amazon FSx for Lustre integrated with S3 for import/export",
      "Amazon S3 Glacier Flexible Retrieval as primary storage",
      "Amazon RDS as a file store with BLOB columns"
    ],
    "answer": 1,
    "explanation": "FSx for Lustre is designed for HPC-style parallel file system performance and supports integration with S3 to stage and persist data while providing high-speed POSIX access during compute phases.",
    "difficulty": "Hard"
  },
  {
    "id": "SAA-583",
    "domainId": "D2",
    "domain": "Design Resilient Architectures",
    "section": "Messaging (Select TWO)",
    "question": "A system must distribute the same event to multiple independent processing services. Requirements: each service must receive its own copy, processing must be durable even if a consumer is down for hours, and the publisher should not need to know who the consumers are.\nWhich TWO AWS services should be used together to BEST meet these requirements? (Choose TWO.)",
    "choices": [
      "Amazon SNS topic for fanout publishing",
      "Amazon SQS queues subscribed to the SNS topic for durable per-consumer processing",
      "A single SQS queue with multiple consumers competing for messages",
      "An EBS volume shared across instances",
      "A Route 53 hosted zone with multiple A records"
    ],
    "answer": [
      0,
      1
    ],
    "explanation": "SNS provides pub/sub fanout while SQS subscriptions give each consumer a durable queue, ensuring each service gets its own copy and can process asynchronously even if temporarily offline.",
    "difficulty": "Hard"
  },
  {
    "id": "SAA-584",
    "domainId": "D4",
    "domain": "Design Cost-Optimized Architectures",
    "section": "Logging Costs",
    "question": "A company ingests large volumes of application logs to CloudWatch Logs and costs are growing rapidly. They need fast search for the last 14 days but must retain raw logs for 2 years. The company wants to reduce cost while preserving query capability for recent data.\nWhich solution BEST meets these requirements?",
    "choices": [
      "Set CloudWatch Logs retention to 14 days and stream logs to S3 (for long-term retention) using a subscription to Kinesis Data Firehose",
      "Keep CloudWatch Logs forever and export to S3 once per year",
      "Disable logs during peak hours to reduce ingestion cost",
      "Store logs only on instance disks and rotate weekly"
    ],
    "answer": 0,
    "explanation": "Short retention in CloudWatch supports fast recent queries while Firehose delivery to S3 provides low-cost long-term retention. This aligns storage tiers with access needs and reduces ongoing CloudWatch cost.",
    "difficulty": "Hard"
  },
  {
    "id": "SAA-585",
    "domainId": "D3",
    "domain": "Design High-Performing Architectures",
    "section": "Search Analytics",
    "question": "A company needs near real-time search and filtering over application logs (seconds to minutes), including full-text search and aggregations. Logs are produced continuously and the team wants managed scaling and high availability.\nWhich solution BEST meets these requirements?",
    "choices": [
      "Amazon Athena over S3 with partitioning",
      "Amazon OpenSearch Service with an ingestion pipeline (for example, Firehose) to index logs",
      "Amazon RDS MySQL with a single table for all logs",
      "S3 Glacier Deep Archive with restore-on-demand"
    ],
    "answer": 1,
    "explanation": "OpenSearch is designed for near real-time indexing, full-text search, and aggregations over log data, and can be fed by managed ingestion services such as Firehose.",
    "difficulty": "Hard"
  }
]