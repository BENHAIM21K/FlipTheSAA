[
  {
    "id": "SAA-001",
    "domainId": "D1",
    "domain": "Design Secure Architectures",
    "section": "IAM",
    "question": "Which feature lets you grant temporary permissions to access AWS resources?",
    "choices": [
      "IAM Users",
      "IAM Groups",
      "IAM Roles",
      "Resource Tags"
    ],
    "answer": 2,
    "explanation": "IAM Roles provide temporary credentials and are commonly assumed by services/users.",
    "difficulty": "Easy"
  },
  {
    "id": "SAA-002",
    "domainId": "D1",
    "domain": "Design Secure Architectures",
    "section": "IAM",
    "question": "What is the best practice for the AWS account root user?",
    "choices": [
      "Use it daily",
      "Disable it",
      "Enable MFA and avoid using it",
      "Share it with admins"
    ],
    "answer": 2,
    "explanation": "Best practice: enable MFA on root and use it only for rare account tasks.",
    "difficulty": "Easy"
  },
  {
    "id": "SAA-003",
    "domainId": "D1",
    "domain": "Design Secure Architectures",
    "section": "KMS",
    "question": "Which AWS service manages encryption keys used to encrypt data in AWS services?",
    "choices": [
      "AWS KMS",
      "AWS Shield",
      "Amazon Inspector",
      "AWS Budgets"
    ],
    "answer": 0,
    "explanation": "AWS KMS manages keys and integrates with many AWS services for encryption.",
    "difficulty": "Easy"
  },
  {
    "id": "SAA-004",
    "domainId": "D1",
    "domain": "Design Secure Architectures",
    "section": "S3",
    "question": "Which S3 feature prevents objects from being deleted or overwritten for a retention period?",
    "choices": [
      "S3 Transfer Acceleration",
      "S3 Object Lock",
      "S3 Inventory",
      "S3 Select"
    ],
    "answer": 1,
    "explanation": "S3 Object Lock helps enforce WORM (write once, read many) retention.",
    "difficulty": "Easy"
  },
  {
    "id": "SAA-005",
    "domainId": "D1",
    "domain": "Design Secure Architectures",
    "section": "VPC",
    "question": "Which VPC component acts as a virtual firewall at the instance level?",
    "choices": [
      "Network ACL",
      "Security Group",
      "Route Table",
      "Internet Gateway"
    ],
    "answer": 1,
    "explanation": "Security Groups are stateful and apply at the ENI/instance level.",
    "difficulty": "Easy"
  },
  {
    "id": "SAA-006",
    "domainId": "D1",
    "domain": "Design Secure Architectures",
    "section": "VPC",
    "question": "Which VPC component is stateless and filters traffic at the subnet boundary?",
    "choices": [
      "Security Group",
      "Network ACL",
      "VPC Peering",
      "NAT Gateway"
    ],
    "answer": 1,
    "explanation": "Network ACLs are stateless and operate at the subnet level.",
    "difficulty": "Easy"
  },
  {
    "id": "SAA-007",
    "domainId": "D1",
    "domain": "Design Secure Architectures",
    "section": "CloudWatch",
    "question": "Which service records AWS API calls for auditing and compliance?",
    "choices": [
      "CloudWatch",
      "CloudTrail",
      "Config",
      "X-Ray"
    ],
    "answer": 1,
    "explanation": "CloudTrail logs API activity (who did what, when, and from where).",
    "difficulty": "Easy"
  },
  {
    "id": "SAA-008",
    "domainId": "D1",
    "domain": "Design Secure Architectures",
    "section": "CloudFront",
    "question": "To block common web exploits (like SQL injection) in front of a CloudFront distribution, what should you use?",
    "choices": [
      "AWS WAF",
      "AWS KMS",
      "AWS Config",
      "Amazon EBS"
    ],
    "answer": 0,
    "explanation": "AWS WAF integrates with CloudFront (and ALB/API Gateway) to filter malicious HTTP requests.",
    "difficulty": "Easy"
  },
  {
    "id": "SAA-009",
    "domainId": "D1",
    "domain": "Design Secure Architectures",
    "section": "RDS",
    "question": "Where should you store database credentials securely with automatic rotation support?",
    "choices": [
      "S3 Standard",
      "Hardcode in app config",
      "AWS Secrets Manager",
      "CloudWatch Logs"
    ],
    "answer": 2,
    "explanation": "Secrets Manager is designed for secrets storage and rotation workflows.",
    "difficulty": "Easy"
  },
  {
    "id": "SAA-010",
    "domainId": "D1",
    "domain": "Design Secure Architectures",
    "section": "S3",
    "question": "How do you restrict S3 access so only CloudFront can read objects privately?",
    "choices": [
      "Make the bucket public",
      "Use an Origin Access Control/Identity with bucket policy",
      "Use S3 website hosting",
      "Disable Block Public Access"
    ],
    "answer": 1,
    "explanation": "Use CloudFront OAC/OAI + a bucket policy to keep S3 private.",
    "difficulty": "Easy"
  },
  {
    "id": "SAA-011",
    "domainId": "D2",
    "domain": "Design Resilient Architectures",
    "section": "ELB",
    "question": "Which load balancer feature helps route traffic to healthy targets only?",
    "choices": [
      "Sticky sessions",
      "Health checks",
      "Path rewriting",
      "TLS termination"
    ],
    "answer": 1,
    "explanation": "Health checks detect unhealthy targets so traffic stops routing to them.",
    "difficulty": "Easy"
  },
  {
    "id": "SAA-012",
    "domainId": "D2",
    "domain": "Design Resilient Architectures",
    "section": "Auto Scaling",
    "question": "What AWS feature automatically replaces unhealthy EC2 instances in a fleet?",
    "choices": [
      "EC2 Spot",
      "Auto Scaling Group",
      "Elastic Beanstalk",
      "AWS Batch"
    ],
    "answer": 1,
    "explanation": "ASGs can perform health checks and replace unhealthy instances.",
    "difficulty": "Easy"
  },
  {
    "id": "SAA-013",
    "domainId": "D2",
    "domain": "Design Resilient Architectures",
    "section": "RDS",
    "question": "Which RDS option provides automatic failover to a standby in another AZ?",
    "choices": [
      "Read Replica",
      "Multi-AZ",
      "Reserved Instances",
      "RDS Proxy"
    ],
    "answer": 1,
    "explanation": "Multi-AZ is for HA and automatic failover across AZs.",
    "difficulty": "Easy"
  },
  {
    "id": "SAA-014",
    "domainId": "D2",
    "domain": "Design Resilient Architectures",
    "section": "Route 53",
    "question": "Which Route 53 policy routes traffic to the endpoint with the lowest latency?",
    "choices": [
      "Weighted",
      "Latency-based",
      "Geolocation",
      "Failover"
    ],
    "answer": 1,
    "explanation": "Latency-based routing selects the region/endpoint with the lowest latency.",
    "difficulty": "Easy"
  },
  {
    "id": "SAA-015",
    "domainId": "D2",
    "domain": "Design Resilient Architectures",
    "section": "S3",
    "question": "Which S3 feature replicates objects automatically to another region?",
    "choices": [
      "S3 CRR",
      "S3 Select",
      "S3 Object Lambda",
      "S3 Glacier"
    ],
    "answer": 0,
    "explanation": "Cross-Region Replication (CRR) replicates objects to another region.",
    "difficulty": "Easy"
  },
  {
    "id": "SAA-016",
    "domainId": "D2",
    "domain": "Design Resilient Architectures",
    "section": "EBS",
    "question": "EBS volumes are replicated within which scope by default?",
    "choices": [
      "Across regions",
      "Across AZs",
      "Within a single AZ",
      "Across accounts"
    ],
    "answer": 2,
    "explanation": "EBS is AZ-scoped; it replicates within the same AZ for durability.",
    "difficulty": "Easy"
  },
  {
    "id": "SAA-017",
    "domainId": "D2",
    "domain": "Design Resilient Architectures",
    "section": "DynamoDB",
    "question": "Which DynamoDB feature provides multi-region, active-active replication?",
    "choices": [
      "DAX",
      "Global Tables",
      "Streams",
      "TTL"
    ],
    "answer": 1,
    "explanation": "DynamoDB Global Tables supports multi-region active-active replication.",
    "difficulty": "Easy"
  },
  {
    "id": "SAA-018",
    "domainId": "D2",
    "domain": "Design Resilient Architectures",
    "section": "SQS",
    "question": "Which service decouples components by buffering messages for later processing?",
    "choices": [
      "SNS",
      "SQS",
      "CloudFront",
      "EFS"
    ],
    "answer": 1,
    "explanation": "SQS is a message queue used to decouple and buffer workloads.",
    "difficulty": "Easy"
  },
  {
    "id": "SAA-019",
    "domainId": "D2",
    "domain": "Design Resilient Architectures",
    "section": "Lambda",
    "question": "What happens if an SQS-triggered Lambda cannot process a message repeatedly?",
    "choices": [
      "Message disappears immediately",
      "Message is moved to a DLQ (if configured)",
      "Queue is deleted",
      "Lambda shuts down permanently"
    ],
    "answer": 1,
    "explanation": "After retries/max receive count, messages can go to a DLQ if configured.",
    "difficulty": "Easy"
  },
  {
    "id": "SAA-020",
    "domainId": "D2",
    "domain": "Design Resilient Architectures",
    "section": "CloudFront",
    "question": "Which CloudFront feature helps keep content available if the primary origin fails?",
    "choices": [
      "Origin failover",
      "Geo restriction only",
      "Signed URLs only",
      "Cache invalidations"
    ],
    "answer": 0,
    "explanation": "Origin failover can route requests to a secondary origin if the primary fails.",
    "difficulty": "Easy"
  },
  {
    "id": "SAA-021",
    "domainId": "D3",
    "domain": "Design High-Performing Architectures",
    "section": "CloudFront",
    "question": "What is the main benefit of CloudFront for global users?",
    "choices": [
      "Cheaper EC2",
      "Lower latency via edge caching",
      "More durable EBS",
      "Faster RDS writes"
    ],
    "answer": 1,
    "explanation": "CloudFront caches content at edge locations, reducing latency for users.",
    "difficulty": "Easy"
  },
  {
    "id": "SAA-022",
    "domainId": "D3",
    "domain": "Design High-Performing Architectures",
    "section": "S3",
    "question": "Which S3 feature lets you retrieve only a portion of an object using SQL-like queries?",
    "choices": [
      "S3 Select",
      "S3 CRR",
      "S3 Object Lock",
      "S3 Batch Operations"
    ],
    "answer": 0,
    "explanation": "S3 Select can query subsets of data from an object (like CSV/JSON) to reduce data transfer.",
    "difficulty": "Easy"
  },
  {
    "id": "SAA-023",
    "domainId": "D3",
    "domain": "Design High-Performing Architectures",
    "section": "EFS",
    "question": "Which storage is best for a shared POSIX file system across multiple EC2 instances?",
    "choices": [
      "EBS",
      "EFS",
      "Instance Store",
      "S3 Standard"
    ],
    "answer": 1,
    "explanation": "EFS is a managed NFS file system that can be mounted by many instances.",
    "difficulty": "Easy"
  },
  {
    "id": "SAA-024",
    "domainId": "D3",
    "domain": "Design High-Performing Architectures",
    "section": "EC2",
    "question": "Which feature increases network throughput for supported EC2 instance types?",
    "choices": [
      "Placement Groups",
      "Enhanced Networking",
      "EBS Snapshots",
      "AMI Copy"
    ],
    "answer": 1,
    "explanation": "Enhanced networking (ENA) improves packet per second and throughput.",
    "difficulty": "Easy"
  },
  {
    "id": "SAA-025",
    "domainId": "D3",
    "domain": "Design High-Performing Architectures",
    "section": "ELB",
    "question": "Which load balancer is best for HTTP/HTTPS with path-based routing?",
    "choices": [
      "ALB",
      "NLB",
      "GWLB",
      "Classic Load Balancer only"
    ],
    "answer": 0,
    "explanation": "ALB supports Layer 7 routing features like host/path-based routing.",
    "difficulty": "Easy"
  },
  {
    "id": "SAA-026",
    "domainId": "D3",
    "domain": "Design High-Performing Architectures",
    "section": "DynamoDB",
    "question": "Which DynamoDB feature accelerates read-heavy workloads with in-memory caching?",
    "choices": [
      "DAX",
      "Streams",
      "TTL",
      "Global Secondary Index"
    ],
    "answer": 0,
    "explanation": "DynamoDB Accelerator (DAX) is an in-memory cache for read performance.",
    "difficulty": "Easy"
  },
  {
    "id": "SAA-027",
    "domainId": "D3",
    "domain": "Design High-Performing Architectures",
    "section": "RDS",
    "question": "What is the main purpose of an RDS Read Replica?",
    "choices": [
      "Automatic failover",
      "Scale reads and offload reporting queries",
      "Encrypt the database",
      "Reduce storage costs"
    ],
    "answer": 1,
    "explanation": "Read replicas are for scaling reads, not for automatic HA failover.",
    "difficulty": "Easy"
  },
  {
    "id": "SAA-028",
    "domainId": "D3",
    "domain": "Design High-Performing Architectures",
    "section": "EBS",
    "question": "Which EBS volume type is generally best for general-purpose SSD workloads with tunable performance?",
    "choices": [
      "st1",
      "sc1",
      "gp3",
      "Glacier Instant Retrieval"
    ],
    "answer": 2,
    "explanation": "gp3 provides good baseline performance and can be provisioned for higher IOPS/throughput.",
    "difficulty": "Easy"
  },
  {
    "id": "SAA-029",
    "domainId": "D3",
    "domain": "Design High-Performing Architectures",
    "section": "SQS",
    "question": "Which SQS feature reduces empty receives by waiting for messages before returning a response?",
    "choices": [
      "Long polling",
      "Dead-letter queue",
      "FIFO ordering",
      "Message deduplication"
    ],
    "answer": 0,
    "explanation": "Long polling waits up to the configured time for messages, reducing empty responses and cost.",
    "difficulty": "Easy"
  },
  {
    "id": "SAA-030",
    "domainId": "D3",
    "domain": "Design High-Performing Architectures",
    "section": "SQS",
    "question": "Which SQS type preserves message order and supports exactly-once processing?",
    "choices": [
      "Standard",
      "FIFO",
      "Delayed",
      "Priority"
    ],
    "answer": 1,
    "explanation": "SQS FIFO provides ordering and exactly-once processing (within FIFO semantics).",
    "difficulty": "Easy"
  },
  {
    "id": "SAA-031",
    "domainId": "D4",
    "domain": "Design Cost-Optimized Architectures",
    "section": "EC2",
    "question": "Which EC2 pricing model offers the biggest discount for interruptible workloads?",
    "choices": [
      "On-Demand",
      "Reserved Instances",
      "Savings Plans only",
      "Spot Instances"
    ],
    "answer": 3,
    "explanation": "Spot Instances are discounted but can be interrupted when capacity is needed.",
    "difficulty": "Easy"
  },
  {
    "id": "SAA-032",
    "domainId": "D4",
    "domain": "Design Cost-Optimized Architectures",
    "section": "S3",
    "question": "Which S3 storage class is best for rarely accessed data with milliseconds retrieval?",
    "choices": [
      "S3 Standard",
      "S3 Standard-IA",
      "S3 Glacier Deep Archive",
      "S3 One Zone-IA (always best)"
    ],
    "answer": 1,
    "explanation": "Standard-IA is for infrequently accessed data with low storage cost and millisecond access.",
    "difficulty": "Easy"
  },
  {
    "id": "SAA-033",
    "domainId": "D4",
    "domain": "Design Cost-Optimized Architectures",
    "section": "S3",
    "question": "Which S3 feature automatically moves objects between storage tiers based on access patterns?",
    "choices": [
      "S3 Intelligent-Tiering",
      "S3 Select",
      "S3 Object Lock",
      "S3 Transfer Acceleration"
    ],
    "answer": 0,
    "explanation": "Intelligent-Tiering optimizes cost by moving objects between access tiers.",
    "difficulty": "Easy"
  },
  {
    "id": "SAA-034",
    "domainId": "D4",
    "domain": "Design Cost-Optimized Architectures",
    "section": "CloudWatch",
    "question": "Which CloudWatch feature notifies you when a metric crosses a threshold?",
    "choices": [
      "CloudWatch Alarms",
      "CloudWatch Events only",
      "CloudWatch Logs only",
      "CloudWatch Dashboards only"
    ],
    "answer": 0,
    "explanation": "CloudWatch Alarms watch metrics and can trigger actions/notifications when thresholds are breached.",
    "difficulty": "Easy"
  },
  {
    "id": "SAA-035",
    "domainId": "D4",
    "domain": "Design Cost-Optimized Architectures",
    "section": "Auto Scaling",
    "question": "For unpredictable spiky traffic, which approach avoids paying for idle EC2 capacity most effectively?",
    "choices": [
      "Run one very large instance",
      "Use Auto Scaling Group with policies",
      "Use Dedicated Hosts",
      "Disable scaling and accept downtime"
    ],
    "answer": 1,
    "explanation": "Auto Scaling matches capacity to demand, reducing idle cost while maintaining availability.",
    "difficulty": "Easy"
  },
  {
    "id": "SAA-036",
    "domainId": "D4",
    "domain": "Design Cost-Optimized Architectures",
    "section": "RDS",
    "question": "Which approach can reduce RDS connection overhead for spiky Lambda traffic?",
    "choices": [
      "Increase instance size always",
      "RDS Proxy",
      "Disable backups",
      "Use Multi-AZ only"
    ],
    "answer": 1,
    "explanation": "RDS Proxy pools and reuses connections, reducing overhead in bursty workloads.",
    "difficulty": "Easy"
  },
  {
    "id": "SAA-037",
    "domainId": "D4",
    "domain": "Design Cost-Optimized Architectures",
    "section": "EBS",
    "question": "Which action can reduce EBS snapshot storage costs over time?",
    "choices": [
      "Turn off encryption",
      "Delete old/unused snapshots",
      "Use larger volumes",
      "Disable backups forever"
    ],
    "answer": 1,
    "explanation": "Deleting unused snapshots reduces storage costs.",
    "difficulty": "Easy"
  },
  {
    "id": "SAA-038",
    "domainId": "D4",
    "domain": "Design Cost-Optimized Architectures",
    "section": "S3",
    "question": "Which storage class is typically the lowest cost for long-term archival with hours retrieval?",
    "choices": [
      "S3 Standard",
      "S3 Glacier Flexible Retrieval",
      "S3 Glacier Deep Archive",
      "S3 Standard-IA"
    ],
    "answer": 2,
    "explanation": "Deep Archive is designed for lowest-cost archival with slower retrieval.",
    "difficulty": "Easy"
  },
  {
    "id": "SAA-039",
    "domainId": "D4",
    "domain": "Design Cost-Optimized Architectures",
    "section": "CloudFront",
    "question": "How can CloudFront reduce costs for a global audience?",
    "choices": [
      "By increasing RDS IOPS",
      "By caching content at the edge to reduce origin load and transfer",
      "By replacing IAM",
      "By disabling TLS"
    ],
    "answer": 1,
    "explanation": "Edge caching reduces origin requests and can reduce backend load and data transfer.",
    "difficulty": "Easy"
  },
  {
    "id": "SAA-040",
    "domainId": "D4",
    "domain": "Design Cost-Optimized Architectures",
    "section": "EC2",
    "question": "Which commitment generally lowers compute cost for steady-state usage over 1–3 years?",
    "choices": [
      "On-Demand only",
      "Reserved Instances or Savings Plans",
      "Always Spot",
      "Always Dedicated Hosts"
    ],
    "answer": 1,
    "explanation": "Reservations/Savings Plans provide discounts for committed usage.",
    "difficulty": "Easy"
  },
  {
    "id": "SAA-041",
    "domainId": "D1",
    "domain": "Design Secure Architectures",
    "section": "IAM",
    "question": "In IAM evaluation, what happens if a request matches an explicit Deny and an Allow?",
    "choices": [
      "Allow wins",
      "Deny wins",
      "It depends on the service",
      "The request is retried"
    ],
    "answer": 1,
    "explanation": "Explicit Deny always overrides Allow in IAM policy evaluation.",
    "difficulty": "Easy"
  },
  {
    "id": "SAA-042",
    "domainId": "D1",
    "domain": "Design Secure Architectures",
    "section": "VPC",
    "question": "What enables private connectivity from a VPC to supported AWS services without internet?",
    "choices": [
      "Internet Gateway",
      "VPC Endpoints",
      "VPC Peering",
      "Public Subnet"
    ],
    "answer": 1,
    "explanation": "VPC endpoints (Gateway/Interface) provide private access to AWS services.",
    "difficulty": "Easy"
  },
  {
    "id": "SAA-043",
    "domainId": "D1",
    "domain": "Design Secure Architectures",
    "section": "KMS",
    "question": "Which S3 server-side encryption option uses KMS-managed keys?",
    "choices": [
      "SSE-S3",
      "SSE-KMS",
      "Client-side only",
      "Unencrypted"
    ],
    "answer": 1,
    "explanation": "SSE-KMS uses AWS KMS keys to encrypt S3 objects.",
    "difficulty": "Easy"
  },
  {
    "id": "SAA-044",
    "domainId": "D2",
    "domain": "Design Resilient Architectures",
    "section": "EFS",
    "question": "EFS offers high availability primarily by being accessible across what?",
    "choices": [
      "Multiple regions by default",
      "Multiple AZs in a region",
      "Only one AZ",
      "Only one subnet"
    ],
    "answer": 1,
    "explanation": "EFS is a regional service and is designed to be accessible across multiple AZs.",
    "difficulty": "Easy"
  },
  {
    "id": "SAA-045",
    "domainId": "D2",
    "domain": "Design Resilient Architectures",
    "section": "SQS",
    "question": "What is the main difference between SQS Standard and FIFO?",
    "choices": [
      "Standard is encrypted, FIFO is not",
      "FIFO preserves order and supports exactly-once processing",
      "FIFO is faster for unlimited throughput always",
      "Standard requires VPC endpoints"
    ],
    "answer": 1,
    "explanation": "FIFO preserves ordering and avoids duplicates (within FIFO semantics).",
    "difficulty": "Easy"
  },
  {
    "id": "SAA-046",
    "domainId": "D3",
    "domain": "Design High-Performing Architectures",
    "section": "VPC",
    "question": "Which design improves throughput between EC2 instances with low network latency needs?",
    "choices": [
      "Spread Placement Group",
      "Cluster Placement Group",
      "Use only public IPs",
      "Disable security groups"
    ],
    "answer": 1,
    "explanation": "Cluster placement groups provide low-latency, high-throughput networking in a single AZ.",
    "difficulty": "Easy"
  },
  {
    "id": "SAA-047",
    "domainId": "D4",
    "domain": "Design Cost-Optimized Architectures",
    "section": "S3",
    "question": "To reduce storage costs for objects with known lifecycle, what should you use?",
    "choices": [
      "S3 Lifecycle rules",
      "S3 Inventory only",
      "CloudTrail",
      "IAM Policy Simulator"
    ],
    "answer": 0,
    "explanation": "Lifecycle rules can transition objects to cheaper classes or expire them automatically.",
    "difficulty": "Easy"
  },
  {
    "id": "SAA-048",
    "domainId": "D3",
    "domain": "Design High-Performing Architectures",
    "section": "Lambda",
    "question": "Which Lambda feature provides a built-in HTTPS endpoint without API Gateway?",
    "choices": [
      "Lambda Function URLs",
      "Lambda Layers",
      "Lambda@Edge only",
      "Provisioned Concurrency"
    ],
    "answer": 0,
    "explanation": "Lambda Function URLs expose a native HTTPS endpoint for a function.",
    "difficulty": "Easy"
  },
  {
    "id": "SAA-049",
    "domainId": "D2",
    "domain": "Design Resilient Architectures",
    "section": "CloudWatch",
    "question": "Which service provides alarms based on metrics like CPUUtilization?",
    "choices": [
      "CloudTrail",
      "CloudWatch",
      "Artifact",
      "KMS"
    ],
    "answer": 1,
    "explanation": "CloudWatch provides metrics, alarms, and dashboards.",
    "difficulty": "Easy"
  },
  {
    "id": "SAA-050",
    "domainId": "D1",
    "domain": "Design Secure Architectures",
    "section": "IAM",
    "question": "Which IAM feature sets the maximum permissions an IAM role/user can have (as a boundary)?",
    "choices": [
      "Security Groups",
      "Permission Boundaries",
      "VPC Endpoints",
      "Route Tables"
    ],
    "answer": 1,
    "explanation": "Permission boundaries define the maximum permissions identity-based policies can grant.",
    "difficulty": "Easy"
  },
  {
    "id": "SAA-051",
    "domainId": "D3",
    "domain": "Design High-Performing Architectures",
    "section": "DynamoDB",
    "question": "Which DynamoDB capacity mode is easiest for unpredictable traffic without capacity planning?",
    "choices": [
      "Provisioned",
      "On-demand",
      "Reserved",
      "Spot"
    ],
    "answer": 1,
    "explanation": "On-demand capacity scales automatically and avoids manual capacity planning.",
    "difficulty": "Easy"
  },
  {
    "id": "SAA-052",
    "domainId": "D3",
    "domain": "Design High-Performing Architectures",
    "section": "SQS",
    "question": "What does the SQS Visibility Timeout control?",
    "choices": [
      "How long messages are stored",
      "How long a received message is hidden from other consumers",
      "How long long polling waits",
      "Maximum message size"
    ],
    "answer": 1,
    "explanation": "Visibility timeout hides a message after receive so another consumer doesn’t process it simultaneously.",
    "difficulty": "Easy"
  },
  {
    "id": "SAA-053",
    "domainId": "D1",
    "domain": "Design Secure Architectures",
    "section": "CloudFront",
    "question": "Which AWS service provides DDoS protection that commonly protects CloudFront by default (Standard)?",
    "choices": [
      "AWS Shield",
      "AWS Glue",
      "AWS Batch",
      "AWS Snowball"
    ],
    "answer": 0,
    "explanation": "AWS Shield Standard helps protect against common DDoS attacks and is included for CloudFront.",
    "difficulty": "Easy"
  },
  {
    "id": "SAA-054",
    "domainId": "D4",
    "domain": "Design Cost-Optimized Architectures",
    "section": "Lambda",
    "question": "For short-lived, event-driven tasks, which compute option can be cost-effective?",
    "choices": [
      "Always-on EC2",
      "Lambda",
      "Dedicated Hosts",
      "Biggest EC2 only"
    ],
    "answer": 1,
    "explanation": "Lambda can be cost-effective for sporadic workloads because you pay per execution.",
    "difficulty": "Easy"
  },
  {
    "id": "SAA-055",
    "domainId": "D3",
    "domain": "Design High-Performing Architectures",
    "section": "EC2",
    "question": "Which EC2 feature is the recommended way to define instance configuration for an Auto Scaling Group today?",
    "choices": [
      "Launch Template",
      "Launch Configuration only",
      "AMI Copy",
      "Placement Group"
    ],
    "answer": 0,
    "explanation": "Launch Templates are the modern, recommended way to define ASG instance configuration.",
    "difficulty": "Easy"
  },
  {
    "id": "SAA-056",
    "domainId": "D2",
    "domain": "Design Resilient Architectures",
    "section": "RDS",
    "question": "Aurora is designed to replicate storage across how many AZs (typical design)?",
    "choices": [
      "1",
      "2",
      "3",
      "6 regions"
    ],
    "answer": 2,
    "explanation": "Aurora typically replicates storage across 3 AZs for durability.",
    "difficulty": "Easy"
  },
  {
    "id": "SAA-057",
    "domainId": "D1",
    "domain": "Design Secure Architectures",
    "section": "S3",
    "question": "Which setting helps ensure all S3 uploads are encrypted automatically?",
    "choices": [
      "Disable versioning",
      "Default encryption",
      "Transfer Acceleration",
      "Requester Pays"
    ],
    "answer": 1,
    "explanation": "Default encryption ensures objects are encrypted when written to the bucket.",
    "difficulty": "Easy"
  },
  {
    "id": "SAA-058",
    "domainId": "D4",
    "domain": "Design Cost-Optimized Architectures",
    "section": "CloudWatch",
    "question": "Which action can reduce CloudWatch Logs costs?",
    "choices": [
      "Increase log retention to never expire",
      "Set retention policies and filter what you log",
      "Turn off encryption always",
      "Send logs to more log groups"
    ],
    "answer": 1,
    "explanation": "Retention policies and logging only what you need help reduce log storage/ingest costs.",
    "difficulty": "Easy"
  },
  {
    "id": "SAA-059",
    "domainId": "D3",
    "domain": "Design High-Performing Architectures",
    "section": "S3",
    "question": "For large file uploads to S3, which feature improves reliability and throughput?",
    "choices": [
      "S3 Multipart Upload",
      "S3 Object Lock",
      "S3 Static Website Hosting",
      "S3 Batch Operations only"
    ],
    "answer": 0,
    "explanation": "Multipart upload uploads parts in parallel and can retry parts independently.",
    "difficulty": "Easy"
  },
  {
    "id": "SAA-060",
    "domainId": "D2",
    "domain": "Design Resilient Architectures",
    "section": "VPC",
    "question": "What provides outbound internet access for private subnets without inbound internet access?",
    "choices": [
      "Internet Gateway",
      "NAT Gateway",
      "VPC Endpoint only",
      "Route 53 Resolver"
    ],
    "answer": 1,
    "explanation": "A NAT Gateway allows instances in private subnets to initiate outbound connections to the internet.",
    "difficulty": "Easy"
  },
  {
    "id": "SAA-061",
    "domainId": "D1",
    "domain": "Design Secure Architectures",
    "section": "IAM",
    "question": "Which IAM policy type is attached directly to an AWS resource like an S3 bucket?",
    "choices": [
      "Identity-based policy",
      "Resource-based policy",
      "Session policy only",
      "Permission boundary only"
    ],
    "answer": 1,
    "explanation": "Resource-based policies are attached to resources (e.g., S3 bucket policy).",
    "difficulty": "Easy"
  },
  {
    "id": "SAA-062",
    "domainId": "D3",
    "domain": "Design High-Performing Architectures",
    "section": "ELB",
    "question": "Which ALB capability helps route traffic to different target groups based on URL path?",
    "choices": [
      "Layer 4 routing",
      "Path-based routing",
      "BGP routing",
      "NAT translation"
    ],
    "answer": 1,
    "explanation": "ALB supports Layer 7 features like host- and path-based routing.",
    "difficulty": "Easy"
  },
  {
    "id": "SAA-063",
    "domainId": "D2",
    "domain": "Design Resilient Architectures",
    "section": "RDS",
    "question": "Which RDS feature enables point-in-time recovery within the backup retention window?",
    "choices": [
      "Manual snapshots only",
      "Automated backups",
      "Read replicas",
      "Security groups"
    ],
    "answer": 1,
    "explanation": "Automated backups (with transaction logs) enable point-in-time recovery.",
    "difficulty": "Easy"
  },
  {
    "id": "SAA-064",
    "domainId": "D4",
    "domain": "Design Cost-Optimized Architectures",
    "section": "RDS",
    "question": "Which choice can reduce cost for dev/test databases that are not used 24/7?",
    "choices": [
      "Run Multi-AZ always",
      "Use the largest instance",
      "Right-size and stop/start where supported",
      "Disable monitoring"
    ],
    "answer": 2,
    "explanation": "Right-sizing and stopping non-prod resources where possible reduces cost.",
    "difficulty": "Easy"
  },
  {
    "id": "SAA-065",
    "domainId": "D1",
    "domain": "Design Secure Architectures",
    "section": "VPC",
    "question": "Which is the most secure way to allow EC2 to access S3 without hardcoding keys?",
    "choices": [
      "Store keys in code",
      "Use an IAM Role attached to the instance",
      "Share root credentials",
      "Put keys in a public S3 bucket"
    ],
    "answer": 1,
    "explanation": "Attach an IAM role to the instance so it receives temporary credentials automatically.",
    "difficulty": "Easy"
  },
  {
    "id": "SAA-066",
    "domainId": "D1",
    "domain": "Design Secure Architectures",
    "section": "IAM",
    "question": "A company has just set up a new AWS account for production workloads and wants to follow best practices for privileged access. Which practice should be mandated for the root user account?",
    "choices": [
      "Use the root account only for initial setup and never share credentials.",
      "Create an IAM user for all day-to-day operations and delete the root account immediately.",
      "Set a strong password policy for all IAM users, but the root account password can be simple since it's rarely used.",
      "Configure Multi-Factor Authentication (MFA) only for critical IAM users, as the root account is already inherently secure."
    ],
    "answer": 0,
    "explanation": "Root is the most privileged identity, so it should be tightly controlled and used only when absolutely necessary; never share it and keep it for account-level tasks.",
    "difficulty": "Medium"
  },
  {
    "id": "SAA-067",
    "domainId": "D4",
    "domain": "Design Cost-Optimized Architectures",
    "section": "EC2",
    "question": "A company must run a critical, stateful database application with stable capacity 24/7 for the next three years and wants the best cost savings. Which EC2 purchasing option provides the greatest savings for this steady-state workload?",
    "choices": [
      "On-Demand Instances, due to the flexibility of paying per second.",
      "Spot Instances, leveraging up to 90% discount for non-critical workloads.",
      "Reserved Instances (3-year term, All Upfront payment).",
      "Capacity Reservations, ensuring capacity in a specific AZ for any duration."
    ],
    "answer": 2,
    "explanation": "A 3-year All Upfront Reserved Instance provides the largest discount for predictable, always-on workloads while keeping capacity stable.",
    "difficulty": "Medium"
  },
  {
    "id": "SAA-068",
    "domainId": "D1",
    "domain": "Design Secure Architectures",
    "section": "Security Groups",
    "question": "An EC2 instance security group allows inbound HTTP (port 80), but client connections time out and outbound rules are default. Based on security group fundamentals, what is the most likely cause?",
    "choices": [
      "The default Network ACL (NACL) is implicitly denying the inbound connection.",
      "The default outbound rule in the security group is denying the return traffic.",
      "The inbound security group rule is configured incorrectly or traffic is being blocked before reaching the instance, resulting in a timeout.",
      "The application server is not running, resulting in a connection refused error."
    ],
    "answer": 2,
    "explanation": "Security groups are stateful, so return traffic is allowed automatically; a timeout usually indicates the request never successfully reaches a listening service (routing/NACL/host firewall/app issue) rather than an outbound SG problem.",
    "difficulty": "Medium"
  },
  {
    "id": "SAA-069",
    "domainId": "D2",
    "domain": "Design Resilient Architectures",
    "section": "ALB",
    "question": "An Application Load Balancer (ALB) distributes traffic across two Availability Zones for high availability. How is cross-zone load balancing configured by default on an ALB, and what is the pricing impact?",
    "choices": [
      "Disabled by default, and inter-AZ data transfer is charged if enabled.",
      "Enabled by default, and there are no additional charges for this cross-zone regional data transfer behavior on ALB.",
      "Enabled by default, but inter-AZ data transfer is charged if enabled.",
      "Disabled by default, but there are no charges for inter-AZ data transfer."
    ],
    "answer": 1,
    "explanation": "ALBs use cross-zone load balancing by default, and ALB does not add a specific cross-zone data transfer fee for this behavior.",
    "difficulty": "Medium"
  },
  {
    "id": "SAA-070",
    "domainId": "D2",
    "domain": "Design Resilient Architectures",
    "section": "SQS",
    "question": "A payment system requires messages to be processed in the exact order received and must prevent duplicate processing. Which Amazon SQS queue type meets these requirements?",
    "choices": [
      "SQS Standard Queue with short polling.",
      "SQS Standard Queue with long polling.",
      "SQS FIFO Queue.",
      "Amazon SNS topic fan-out pattern."
    ],
    "answer": 2,
    "explanation": "SQS FIFO provides ordered message processing and supports exactly-once processing semantics (with deduplication) for correctly designed consumers.",
    "difficulty": "Medium"
  },
  {
    "id": "SAA-071",
    "domainId": "D4",
    "domain": "Design Cost-Optimized Architectures",
    "section": "S3",
    "question": "A media company stores video data in S3: frequent access for 30 days, rare access from day 30 to 90 (but fast retrieval), then long-term archive after 90 days where hours of retrieval time is acceptable. Which lifecycle transition is most cost-effective while meeting access needs?",
    "choices": [
      "Standard for 30 days -> transition to S3 Standard-IA for 60 days -> transition to S3 Glacier Flexible Retrieval after 90 days.",
      "S3 Intelligent-Tiering -> S3 Glacier Deep Archive after 90 days.",
      "S3 One Zone-IA for 30 days -> S3 Standard-IA for 60 days -> S3 Glacier Instant Retrieval.",
      "Use S3 Glacier Instant Retrieval immediately as retrieval latency is low."
    ],
    "answer": 0,
    "explanation": "Standard fits frequent access, Standard-IA fits infrequent-but-fast retrieval, and Glacier Flexible Retrieval fits long-term archiving with hour-level retrieval latency.",
    "difficulty": "Medium"
  },
  {
    "id": "SAA-072",
    "domainId": "D1",
    "domain": "Design Secure Architectures",
    "section": "VPC",
    "question": "VPC flow logs show outbound traffic from a private subnet instance is ACCEPTED, but the inbound return traffic is REJECTED at the subnet level. Assuming security groups are correct, what should be checked and modified to allow the connection to succeed?",
    "choices": [
      "The EC2 instance security group, because security groups are stateless.",
      "The NACL outbound rules for the private subnet, because NACLs are stateful.",
      "The NACL inbound rules for the private subnet, ensuring the ephemeral port range is explicitly allowed.",
      "The NACL outbound rules for the public subnet, ensuring port 443 is explicitly allowed."
    ],
    "answer": 2,
    "explanation": "NACLs are stateless, so you must explicitly allow return traffic on ephemeral ports in the inbound NACL rules for the subnet.",
    "difficulty": "Medium"
  },
  {
    "id": "SAA-073",
    "domainId": "D2",
    "domain": "Design Resilient Architectures",
    "section": "Aurora",
    "question": "A company uses Aurora MySQL in us-east-1 and needs cross-region expansion to eu-west-1 with very low RTO for failover (under 1 minute) and low-latency global reads. Which Aurora feature best meets both needs?",
    "choices": [
      "RDS Multi-AZ deployment.",
      "Aurora cross-region read replicas.",
      "Aurora Serverless deployment in eu-west-1.",
      "Aurora Global Database."
    ],
    "answer": 3,
    "explanation": "Aurora Global Database is designed for low-latency cross-region reads and fast disaster recovery with promoted secondary regions.",
    "difficulty": "Medium"
  },
  {
    "id": "SAA-074",
    "domainId": "D1",
    "domain": "Design Secure Architectures",
    "section": "Monitoring",
    "question": "An admin wants immediate alerts when someone attempts to terminate a production EC2 instance, a history of configuration changes, and a graph of average CPU over time. Which three AWS services meet these requirements, respectively?",
    "choices": [
      "CloudWatch (CPU), CloudTrail (API calls/history), AWS Config (configuration history).",
      "Trusted Advisor (security), CloudWatch (CPU), S3 (history).",
      "CloudWatch (CPU), CloudTrail (configuration history), CloudWatch Logs (API calls).",
      "GuardDuty (alerts), EventBridge (history), AWS Config (CPU)."
    ],
    "answer": 0,
    "explanation": "CloudWatch provides metrics and graphs, CloudTrail records API activity such as termination attempts, and AWS Config tracks configuration changes over time.",
    "difficulty": "Medium"
  },
  {
    "id": "SAA-075",
    "domainId": "D3",
    "domain": "Design High-Performing Architectures",
    "section": "Serverless",
    "question": "Users upload large images to S3, and a serverless microservice must generate thumbnails and analyze metadata immediately after each upload. What is the most appropriate serverless pattern to trigger the processing?",
    "choices": [
      "Configure S3 event notifications to invoke an AWS Lambda function directly.",
      "Use AWS Batch to run the thumbnail job based on a scheduled CloudWatch Event.",
      "Configure S3 event notifications to publish to an SNS topic, which then triggers the microservice running on Fargate tasks.",
      "Use a single EC2 instance with a user data script running the thumbnail application."
    ],
    "answer": 0,
    "explanation": "S3 event notifications can directly trigger Lambda on object creation, providing a fully serverless, scalable event-driven pipeline.",
    "difficulty": "Medium"
  },
  {
    "id": "SAA-076",
    "domainId": "D1",
    "domain": "Design Secure Architectures",
    "section": "IAM",
    "question": "A startup uses an AWS account shared by multiple teams. Developers currently attach the AdministratorAccess policy to their IAM users “temporarily” when troubleshooting, and sometimes forget to remove it.\nThe security team wants a guardrail that limits the maximum permissions developers can ever obtain, while still allowing team leads to grant temporary elevated access within that limit.\nWhich solution will meet these requirements with the LEAST operational overhead?",
    "choices": [
      "Attach a permissions boundary to all developer IAM users that caps their maximum permissions",
      "Use an identity-based policy that explicitly allows only read-only access for developers",
      "Create an SCP that allows AdministratorAccess only for users in a specific IAM group",
      "Enable AWS Config and automatically revert any policy changes detected on IAM users"
    ],
    "answer": 0,
    "explanation": "Permissions boundaries define the maximum permissions an IAM principal can receive, even if broader policies are attached later. This creates a strong guardrail without blocking legitimate temporary elevation by team leads, as long as it stays within the boundary.",
    "difficulty": "Medium"
  },
  {
    "id": "SAA-077",
    "domainId": "D1",
    "domain": "Design Secure Architectures",
    "section": "S3",
    "question": "A company stores internal build artifacts in Amazon S3. The bucket must never become publicly accessible, even if someone accidentally adds a public bucket policy or object ACL.\nWhich configuration best meets the requirement?",
    "choices": [
      "Enable S3 Block Public Access at the account level and for the bucket",
      "Use S3 default encryption with SSE-S3",
      "Enable S3 versioning and MFA Delete",
      "Create an S3 access point for each application and disable bucket policies"
    ],
    "answer": 0,
    "explanation": "S3 Block Public Access can prevent public access via bucket policies and ACLs at both the account and bucket level, providing a safety net against accidental exposure. Encryption and versioning do not prevent public access.",
    "difficulty": "Medium"
  },
  {
    "id": "SAA-078",
    "domainId": "D1",
    "domain": "Design Secure Architectures",
    "section": "KMS",
    "question": "A security policy requires that all data stored in S3 be encrypted using customer-managed keys, and that access to decrypt the data be centrally controlled and auditable.\nWhich approach should you implement?",
    "choices": [
      "Enable default encryption on the bucket using SSE-KMS with a customer-managed KMS key",
      "Enable default encryption on the bucket using SSE-S3",
      "Use client-side encryption and store the encryption key in the application code repository",
      "Store objects unencrypted and rely on TLS in transit"
    ],
    "answer": 0,
    "explanation": "SSE-KMS with a customer-managed KMS key enforces encryption at rest and allows centralized, auditable control over key usage through KMS key policies and CloudTrail logs.",
    "difficulty": "Medium"
  },
  {
    "id": "SAA-079",
    "domainId": "D1",
    "domain": "Design Secure Architectures",
    "section": "CloudTrail",
    "question": "A regulated company must retain an immutable record of all API calls in their AWS account for 7 years. The security team also wants to be alerted if CloudTrail logging is disabled or modified.\nWhich solution is MOST appropriate?",
    "choices": [
      "Enable an organization trail (or account trail) that logs to an S3 bucket with Object Lock, and create an AWS Config rule (or CloudWatch/EventBridge alert) to detect changes to CloudTrail",
      "Enable VPC Flow Logs to S3 and store the logs for 7 years",
      "Enable AWS Config only and store configuration snapshots in S3 for 7 years",
      "Send CloudTrail logs to an EC2 instance and back them up nightly to S3"
    ],
    "answer": 0,
    "explanation": "CloudTrail records API activity. Storing logs in S3 with Object Lock helps meet immutability/retention requirements, while Config and/or EventBridge/CloudWatch can alert on CloudTrail configuration changes. VPC Flow Logs capture network traffic, not API calls.",
    "difficulty": "Medium"
  },
  {
    "id": "SAA-080",
    "domainId": "D1",
    "domain": "Design Secure Architectures",
    "section": "VPC",
    "question": "A team is deploying a web app in private subnets. They want to allow HTTPS access to a third-party API on the internet, but block all inbound traffic from the internet.\nWhich network design meets these requirements?",
    "choices": [
      "Deploy instances in private subnets, route outbound internet traffic through a NAT Gateway in a public subnet, and keep inbound rules restrictive on security groups",
      "Deploy instances in public subnets with public IPs and restrict inbound traffic using NACLs",
      "Deploy instances in private subnets and attach an Internet Gateway directly to the private subnets",
      "Deploy instances in public subnets and use an S3 Gateway Endpoint for internet access"
    ],
    "answer": 0,
    "explanation": "Instances in private subnets have no direct inbound internet connectivity. A NAT Gateway in a public subnet provides outbound-only internet access for private instances. Security groups and route tables enforce the inbound restriction.",
    "difficulty": "Medium"
  },
  {
    "id": "SAA-081",
    "domainId": "D1",
    "domain": "Design Secure Architectures",
    "section": "ACM",
    "question": "A company hosts multiple HTTPS applications behind Application Load Balancers. The applications must use publicly trusted certificates and the team wants automatic certificate renewal.\nWhich solution should you choose?",
    "choices": [
      "Use AWS Certificate Manager (ACM) to provision public certificates and attach them to the ALB HTTPS listeners",
      "Use AWS Certificate Manager Private CA to issue certificates for the ALBs",
      "Create self-signed certificates and import them to ACM",
      "Run Let’s Encrypt certbot on each EC2 instance and manage renewals with cron"
    ],
    "answer": 0,
    "explanation": "ACM public certificates are publicly trusted, integrate directly with ALBs, and renew automatically. Private CA and self-signed certificates are not publicly trusted for internet clients.",
    "difficulty": "Medium"
  },
  {
    "id": "SAA-082",
    "domainId": "D1",
    "domain": "Design Secure Architectures",
    "section": "WAF",
    "question": "A security team wants to protect a public web application from common web exploits (SQL injection, XSS) and also wants to block known bad IP ranges. The solution must be managed and easy to update.\nWhich option best meets these requirements?",
    "choices": [
      "Attach AWS WAF to the application entry point (ALB or CloudFront) and use managed rule groups plus an IP set",
      "Use Security Groups to block SQL injection and XSS",
      "Enable AWS Shield Standard and configure it to block bad IPs",
      "Use NACLs with deep packet inspection rules for HTTP payloads"
    ],
    "answer": 0,
    "explanation": "AWS WAF provides managed protections for common web exploits and supports IP sets for allow/deny lists. Security groups and NACLs operate at L3/L4 and cannot inspect HTTP payloads for SQLi/XSS.",
    "difficulty": "Medium"
  },
  {
    "id": "SAA-083",
    "domainId": "D1",
    "domain": "Design Secure Architectures",
    "section": "Secrets Manager",
    "question": "An application running on ECS needs to retrieve database credentials securely. The credentials rotate every 30 days, and the app should not require redeployment when rotation happens.\nWhich solution is MOST suitable?",
    "choices": [
      "Store credentials in AWS Secrets Manager with rotation enabled and have the app retrieve them at runtime",
      "Store credentials in an S3 object encrypted with SSE-S3 and download them on container startup",
      "Store credentials in environment variables baked into the container image",
      "Store credentials in a Parameter Store standard parameter without encryption"
    ],
    "answer": 0,
    "explanation": "Secrets Manager is designed for storing and rotating secrets like database credentials. Applications can fetch the current secret value at runtime, so rotation doesn’t require rebuilding images or redeploying configs.",
    "difficulty": "Medium"
  },
  {
    "id": "SAA-084",
    "domainId": "D1",
    "domain": "Design Secure Architectures",
    "section": "IAM",
    "question": "A company wants to prevent developers from creating IAM access keys for their own users to reduce the risk of long-lived credentials. Console access with MFA is allowed.\nWhich approach provides the strongest preventive control?",
    "choices": [
      "Apply an SCP (in AWS Organizations) or an IAM permissions boundary/policy that explicitly denies iam:CreateAccessKey for the developer principals",
      "Enable AWS CloudTrail and review access key creation events weekly",
      "Enable AWS Config to detect access keys and notify via email",
      "Use a strong password policy for IAM users"
    ],
    "answer": 0,
    "explanation": "A preventive deny (via SCP or identity policies/permissions boundaries where applicable) blocks the action from occurring. Detective controls like CloudTrail/Config only alert after access keys are created.",
    "difficulty": "Medium"
  },
  {
    "id": "SAA-085",
    "domainId": "D1",
    "domain": "Design Secure Architectures",
    "section": "Security Groups",
    "question": "A team is confused about AWS network controls. They need a control that is stateful, supports allow rules only, and is associated directly with an ENI (instance/network interface).\nWhich AWS feature are they describing?",
    "choices": [
      "Security group",
      "Network ACL",
      "Route table",
      "VPC Flow Logs"
    ],
    "answer": 0,
    "explanation": "Security groups are stateful, contain allow rules only, and are attached to network interfaces. NACLs are stateless and support both allow and deny rules at the subnet level.",
    "difficulty": "Medium"
  },
  {
    "id": "SAA-086",
    "domainId": "D1",
    "domain": "Design Secure Architectures",
    "section": "GuardDuty",
    "question": "A company wants to detect potentially compromised EC2 instances, unusual API calls, and suspicious DNS activity without deploying agents.\nWhich service should they enable?",
    "choices": [
      "Amazon GuardDuty",
      "Amazon Inspector",
      "AWS Shield Advanced",
      "AWS Systems Manager"
    ],
    "answer": 0,
    "explanation": "GuardDuty is a managed threat detection service that analyzes CloudTrail, VPC Flow Logs, and DNS logs to identify suspicious activity without requiring agents on instances.",
    "difficulty": "Medium"
  },
  {
    "id": "SAA-087",
    "domainId": "D1",
    "domain": "Design Secure Architectures",
    "section": "Organizations",
    "question": "A company is setting up a multi-account environment and wants to ensure all accounts follow the same mandatory security controls, like disallowing changes to CloudTrail log buckets and restricting regions.\nWhich solution provides centralized governance?",
    "choices": [
      "AWS Organizations with Organizational Units (OUs) and Service Control Policies (SCPs)",
      "Creating identical IAM users in every account",
      "Using VPC peering between all accounts",
      "Enabling AWS Shield Standard in every account"
    ],
    "answer": 0,
    "explanation": "AWS Organizations allows centralized governance through OUs and SCPs that set account-wide permission guardrails. This is the standard approach for enforcing controls across many accounts.",
    "difficulty": "Medium"
  },
  {
    "id": "SAA-088",
    "domainId": "D1",
    "domain": "Design Secure Architectures",
    "section": "S3",
    "question": "A client stores confidential reports in S3 and wants to ensure that objects cannot be deleted unless a second factor is used, even by administrators.\nWhat should you configure?",
    "choices": [
      "Enable versioning on the bucket and enable MFA Delete",
      "Enable S3 Block Public Access",
      "Enable default encryption using SSE-S3",
      "Enable S3 Transfer Acceleration"
    ],
    "answer": 0,
    "explanation": "MFA Delete (used with versioning) requires MFA to permanently delete object versions or change the versioning state, providing stronger protection against accidental or malicious deletion.",
    "difficulty": "Medium"
  },
  {
    "id": "SAA-089",
    "domainId": "D1",
    "domain": "Design Secure Architectures",
    "section": "CloudFront",
    "question": "A company serves a static website globally using CloudFront with an S3 origin. They want to ensure viewers can access content only if they are authenticated by the company’s identity provider.\nWhich CloudFront feature best supports this?",
    "choices": [
      "Use signed URLs or signed cookies with CloudFront",
      "Enable S3 website hosting and require Basic Auth",
      "Use S3 Transfer Acceleration to restrict access",
      "Use Route 53 geolocation routing only"
    ],
    "answer": 0,
    "explanation": "CloudFront signed URLs/cookies restrict access to content by requiring a valid signature, commonly used alongside an authentication system to grant time-limited access to users.",
    "difficulty": "Medium"
  },
  {
    "id": "SAA-090",
    "domainId": "D1",
    "domain": "Design Secure Architectures",
    "section": "IAM",
    "question": "A security team wants to quickly identify S3 buckets, KMS keys, and other supported resources that have resource policies granting access to external AWS accounts.\nWhich service should they use?",
    "choices": [
      "IAM Access Analyzer",
      "AWS Trusted Advisor",
      "AWS Artifact",
      "AWS Budgets"
    ],
    "answer": 0,
    "explanation": "IAM Access Analyzer evaluates supported resource policies to identify unintended public or cross-account access, helping detect overly permissive sharing.",
    "difficulty": "Medium"
  },
  {
    "id": "SAA-091",
    "domainId": "D1",
    "domain": "Design Secure Architectures",
    "section": "VPC",
    "question": "A company wants to inspect and control outbound DNS queries from workloads in a VPC and block known malicious domains at the DNS layer.\nWhich managed AWS service capability is MOST suitable?",
    "choices": [
      "Amazon Route 53 Resolver DNS Firewall",
      "Security groups with DNS deny rules",
      "Network ACLs with domain-based rules",
      "AWS Shield Standard"
    ],
    "answer": 0,
    "explanation": "Route 53 Resolver DNS Firewall lets you define rules to allow/deny domain names for DNS queries from VPCs, providing managed DNS-layer protection. SGs/NACLs don’t filter by domain name.",
    "difficulty": "Medium"
  },
  {
    "id": "SAA-092",
    "domainId": "D2",
    "domain": "Design Resilient Architectures",
    "section": "RDS",
    "question": "A company runs a production PostgreSQL database on Amazon RDS. They need automatic failover in case the primary AZ becomes unavailable, with minimal application changes.\nWhich solution best meets this requirement?",
    "choices": [
      "Enable Multi-AZ deployment for the RDS instance",
      "Create an RDS read replica and point the application to it",
      "Export automated snapshots daily to S3",
      "Deploy the database on a single EC2 instance with EBS snapshots"
    ],
    "answer": 0,
    "explanation": "RDS Multi-AZ provides synchronous replication to a standby in another AZ and automatic failover to maintain availability with minimal application changes. Read replicas are primarily for scaling reads and can have asynchronous replication.",
    "difficulty": "Medium"
  },
  {
    "id": "SAA-093",
    "domainId": "D2",
    "domain": "Design Resilient Architectures",
    "section": "Route 53",
    "question": "A global e-commerce site runs active applications in two AWS Regions. The business wants users to be routed to the closest healthy region and fail over automatically if one region becomes unhealthy.\nWhich Route 53 routing policy best fits?",
    "choices": [
      "Latency-based routing with health checks",
      "Weighted routing without health checks",
      "Geolocation routing without health checks",
      "Simple routing"
    ],
    "answer": 0,
    "explanation": "Latency-based routing directs users to the region that provides the lowest latency, and health checks enable automatic failover away from unhealthy endpoints.",
    "difficulty": "Medium"
  },
  {
    "id": "SAA-094",
    "domainId": "D2",
    "domain": "Design Resilient Architectures",
    "section": "SQS",
    "question": "A team uses Amazon SQS to decouple a web tier from a worker tier. Sometimes, the workers fail to process a message due to a transient error, and messages get retried repeatedly.\nThe team wants a safe way to isolate problematic messages for later analysis without blocking the queue.\nWhich feature should they use?",
    "choices": [
      "Configure a dead-letter queue (DLQ) with a maxReceiveCount",
      "Enable SQS long polling",
      "Enable FIFO on the queue",
      "Increase the message retention period to 14 days"
    ],
    "answer": 0,
    "explanation": "A DLQ moves messages that fail processing too many times to a separate queue for investigation, preventing them from being retried indefinitely and blocking progress.",
    "difficulty": "Medium"
  },
  {
    "id": "SAA-095",
    "domainId": "D2",
    "domain": "Design Resilient Architectures",
    "section": "ECS",
    "question": "A service runs on Amazon ECS with the Fargate launch type across two AZs. The team needs tasks to be automatically replaced when they fail, and wants to maintain a desired number of running tasks.\nWhich ECS feature provides this behavior?",
    "choices": [
      "An ECS service with a desired count and health checks",
      "An ECS task definition only",
      "ECS Exec",
      "An S3 lifecycle policy"
    ],
    "answer": 0,
    "explanation": "An ECS service maintains the desired number of tasks and will replace failed tasks automatically. Health checks help ECS/ALB determine unhealthy tasks and trigger replacement.",
    "difficulty": "Medium"
  },
  {
    "id": "SAA-096",
    "domainId": "D2",
    "domain": "Design Resilient Architectures",
    "section": "ELB/ASG",
    "question": "A web application is deployed on EC2 instances in an Auto Scaling group behind an Application Load Balancer. The team wants unhealthy instances to be replaced automatically when they fail application-level health checks.\nWhich configuration should they implement?",
    "choices": [
      "Configure ALB target group health checks and enable Auto Scaling health checks that use ELB health status",
      "Enable detailed monitoring on EC2 instances only",
      "Use a Network Load Balancer and disable health checks",
      "Use Amazon CloudFront in front of the ALB and rely on edge caching"
    ],
    "answer": 0,
    "explanation": "ALB target group health checks detect application health. When Auto Scaling uses ELB health checks, it can terminate and replace instances that fail the load balancer health checks automatically.",
    "difficulty": "Medium"
  },
  {
    "id": "SAA-097",
    "domainId": "D2",
    "domain": "Design Resilient Architectures",
    "section": "S3",
    "question": "A company needs to protect critical S3 objects from accidental overwrites and deletions, but they also want the ability to recover previous versions.\nWhich S3 feature best meets this requirement?",
    "choices": [
      "Enable S3 versioning",
      "Enable S3 Transfer Acceleration",
      "Enable S3 Requester Pays",
      "Enable S3 static website hosting"
    ],
    "answer": 0,
    "explanation": "S3 versioning preserves multiple variants of an object in the same bucket, enabling recovery from accidental overwrites and deletions.",
    "difficulty": "Medium"
  },
  {
    "id": "SAA-098",
    "domainId": "D2",
    "domain": "Design Resilient Architectures",
    "section": "Lambda",
    "question": "A serverless workload writes items to DynamoDB. Occasionally, downstream processing fails and needs to be retried without losing events.\nWhich option provides the MOST resilient event-driven design?",
    "choices": [
      "Use DynamoDB Streams to trigger a Lambda function and configure retries with a DLQ (or on-failure destination) for failed records",
      "Have the Lambda poll DynamoDB every minute and scan the table",
      "Write DynamoDB items and rely on manual reprocessing only",
      "Trigger Lambda directly from an S3 bucket event"
    ],
    "answer": 0,
    "explanation": "DynamoDB Streams provide an ordered change log for table modifications. Lambda integrations support retries, and a DLQ/destination can capture failed records for later reprocessing, improving resilience.",
    "difficulty": "Medium"
  },
  {
    "id": "SAA-099",
    "domainId": "D2",
    "domain": "Design Resilient Architectures",
    "section": "EFS",
    "question": "A fleet of EC2 instances across multiple AZs needs shared access to the same file system for user uploads. The application requires automatic high availability across AZs.\nWhich storage service is MOST suitable?",
    "choices": [
      "Amazon EFS",
      "Amazon EBS",
      "Instance store",
      "Amazon S3 Glacier Deep Archive"
    ],
    "answer": 0,
    "explanation": "EFS is a managed, elastic NFS file system designed for shared access and is accessible from multiple AZs, supporting highly available shared storage for EC2/ECS workloads.",
    "difficulty": "Medium"
  },
  {
    "id": "SAA-100",
    "domainId": "D2",
    "domain": "Design Resilient Architectures",
    "section": "CloudFront",
    "question": "A company serves static and dynamic content worldwide. They want improved availability and reduced latency for static assets, and they want to reduce the impact of origin outages for cached content.\nWhich service should they use?",
    "choices": [
      "Amazon CloudFront",
      "Amazon EBS",
      "AWS Direct Connect",
      "AWS Snowball"
    ],
    "answer": 0,
    "explanation": "CloudFront caches content at edge locations, improving performance and providing some resilience by serving cached objects even when the origin is temporarily unavailable (subject to cache settings).",
    "difficulty": "Medium"
  },
  {
    "id": "SAA-101",
    "domainId": "D2",
    "domain": "Design Resilient Architectures",
    "section": "Backup",
    "question": "A company wants to centrally manage backups for Amazon RDS, EBS volumes, and EFS file systems across multiple accounts. They need retention policies and centralized reporting.\nWhich solution is MOST suitable?",
    "choices": [
      "Use AWS Backup with centralized backup policies (optionally via Organizations)",
      "Create custom scripts that take snapshots and store them in S3",
      "Rely on each team to manually create snapshots",
      "Use CloudTrail to store backups"
    ],
    "answer": 0,
    "explanation": "AWS Backup provides centralized backup management, scheduling, retention, and reporting for supported services and can be used across accounts with Organizations integration.",
    "difficulty": "Medium"
  },
  {
    "id": "SAA-102",
    "domainId": "D2",
    "domain": "Design Resilient Architectures",
    "section": "DynamoDB",
    "question": "A mobile app backend uses DynamoDB and must continue serving reads and writes even if an entire AWS Region becomes unavailable. The application requires near real-time replication between regions.\nWhich DynamoDB feature should you use?",
    "choices": [
      "DynamoDB global tables",
      "DynamoDB DAX",
      "DynamoDB TTL",
      "DynamoDB Streams only in a single region"
    ],
    "answer": 0,
    "explanation": "Global tables provide multi-region, multi-active replication for DynamoDB, enabling reads and writes in multiple regions with near real-time replication and improved regional resilience.",
    "difficulty": "Medium"
  },
  {
    "id": "SAA-103",
    "domainId": "D2",
    "domain": "Design Resilient Architectures",
    "section": "SNS/SQS",
    "question": "A company needs to send an event to multiple independent processing systems. Each system must receive every message and process it at its own pace. If one system is down, others must not be impacted.\nWhich design best meets these requirements?",
    "choices": [
      "Publish to an SNS topic and subscribe multiple SQS queues (one per system)",
      "Send messages to a single SQS queue shared by all systems",
      "Write events to an S3 bucket and have systems list objects periodically",
      "Send events directly to each system over HTTP from the producer"
    ],
    "answer": 0,
    "explanation": "SNS fanout to multiple SQS queues ensures each consumer system receives its own copy of each message, decouples processing rates, and isolates failures between systems.",
    "difficulty": "Medium"
  },
  {
    "id": "SAA-104",
    "domainId": "D2",
    "domain": "Design Resilient Architectures",
    "section": "ASG",
    "question": "A company wants to automatically scale a fleet of EC2 instances based on CPU utilization and replace unhealthy instances. They want the platform to handle capacity changes automatically.\nWhich solution best fits?",
    "choices": [
      "Use an Auto Scaling group with scaling policies and health checks",
      "Use EC2 Spot Instances only and manually add instances when needed",
      "Use AWS OpsWorks to deploy the application but not scale",
      "Use a single large EC2 instance with vertical scaling"
    ],
    "answer": 0,
    "explanation": "Auto Scaling groups provide automatic capacity management and instance replacement based on health checks and scaling policies, improving availability and resilience.",
    "difficulty": "Medium"
  },
  {
    "id": "SAA-105",
    "domainId": "D2",
    "domain": "Design Resilient Architectures",
    "section": "S3",
    "question": "A company needs to replicate objects from an S3 bucket in us-east-1 to another bucket in eu-west-1 for disaster recovery. Replication must be automatic after objects are uploaded.\nWhich feature should be used?",
    "choices": [
      "S3 Cross-Region Replication (CRR)",
      "S3 multipart upload",
      "S3 Transfer Acceleration",
      "S3 Select"
    ],
    "answer": 0,
    "explanation": "S3 Cross-Region Replication automatically replicates objects to a bucket in another region, supporting disaster recovery and compliance use cases.",
    "difficulty": "Medium"
  },
  {
    "id": "SAA-106",
    "domainId": "D3",
    "domain": "Design High-Performing Architectures",
    "section": "ELB",
    "question": "A multiplayer game uses UDP for real-time communication between clients and game servers running on EC2. The solution must distribute UDP traffic across instances with low latency.\nWhich load balancing option should you choose?",
    "choices": [
      "Network Load Balancer (NLB)",
      "Application Load Balancer (ALB)",
      "Classic Load Balancer (CLB) with HTTP listeners",
      "CloudFront distribution"
    ],
    "answer": 0,
    "explanation": "NLB operates at Layer 4 and supports UDP, providing very high performance and low latency load balancing. ALB is Layer 7 and supports HTTP/HTTPS, not UDP.",
    "difficulty": "Medium"
  },
  {
    "id": "SAA-107",
    "domainId": "D3",
    "domain": "Design High-Performing Architectures",
    "section": "DynamoDB",
    "question": "A product catalog API requires single-digit millisecond latency for reads at very high request rates. The data is key-value and read-heavy.\nWhich AWS service is MOST suitable as the primary datastore?",
    "choices": [
      "Amazon DynamoDB",
      "Amazon RDS MySQL",
      "Amazon S3 Select",
      "Amazon Redshift"
    ],
    "answer": 0,
    "explanation": "DynamoDB is a managed key-value/NoSQL database designed for single-digit millisecond latency at scale. Relational and analytics services are not optimized for this access pattern.",
    "difficulty": "Medium"
  },
  {
    "id": "SAA-108",
    "domainId": "D3",
    "domain": "Design High-Performing Architectures",
    "section": "CloudFront",
    "question": "A company serves large static assets (images, JS, CSS) to users worldwide. They want to reduce latency and offload requests from the origin servers.\nWhich solution should they implement?",
    "choices": [
      "Use Amazon CloudFront to cache content at edge locations",
      "Increase the EC2 instance size of the origin servers",
      "Move the assets to Amazon EBS",
      "Use AWS Snowball to deliver content to users"
    ],
    "answer": 0,
    "explanation": "CloudFront caches and serves static content from edge locations close to users, reducing latency and origin load.",
    "difficulty": "Medium"
  },
  {
    "id": "SAA-109",
    "domainId": "D3",
    "domain": "Design High-Performing Architectures",
    "section": "EBS",
    "question": "A database on EC2 needs the highest possible IOPS with consistent, low-latency storage performance.\nWhich EBS volume type is MOST appropriate?",
    "choices": [
      "Provisioned IOPS SSD (io1/io2)",
      "Cold HDD (sc1)",
      "Throughput Optimized HDD (st1)",
      "Magnetic (standard)"
    ],
    "answer": 0,
    "explanation": "io1/io2 volumes are designed for high IOPS and consistent performance, which is critical for latency-sensitive databases.",
    "difficulty": "Medium"
  },
  {
    "id": "SAA-110",
    "domainId": "D3",
    "domain": "Design High-Performing Architectures",
    "section": "S3",
    "question": "A client uploads very large files to S3, and uploads frequently fail due to unstable connections. They want higher reliability and better throughput.\nWhich S3 feature should they use?",
    "choices": [
      "S3 Multipart Upload",
      "S3 Object Lock",
      "S3 Inventory only",
      "S3 Static Website Hosting"
    ],
    "answer": 0,
    "explanation": "Multipart Upload splits large objects into parts that can be uploaded in parallel and retried independently, improving throughput and reliability for large uploads.",
    "difficulty": "Medium"
  },
  {
    "id": "SAA-111",
    "domainId": "D3",
    "domain": "Design High-Performing Architectures",
    "section": "RDS",
    "question": "An application has read-heavy traffic and uses an Amazon RDS database. The team wants to increase read throughput without changing the application’s write logic.\nWhich solution is MOST suitable?",
    "choices": [
      "Add one or more RDS read replicas and direct read traffic to them",
      "Enable Multi-AZ and send reads to the standby instance",
      "Increase storage size to improve reads",
      "Move the database to S3"
    ],
    "answer": 0,
    "explanation": "Read replicas scale out read traffic. In standard RDS Multi-AZ, the standby is for failover and typically not used for serving reads.",
    "difficulty": "Medium"
  },
  {
    "id": "SAA-112",
    "domainId": "D3",
    "domain": "Design High-Performing Architectures",
    "section": "Global Accelerator",
    "question": "A company has a global user base accessing a latency-sensitive API hosted behind an ALB in a single region. They want improved global performance without changing the application.\nWhich service can provide faster global routing to the regional endpoint?",
    "choices": [
      "AWS Global Accelerator",
      "AWS Snowcone",
      "Amazon S3 Glacier",
      "AWS Backup"
    ],
    "answer": 0,
    "explanation": "Global Accelerator uses the AWS global network to route users to the optimal endpoint, improving performance for latency-sensitive applications.",
    "difficulty": "Medium"
  },
  {
    "id": "SAA-113",
    "domainId": "D3",
    "domain": "Design High-Performing Architectures",
    "section": "ElastiCache",
    "question": "A web application repeatedly queries the same small set of product data, causing high load on the database. The team wants sub-millisecond retrieval for hot items.\nWhich solution should they implement?",
    "choices": [
      "Add an in-memory cache layer using Amazon ElastiCache (Redis or Memcached)",
      "Move the product data to Glacier Deep Archive",
      "Enable EBS snapshots more frequently",
      "Use AWS CloudTrail insights"
    ],
    "answer": 0,
    "explanation": "An in-memory cache like ElastiCache reduces database load and provides very low-latency retrieval for frequently accessed data.",
    "difficulty": "Medium"
  },
  {
    "id": "SAA-114",
    "domainId": "D3",
    "domain": "Design High-Performing Architectures",
    "section": "SQS",
    "question": "A worker application polls an SQS queue and often receives empty responses, increasing cost and CPU usage. The team wants to reduce the number of empty receives.\nWhich feature should they enable?",
    "choices": [
      "SQS long polling",
      "SQS FIFO",
      "SQS encryption",
      "SQS dead-letter queue"
    ],
    "answer": 0,
    "explanation": "Long polling waits for messages to arrive before returning a response, reducing empty receives and lowering cost.",
    "difficulty": "Medium"
  },
  {
    "id": "SAA-115",
    "domainId": "D3",
    "domain": "Design High-Performing Architectures",
    "section": "ECS",
    "question": "A containerized service needs to scale horizontally based on request rate, and tasks should be distributed across multiple AZs. The team prefers a managed container platform.\nWhich AWS service is MOST appropriate?",
    "choices": [
      "Amazon ECS (with Fargate or EC2 launch type) using a Service and Service Auto Scaling",
      "Amazon S3",
      "AWS Snowball Edge",
      "AWS Storage Gateway"
    ],
    "answer": 0,
    "explanation": "ECS provides managed container orchestration, supports multi-AZ placement, and can scale services automatically based on metrics such as request count or CPU.",
    "difficulty": "Medium"
  },
  {
    "id": "SAA-116",
    "domainId": "D3",
    "domain": "Design High-Performing Architectures",
    "section": "S3",
    "question": "An analytics team needs to run SQL queries on large CSV files stored in S3 without loading them into a database first.\nWhich service should they use?",
    "choices": [
      "Amazon Athena",
      "Amazon RDS",
      "Amazon ElastiCache",
      "AWS Secrets Manager"
    ],
    "answer": 0,
    "explanation": "Athena is a serverless query service that uses SQL to analyze data directly in S3, ideal for ad-hoc queries over files.",
    "difficulty": "Medium"
  },
  {
    "id": "SAA-117",
    "domainId": "D3",
    "domain": "Design High-Performing Architectures",
    "section": "EC2",
    "question": "A high-performance computing job requires low-latency, high-throughput network communication between EC2 instances.\nWhich EC2 placement strategy best supports this?",
    "choices": [
      "Cluster placement group",
      "Spread placement group across multiple racks",
      "Partition placement group with isolated partitions only",
      "Run instances in different regions"
    ],
    "answer": 0,
    "explanation": "Cluster placement groups place instances close together within an AZ to achieve low-latency, high-throughput networking, suitable for tightly coupled workloads.",
    "difficulty": "Medium"
  },
  {
    "id": "SAA-118",
    "domainId": "D3",
    "domain": "Design High-Performing Architectures",
    "section": "S3",
    "question": "A company uploads files to S3 from users around the world and wants faster uploads by optimizing transfer paths to S3.\nWhich S3 feature can help?",
    "choices": [
      "S3 Transfer Acceleration",
      "S3 Glacier Deep Archive",
      "S3 Object Lock",
      "S3 Batch Operations"
    ],
    "answer": 0,
    "explanation": "Transfer Acceleration uses CloudFront edge locations to accelerate uploads to S3 over long distances, improving performance for global users.",
    "difficulty": "Medium"
  },
  {
    "id": "SAA-119",
    "domainId": "D4",
    "domain": "Design Cost-Optimized Architectures",
    "section": "S3",
    "question": "A team stores monthly reports in S3. Reports are accessed frequently for the first 30 days and then rarely accessed, but they still need millisecond retrieval when they are accessed.\nWhich storage class transition is MOST cost-effective?",
    "choices": [
      "Transition objects to S3 Standard-IA after 30 days using a lifecycle rule",
      "Transition objects to S3 Glacier Deep Archive after 30 days",
      "Keep objects in S3 Standard forever",
      "Transition objects to S3 Glacier Flexible Retrieval immediately"
    ],
    "answer": 0,
    "explanation": "Standard-IA is designed for infrequently accessed data with the same millisecond access as Standard, making it a common cost optimization after the frequent-access period.",
    "difficulty": "Medium"
  },
  {
    "id": "SAA-120",
    "domainId": "D4",
    "domain": "Design Cost-Optimized Architectures",
    "section": "EC2",
    "question": "A company runs a steady-state workload 24/7 for the next 1–3 years. They want lower cost than On-Demand while keeping predictable capacity.\nWhich pricing option is typically MOST cost-effective?",
    "choices": [
      "Reserved Instances or Savings Plans",
      "Spot Instances only",
      "On-Demand Instances only",
      "Dedicated Hosts only"
    ],
    "answer": 0,
    "explanation": "For long-running steady workloads, Reserved Instances or Savings Plans usually provide significant discounts compared to On-Demand, without the interruption risk of Spot.",
    "difficulty": "Medium"
  },
  {
    "id": "SAA-121",
    "domainId": "D4",
    "domain": "Design Cost-Optimized Architectures",
    "section": "S3",
    "question": "A company stores backups in S3 that are almost never accessed. Retrieval can take hours, and the priority is minimizing storage cost.\nWhich S3 storage class is MOST suitable?",
    "choices": [
      "S3 Glacier Deep Archive",
      "S3 Standard",
      "S3 Standard-IA",
      "S3 Glacier Instant Retrieval"
    ],
    "answer": 0,
    "explanation": "Glacier Deep Archive is designed for long-term archival with the lowest storage cost, and it supports hours-level retrieval times, matching the requirement.",
    "difficulty": "Medium"
  },
  {
    "id": "SAA-122",
    "domainId": "D4",
    "domain": "Design Cost-Optimized Architectures",
    "section": "NAT/VPC",
    "question": "A workload in private subnets calls Amazon S3 frequently. Using a NAT Gateway is generating significant data processing charges.\nWhich change reduces cost while keeping traffic private?",
    "choices": [
      "Add an S3 Gateway VPC endpoint and route S3 traffic through it",
      "Add another NAT Gateway in a second AZ",
      "Move the instances to public subnets with public IPs",
      "Use AWS Direct Connect for internet access"
    ],
    "answer": 0,
    "explanation": "Gateway endpoints for S3 keep traffic within the AWS network and avoid NAT Gateway data processing charges for S3 access from private subnets.",
    "difficulty": "Medium"
  },
  {
    "id": "SAA-123",
    "domainId": "D4",
    "domain": "Design Cost-Optimized Architectures",
    "section": "DynamoDB",
    "question": "A startup has unpredictable traffic patterns and wants to avoid capacity planning for a DynamoDB table. They prefer a pay-per-request model.\nWhich DynamoDB capacity mode should they choose?",
    "choices": [
      "On-demand capacity mode",
      "Provisioned capacity without auto scaling",
      "Provisioned capacity with a fixed WCU/RCU",
      "Local DynamoDB on EC2"
    ],
    "answer": 0,
    "explanation": "On-demand capacity charges per request and automatically scales to handle traffic without manual capacity planning, which is ideal for unpredictable workloads.",
    "difficulty": "Medium"
  },
  {
    "id": "SAA-124",
    "domainId": "D4",
    "domain": "Design Cost-Optimized Architectures",
    "section": "RDS",
    "question": "A development database on RDS is used only during business hours (8 AM–6 PM weekdays). Outside those hours, it can be stopped to save cost.\nWhich approach is MOST appropriate?",
    "choices": [
      "Stop the RDS instance outside business hours using automation (for example, AWS Instance Scheduler or a scheduled Lambda), and start it when needed",
      "Enable Multi-AZ so the standby is stopped automatically",
      "Move the database to a larger instance type",
      "Use an EC2 instance with the database running 24/7"
    ],
    "answer": 0,
    "explanation": "Stopping a non-production RDS instance during off-hours can reduce cost. Multi-AZ increases cost and doesn’t stop the database; larger instances cost more.",
    "difficulty": "Medium"
  },
  {
    "id": "SAA-125",
    "domainId": "D4",
    "domain": "Design Cost-Optimized Architectures",
    "section": "S3",
    "question": "A company wants to automatically move objects to cheaper storage classes over time without changing application code.\nWhich S3 feature supports this?",
    "choices": [
      "S3 lifecycle policies",
      "S3 Select",
      "S3 Transfer Acceleration",
      "S3 Object Lock"
    ],
    "answer": 0,
    "explanation": "Lifecycle policies automate transitions between storage classes and can also expire objects, enabling cost optimization without application changes.",
    "difficulty": "Medium"
  },
  {
    "id": "SAA-126",
    "domainId": "D4",
    "domain": "Design Cost-Optimized Architectures",
    "section": "CloudFront",
    "question": "A company serves static files from S3 to users worldwide. They are paying high S3 data transfer costs and users in distant regions have high latency.\nWhich solution can both improve performance and potentially reduce origin load/cost?",
    "choices": [
      "Use CloudFront in front of S3 to cache content at edge locations",
      "Move content from S3 to EBS",
      "Use Glacier Deep Archive for static files",
      "Use a single larger EC2 instance as a file server"
    ],
    "answer": 0,
    "explanation": "CloudFront edge caching reduces repeated origin fetches and improves latency for global users, which can also reduce S3 request load and overall cost depending on access patterns.",
    "difficulty": "Medium"
  },
  {
    "id": "SAA-127",
    "domainId": "D4",
    "domain": "Design Cost-Optimized Architectures",
    "section": "EBS",
    "question": "A batch workload needs low-cost storage for infrequently accessed data, but it still requires reasonably fast access when needed.\nWhich EBS volume type is MOST cost-effective for throughput-oriented workloads?",
    "choices": [
      "Throughput Optimized HDD (st1)",
      "Provisioned IOPS SSD (io2)",
      "Cold HDD (sc1) for high IOPS",
      "Magnetic (standard) for best performance"
    ],
    "answer": 0,
    "explanation": "st1 is designed for throughput-intensive workloads at lower cost than SSD options. io2 is higher-cost and optimized for IOPS, while sc1 is lowest cost for infrequent access with lower performance.",
    "difficulty": "Medium"
  },
  {
    "id": "SAA-128",
    "domainId": "D4",
    "domain": "Design Cost-Optimized Architectures",
    "section": "Compute",
    "question": "A company runs a fault-tolerant background processing fleet where instances can be interrupted and the workload can resume.\nThey want the lowest compute cost.\nWhich EC2 pricing option is MOST suitable?",
    "choices": [
      "Spot Instances",
      "On-Demand Instances",
      "Dedicated Hosts",
      "Reserved Instances for 3 years only"
    ],
    "answer": 0,
    "explanation": "Spot Instances provide the largest discounts for fault-tolerant workloads that can handle interruptions.",
    "difficulty": "Medium"
  },
  {
    "id": "SAA-129",
    "domainId": "D4",
    "domain": "Design Cost-Optimized Architectures",
    "section": "Logs",
    "question": "A company stores application logs in CloudWatch Logs but notices that older logs are rarely accessed. They want to reduce ongoing log storage cost.\nWhat should they do?",
    "choices": [
      "Set log retention policies to automatically expire older log events",
      "Disable logging entirely after 30 days",
      "Increase log verbosity to reduce storage",
      "Move logs to EBS volumes attached to EC2"
    ],
    "answer": 0,
    "explanation": "CloudWatch Logs retention policies automatically delete log events older than a specified period, reducing storage cost while keeping recent logs available.",
    "difficulty": "Medium"
  },
  {
    "id": "SAA-130",
    "domainId": "D4",
    "domain": "Design Cost-Optimized Architectures",
    "section": "S3",
    "question": "A company stores images in S3. A subset under the prefix /realtime/ must always have millisecond retrieval. Older images under /archive/ can take hours to retrieve after 90 days.\nThey want the most cost-effective lifecycle configuration.\nWhich option best meets the requirements?",
    "choices": [
      "Lifecycle rule: keep /realtime/ in Standard or Standard-IA as appropriate, and transition /archive/ to Glacier Flexible Retrieval or Deep Archive after 90 days",
      "Move the entire bucket to Glacier Deep Archive after 90 days",
      "Use Intelligent-Tiering for all objects and never transition to archive tiers",
      "Enable S3 Transfer Acceleration for /archive/ objects"
    ],
    "answer": 0,
    "explanation": "Using prefix-based lifecycle rules lets you keep the performance-critical prefix in a millisecond-access class while moving archival content to cheaper archive tiers when retrieval time allows, optimizing cost.",
    "difficulty": "Medium"
  },
  {
    "id": "SAA-131",
    "domainId": "D1",
    "domain": "Design Secure Architectures",
    "section": "ACM",
    "question": "A company hosts dozens of internet-facing applications, each behind its own Application Load Balancer (ALB) across multiple Availability Zones. Each app has its own fully qualified domain name.\nThe security team requires publicly trusted SSL/TLS certificates and wants automatic renewal with minimal ongoing operations.\nWhich solution will meet these requirements with the LEAST operational overhead?",
    "choices": [
      "Use AWS Certificate Manager (ACM) to request public certificates for each domain and associate them with the HTTPS listeners on each ALB",
      "Use AWS Certificate Manager Private CA to issue certificates and upload the root certificate to all customer browsers",
      "Generate self-signed certificates and import them into ACM for each ALB",
      "Run Let’s Encrypt certbot on the EC2 instances behind the ALBs and manage renewals with a scheduled job"
    ],
    "answer": 0,
    "explanation": "ACM public certificates are publicly trusted, integrate directly with ALB listeners, and renew automatically. Private CA and self-signed certificates are not publicly trusted for general internet clients, and self-managing Let’s Encrypt introduces significant operational overhead.",
    "difficulty": "Hard"
  },
  {
    "id": "SAA-132",
    "domainId": "D1",
    "domain": "Design Secure Architectures",
    "section": "Organizations",
    "question": "A company uses AWS Organizations with multiple accounts. The security team mandates that no one can disable CloudTrail logging or delete CloudTrail log files, even in development accounts.\nDevelopers still need broad permissions within their accounts for day-to-day work.\nWhich combination of controls best enforces this requirement?",
    "choices": [
      "Apply an SCP that denies stopping/deleting CloudTrail and denies deleting objects in the centralized log bucket; store logs in a dedicated logging account",
      "Attach AdministratorAccess to all developers and rely on CloudTrail alarms to detect changes",
      "Enable AWS Config in each account and automatically revert changes to CloudTrail via a Lambda function",
      "Place CloudTrail logs in each account’s local S3 bucket with bucket policies that allow deletion only by admins"
    ],
    "answer": 0,
    "explanation": "SCPs provide account-level guardrails that apply even to administrators in member accounts. Centralizing CloudTrail logs in a dedicated logging account further reduces risk. Detective/auto-remediation is helpful but does not prevent the action from occurring.",
    "difficulty": "Hard"
  },
  {
    "id": "SAA-133",
    "domainId": "D1",
    "domain": "Design Secure Architectures",
    "section": "KMS",
    "question": "A partner in a separate AWS account needs read access to objects in your S3 bucket for a short-lived project. The objects are encrypted with SSE-KMS using a customer-managed KMS key in your account.\nThe partner can read the objects but gets AccessDenied when attempting to decrypt.\nWhat is the MOST appropriate fix?",
    "choices": [
      "Update the KMS key policy (and/or grants) to allow the partner’s IAM role to use the key for decryption, and ensure the S3 bucket policy allows the role to read the objects",
      "Disable SSE-KMS and re-upload objects with SSE-S3 so other accounts can read them",
      "Copy the objects to an unencrypted bucket and share that bucket publicly",
      "Enable S3 Transfer Acceleration so decryption happens at the edge"
    ],
    "answer": 0,
    "explanation": "For SSE-KMS, both S3 permissions and KMS key permissions are required. Cross-account consumers must be granted KMS decrypt permissions via the key policy or a grant, in addition to S3 read permissions.",
    "difficulty": "Hard"
  },
  {
    "id": "SAA-134",
    "domainId": "D1",
    "domain": "Design Secure Architectures",
    "section": "WAF",
    "question": "A company runs many CloudFront distributions across multiple AWS accounts. The security team wants to enforce a standard AWS WAF web ACL (managed rule groups + IP reputation lists) across all distributions and have a single place to manage these policies.\nWhich solution meets these requirements with the LEAST operational overhead?",
    "choices": [
      "Use AWS Firewall Manager to centrally deploy and manage AWS WAF policies across accounts and CloudFront distributions",
      "Create identical WAF web ACLs manually in every account and attach them to each distribution",
      "Use security groups on the origin EC2 instances to block malicious HTTP payloads",
      "Enable AWS Shield Standard on CloudFront and rely on it for application-layer protections"
    ],
    "answer": 0,
    "explanation": "AWS Firewall Manager provides centralized management and enforcement of security policies like AWS WAF across multiple accounts and resources, reducing manual configuration and drift.",
    "difficulty": "Hard"
  },
  {
    "id": "SAA-135",
    "domainId": "D1",
    "domain": "Design Secure Architectures",
    "section": "IAM Identity Center",
    "question": "A company wants employees to sign in to AWS using their corporate identity provider (IdP) and be assigned AWS permissions based on their job role. The solution should avoid creating IAM users and should be easy to manage as employees join/leave.\nWhich approach is MOST suitable?",
    "choices": [
      "Use AWS IAM Identity Center (AWS SSO) integrated with the corporate IdP and assign permission sets to users/groups",
      "Create an IAM user for each employee and enforce MFA",
      "Use access keys distributed through a password manager and rotate them monthly",
      "Use Amazon Cognito user pools for employee access to the AWS console"
    ],
    "answer": 0,
    "explanation": "IAM Identity Center is designed for workforce authentication and authorization into AWS accounts, integrating with external IdPs and mapping users/groups to permission sets. This avoids managing long-lived IAM users.",
    "difficulty": "Hard"
  },
  {
    "id": "SAA-136",
    "domainId": "D1",
    "domain": "Design Secure Architectures",
    "section": "S3",
    "question": "A company stores critical compliance evidence in S3. The files must be retained for 5 years and must not be deletable or overwriteable during the retention period, even by administrators.\nWhich solution best meets these requirements?",
    "choices": [
      "Enable S3 versioning and S3 Object Lock in Compliance mode with a 5-year retention period",
      "Enable S3 versioning and set a lifecycle rule to transition objects to Glacier Deep Archive after 30 days",
      "Enable MFA Delete and keep the root MFA device offline",
      "Encrypt objects with SSE-S3 and restrict s3:DeleteObject via IAM"
    ],
    "answer": 0,
    "explanation": "S3 Object Lock in Compliance mode provides WORM protection that prevents deletion or modification of protected object versions for the retention period, even by users with high privileges. Versioning is required for Object Lock.",
    "difficulty": "Hard"
  },
  {
    "id": "SAA-137",
    "domainId": "D1",
    "domain": "Design Secure Architectures",
    "section": "VPC",
    "question": "A security team requires that EC2 instances in private subnets can access AWS public services (like S3, DynamoDB, and Secrets Manager) without traversing the public internet, and that access can be controlled with IAM policies and VPC policies.\nWhich design best meets the requirement?",
    "choices": [
      "Create VPC endpoints: gateway endpoints for S3/DynamoDB and interface endpoints for Secrets Manager (and other services), and update route tables/DNS accordingly",
      "Route all private subnet traffic through a NAT Gateway to reach AWS public endpoints",
      "Use an Internet Gateway and assign public IPs to the instances",
      "Create VPC peering to an AWS-managed VPC that hosts the AWS services"
    ],
    "answer": 0,
    "explanation": "VPC endpoints keep traffic within the AWS network and avoid public internet routing. Gateway endpoints are used for S3 and DynamoDB, while interface endpoints (PrivateLink) are used for services like Secrets Manager.",
    "difficulty": "Hard"
  },
  {
    "id": "SAA-138",
    "domainId": "D1",
    "domain": "Design Secure Architectures",
    "section": "CloudTrail",
    "question": "A company wants to detect and alert on suspicious root account usage (console sign-in or access key usage) in near real time. They also want a searchable history of these events.\nWhich solution is MOST suitable?",
    "choices": [
      "Enable CloudTrail and create an EventBridge rule for relevant CloudTrail events that sends notifications (SNS), and store logs centrally in S3/CloudWatch Logs for search",
      "Enable VPC Flow Logs and create alarms when port 443 traffic increases",
      "Enable AWS Config and run compliance evaluations every 24 hours",
      "Enable AWS Shield Advanced and monitor Shield events"
    ],
    "answer": 0,
    "explanation": "Root account usage is captured in CloudTrail. EventBridge can match specific CloudTrail events and trigger near-real-time notifications. Centralized log storage enables audit and search.",
    "difficulty": "Hard"
  },
  {
    "id": "SAA-139",
    "domainId": "D1",
    "domain": "Design Secure Architectures",
    "section": "KMS",
    "question": "A company must encrypt EBS volumes on EC2 instances. The security team requires that encryption keys be rotated automatically, and access to use the key must be limited to a specific set of roles.\nWhich solution should you implement?",
    "choices": [
      "Use EBS encryption with a customer-managed KMS key, enable automatic key rotation, and restrict key usage via the key policy to approved roles",
      "Use EBS encryption with AWS-managed keys and rely on IAM user policies only",
      "Use client-side encryption inside the EC2 instance and store keys in the AMI",
      "Use unencrypted EBS and enforce TLS for all disk I/O"
    ],
    "answer": 0,
    "explanation": "Customer-managed KMS keys support automatic rotation and fine-grained control through key policies and grants. EBS integrates directly with KMS for encryption at rest.",
    "difficulty": "Hard"
  },
  {
    "id": "SAA-140",
    "domainId": "D1",
    "domain": "Design Secure Architectures",
    "section": "STS",
    "question": "A vendor needs temporary access to your AWS account to troubleshoot a production issue. Your company forbids sharing long-lived credentials and wants the access to automatically expire after a few hours.\nWhich solution is MOST appropriate?",
    "choices": [
      "Create an IAM role with required permissions and a trust policy for the vendor’s AWS account, and require the vendor to assume the role using STS with a short session duration",
      "Create an IAM user for the vendor and rotate the access keys after the troubleshooting session",
      "Share the root account credentials for the troubleshooting window and then change the password",
      "Create a security group rule to allow the vendor’s IP and let them SSH to all instances"
    ],
    "answer": 0,
    "explanation": "Assuming an IAM role via STS provides temporary credentials that expire automatically and avoids sharing long-lived secrets. Trust policies and session duration enforce controlled access.",
    "difficulty": "Hard"
  },
  {
    "id": "SAA-141",
    "domainId": "D1",
    "domain": "Design Secure Architectures",
    "section": "Secrets Manager",
    "question": "A microservice running on ECS retrieves DB credentials from Secrets Manager. A new compliance rule requires that services must not access secrets unless they are running in the approved VPC and use a specific VPC endpoint.\nWhich design best meets this requirement?",
    "choices": [
      "Create an interface VPC endpoint for Secrets Manager and use a resource policy/endpoint policy plus IAM conditions to restrict secret access through the endpoint",
      "Store the secret in an S3 bucket and restrict access with a bucket policy",
      "Use environment variables and rotate the container image on every rotation",
      "Use a NAT Gateway and allow the service to call Secrets Manager over the internet"
    ],
    "answer": 0,
    "explanation": "Interface endpoints allow private connectivity to Secrets Manager. Endpoint policies and IAM conditions (for example, requiring a source VPC endpoint) can enforce that secrets are accessed only through the approved private path.",
    "difficulty": "Hard"
  },
  {
    "id": "SAA-142",
    "domainId": "D1",
    "domain": "Design Secure Architectures",
    "section": "S3",
    "question": "A company exposes private documents to authenticated customers via CloudFront. Documents must remain private in S3, and direct access to the S3 bucket must be blocked.\nWhich architecture should you implement?",
    "choices": [
      "Use CloudFront with an Origin Access Control (or Origin Access Identity) so only CloudFront can read from the S3 origin, and use signed URLs/cookies for authenticated access",
      "Make the S3 bucket public and rely on signed URLs to hide the object keys",
      "Use S3 static website hosting with Basic Auth enabled",
      "Expose the S3 bucket through an internet-facing ALB"
    ],
    "answer": 0,
    "explanation": "OAC/OAI prevents direct access to the S3 origin by allowing only CloudFront to fetch objects. Signed URLs/cookies then restrict which viewers can access the content through CloudFront.",
    "difficulty": "Hard"
  },
  {
    "id": "SAA-143",
    "domainId": "D1",
    "domain": "Design Secure Architectures",
    "section": "VPC",
    "question": "A company wants to allow inbound SSH access to a small set of EC2 instances for administrators, but only after the administrators authenticate to AWS. The company wants to avoid managing bastion host patching and SSH keys.\nWhich solution provides secure access with the LEAST operational overhead?",
    "choices": [
      "Use AWS Systems Manager Session Manager for shell access and remove inbound SSH access from security groups",
      "Deploy a hardened bastion host in a public subnet and rotate SSH keys weekly",
      "Open port 22 to the administrators’ IP addresses and enforce strong SSH passwords",
      "Use a VPN appliance on EC2 and have admins connect over SSH"
    ],
    "answer": 0,
    "explanation": "Session Manager provides auditable, IAM-controlled access to instances without opening inbound SSH ports or managing bastion hosts and keys. It reduces operational overhead while improving security.",
    "difficulty": "Hard"
  },
  {
    "id": "SAA-144",
    "domainId": "D1",
    "domain": "Design Secure Architectures",
    "section": "Security Hub",
    "question": "A company wants a centralized view of security findings across GuardDuty, Inspector, and Config rules for all AWS accounts. They also want to automatically open tickets when critical findings appear.\nWhich solution is MOST suitable?",
    "choices": [
      "Enable AWS Security Hub organization-wide, aggregate findings to a central account, and use EventBridge rules to route critical findings to an incident/ticketing workflow",
      "Enable CloudWatch Logs Insights across accounts to query for security events",
      "Enable AWS Trusted Advisor in every account and export the report weekly",
      "Use AWS Budgets alerts to detect security issues"
    ],
    "answer": 0,
    "explanation": "Security Hub aggregates findings from multiple AWS services and can centralize them in a delegated administrator account. EventBridge can trigger automated workflows based on finding severity.",
    "difficulty": "Hard"
  },
  {
    "id": "SAA-145",
    "domainId": "D1",
    "domain": "Design Secure Architectures",
    "section": "IAM",
    "question": "An application in Account A needs to write objects to an S3 bucket in Account B. The security team requires least privilege, no long-lived credentials, and clear separation of duties.\nWhich option best meets these requirements?",
    "choices": [
      "Create an IAM role in Account B that Account A can assume, grant it s3:PutObject to the bucket, and allow the role in the bucket policy",
      "Create an IAM user in Account B and share the access keys with Account A",
      "Make the bucket public-write and use object prefixes to separate writes",
      "Use pre-signed URLs generated by Account A without changing Account B"
    ],
    "answer": 0,
    "explanation": "Cross-account role assumption provides temporary credentials and supports least privilege. Bucket policies can restrict writes to the role, avoiding shared long-lived access keys.",
    "difficulty": "Hard"
  },
  {
    "id": "SAA-146",
    "domainId": "D1",
    "domain": "Design Secure Architectures",
    "section": "IAM",
    "question": "A team uses IAM roles for EC2 instances. During an incident, a developer added a broad inline policy to the instance role. Security wants to ensure that role permissions cannot be expanded beyond a predefined maximum, but still allow adding narrower permissions when needed.\nWhich control should be used?",
    "choices": [
      "Attach a permissions boundary to the role to cap its maximum permissions",
      "Use an ACL on the EC2 instance to deny outbound network traffic",
      "Enable AWS Shield Advanced on the EC2 instance",
      "Add the role to an IAM group with restricted permissions"
    ],
    "answer": 0,
    "explanation": "Permissions boundaries can be applied to roles (not just users) to limit the maximum effective permissions, preventing expansion beyond a defined scope while still allowing additional allowed permissions to be attached.",
    "difficulty": "Hard"
  },
  {
    "id": "SAA-147",
    "domainId": "D1",
    "domain": "Design Secure Architectures",
    "section": "S3",
    "question": "A company requires that all S3 access to a sensitive bucket must come from within their VPC over a specific VPC endpoint, and any request from the public internet must be denied, even if credentials are valid.\nWhich solution best enforces this?",
    "choices": [
      "Use an S3 bucket policy that denies requests unless they come through the specified VPC endpoint (aws:sourceVpce), and use an S3 Gateway VPC endpoint",
      "Enable SSE-KMS on the bucket and deny kms:Decrypt from the internet",
      "Enable S3 Transfer Acceleration to force requests through edge locations",
      "Enable S3 Block Public Access only"
    ],
    "answer": 0,
    "explanation": "Bucket policies can enforce network-based conditions such as requiring a particular VPC endpoint. Using an S3 gateway endpoint ensures traffic can stay within the AWS network, and the deny condition blocks any requests not coming through that endpoint.",
    "difficulty": "Hard"
  },
  {
    "id": "SAA-148",
    "domainId": "D1",
    "domain": "Design Secure Architectures",
    "section": "Shield/WAF",
    "question": "A financial services company runs an internet-facing application behind CloudFront and ALB. They are concerned about large-scale DDoS attacks and want DDoS response support plus cost protection for scaling-related charges during an attack.\nWhich solution is MOST suitable?",
    "choices": [
      "Subscribe to AWS Shield Advanced and (optionally) integrate AWS WAF for L7 protections",
      "Enable AWS Shield Standard only and rely on security groups",
      "Use Amazon Inspector to detect DDoS attempts",
      "Deploy the application only in private subnets and remove the ALB"
    ],
    "answer": 0,
    "explanation": "Shield Advanced provides enhanced DDoS protections, access to the DDoS response team, and financial protections for scaling charges resulting from attacks. WAF complements by filtering application-layer traffic.",
    "difficulty": "Hard"
  },
  {
    "id": "SAA-149",
    "domainId": "D1",
    "domain": "Design Secure Architectures",
    "section": "KMS",
    "question": "A company uses KMS keys for encrypting data. Security requires that only a specific microservice role can decrypt data, and administrators should be able to manage the key (rotate/disable) but not decrypt application data.\nWhich configuration best meets this requirement?",
    "choices": [
      "Use a customer-managed KMS key with a key policy that separates key administration permissions from key usage (encrypt/decrypt) permissions",
      "Use an AWS-managed KMS key and attach decrypt permissions to the admin role",
      "Store the key material in the application container and restrict access with security groups",
      "Use S3 SSE-S3 so KMS policies are not needed"
    ],
    "answer": 0,
    "explanation": "KMS key policies can separate administrative actions (like enabling/disabling, rotating) from cryptographic usage actions (Encrypt/Decrypt). Grant decrypt only to the microservice role while allowing admins to administer the key without data access.",
    "difficulty": "Hard"
  },
  {
    "id": "SAA-150",
    "domainId": "D1",
    "domain": "Design Secure Architectures",
    "section": "Config",
    "question": "A company must prove that security groups never allow inbound 0.0.0.0/0 access to SSH or RDP, and they need continuous monitoring with automatic evidence for auditors.\nWhich solution best meets these requirements?",
    "choices": [
      "Use AWS Config with managed rules (or custom rules) to evaluate security group configurations continuously, and store compliance history",
      "Use VPC Flow Logs and manually inspect logs for port 22/3389 traffic",
      "Enable GuardDuty and rely on findings for open ports",
      "Use CloudTrail only and search for AuthorizeSecurityGroupIngress calls"
    ],
    "answer": 0,
    "explanation": "AWS Config continuously evaluates resource configurations against rules and retains compliance history, which is useful for audit evidence. CloudTrail and flow logs are helpful but do not provide continuous configuration compliance evaluation by themselves.",
    "difficulty": "Hard"
  },
  {
    "id": "SAA-151",
    "domainId": "D2",
    "domain": "Design Resilient Architectures",
    "section": "DR/Route 53",
    "question": "A SaaS provider runs its primary workload in Region A. The application stack includes ALB + EC2, an RDS database, and an S3 bucket for user uploads. The business requires:\n- RPO of 15 minutes for the database\n- RTO of 1 hour for the application\n- Minimal ongoing costs in the secondary region\nWhich disaster recovery strategy BEST meets these requirements?",
    "choices": [
      "Pilot light: keep minimal core components running in Region B, use cross-region backups/replication (including frequent DB backups or replication) and scale up on failover",
      "Backup and restore only: keep no resources in Region B and rely solely on nightly backups",
      "Active-active: run the full stack at production scale in both regions at all times",
      "Warm standby: run a fully scaled stack in Region B at all times"
    ],
    "answer": 0,
    "explanation": "Pilot light keeps a minimal footprint in the secondary region (lower cost than warm standby/active-active) while enabling faster recovery than backup/restore. Achieving a 15-minute RPO typically requires frequent replication/backup for the database and automated procedures to scale the rest of the stack within the 1-hour RTO.",
    "difficulty": "Hard"
  },
  {
    "id": "SAA-152",
    "domainId": "D2",
    "domain": "Design Resilient Architectures",
    "section": "RDS/Aurora",
    "question": "A company runs an Aurora MySQL cluster for a critical application. They want protection against an AZ failure with automatic failover, and they also want to be able to fail over to another region for a regional outage with the lowest RPO possible.\nWhich design is MOST appropriate?",
    "choices": [
      "Use Aurora Multi-AZ (cluster with replicas in multiple AZs) and configure Aurora Global Database for cross-region replication",
      "Use a single-instance Aurora cluster and take manual snapshots to copy to another region",
      "Use RDS read replicas in the same AZ only and promote one manually",
      "Use DynamoDB global tables instead of Aurora without changing the application"
    ],
    "answer": 0,
    "explanation": "Aurora provides Multi-AZ high availability via replicas and automatic failover within a region. Aurora Global Database provides low-latency cross-region replication to reduce RPO for regional failover scenarios.",
    "difficulty": "Hard"
  },
  {
    "id": "SAA-153",
    "domainId": "D2",
    "domain": "Design Resilient Architectures",
    "section": "SQS/Lambda",
    "question": "A company processes orders using SQS and Lambda. The same order event can be delivered more than once due to retries, and the downstream system must never create duplicate orders.\nThe team wants a resilient design that handles retries safely.\nWhich solution is MOST suitable?",
    "choices": [
      "Make the Lambda processing idempotent using a DynamoDB table to track processed order IDs, and keep retries/DLQ for failures",
      "Disable retries in Lambda so messages are never reprocessed",
      "Increase the SQS visibility timeout to 12 hours so duplicates cannot occur",
      "Use SNS only without SQS so delivery happens once"
    ],
    "answer": 0,
    "explanation": "Event-driven systems can deliver duplicates. Idempotent processing (tracking processed IDs in DynamoDB or equivalent) ensures retries do not create duplicates, while DLQs capture poison messages for investigation.",
    "difficulty": "Hard"
  },
  {
    "id": "SAA-154",
    "domainId": "D2",
    "domain": "Design Resilient Architectures",
    "section": "ECS/ALB",
    "question": "A production service runs on ECS Fargate behind an ALB. During deployments, users occasionally see 5xx errors because tasks are terminated before the new tasks are ready.\nThe team wants zero-downtime deployments with minimal effort.\nWhich approach should they implement?",
    "choices": [
      "Use an ECS service with rolling updates, configure ALB health checks, and set a deployment minimumHealthyPercent/maximumPercent so new tasks pass health checks before old tasks are drained",
      "Manually stop all running tasks, then start new tasks after the image is updated",
      "Switch to an NLB because it does not do health checks",
      "Place CloudFront in front of the ALB and disable origin health checks"
    ],
    "answer": 0,
    "explanation": "ECS service deployments can be configured to keep a minimum healthy capacity while starting new tasks. Combined with ALB health checks and connection draining, this avoids terminating old tasks until new ones are healthy.",
    "difficulty": "Hard"
  },
  {
    "id": "SAA-155",
    "domainId": "D2",
    "domain": "Design Resilient Architectures",
    "section": "Route 53",
    "question": "A company has two copies of a web application: one in us-east-1 and one in eu-west-1. They want active-active traffic distribution, but if one region fails, 100% of traffic should go to the healthy region automatically.\nWhich Route 53 configuration best meets this?",
    "choices": [
      "Use weighted routing with health checks on each regional endpoint",
      "Use failover routing only with a single primary and no secondary health check",
      "Use geolocation routing without health checks",
      "Use multivalue answer routing without health checks"
    ],
    "answer": 0,
    "explanation": "Weighted routing can split traffic across multiple endpoints and, when paired with health checks, will stop returning unhealthy endpoints—effectively shifting traffic to the healthy region automatically.",
    "difficulty": "Hard"
  },
  {
    "id": "SAA-156",
    "domainId": "D2",
    "domain": "Design Resilient Architectures",
    "section": "S3",
    "question": "A company replicates data using S3 Cross-Region Replication (CRR). They recently enabled CRR but noticed that older objects that already existed in the bucket were not replicated.\nThey want all existing objects to be replicated to the destination bucket.\nWhich action should they take?",
    "choices": [
      "Use S3 Batch Operations (or a one-time copy job) to replicate existing objects, since CRR applies automatically only to new objects by default",
      "Disable and re-enable CRR and it will backfill all objects automatically",
      "Enable S3 Transfer Acceleration to speed up replication of existing objects",
      "Enable S3 Select so CRR can find old objects"
    ],
    "answer": 0,
    "explanation": "CRR typically replicates new objects after the rule is enabled; existing objects require an explicit backfill process (such as S3 Batch Operations or a copy job) to replicate them to the destination bucket.",
    "difficulty": "Hard"
  },
  {
    "id": "SAA-157",
    "domainId": "D2",
    "domain": "Design Resilient Architectures",
    "section": "ElastiCache",
    "question": "An application stores user session state in-memory on the web servers. During Auto Scaling events, users are frequently logged out because they land on new instances.\nThe company needs a resilient approach that preserves sessions even when instances scale in/out or fail.\nWhich solution is MOST suitable?",
    "choices": [
      "Store sessions in a centralized shared store such as Amazon ElastiCache (Redis) or DynamoDB instead of on-instance memory",
      "Enable ALB sticky sessions and store sessions only in instance memory",
      "Increase the Auto Scaling cooldown to reduce scaling events",
      "Use a larger instance type so scaling isn’t needed"
    ],
    "answer": 0,
    "explanation": "Storing session state in a centralized external store decouples sessions from individual instances and improves resilience across scaling and failures. Sticky sessions help but still lose sessions if an instance fails or scales in.",
    "difficulty": "Hard"
  },
  {
    "id": "SAA-158",
    "domainId": "D2",
    "domain": "Design Resilient Architectures",
    "section": "Multi-AZ",
    "question": "A critical internal service runs on EC2 instances in a single subnet in one AZ. The business requires the service to remain available during an AZ outage.\nWhich change provides the MOST reliable improvement?",
    "choices": [
      "Deploy the service across at least two AZs using an Auto Scaling group and a load balancer, with subnets in each AZ",
      "Increase the instance size in the current AZ",
      "Take EBS snapshots every hour",
      "Enable detailed monitoring on the instance"
    ],
    "answer": 0,
    "explanation": "High availability against AZ failure requires running across multiple AZs. An ASG plus a load balancer and subnets in multiple AZs ensures the service can continue even if one AZ becomes unavailable.",
    "difficulty": "Hard"
  },
  {
    "id": "SAA-159",
    "domainId": "D2",
    "domain": "Design Resilient Architectures",
    "section": "RDS",
    "question": "A company uses an RDS MySQL database. Reporting queries occasionally cause performance issues for the production workload.\nThey want to isolate reporting reads without impacting write performance and still keep production highly available.\nWhich solution is MOST suitable?",
    "choices": [
      "Create an RDS read replica for reporting queries, and keep Multi-AZ enabled for the primary for availability",
      "Enable Multi-AZ and direct reporting queries to the standby instance",
      "Scale up the primary database instance and run reporting on it",
      "Export all production data to S3 daily and query it with S3 Select"
    ],
    "answer": 0,
    "explanation": "Read replicas offload read-heavy workloads like reporting, while Multi-AZ protects availability. The standby in Multi-AZ is not designed for reads in standard RDS Multi-AZ deployments.",
    "difficulty": "Hard"
  },
  {
    "id": "SAA-160",
    "domainId": "D2",
    "domain": "Design Resilient Architectures",
    "section": "DynamoDB",
    "question": "A company uses DynamoDB with provisioned capacity. During sudden traffic spikes, requests are throttled, causing errors.\nThe business needs the table to handle unpredictable spikes reliably while still optimizing for cost during normal traffic.\nWhich configuration is MOST appropriate?",
    "choices": [
      "Enable auto scaling for provisioned read/write capacity (or use on-demand if unpredictability is extreme)",
      "Disable throttling by turning off DynamoDB partitioning",
      "Move the table to S3 Standard to absorb spikes",
      "Use a larger EC2 instance to host DynamoDB locally"
    ],
    "answer": 0,
    "explanation": "DynamoDB auto scaling adjusts provisioned capacity based on utilization, helping handle spikes while reducing cost during low usage. For highly unpredictable patterns, on-demand capacity may be appropriate as well.",
    "difficulty": "Hard"
  },
  {
    "id": "SAA-161",
    "domainId": "D2",
    "domain": "Design Resilient Architectures",
    "section": "EventBridge",
    "question": "A company wants to decouple multiple microservices and route events based on event content (for example, route “fraud-alert” events to a specific service and “order-created” events to another).\nThey also want built-in retry and DLQ capabilities.\nWhich service is MOST suitable?",
    "choices": [
      "Amazon EventBridge with rules and targets (plus DLQ where appropriate)",
      "Amazon S3 event notifications only",
      "Amazon EC2 Auto Scaling lifecycle hooks",
      "Amazon Route 53 Resolver"
    ],
    "answer": 0,
    "explanation": "EventBridge supports content-based routing using rules and can integrate with targets that provide retry/DLQ behavior, enabling resilient event-driven architectures across services.",
    "difficulty": "Hard"
  },
  {
    "id": "SAA-162",
    "domainId": "D2",
    "domain": "Design Resilient Architectures",
    "section": "EFS",
    "question": "A media processing application runs in two AZs and writes intermediate files to a shared file system. The team wants the shared storage to remain available even if one AZ is impaired, with minimal management.\nWhich choice best meets this requirement?",
    "choices": [
      "Use Amazon EFS mounted from both AZs",
      "Use an EBS volume attached to one instance and share it over NFS yourself",
      "Use instance store on each EC2 instance",
      "Use S3 Glacier Deep Archive for intermediate files"
    ],
    "answer": 0,
    "explanation": "EFS is a managed multi-AZ file system designed for shared access from multiple AZs, providing high availability with minimal operational overhead compared to self-managed NFS on EBS.",
    "difficulty": "Hard"
  },
  {
    "id": "SAA-163",
    "domainId": "D2",
    "domain": "Design Resilient Architectures",
    "section": "S3",
    "question": "A company wants strong protection against accidental deletions and ransomware for an S3 bucket, while still being able to recover data to a previous point in time.\nThey also need the ability to replicate data to another region for DR.\nWhich combination best meets these requirements?",
    "choices": [
      "Enable S3 versioning and use S3 Object Lock (if WORM is needed) plus S3 Cross-Region Replication where appropriate",
      "Enable S3 Transfer Acceleration and store objects as multipart uploads",
      "Use S3 Select and store query results in another region",
      "Use S3 static website hosting and enable logging"
    ],
    "answer": 0,
    "explanation": "Versioning protects against overwrites and deletions by keeping prior versions. Object Lock can provide additional WORM protection. Cross-Region Replication supports region-level disaster recovery by copying objects to another region.",
    "difficulty": "Hard"
  },
  {
    "id": "SAA-164",
    "domainId": "D2",
    "domain": "Design Resilient Architectures",
    "section": "CloudFront",
    "question": "A company uses CloudFront in front of an ALB. The origin sometimes becomes temporarily overloaded, and the company wants CloudFront to serve stale cached objects during brief origin outages to improve resilience.\nWhich CloudFront setting helps achieve this?",
    "choices": [
      "Configure CloudFront to serve stale content on origin errors by using appropriate cache/error settings (stale-while-revalidate / stale-if-error behavior where supported)",
      "Disable caching entirely so CloudFront always fetches from the origin",
      "Use Route 53 weighted routing between two CloudFront distributions",
      "Enable S3 Transfer Acceleration on the ALB"
    ],
    "answer": 0,
    "explanation": "Serving stale cached content during origin errors can reduce user impact during transient origin problems. This is achieved through CloudFront cache/error behavior settings that allow stale responses under certain conditions.",
    "difficulty": "Hard"
  },
  {
    "id": "SAA-165",
    "domainId": "D2",
    "domain": "Design Resilient Architectures",
    "section": "Step Functions",
    "question": "A company has a multi-step serverless workflow (validate → charge → provision → notify). They need reliable orchestration with retries, error handling, and the ability to see where executions failed.\nWhich service is MOST suitable?",
    "choices": [
      "AWS Step Functions",
      "Amazon SNS",
      "Amazon S3",
      "AWS Glue"
    ],
    "answer": 0,
    "explanation": "Step Functions provides workflow orchestration with built-in retries, error handling, state tracking, and execution history, improving resilience and observability for multi-step serverless processes.",
    "difficulty": "Hard"
  },
  {
    "id": "SAA-166",
    "domainId": "D2",
    "domain": "Design Resilient Architectures",
    "section": "VPC",
    "question": "A company runs workloads in two AZs. During an AZ outage, they want their private subnets in the remaining AZ to continue having outbound internet access (for example, to reach a third-party API) without manual intervention.\nWhich design best meets the requirement?",
    "choices": [
      "Deploy a NAT Gateway in each AZ and configure route tables so each private subnet uses the NAT Gateway in the same AZ",
      "Deploy a single NAT Gateway in one AZ and route all private subnets to it",
      "Remove NAT and assign public IPs to instances in private subnets",
      "Use an Internet Gateway attached directly to the private subnets"
    ],
    "answer": 0,
    "explanation": "Using one NAT Gateway per AZ avoids a single-AZ dependency. If an AZ fails, private subnets in the remaining AZ can still route through their local NAT Gateway, maintaining outbound connectivity.",
    "difficulty": "Hard"
  },
  {
    "id": "SAA-167",
    "domainId": "D2",
    "domain": "Design Resilient Architectures",
    "section": "Auto Scaling",
    "question": "An application experiences sudden bursts of traffic. The team uses an Auto Scaling group but scaling out takes several minutes due to long bootstrapping, causing errors during bursts.\nThey want a more resilient way to absorb short spikes while the ASG scales.\nWhich solution is MOST suitable?",
    "choices": [
      "Place an SQS queue (or similar buffer) between the request intake and the workers to absorb bursts, allowing workers to scale and drain the backlog",
      "Increase the instance size so scale-out is unnecessary",
      "Disable health checks to avoid replacing instances",
      "Move the application to a single larger EC2 instance"
    ],
    "answer": 0,
    "explanation": "Introducing a queue buffers bursty workloads and decouples ingestion from processing. This helps maintain resilience during spikes while compute capacity scales to handle the backlog.",
    "difficulty": "Hard"
  },
  {
    "id": "SAA-168",
    "domainId": "D3",
    "domain": "Design High-Performing Architectures",
    "section": "CloudFront",
    "question": "A global news website serves dynamic HTML (personalized) and large static images from the same domain. Users complain that pages are slow during peak hours.\nRequirements:\n- Personalized HTML must not be cached for long\n- Images should be cached globally to reduce origin load\n- Minimal application code changes\nWhich solution BEST meets these requirements?",
    "choices": [
      "Use CloudFront with separate cache behaviors: cache images aggressively (path-based) and set minimal/zero caching for personalized HTML; forward only needed headers/cookies for dynamic paths",
      "Use S3 Glacier for images and serve them directly to users",
      "Use an NLB in front of the web servers to cache HTML",
      "Increase the origin server instance size and disable caching"
    ],
    "answer": 0,
    "explanation": "CloudFront cache behaviors allow different caching rules per path pattern. You can cache static assets heavily while keeping personalized content minimally cached and forwarding only what is required, improving performance and reducing origin load with limited code changes.",
    "difficulty": "Hard"
  },
  {
    "id": "SAA-169",
    "domainId": "D3",
    "domain": "Design High-Performing Architectures",
    "section": "DynamoDB/DAX",
    "question": "A shopping cart service stores cart items in DynamoDB and must serve extremely high read traffic with sub-millisecond latency for the hottest keys during flash sales.\nWrites must still be strongly consistent in DynamoDB.\nWhich solution is MOST suitable to improve read performance?",
    "choices": [
      "Add DynamoDB Accelerator (DAX) in front of DynamoDB for cached reads",
      "Move the cart data to S3 Standard and query it with Athena",
      "Add Multi-AZ to DynamoDB",
      "Use RDS read replicas for the cart table"
    ],
    "answer": 0,
    "explanation": "DAX is an in-memory caching layer for DynamoDB designed to significantly reduce read latency and improve throughput for read-heavy workloads. It complements DynamoDB, which remains the system of record for writes.",
    "difficulty": "Hard"
  },
  {
    "id": "SAA-170",
    "domainId": "D3",
    "domain": "Design High-Performing Architectures",
    "section": "ALB/NLB",
    "question": "A company runs microservices: some are HTTP/2 gRPC services, others are standard HTTP REST services, and one service uses raw TCP.\nThey want to front these services with load balancers while preserving performance and choosing the right protocol support.\nWhich design is MOST appropriate?",
    "choices": [
      "Use an ALB for HTTP/HTTPS (including gRPC) services and an NLB for the TCP service",
      "Use only an ALB for all services including raw TCP",
      "Use only an NLB for all services and terminate TLS on instances",
      "Use CloudFront as the only load balancer for TCP services"
    ],
    "answer": 0,
    "explanation": "ALB is best for Layer 7 HTTP/HTTPS use cases and supports modern features like HTTP routing and gRPC, while NLB is Layer 4 and supports TCP/UDP with high performance. Using both matches protocol needs and performance goals.",
    "difficulty": "Hard"
  },
  {
    "id": "SAA-171",
    "domainId": "D3",
    "domain": "Design High-Performing Architectures",
    "section": "EBS/EFS",
    "question": "A video rendering farm runs on hundreds of EC2 instances. Each job reads large shared media files and writes per-job output files. The shared input data needs high throughput and must be accessible concurrently by all instances.\nWhich storage approach provides the BEST performance and simplest scaling for the shared input data?",
    "choices": [
      "Store shared input media in S3 and download needed objects per job (or stream), optionally using CloudFront for edge caching if needed",
      "Attach a single EBS volume to one instance and export it via NFS to all instances",
      "Use instance store on one instance and share it across the fleet",
      "Store all shared media in DynamoDB"
    ],
    "answer": 0,
    "explanation": "S3 scales massively for shared object storage and avoids single-instance bottlenecks that occur with self-managed NFS on EBS. For large fleets, object-based distribution from S3 is typically simpler and more scalable for shared read-heavy inputs.",
    "difficulty": "Hard"
  },
  {
    "id": "SAA-172",
    "domainId": "D3",
    "domain": "Design High-Performing Architectures",
    "section": "RDS/Aurora",
    "question": "A SaaS application uses Aurora and has a heavy write workload plus a growing number of read-only analytics queries. The team wants to scale reads independently and reduce load on the writer without redesigning the schema.\nWhich solution best meets this requirement?",
    "choices": [
      "Add Aurora reader instances and route read-only queries to the reader endpoint, keeping writes on the writer endpoint",
      "Enable Multi-AZ and route analytics queries to the standby instance",
      "Increase the Aurora storage size to improve read throughput",
      "Move analytics queries to S3 Select against database snapshots"
    ],
    "answer": 0,
    "explanation": "Aurora supports multiple reader instances and provides a reader endpoint to load balance read traffic. This offloads analytics reads from the writer and scales reads independently.",
    "difficulty": "Hard"
  },
  {
    "id": "SAA-173",
    "domainId": "D3",
    "domain": "Design High-Performing Architectures",
    "section": "S3/Glacier",
    "question": "A media company stores raw video files in S3 and must support occasional reprocessing. Most files are rarely accessed after 30 days, but when they are needed they must be retrievable in minutes, not hours.\nThe team wants to reduce storage cost while maintaining the retrieval requirement.\nWhich lifecycle transition is MOST appropriate?",
    "choices": [
      "Transition objects to S3 Glacier Instant Retrieval (or S3 Glacier Flexible Retrieval with expedited where appropriate) after 30 days, based on the minutes-level access requirement",
      "Transition objects directly to S3 Glacier Deep Archive after 30 days",
      "Keep all objects in S3 Standard forever",
      "Transition objects to S3 One Zone-IA and delete them after 30 days"
    ],
    "answer": 0,
    "explanation": "For minutes-level retrieval, Glacier Instant Retrieval (or Flexible Retrieval with a suitable retrieval tier) fits better than Deep Archive, which typically has hours-level retrieval. Lifecycle transitions reduce cost while meeting access needs.",
    "difficulty": "Hard"
  },
  {
    "id": "SAA-174",
    "domainId": "D3",
    "domain": "Design High-Performing Architectures",
    "section": "Global Accelerator",
    "question": "A gaming company runs regional game server fleets in three regions. Players should always connect to the closest healthy region with the lowest latency, and fail over quickly when a region becomes unavailable.\nThey also want to keep using UDP and avoid complex client-side logic.\nWhich solution is MOST suitable?",
    "choices": [
      "Use AWS Global Accelerator with multiple regional endpoints (NLBs) and health checks to route players to the optimal healthy region",
      "Use CloudFront to cache UDP game traffic at the edge",
      "Use Route 53 simple routing with a single record",
      "Use an ALB with HTTP routing rules"
    ],
    "answer": 0,
    "explanation": "Global Accelerator provides fast, deterministic routing over the AWS global network and supports health-based failover to the closest healthy endpoint. It’s well suited for latency-sensitive, global applications and can front NLB endpoints for UDP.",
    "difficulty": "Hard"
  },
  {
    "id": "SAA-175",
    "domainId": "D3",
    "domain": "Design High-Performing Architectures",
    "section": "Kinesis",
    "question": "A company collects clickstream events from millions of users and needs near real-time processing and aggregation. The ingestion layer must handle very high throughput, and multiple consumers (fraud detection, analytics, personalization) must process the same event stream independently.\nWhich solution is MOST appropriate?",
    "choices": [
      "Use Amazon Kinesis Data Streams for ingestion and have multiple consumer applications read from the stream",
      "Send events directly to an RDS database table and run triggers",
      "Write all events to S3 and run nightly batch jobs only",
      "Use a single SQS queue shared by all consumers"
    ],
    "answer": 0,
    "explanation": "Kinesis Data Streams is designed for high-throughput streaming ingestion and supports multiple consumers processing the same stream. SQS does not naturally support multiple independent consumers each receiving all messages without fanout.",
    "difficulty": "Hard"
  },
  {
    "id": "SAA-176",
    "domainId": "D3",
    "domain": "Design High-Performing Architectures",
    "section": "VPC",
    "question": "A private application in a VPC needs low-latency access to Amazon S3 for large object reads. The company wants to avoid NAT bottlenecks and reduce latency jitter.\nWhich network configuration BEST meets this requirement?",
    "choices": [
      "Create an S3 Gateway VPC endpoint and route S3 traffic through it",
      "Route S3 traffic through a NAT Gateway in a public subnet",
      "Assign public IPs to instances and access S3 over the internet",
      "Use VPC peering to an S3 VPC in another account"
    ],
    "answer": 0,
    "explanation": "An S3 gateway endpoint provides private connectivity to S3 without NAT, improving performance and removing NAT as a throughput bottleneck for large S3 transfers.",
    "difficulty": "Hard"
  },
  {
    "id": "SAA-177",
    "domainId": "D3",
    "domain": "Design High-Performing Architectures",
    "section": "EBS",
    "question": "A transactional database on EC2 requires both high IOPS and high throughput. During peak hours, storage performance becomes the bottleneck.\nWhich combination is MOST likely to improve storage performance?",
    "choices": [
      "Move to io2 (Provisioned IOPS) volumes and ensure the instance type supports sufficient EBS bandwidth; consider EBS-optimized instances",
      "Switch to sc1 (Cold HDD) volumes for higher IOPS",
      "Move the database files to S3 and mount it as a file system",
      "Reduce EBS volume size to increase throughput"
    ],
    "answer": 0,
    "explanation": "Provisioned IOPS SSD volumes provide higher and more consistent IOPS. Instance EBS bandwidth limits can also bottleneck, so choosing an instance type with higher EBS throughput (and EBS-optimized) is important.",
    "difficulty": "Hard"
  },
  {
    "id": "SAA-178",
    "domainId": "D3",
    "domain": "Design High-Performing Architectures",
    "section": "Athena/Glue",
    "question": "A data team runs frequent SQL queries on S3 data using Athena. Query performance is inconsistent because the data is stored as large, uncompressed CSV files with many columns, but most queries read only a few columns.\nThey want faster queries and lower cost.\nWhich approach is MOST suitable?",
    "choices": [
      "Convert the data to a columnar, compressed format (like Parquet/ORC) and partition it appropriately using AWS Glue/Athena best practices",
      "Increase Athena concurrency by running queries from more clients",
      "Move the data into S3 Glacier Deep Archive",
      "Store the CSV files in EBS instead of S3"
    ],
    "answer": 0,
    "explanation": "Columnar, compressed formats and partitioning reduce scanned data and improve Athena query performance and cost. Glue can help catalog and transform data into optimized layouts.",
    "difficulty": "Hard"
  },
  {
    "id": "SAA-179",
    "domainId": "D3",
    "domain": "Design High-Performing Architectures",
    "section": "ECS",
    "question": "A company’s containerized API experiences periodic latency spikes due to noisy neighbors on shared EC2 hosts. They want more predictable performance without managing servers.\nWhich approach is MOST suitable?",
    "choices": [
      "Run the service on AWS Fargate to get serverless containers with more isolation and predictable resource allocation per task",
      "Run the service on spot instances only",
      "Move the service to S3 static hosting",
      "Use a single larger EC2 instance with no scaling"
    ],
    "answer": 0,
    "explanation": "Fargate provides task-level CPU/memory allocation and removes the need to manage the underlying EC2 fleet, often improving predictability compared to a heavily shared EC2 cluster configuration.",
    "difficulty": "Hard"
  },
  {
    "id": "SAA-180",
    "domainId": "D3",
    "domain": "Design High-Performing Architectures",
    "section": "CloudFront/ALB",
    "question": "A company serves an API through CloudFront in front of an ALB. They want to reduce latency for global users but must ensure that authentication headers are forwarded and that cached responses do not leak between users.\nWhich CloudFront configuration BEST meets these requirements?",
    "choices": [
      "Disable caching (or set very low TTL) for authenticated API paths and forward only required headers/cookies; cache only truly public responses",
      "Cache all API responses for 24 hours to maximize hit ratio",
      "Remove authentication headers at CloudFront to improve performance",
      "Use S3 as the origin for the API"
    ],
    "answer": 0,
    "explanation": "For personalized/authenticated API responses, caching can cause data leakage unless carefully keyed and controlled. The safest approach is to minimize caching for authenticated paths while forwarding only necessary headers/cookies, caching only public endpoints.",
    "difficulty": "Hard"
  },
  {
    "id": "SAA-181",
    "domainId": "D3",
    "domain": "Design High-Performing Architectures",
    "section": "EC2",
    "question": "A compute workload requires very high packet-per-second performance and low network latency. The team also wants to minimize CPU overhead for networking.\nWhich EC2 feature best supports this?",
    "choices": [
      "Enhanced networking (ENA) on supported instance types",
      "Using a smaller instance type to reduce noise",
      "Placing instances in multiple regions",
      "Using S3 Transfer Acceleration"
    ],
    "answer": 0,
    "explanation": "Enhanced networking with ENA provides higher bandwidth, higher PPS, and lower latency by using SR-IOV, reducing CPU overhead for networking on supported instances.",
    "difficulty": "Hard"
  },
  {
    "id": "SAA-182",
    "domainId": "D3",
    "domain": "Design High-Performing Architectures",
    "section": "S3",
    "question": "A company stores large log files in S3 and frequently needs to retrieve only a subset of fields from the logs (for example, a few columns) without downloading entire objects.\nWhich S3 capability best meets this requirement?",
    "choices": [
      "Use S3 Select to retrieve only the required data from objects",
      "Use S3 Glacier Deep Archive and restore the object",
      "Use S3 Transfer Acceleration to download the full object faster",
      "Use S3 Object Lock to prevent changes"
    ],
    "answer": 0,
    "explanation": "S3 Select allows applications to retrieve a subset of data (using SQL expressions) from an object, reducing data transfer and improving performance when only parts of the object are needed.",
    "difficulty": "Hard"
  },
  {
    "id": "SAA-183",
    "domainId": "D3",
    "domain": "Design High-Performing Architectures",
    "section": "Caching",
    "question": "A web application uses an RDS database and experiences spikes in read traffic for a small set of “hot” products. The team wants to reduce database load and keep response times consistently low during spikes.\nThey also want the solution to be simple to operate.\nWhich solution is MOST suitable?",
    "choices": [
      "Cache hot items in ElastiCache and apply an appropriate cache invalidation/TTL strategy",
      "Enable RDS Multi-AZ and send reads to the standby",
      "Increase EBS volume size on the database instance",
      "Store product data only in S3 Glacier to reduce DB load"
    ],
    "answer": 0,
    "explanation": "ElastiCache provides low-latency caching for hot data, reducing repetitive reads to the database and improving performance during spikes. Multi-AZ improves availability but doesn’t offload reads in typical configurations.",
    "difficulty": "Hard"
  },
  {
    "id": "SAA-184",
    "domainId": "D4",
    "domain": "Design Cost-Optimized Architectures",
    "section": "S3",
    "question": "A company stores confidential build artifacts in S3 and wants to “never worry about capacity.” For the first 30 days, all artifacts are accessed frequently. After 30 days, most artifacts are rarely accessed, and retrieval time is not strict for developers.\nHowever, objects under the prefix /finance-fast/ are used by an automated post-processing pipeline that requires millisecond retrieval at any time.\nWhich lifecycle approach is MOST cost-effective while meeting the access requirements?",
    "choices": [
      "Use lifecycle rules to transition most objects to Glacier Flexible Retrieval after 30 days, but transition /finance-fast/ objects to S3 Standard-IA (or keep in Standard) to maintain millisecond retrieval",
      "Transition the entire bucket to S3 Glacier Deep Archive after 30 days",
      "Enable S3 Intelligent-Tiering for the entire bucket and disable any archive tiers",
      "Keep everything in S3 Standard and rely on compression to reduce cost"
    ],
    "answer": 0,
    "explanation": "Most artifacts can move to an archive tier (like Glacier Flexible Retrieval) after the frequent-access window because developers have no strict retrieval latency requirement. The /finance-fast/ prefix must stay in a millisecond-access class (Standard or Standard-IA). Prefix-based lifecycle rules meet both requirements at lowest cost.",
    "difficulty": "Hard"
  },
  {
    "id": "SAA-185",
    "domainId": "D4",
    "domain": "Design Cost-Optimized Architectures",
    "section": "EC2",
    "question": "A company has a mixed compute fleet:\n- A baseline set of instances runs 24/7 year-round\n- Additional instances run only during occasional peak campaigns\nThey want to minimize cost while keeping flexibility for peaks.\nWhich purchasing strategy is MOST cost-effective?",
    "choices": [
      "Use Savings Plans or Reserved Instances for the baseline, and use On-Demand or Spot (where appropriate) for the variable peak capacity",
      "Use On-Demand for everything to keep flexibility",
      "Use Dedicated Hosts for all instances to reduce cost",
      "Use Spot Instances for the baseline steady-state because it is cheapest"
    ],
    "answer": 0,
    "explanation": "A blended strategy is typically optimal: commit discounts (RI/Savings Plans) for steady usage, and use flexible capacity (On-Demand or Spot for fault-tolerant workloads) for peaks. Spot for baseline is risky due to interruptions.",
    "difficulty": "Hard"
  },
  {
    "id": "SAA-186",
    "domainId": "D4",
    "domain": "Design Cost-Optimized Architectures",
    "section": "RDS/Aurora",
    "question": "A startup is building an application with an unpredictable traffic pattern. They need a relational database but want to minimize operational overhead and avoid paying for unused capacity during idle periods.\nWhich option is MOST cost-effective and operationally simple?",
    "choices": [
      "Use Aurora Serverless (where supported) to automatically scale capacity based on demand",
      "Run MySQL on a large EC2 instance and scale it manually",
      "Use a multi-node self-managed PostgreSQL cluster on EC2 for high availability",
      "Use Redshift because it is serverless"
    ],
    "answer": 0,
    "explanation": "Aurora Serverless is designed for variable and unpredictable workloads, automatically scaling capacity and reducing the need to overprovision. Managing databases on EC2 generally increases operational overhead and can be less cost-effective for spiky usage.",
    "difficulty": "Hard"
  },
  {
    "id": "SAA-187",
    "domainId": "D4",
    "domain": "Design Cost-Optimized Architectures",
    "section": "NAT/VPC",
    "question": "A company has workloads in three AZs. Each private subnet routes outbound internet traffic through a single NAT Gateway. Costs are high and throughput is occasionally constrained.\nThey also want to be resilient to an AZ outage.\nWhich design best optimizes BOTH cost and resilience?",
    "choices": [
      "Deploy one NAT Gateway per AZ and route each private subnet to the NAT Gateway in the same AZ; add VPC endpoints for high-volume AWS services like S3/DynamoDB to reduce NAT usage",
      "Keep one NAT Gateway and increase its size",
      "Move all instances to public subnets to avoid NAT cost",
      "Replace NAT Gateway with an Internet Gateway in private subnets"
    ],
    "answer": 0,
    "explanation": "One NAT per AZ avoids a single-AZ dependency, improving resilience. Adding VPC endpoints for high-volume AWS services reduces NAT data processing charges and can improve throughput, optimizing overall cost and performance.",
    "difficulty": "Hard"
  },
  {
    "id": "SAA-188",
    "domainId": "D4",
    "domain": "Design Cost-Optimized Architectures",
    "section": "DynamoDB",
    "question": "A company uses DynamoDB for an API with a predictable daily traffic pattern: low at night, very high during business hours. They want to minimize cost while avoiding throttling.\nWhich configuration is MOST suitable?",
    "choices": [
      "Use provisioned capacity with auto scaling (and scheduled scaling if needed) to match predictable peaks and troughs",
      "Use on-demand capacity because it is always cheapest",
      "Fix provisioned capacity at the peak level 24/7",
      "Move the API data to S3 Standard to reduce costs"
    ],
    "answer": 0,
    "explanation": "Provisioned capacity with auto scaling (and optionally scheduled scaling) is well suited for predictable patterns, reducing cost during low periods while scaling up during known peaks. On-demand is simpler but may be more expensive for predictable steady usage.",
    "difficulty": "Hard"
  },
  {
    "id": "SAA-189",
    "domainId": "D4",
    "domain": "Design Cost-Optimized Architectures",
    "section": "S3",
    "question": "A data lake stores raw data in S3. The analytics team needs frequent queries on recent data (last 7 days) and rarely queries older data, but when they do, queries must still work without manual restores.\nThey want to reduce storage cost without breaking analytics workflows.\nWhich S3 storage strategy is MOST appropriate?",
    "choices": [
      "Keep recent data in S3 Standard and transition older data to S3 Intelligent-Tiering (with archive tiers if retrieval latency is acceptable) so access remains transparent",
      "Move all older data to Glacier Deep Archive after 7 days",
      "Delete all data older than 7 days and rely on backups",
      "Store all data in EBS volumes attached to an EC2 instance"
    ],
    "answer": 0,
    "explanation": "Intelligent-Tiering can automatically move objects between access tiers while keeping access transparent to applications, which helps when older data is occasionally queried without requiring manual restore steps (depending on selected tiers and retrieval expectations).",
    "difficulty": "Hard"
  },
  {
    "id": "SAA-190",
    "domainId": "D4",
    "domain": "Design Cost-Optimized Architectures",
    "section": "CloudFront",
    "question": "A company has a global customer base and serves large downloadable installers from an S3 bucket in one region. They pay high data transfer charges from S3 and users far from the region have slow downloads.\nThey want to improve download performance and reduce origin load, with minimal changes.\nWhich solution is MOST suitable?",
    "choices": [
      "Use CloudFront in front of the S3 bucket and cache the installers at edge locations; set appropriate TTLs and enable compression if applicable",
      "Move the installers to Glacier Deep Archive to reduce cost",
      "Use an ALB in front of S3 to reduce transfer charges",
      "Use a NAT Gateway to speed up downloads"
    ],
    "answer": 0,
    "explanation": "CloudFront caches large files at edge locations, improving download performance globally and reducing repeated origin fetches. This can reduce S3 request load and may lower overall cost depending on traffic patterns.",
    "difficulty": "Hard"
  },
  {
    "id": "SAA-191",
    "domainId": "D4",
    "domain": "Design Cost-Optimized Architectures",
    "section": "EFS",
    "question": "A company uses Amazon EFS for shared storage. Most files are read only a few times after creation, but must remain instantly accessible when needed.\nThey want to reduce ongoing storage costs without changing the application.\nWhich EFS feature should they use?",
    "choices": [
      "Enable EFS lifecycle management to transition files to EFS Infrequent Access (EFS IA) after a defined period",
      "Transition files to S3 Glacier Deep Archive automatically",
      "Disable encryption on EFS to reduce cost",
      "Mount the EFS file system only during business hours"
    ],
    "answer": 0,
    "explanation": "EFS lifecycle management can move infrequently accessed files into EFS IA automatically, reducing storage cost while keeping the same file system interface and immediate access when needed.",
    "difficulty": "Hard"
  },
  {
    "id": "SAA-192",
    "domainId": "D4",
    "domain": "Design Cost-Optimized Architectures",
    "section": "RDS",
    "question": "A company’s RDS database storage keeps growing. They store large audit records that are never updated and are queried only a few times per year. The production database must stay fast and cost-effective.\nWhich approach is MOST cost-effective long term?",
    "choices": [
      "Archive historical audit records to S3 (for example, in Parquet) and query them with Athena when needed, keeping only recent/hot data in RDS",
      "Keep all audit records in RDS and increase storage indefinitely",
      "Move the entire database to a larger RDS instance type",
      "Store audit records in EC2 instance store for low cost"
    ],
    "answer": 0,
    "explanation": "Keeping rarely accessed historical data in RDS increases cost and can impact performance. Archiving cold data to S3 and querying with Athena is typically more cost-effective for infrequent access while keeping the production database lean.",
    "difficulty": "Hard"
  },
  {
    "id": "SAA-193",
    "domainId": "D4",
    "domain": "Design Cost-Optimized Architectures",
    "section": "Messaging",
    "question": "A company needs to process images uploaded by users. Processing is bursty: huge spikes during events and almost none at other times.\nThey want to minimize cost while ensuring the system can handle spikes without losing requests.\nWhich architecture is MOST cost-effective?",
    "choices": [
      "Use S3 event notifications to an SQS queue and scale workers (Lambda or ECS) based on queue depth; use DLQ for failures",
      "Run a fixed fleet of EC2 workers 24/7 sized for peak load",
      "Write all uploads to EBS and poll the disk every minute",
      "Process images synchronously in the upload request path"
    ],
    "answer": 0,
    "explanation": "Queue-based buffering decouples ingestion from processing, allowing cost-efficient scale-out during spikes and scale-in when idle. A fixed peak-sized fleet wastes money during idle periods, and synchronous processing increases latency and failure risk.",
    "difficulty": "Hard"
  },
  {
    "id": "SAA-194",
    "domainId": "D4",
    "domain": "Design Cost-Optimized Architectures",
    "section": "Compute",
    "question": "A company runs CI jobs that compile code for 10–20 minutes and then terminate. Jobs are fault-tolerant and can be retried. The team wants the lowest possible compute cost.\nWhich option is MOST suitable?",
    "choices": [
      "Use Spot Instances (or Spot capacity in a managed service) with retry handling",
      "Use Dedicated Hosts to get discounts on short jobs",
      "Use 3-year Reserved Instances for all CI jobs",
      "Use On-Demand instances only"
    ],
    "answer": 0,
    "explanation": "Short-lived, fault-tolerant workloads are ideal for Spot, which can offer deep discounts. Retries handle interruptions. Reserved Instances and Dedicated Hosts are less suitable for highly variable short jobs.",
    "difficulty": "Hard"
  },
  {
    "id": "SAA-195",
    "domainId": "D4",
    "domain": "Design Cost-Optimized Architectures",
    "section": "S3",
    "question": "A company must keep a large volume of documents for 7 years for compliance. During the first 90 days, documents are accessed infrequently but must be retrieved in milliseconds. After 90 days, documents are almost never accessed and retrieval can take hours.\nThey want the most cost-effective S3 lifecycle plan.\nWhich option BEST meets the requirements?",
    "choices": [
      "Store in S3 Standard initially, transition to S3 Standard-IA shortly after creation, and transition to S3 Glacier Deep Archive after 90 days",
      "Store in S3 Glacier Deep Archive immediately",
      "Store in S3 Intelligent-Tiering only and disable archive tiers",
      "Store in S3 One Zone-IA for 90 days then delete"
    ],
    "answer": 0,
    "explanation": "Standard-IA provides millisecond retrieval for infrequent access during the first 90 days. After 90 days, Deep Archive minimizes cost when hours-level retrieval is acceptable. This lifecycle aligns storage class to access and latency needs over time.",
    "difficulty": "Hard"
  },
  {
    "id": "SAA-196",
    "domainId": "D3",
    "domain": "Design High-Performing Architectures",
    "section": "EC2",
    "question": "In the instance name m5.2xlarge, what does the “5” represent?",
    "choices": [
      "Instance size",
      "Network speed tier",
      "Storage type",
      "Generation"
    ],
    "answer": 3,
    "explanation": "In EC2 instance naming, the number indicates the instance generation (e.g., m5 is 5th-generation general purpose).",
    "difficulty": "Easy"
  },
  {
    "id": "SAA-197",
    "domainId": "D3",
    "domain": "Design High-Performing Architectures",
    "section": "EC2",
    "question": "What is an AMI mainly used for?",
    "choices": [
      "Preconfigured image to launch EC2s with OS/software",
      "Scaling traffic across instances",
      "Long-term object storage",
      "Attaching a second ENI"
    ],
    "answer": 0,
    "explanation": "An AMI (Amazon Machine Image) is a template used to launch EC2 instances with a predefined OS and optional software/configuration.",
    "difficulty": "Easy"
  },
  {
    "id": "SAA-198",
    "domainId": "D3",
    "domain": "Design High-Performing Architectures",
    "section": "EBS",
    "question": "What happens to a root EBS volume on instance termination by default?",
    "choices": [
      "Always kept",
      "Snapshotted automatically",
      "Deleted by default",
      "Moved to another AZ"
    ],
    "answer": 2,
    "explanation": "By default, the root EBS volume has DeleteOnTermination=true, so it is deleted when the instance is terminated (unless you change that setting).",
    "difficulty": "Easy"
  },
  {
    "id": "SAA-199",
    "domainId": "D4",
    "domain": "Design Cost-Optimized Architectures",
    "section": "EC2 Pricing",
    "question": "Which purchase option is best for short, unpredictable workloads?",
    "choices": [
      "Reserved Instances",
      "Savings Plans",
      "On-Demand",
      "Dedicated Hosts"
    ],
    "answer": 2,
    "explanation": "On-Demand is best for short-term, spiky, or unpredictable usage because it requires no commitment and you pay only for what you use.",
    "difficulty": "Easy"
  },
  {
    "id": "SAA-200",
    "domainId": "D1",
    "domain": "Design Secure Architectures",
    "section": "IAM",
    "question": "In which ways can a user access AWS?",
    "choices": [
      "AWS Console, SSH, FTP",
      "SSH, CLI, SDK",
      "Console only",
      "AWS Console, CLI, SDK"
    ],
    "answer": 3,
    "explanation": "Users access AWS via the Management Console, AWS CLI, and AWS SDKs/APIs. SSH/FTP are used to access servers (like EC2), not to access AWS services directly.",
    "difficulty": "Easy"
  },
  {
    "id": "SAA-201",
    "domainId": "D1",
    "domain": "Design Secure Architectures",
    "section": "IAM",
    "question": "In IAM, where do you usually attach permissions for many users at once?",
    "choices": [
      "To groups with policies",
      "To VPCs",
      "To S3 buckets",
      "To passwords"
    ],
    "answer": 0,
    "explanation": "Best practice is to attach policies to IAM groups (or roles) and then add users to groups, so you manage permissions at scale.",
    "difficulty": "Easy"
  },
  {
    "id": "SAA-202",
    "domainId": "D1",
    "domain": "Design Secure Architectures",
    "section": "VPC",
    "question": "By default, a Security Group allows:",
    "choices": [
      "All inbound and blocks all outbound",
      "All inbound and all outbound",
      "Blocks all inbound and allows all outbound",
      "Blocks all inbound and outbound"
    ],
    "answer": 2,
    "explanation": "A new security group starts with no inbound rules (so inbound is blocked) and an allow-all outbound rule (so outbound is allowed).",
    "difficulty": "Easy"
  },
  {
    "id": "SAA-203",
    "domainId": "D3",
    "domain": "Design High-Performing Architectures",
    "section": "EC2 Networking",
    "question": "Your EC2 public IP keeps changing after stop/start. What’s the simple AWS feature to keep a fixed public IPv4?",
    "choices": [
      "NAT Gateway",
      "Elastic IP",
      "Private IP",
      "Route 53 Alias"
    ],
    "answer": 1,
    "explanation": "An Elastic IP (EIP) is a static public IPv4 address you can allocate and associate to an instance (or other resources). It stays the same across stop/start as long as it remains allocated to you.",
    "difficulty": "Easy"
  },
  {
    "id": "SAA-204",
    "domainId": "D3",
    "domain": "Design High-Performing Architectures",
    "section": "Storage",
    "question": "EBS vs EFS — which pairing is MOST accurate?",
    "choices": [
      "EBS: multi-AZ, many instances; EFS: single instance only",
      "Both are multi-AZ, many instances",
      "EBS: single instance / AZ-scoped; EFS: multi-AZ, many instances",
      "Both are single-instance only"
    ],
    "answer": 2,
    "explanation": "EBS is block storage that is scoped to a single Availability Zone and typically attached to one instance (with limited exceptions like Multi-Attach within the same AZ). EFS is a regional, multi-AZ file system that can be mounted by many instances concurrently.",
    "difficulty": "Medium"
  },
  {
    "id": "SAA-205",
    "domainId": "D3",
    "domain": "Design High-Performing Architectures",
    "section": "EC2",
    "question": "EC2 User Data scripts run…",
    "choices": [
      "Once, at the first start of the instance",
      "Every time the instance reboots",
      "Every hour",
      "After the instance is terminated"
    ],
    "answer": 0,
    "explanation": "By default, EC2 user data runs only on the first boot/first launch of the instance (unless you build custom logic to run it again).",
    "difficulty": "Easy"
  },
  {
    "id": "SAA-206",
    "domainId": "D3",
    "domain": "Design High-Performing Architectures",
    "section": "ELB",
    "question": "Your application runs on EC2 instances in two AZs. You need a managed service to distribute incoming HTTP/HTTPS traffic across all instances. What should you use?",
    "choices": [
      "Amazon Route 53",
      "Classic Load Balancer",
      "Network Load Balancer",
      "Application Load Balancer"
    ],
    "answer": 3,
    "explanation": "An Application Load Balancer (ALB) is designed for HTTP/HTTPS (Layer 7) traffic, supports advanced routing (host/path rules), and can distribute requests across targets in multiple AZs.",
    "difficulty": "Easy"
  },
  {
    "id": "SAA-207",
    "domainId": "D2",
    "domain": "Design Resilient Architectures",
    "section": "ELB",
    "question": "You have an ALB with targets in multiple AZs. One instance fails its health checks. What will the ALB do?",
    "choices": [
      "Terminate the instance and launch a new one",
      "Continue sending some traffic until all instances are unhealthy",
      "Stop sending traffic to the unhealthy instance",
      "Automatically resize the instance type"
    ],
    "answer": 2,
    "explanation": "An ALB uses health checks to determine target health. If a target becomes unhealthy, the ALB stops routing traffic to it. (Replacing/terminating instances is the job of Auto Scaling, not the ALB.)",
    "difficulty": "Easy"
  },
  {
    "id": "SAA-208",
    "domainId": "D2",
    "domain": "Design Resilient Architectures",
    "section": "Auto Scaling",
    "question": "Which option BEST describes how an Auto Scaling Group (ASG) works?",
    "choices": [
      "Automatically adds or removes EC2 instances based on policies and health checks",
      "Manually starts EC2 instances on a fixed schedule only",
      "Only replaces unhealthy instances but never changes capacity",
      "Is used only with Spot Instances"
    ],
    "answer": 0,
    "explanation": "An Auto Scaling Group maintains desired capacity and can scale out/in automatically using scaling policies (for example, CPU-based) and can also replace unhealthy instances based on health checks.",
    "difficulty": "Easy"
  },
  {
    "id": "SAA-209",
    "domainId": "D2",
    "domain": "Design Resilient Architectures",
    "section": "Auto Scaling",
    "question": "You configure an ASG with Min=2, Max=6, Desired=3. A scaling policy adds 2 instances when CPU > 70%. What happens on the first scale-out event?",
    "choices": [
      "ASG will have 3 instances",
      "ASG will have 5 instances",
      "ASG will have 4 instances",
      "ASG will have 6 instances"
    ],
    "answer": 1,
    "explanation": "The ASG starts at Desired=3. On the first scale-out event, the policy adds 2 instances, bringing it to 5 total. This is within Max=6, so it scales to 5.",
    "difficulty": "Easy"
  },
  {
    "id": "SAA-210",
    "domainId": "D3",
    "domain": "Design High-Performing Architectures",
    "section": "ELB",
    "question": "You need extremely high performance TCP traffic handling with static IPs per AZ. Which load balancer should you choose?",
    "choices": [
      "Network Load Balancer",
      "Application Load Balancer",
      "Classic Load Balancer",
      "Gateway Load Balancer"
    ],
    "answer": 0,
    "explanation": "A Network Load Balancer (NLB) operates at Layer 4 (TCP/UDP/TLS), supports very high throughput and low latency, and provides static IP addresses per Availability Zone (or you can use Elastic IPs).",
    "difficulty": "Medium"
  },
  {
    "id": "SAA-211",
    "domainId": "D2",
    "domain": "Design Resilient Architectures",
    "section": "RDS",
    "question": "Your production MySQL database on RDS must have automatic failover to another AZ with minimal changes to your application endpoint. What should you enable?",
    "choices": [
      "Store data only on EBS attached to EC2",
      "RDS Read Replica in the same AZ",
      "RDS Multi-AZ deployment",
      "RDS snapshot every hour"
    ],
    "answer": 2,
    "explanation": "RDS Multi-AZ provides synchronous replication to a standby in a different AZ and supports automatic failover. The DB endpoint remains the same, so application changes are minimal. Read replicas are mainly for read scaling and are not the primary HA/failover mechanism.",
    "difficulty": "Medium"
  },
  {
    "id": "SAA-212",
    "domainId": "D2",
    "domain": "Design Resilient Architectures",
    "section": "Aurora",
    "question": "Which statement about Amazon Aurora is MOST accurate?",
    "choices": [
      "Aurora supports only one AZ",
      "Aurora has no separation between writer and reader",
      "Aurora is only for key-value workloads",
      "Aurora automatically replicates data across multiple AZs"
    ],
    "answer": 3,
    "explanation": "Amazon Aurora is a relational database compatible with MySQL/PostgreSQL and is designed for high availability by replicating data across multiple Availability Zones in a region. It supports a writer instance and multiple reader instances for read scaling.",
    "difficulty": "Medium"
  },
  {
    "id": "SAA-213",
    "domainId": "D3",
    "domain": "Design High-Performing Architectures",
    "section": "ElastiCache",
    "question": "You want to reduce read load on your RDS database by caching frequently accessed session data in memory. Which AWS service is the BEST fit?",
    "choices": [
      "Amazon S3",
      "AWS Lambda",
      "Amazon ElastiCache",
      "Amazon EFS"
    ],
    "answer": 2,
    "explanation": "Amazon ElastiCache (Redis or Memcached) is an in-memory caching service that reduces database load and improves latency for frequently accessed data like sessions, tokens, or hot reads.",
    "difficulty": "Easy"
  },
  {
    "id": "SAA-214",
    "domainId": "D3",
    "domain": "Design High-Performing Architectures",
    "section": "ElastiCache",
    "question": "You need a simple in-memory cache with multiple nodes, no persistence, and easy horizontal scaling. Which ElastiCache engine is MOST suitable?",
    "choices": [
      "Redis",
      "Amazon DynamoDB",
      "Amazon Aurora MySQL",
      "Memcached"
    ],
    "answer": 3,
    "explanation": "Memcached is a simple, distributed in-memory cache designed for ease of horizontal scaling and does not provide persistence. Redis supports more advanced data structures and can provide persistence/replication, but for a simple non-persistent cache, Memcached is the better fit.",
    "difficulty": "Medium"
  },
  {
    "id": "SAA-215",
    "domainId": "D2",
    "domain": "Design Resilient Architectures",
    "section": "Architecture",
    "question": "An app runs behind an ALB with an ASG and uses RDS Multi-AZ plus ElastiCache. Which statement BEST describes this architecture?",
    "choices": [
      "It guarantees zero downtime in all failure scenarios",
      "It is designed for high availability and scalability",
      "It only improves security, not availability",
      "It removes the need for backups"
    ],
    "answer": 1,
    "explanation": "ALB + ASG provides scalable and fault-tolerant compute across AZs. RDS Multi-AZ adds database high availability with automatic failover. ElastiCache improves read performance and can reduce DB load. Together this architecture is designed for high availability and scalability, but it doesn’t guarantee zero downtime in every scenario and it does not eliminate the need for backups.",
    "difficulty": "Medium"
  },
  {
    "id": "SAA-216",
    "domainId": "D2",
    "domain": "Design Resilient Architectures",
    "section": "Route 53",
    "question": "You need to map the root domain example.com to an Application Load Balancer. What should you create in Route 53?",
    "choices": [
      "CNAME record pointing to the ALB DNS name",
      "Alias A record pointing to the ALB",
      "Simple routing policy with the ALB’s IPs",
      "NS record pointing to the ALB"
    ],
    "answer": 1,
    "explanation": "Route 53 does not allow a CNAME at the zone apex (root domain). To point example.com to an ALB, you create an Alias A record to the ALB DNS name. Alias records work at the apex and don’t require hardcoding IPs.",
    "difficulty": "Medium"
  },
  {
    "id": "SAA-217",
    "domainId": "D2",
    "domain": "Design Resilient Architectures",
    "section": "Route 53",
    "question": "You want to send 20% of traffic to a new version and 80% to the old one, both behind different target groups. Which policy fits best?",
    "choices": [
      "Simple",
      "Latency-based",
      "Weighted",
      "Geolocation"
    ],
    "answer": 2,
    "explanation": "Weighted routing lets you split traffic across multiple records by percentage using weights (for example, 20/80). This is commonly used for gradual rollouts and A/B testing.",
    "difficulty": "Medium"
  },
  {
    "id": "SAA-218",
    "domainId": "D2",
    "domain": "Design Resilient Architectures",
    "section": "Route 53",
    "question": "You run active–passive across two endpoints. If the primary fails health checks, traffic must move to standby automatically. What should you use?",
    "choices": [
      "Geoproximity routing",
      "Multi-Value Answer",
      "Latency-based routing",
      "Failover routing with health checks"
    ],
    "answer": 3,
    "explanation": "Failover routing is built for active-passive setups. You configure primary and secondary records and associate health checks so Route 53 routes traffic to the secondary endpoint when the primary fails.",
    "difficulty": "Medium"
  },
  {
    "id": "SAA-219",
    "domainId": "D2",
    "domain": "Design Resilient Architectures",
    "section": "Route 53",
    "question": "You want EU visitors routed to eu-west-1 even if another region is currently lower latency for some users. Which policy?",
    "choices": [
      "Weighted",
      "Geolocation",
      "Latency-based",
      "Multi-Value Answer"
    ],
    "answer": 1,
    "explanation": "Geolocation routing routes users based on the geographic location of their DNS resolvers (for example, Europe to eu-west-1). It is chosen when you want location-based control, not “best latency.”",
    "difficulty": "Medium"
  },
  {
    "id": "SAA-220",
    "domainId": "D2",
    "domain": "Design Resilient Architectures",
    "section": "Route 53",
    "question": "Your app runs on several EC2 instances with public IPs. You don’t need L7 features, just simple DNS returning several healthy IPs. Which policy?",
    "choices": [
      "Multi-Value Answer",
      "Geoproximity",
      "Latency-based",
      "Failover"
    ],
    "answer": 0,
    "explanation": "Multi-Value Answer routing returns multiple values (IPs) for a record and can be associated with health checks to return only healthy endpoints. It’s a simple way to do basic DNS-based load distribution without advanced routing logic.",
    "difficulty": "Medium"
  },
  {
    "id": "SAA-221",
    "domainId": "D3",
    "domain": "Design High-Performing Architectures",
    "section": "Route 53",
    "question": "You’re hosting a static website directly on S3 and want example.com to resolve to it. What Route 53 record do you need?",
    "choices": [
      "CNAME to the S3 REST endpoint",
      "Alias A record to the S3 website endpoint",
      "Alias A record to the ALB",
      "AAAA record to the bucket"
    ],
    "answer": 1,
    "explanation": "For an S3 static website, you use the S3 **website endpoint** (not the REST endpoint). To map the root domain (example.com), create an Alias A record pointing to the S3 website endpoint so it works at the zone apex.",
    "difficulty": "Medium"
  },
  {
    "id": "SAA-222",
    "domainId": "D2",
    "domain": "Design Resilient Architectures",
    "section": "S3",
    "question": "Which statement about S3 Versioning is most accurate?",
    "choices": [
      "It can be enabled and later suspended; past versions remain, helping recover deletes/overwrites.",
      "It can be turned on and fully turned off with all old versions deleted automatically",
      "It’s required only for Glacier usage",
      "It automatically replicates objects across regions"
    ],
    "answer": 0,
    "explanation": "S3 versioning can be enabled and later suspended, but it cannot be fully “disabled” back to a never-versioned state. Existing versions remain and help recover from accidental deletes/overwrites. Replication across regions is a separate feature (CRR).",
    "difficulty": "Medium"
  },
  {
    "id": "SAA-223",
    "domainId": "D2",
    "domain": "Design Resilient Architectures",
    "section": "S3",
    "question": "You need Cross-Region Replication (CRR) from us-east-1 to eu-west-1. What is a hard prerequisite?",
    "choices": [
      "A lifecycle rule to transition objects to IA",
      "Default bucket encryption enabled",
      "Object Lock enabled on both buckets",
      "Versioning enabled on both source and destination"
    ],
    "answer": 3,
    "explanation": "Cross-Region Replication requires versioning to be enabled on both the source and destination buckets. Without versioning, CRR cannot replicate objects.",
    "difficulty": "Medium"
  },
  {
    "id": "SAA-224",
    "domainId": "D4",
    "domain": "Design Cost-Optimized Architectures",
    "section": "S3",
    "question": "You store objects that are rarely accessed but must be retrieved in milliseconds when needed. You are ok with a single AZ to cut costs. Which storage class?",
    "choices": [
      "S3 Standard",
      "S3 Standard-IA",
      "S3 One Zone-IA",
      "S3 Glacier Instant Retrieval"
    ],
    "answer": 2,
    "explanation": "S3 One Zone-IA is designed for infrequently accessed data with millisecond access, stored in a single Availability Zone at a lower cost than Standard-IA. This matches the requirement for rare access, millisecond retrieval, and cost savings by using one AZ.",
    "difficulty": "Medium"
  },
  {
    "id": "SAA-225",
    "domainId": "D4",
    "domain": "Design Cost-Optimized Architectures",
    "section": "S3",
    "question": "You have tens of millions of objects with unpredictable access patterns. You want automatic cost optimization without changing the app, millisecond retrieval when accessed again, and no retrieval fees. Which storage class is best?",
    "choices": [
      "S3 Standard-IA",
      "S3 Glacier Instant Retrieval",
      "S3 One Zone-IA",
      "S3 Intelligent-Tiering"
    ],
    "answer": 3,
    "explanation": "S3 Intelligent-Tiering automatically moves objects between access tiers based on usage, requires no application changes, keeps millisecond retrieval, and does not charge retrieval fees (it charges a small monitoring/automation fee). This matches the requirements for unpredictable access at very large scale.",
    "difficulty": "Hard"
  },
  {
    "id": "SAA-226",
    "domainId": "D4",
    "domain": "Design Cost-Optimized Architectures",
    "section": "S3",
    "question": "You host a public dataset in S3 and want downloaders to pay request and data-transfer costs while you continue paying for storage. What should you enable?",
    "choices": [
      "S3 Access Points with VPC restriction",
      "Bucket ACLs granting Everyone: READ",
      "S3 Transfer Acceleration",
      "Requester Pays"
    ],
    "answer": 3,
    "explanation": "Enable S3 Requester Pays so the requester (downloader) is charged for request and data transfer costs, while the bucket owner continues to pay for storage.",
    "difficulty": "Medium"
  },
  {
    "id": "SAA-227",
    "domainId": "D3",
    "domain": "Design High-Performing Architectures",
    "section": "S3",
    "question": "You must apply a new tag to 50 million existing objects across several buckets, and get a progress report. what is the easiest native option?",
    "choices": [
      "S3 Batch Operations with a manifest",
      "Parallel PutObjectTagging from a custom script",
      "AWS Glue crawler + Lambda per object",
      "S3 Storage Lens"
    ],
    "answer": 0,
    "explanation": "S3 Batch Operations is designed for large-scale object operations (like tagging) across millions or billions of objects. You provide a manifest of objects and get a job progress/completion report. This is the most native and operationally simple option compared to running custom scripts.",
    "difficulty": "Hard"
  },
  {
    "id": "SAA-228",
    "domainId": "D1",
    "domain": "Design Secure Architectures",
    "section": "S3",
    "question": "Security requires all new objects be encrypted with your KMS CMK. How do you enforce it?",
    "choices": [
      "Turn on default encryption SSE-S3",
      "Use ACLs to deny unencrypted uploads",
      "Bucket policy that allows s3:PutObject only when s3:x-amz-server-side-encryption = aws:kms and s3:x-amz-server-side-encryption-aws-kms-key-id = your CMK",
      "Enable Object Lock in Compliance mode"
    ],
    "answer": 2,
    "explanation": "Default encryption helps, but enforcement is done with a bucket policy. You can require that PutObject requests specify SSE-KMS and the exact KMS key ID (your CMK). If the request doesn't include these headers/values, the upload is denied, guaranteeing all new objects use your CMK.",
    "difficulty": "Hard"
  },
  {
    "id": "SAA-229",
    "domainId": "D1",
    "domain": "Design Secure Architectures",
    "section": "S3",
    "question": "A web app at https://app.example.com must use JavaScript to PUT/GET objects in https://my-bucket.s3.amazonaws.com. Requests are blocked by the browser. What must you configure?",
    "choices": [
      "Pre-signed URLs only",
      "S3 CORS rules allowing the app origin and required methods/headers",
      "Bucket ACLs for Everyone: WRITE",
      "CloudTrail data events"
    ],
    "answer": 1,
    "explanation": "Browser-based cross-origin requests require the bucket to allow the origin and HTTP methods via CORS. Configure S3 CORS to allow https://app.example.com and the required methods (GET/PUT) and headers so the browser permits the requests.",
    "difficulty": "Medium"
  },
  {
    "id": "SAA-230",
    "domainId": "D1",
    "domain": "Design Secure Architectures",
    "section": "S3",
    "question": "Your records must be immutable for 7 years to meet regulatory WORM requirements and prevent privileged users from deletion or alteration. Which feature can handle this requirement?",
    "choices": [
      "S3 Object Lock in Compliance mode",
      "Glacier Vault Lock only",
      "S3 Versioning alone",
      "S3 Lifecycle with Glacier Deep Archive"
    ],
    "answer": 0,
    "explanation": "S3 Object Lock in Compliance mode enforces WORM retention so objects cannot be deleted or overwritten until the retention period expires, even by root or administrators. Versioning alone does not prevent deletion, and lifecycle policies are for transitions/expiration, not enforcement of immutability.",
    "difficulty": "Hard"
  },
  {
    "id": "SAA-231",
    "domainId": "D1",
    "domain": "Design Secure Architectures",
    "section": "CloudFront",
    "question": "Your streaming service must block viewers from specific countries due to licensing. How can you enforce this at the edge?",
    "choices": [
      "Signed cookies",
      "CloudFront geo restriction",
      "Route 53 geolocation routing",
      "Security groups on the origin"
    ],
    "answer": 1,
    "explanation": "CloudFront geo restriction allows you to whitelist or blacklist specific countries at edge locations. This blocks requests before they reach your origin. Route 53 geolocation influences DNS responses but does not enforce blocking; origin security groups do not filter by country; signed cookies control who can access, not location-based blocking.",
    "difficulty": "Medium"
  },
  {
    "id": "SAA-232",
    "domainId": "D2",
    "domain": "Design Resilient Architectures",
    "section": "DataSync",
    "question": "You must migrate 300 TB from an on-prem NFS server to Amazon EFS, keeping metadata, with scheduling, verification, and incremental syncs. What is the best service?",
    "choices": [
      "AWS Transfer Family",
      "Snowball Edge Storage Optimized",
      "AWS DataSync",
      "AWS Backup"
    ],
    "answer": 2,
    "explanation": "AWS DataSync is built for large-scale data transfer to AWS storage services (EFS, S3, FSx) and supports metadata preservation, scheduled runs, verification, and incremental syncs after the initial copy.",
    "difficulty": "Hard"
  },
  {
    "id": "SAA-233",
    "domainId": "D2",
    "domain": "Design Resilient Architectures",
    "section": "Storage Gateway",
    "question": "Your backup software expects an iSCSI virtual tape library and you want to retire physical tapes while keeping long-term retention in S3/Glacier. Which gateway should you use?",
    "choices": [
      "File Gateway",
      "Tape Gateway",
      "Volume Gateway – Cached",
      "Volume Gateway – Stored"
    ],
    "answer": 1,
    "explanation": "Storage Gateway Tape Gateway provides a virtual tape library (VTL) interface over iSCSI for existing backup software, while storing virtual tapes in S3 and archiving them to Glacier for long-term retention.",
    "difficulty": "Hard"
  },
  {
    "id": "SAA-234",
    "domainId": "D3",
    "domain": "Design High-Performing Architectures",
    "section": "FSx",
    "question": "A Linux HPC workload needs a POSIX file system with sub-millisecond latencies and the ability to link a dataset in S3 so compute nodes can process it as a file system. Which service?",
    "choices": [
      "FSx for Lustre",
      "S3 + Transfer Acceleration",
      "FSx for Windows File Server",
      "Storage Gateway – File Gateway"
    ],
    "answer": 0,
    "explanation": "FSx for Lustre is designed for HPC workloads with very low latencies and high throughput. It integrates with S3 so you can link S3 data to a Lustre file system for high-performance processing by compute nodes.",
    "difficulty": "Hard"
  },
  {
    "id": "SAA-235",
    "domainId": "D2",
    "domain": "Design Resilient Architectures",
    "section": "Snow Family",
    "question": "Your company must collect and migrate ~300 TB of data from 8 remote plants that have no high-bandwidth network. You also need to run lightweight validation scripts at the edge before shipment, and require KMS encryption and chain-of-custody tracking. Which device should you choose?",
    "choices": [
      "AWS DataSync",
      "AWS Snowcone",
      "AWS Snowmobile",
      "AWS Snowball Edge Storage Optimized"
    ],
    "answer": 3,
    "explanation": "Snowball Edge Storage Optimized is designed for large offline data transfers (hundreds of TB), supports encryption with KMS, includes chain-of-custody tracking, and provides onboard compute capabilities to run lightweight processing/validation at the edge. Snowcone is for much smaller datasets, and Snowmobile is for exabyte-scale transfers.",
    "difficulty": "Hard"
  },
  {
    "id": "SAA-236",
    "domainId": "D2",
    "domain": "Design Resilient Architectures",
    "section": "SQS",
    "question": "Your SQS-triggered Lambda sometimes takes 8–10 minutes to process a message. After ~5 minutes, the same message is delivered again to another Lambda instance, causing duplicate work. Which configuration should you use to prevent this duplicate processing?",
    "choices": [
      "Enable SQS long polling at 20 seconds",
      "Reduce Lambda timeout to 5 minutes",
      "Increase the SQS visibility timeout to be greater than the maximum Lambda processing time",
      "Enable FIFO on the queue"
    ],
    "answer": 2,
    "explanation": "If the visibility timeout expires before processing finishes, SQS makes the message visible again and it can be received by another Lambda invocation. Set the visibility timeout longer than the maximum end-to-end processing time (and include buffer). Long polling and FIFO do not solve visibility-timeout re-delivery by themselves.",
    "difficulty": "Medium"
  },
  {
    "id": "SAA-237",
    "domainId": "D3",
    "domain": "Design High-Performing Architectures",
    "section": "SNS",
    "question": "You must fan out each event to multiple consumers while preserving strict ordering and exactly-once semantics. Which architecture should you choose?",
    "choices": [
      "SNS standard topic → SQS standard queues",
      "SQS standard queue with multiple consumers",
      "Kinesis Data Firehose with multiple destinations",
      "SNS FIFO topic → SQS FIFO subscriptions using Message Group IDs"
    ],
    "answer": 3,
    "explanation": "To preserve ordering and get FIFO exactly-once processing semantics, you need FIFO end-to-end. Use an SNS FIFO topic fan-out to multiple SQS FIFO queues, and use Message Group IDs to control ordering per group. Standard SNS/SQS do not provide strict ordering, and Firehose is for delivery to destinations (not ordered fan-out to multiple independent consumers).",
    "difficulty": "Hard"
  },
  {
    "id": "SAA-238",
    "domainId": "D2",
    "domain": "Design Resilient Architectures",
    "section": "Lambda",
    "question": "An SQS-triggered Lambda scales up quickly and overwhelms RDS during traffic spikes. You want to throttle how many Lambdas run in parallel for this queue. Which configuration should you use?",
    "choices": [
      "Increase batch size",
      "Set a Reserved Concurrency on the Lambda function to cap parallel executions",
      "Increase visibility timeout",
      "Use SNS instead of SQS"
    ],
    "answer": 1,
    "explanation": "Reserved Concurrency caps the maximum number of concurrent Lambda executions, which throttles how fast SQS messages can be processed and protects downstream systems like RDS. Batch size changes how many messages each invocation receives, but it doesn’t directly cap concurrency; visibility timeout doesn’t limit concurrency either.",
    "difficulty": "Medium"
  },
  {
    "id": "SAA-239",
    "domainId": "D3",
    "domain": "Design High-Performing Architectures",
    "section": "Lambda",
    "question": "You have a Java 11 Lambda that experiences spiky, unpredictable traffic. You must minimize cold-start latency when requests arrive but avoid paying for pre-warmed capacity when idle. Which feature should you choose?",
    "choices": [
      "Lambda SnapStart for Java",
      "Lambda Provisioned Concurrency",
      "Lambda@Edge",
      "Increase the function memory size only"
    ],
    "answer": 0,
    "explanation": "SnapStart reduces cold-start latency for Java functions without needing to keep provisioned instances warm during idle periods. Provisioned Concurrency minimizes cold starts too, but you pay for pre-warmed capacity even when there’s no traffic. Memory can help performance but does not reliably eliminate cold starts.",
    "difficulty": "Hard"
  },
  {
    "id": "SAA-240",
    "domainId": "D3",
    "domain": "Design High-Performing Architectures",
    "section": "EKS",
    "question": "Your platform team mandates Kubernetes APIs and wants a managed control plane with optional managed node groups and integration with VPC CNI. Which service should you choose?",
    "choices": [
      "Amazon EKS",
      "Amazon ECS Fargate",
      "AWS Lambda",
      "Docker on EC2 with an ALB"
    ],
    "answer": 0,
    "explanation": "Amazon EKS provides a managed Kubernetes control plane and supports managed node groups and AWS VPC CNI integration for pod networking.",
    "difficulty": "Easy"
  },
  {
    "id": "SAA-241",
    "domainId": "D3",
    "domain": "Design High-Performing Architectures",
    "section": "ECS",
    "question": "You need to run a long-running, HTTP microservice in containers with no server management, integrate with an ALB, and run in private subnets. Which service should you choose?",
    "choices": [
      "Amazon EKS with self-managed nodes",
      "Amazon ECS on EC2 launch type",
      "Amazon ECS on Fargate launch type",
      "AWS App Runner on Git repo"
    ],
    "answer": 2,
    "explanation": "ECS on Fargate lets you run containers without managing EC2 instances, supports ALB integration, and can run tasks in private subnets. ECS on EC2 requires server management, and EKS with self-managed nodes also increases operational overhead.",
    "difficulty": "Medium"
  },
  {
    "id": "SAA-242",
    "domainId": "D4",
    "domain": "Design Cost-Optimized Architectures",
    "section": "DynamoDB",
    "question": "Your DynamoDB workload has unpredictable spikes, and you don’t want to plan read/write capacity or manage auto scaling. Which capacity mode should you choose?",
    "choices": [
      "Provisioned with auto scaling",
      "Global tables with provisioned capacity",
      "On-demand capacity mode",
      "DAX with provisioned capacity"
    ],
    "answer": 2,
    "explanation": "On-demand capacity automatically accommodates unpredictable traffic without you having to plan RCUs/WCUs or configure auto scaling. Provisioned + auto scaling still requires capacity planning and tuning; DAX is a caching layer and doesn’t replace capacity mode.",
    "difficulty": "Medium"
  },
  {
    "id": "SAA-243",
    "domainId": "D1",
    "domain": "Design Secure Architectures",
    "section": "CloudFront",
    "question": "Your distribution must authenticate viewers at the edge by calling an external authorization API, then add/remove headers and possibly return a 302 redirect before the request reaches the origin. Which feature should you choose?",
    "choices": [
      "AWS WAF rate-based rule",
      "CloudFront Functions",
      "ALB listener rules behind CloudFront",
      "Lambda@Edge"
    ],
    "answer": 3,
    "explanation": "Lambda@Edge can run at CloudFront viewer request, call external authorization endpoints, and then modify headers or generate responses (including redirects) before forwarding to the origin. CloudFront Functions are lightweight and fast but cannot make network calls to external APIs. WAF rate rules don’t perform custom auth logic.",
    "difficulty": "Hard"
  },
  {
    "id": "SAA-244",
    "domainId": "D3",
    "domain": "Design High-Performing Architectures",
    "section": "Kinesis",
    "question": "Your team needs to ingest real-time clickstream events at high throughput, process them with sub-second latency, allow multiple independent consumers (analytics + fraud), and be able to replay data from the last 24–72 hours to reprocess if logic changes. Which service should you choose?",
    "choices": [
      "Amazon Kinesis Data Streams",
      "Amazon Kinesis Data Firehose",
      "Amazon SQS",
      "Amazon SNS"
    ],
    "answer": 0,
    "explanation": "Kinesis Data Streams supports high-throughput streaming ingestion, multiple consumer applications (enhanced fan-out if needed), low-latency processing, and data retention for replay (for example 24–72 hours or longer depending on configuration). Firehose is primarily for delivery to storage/analytics destinations with limited replay semantics.",
    "difficulty": "Hard"
  },
  {
    "id": "SAA-245",
    "domainId": "D4",
    "domain": "Design Cost-Optimized Architectures",
    "section": "Batch",
    "question": "Your company has a nightly automation script that takes 2–3 hours to complete. They prefer a fully managed, serverless option. Which service should you choose?",
    "choices": [
      "AWS Lambda with Provisioned Concurrency",
      "AWS Lambda orchestrated by Step Functions looping for hours",
      "AWS Batch with a Fargate compute environment",
      "AWS Lambda with the timeout increased to 3 hours"
    ],
    "answer": 2,
    "explanation": "Lambda can’t run for hours (maximum execution time is much lower), so options D and B are not suitable. Provisioned Concurrency doesn’t change Lambda’s max runtime. AWS Batch can run long jobs, and with a Fargate compute environment you avoid managing servers while still running multi-hour workloads reliably on a schedule.",
    "difficulty": "Hard"
  },
  {
    "id": "SAA-246",
    "domainId": "D3",
    "domain": "Design High-Performing Architectures",
    "section": "Neptune",
    "question": "Your company is building a knowledge graph to support features like friend-of-friend, shortest path, and fraud rings. You need a fully managed graph database that supports Gremlin and SPARQL, offers high availability across AZs, and integrates with IAM/KMS for security. Which service should you choose?",
    "choices": [
      "Amazon RDS for PostgreSQL",
      "Amazon DocumentDB",
      "Amazon DynamoDB",
      "Amazon Neptune"
    ],
    "answer": 3,
    "explanation": "Amazon Neptune is a fully managed graph database service that supports Gremlin and SPARQL, provides high availability, and integrates with IAM/KMS for access control and encryption.",
    "difficulty": "Medium"
  },
  {
    "id": "SAA-247",
    "domainId": "D3",
    "domain": "Design High-Performing Architectures",
    "section": "DocumentDB",
    "question": "A legacy microservice uses MongoDB drivers and stores schema-flexible JSON. You want a drop-in managed replacement with automatic backups, VPC isolation, and no manual sharding/patching. Which service should you choose?",
    "choices": [
      "Amazon DynamoDB",
      "Amazon DocumentDB",
      "Amazon Aurora MySQL",
      "Amazon ElastiCache for Redis"
    ],
    "answer": 1,
    "explanation": "Amazon DocumentDB is MongoDB-compatible, fully managed, supports VPC isolation and automated backups, and removes the operational overhead of running MongoDB yourself.",
    "difficulty": "Medium"
  },
  {
    "id": "SAA-248",
    "domainId": "D3",
    "domain": "Design High-Performing Architectures",
    "section": "ElastiCache",
    "question": "Your web tier stores ephemeral session state, needs sub-millisecond latency, TTL eviction, and optional pub/sub. Data must live in memory and offload reads from your primary database. Which service should you choose?",
    "choices": [
      "Amazon S3 Standard",
      "Amazon RDS for MySQL",
      "Amazon EFS",
      "Amazon ElastiCache for Redis"
    ],
    "answer": 3,
    "explanation": "ElastiCache for Redis provides in-memory storage with sub-millisecond latency, supports TTL eviction, and supports pub/sub, making it ideal for session state and offloading reads from databases.",
    "difficulty": "Medium"
  },
  {
    "id": "SAA-249",
    "domainId": "D4",
    "domain": "Design Cost-Optimized Architectures",
    "section": "Athena",
    "question": "Analysts keep CSV/Parquet in Amazon S3 and need to run one-off SQL and join datasets without provisioning clusters. Results should be billed per query and use the Glue Data Catalog for schemas. Which service should you choose?",
    "choices": [
      "Amazon Redshift",
      "AWS Glue",
      "Amazon Athena",
      "Amazon EMR"
    ],
    "answer": 2,
    "explanation": "Amazon Athena is serverless SQL on S3, billed per query, and integrates with the AWS Glue Data Catalog for table definitions and schemas.",
    "difficulty": "Medium"
  },
  {
    "id": "SAA-250",
    "domainId": "D3",
    "domain": "Design High-Performing Architectures",
    "section": "Redshift",
    "question": "BI teams require a columnar, massively parallel SQL engine with concurrency scaling, materialized views, and integration with QuickSight. Data loads from S3 and operational stores nightly. Which service should you choose?",
    "choices": [
      "Amazon QuickSight",
      "Amazon Redshift",
      "AWS Glue",
      "Amazon Athena"
    ],
    "answer": 1,
    "explanation": "Amazon Redshift is a columnar, MPP data warehouse that supports features like concurrency scaling and materialized views and integrates well with BI tools like QuickSight.",
    "difficulty": "Medium"
  },
  {
    "id": "SAA-251",
    "domainId": "D3",
    "domain": "Design High-Performing Architectures",
    "section": "Glue",
    "question": "Nightly jobs must crawl S3, infer/update table schemas, run Spark transformations from CSV → Parquet, and load curated data to Redshift with minimal ops. Which service should you choose?",
    "choices": [
      "AWS Glue",
      "Amazon EMR with long-running clusters",
      "Amazon Athena CTAS queries only",
      "AWS Data Pipeline"
    ],
    "answer": 0,
    "explanation": "AWS Glue provides crawlers to infer schemas and update the Data Catalog, and managed Spark ETL jobs to transform data (CSV to Parquet) and load curated outputs to targets like Redshift with low operational overhead.",
    "difficulty": "Medium"
  },
  {
    "id": "SAA-252",
    "domainId": "D3",
    "domain": "Design High-Performing Architectures",
    "section": "Rekognition",
    "question": "Your app must detect objects and faces in images and return labels with confidence scores through a managed API. Which service should you choose?",
    "choices": [
      "Comprehend",
      "Rekognition",
      "Polly",
      "Transcribe"
    ],
    "answer": 1,
    "explanation": "Amazon Rekognition provides managed image/video analysis APIs to detect objects, scenes, and faces and returns labels with confidence scores.",
    "difficulty": "Easy"
  },
  {
    "id": "SAA-253",
    "domainId": "D3",
    "domain": "Design High-Performing Architectures",
    "section": "Polly",
    "question": "Marketing needs to turn blog posts into audio using lifelike voices via an API. Which service should you choose?",
    "choices": [
      "Transcribe",
      "Lex",
      "Comprehend",
      "Polly"
    ],
    "answer": 3,
    "explanation": "Amazon Polly converts text to lifelike speech using a managed API (text-to-speech).",
    "difficulty": "Easy"
  },
  {
    "id": "SAA-254",
    "domainId": "D1",
    "domain": "Design Secure Architectures",
    "section": "CloudTrail",
    "question": "Yesterday a production outage was traced to a security group rule change. You need to answer, “Which principal made the API call, from which IP, and at what exact time?” Which service should you choose?",
    "choices": [
      "AWS CloudTrail",
      "Amazon CloudWatch Metrics",
      "AWS Config conformance packs",
      "AWS Systems Manager"
    ],
    "answer": 0,
    "explanation": "AWS CloudTrail records API activity and includes who made the call (principal), source IP, request details, and timestamps—ideal for auditing and forensics.",
    "difficulty": "Medium"
  },
  {
    "id": "SAA-255",
    "domainId": "D1",
    "domain": "Design Secure Architectures",
    "section": "Organizations",
    "question": "Your company uses AWS Organizations with Control Tower. At the Root, an SCP is attached that denies ec2:TerminateInstances on all resources. An admin in a member account (with AdministratorAccess) tries to terminate an EC2 instance in any region. What does this SCP mean for the attached accounts?",
    "choices": [
      "The action is allowed because AdministratorAccess overrides the SCP at the account level",
      "The action is allowed only if the instance has a certain tag",
      "The action is denied for all principals in all attached accounts in all regions, regardless of IAM permissions",
      "The action is denied only when called from the console, not the CLI"
    ],
    "answer": 2,
    "explanation": "SCPs set the maximum permissions for accounts/OUs. An explicit Deny in an SCP cannot be overridden by IAM permissions, so ec2:TerminateInstances is denied for all principals in all attached accounts in all regions.",
    "difficulty": "Hard"
  },
  {
    "id": "SAA-256",
    "domainId": "D1",
    "domain": "Design Secure Architectures",
    "section": "KMS",
    "question": "Your app writes data in us-east-1 and replicates the ciphertext to eu-west-1. You need to decrypt in both Regions without re-encrypting and keep keys cryptographically equivalent across Regions. Which KMS feature should you choose?",
    "choices": [
      "A single-Region KMS key shared to eu-west-1",
      "KMS multi-Region keys",
      "Customer-managed alias pointing to different keys per Region",
      "SSE-S3 without KMS"
    ],
    "answer": 1,
    "explanation": "KMS multi-Region keys create linked, cryptographically equivalent keys in multiple Regions so ciphertext encrypted in one Region can be decrypted in another without re-encrypting.",
    "difficulty": "Hard"
  },
  {
    "id": "SAA-257",
    "domainId": "D1",
    "domain": "Design Secure Architectures",
    "section": "S3",
    "question": "You enable S3 Cross-Region Replication for a bucket using SSE-KMS. Replication fails with an access error on the destination key. Which change should you implement so the replicas are encrypted at the destination?",
    "choices": [
      "Turn off KMS on the source bucket",
      "Update the destination KMS key policy to allow the source bucket’s replication role to use kms:Encrypt",
      "Use SSE-S3 on the destination only",
      "Create a VPC endpoint for S3"
    ],
    "answer": 1,
    "explanation": "For CRR with SSE-KMS, the replication IAM role must be permitted by the destination KMS key policy to encrypt (and typically generate data keys). Grant the replication role the required KMS permissions on the destination key.",
    "difficulty": "Hard"
  },
  {
    "id": "SAA-258",
    "domainId": "D1",
    "domain": "Design Secure Architectures",
    "section": "EC2",
    "question": "You must share an EBS-backed AMI encrypted with your CMK so another AWS account can launch it. Which steps should you choose?",
    "choices": [
      "Share only the AMI",
      "Share the AMI and its encrypted snapshot, and grant the other account kms:Decrypt on the CMK (or let them copy the snapshot to their CMK)",
      "Copy the AMI to S3 and send a link",
      "Share just the snapshot"
    ],
    "answer": 1,
    "explanation": "For an encrypted EBS-backed AMI, you must share the AMI and the underlying encrypted snapshot and also allow the target account to use the KMS key (or have them copy the snapshot/AMI using their own CMK). Sharing only the AMI is not sufficient.",
    "difficulty": "Hard"
  },
  {
    "id": "SAA-259",
    "domainId": "D1",
    "domain": "Design Secure Architectures",
    "section": "Secrets Manager",
    "question": "You store database credentials and must rotate them automatically every 30 days, with built-in rotation workflows and audit. Which service should you choose?",
    "choices": [
      "SSM Parameter Store",
      "S3 with SSE-KMS",
      "AWS Secrets Manager",
      "IAM Roles Anywhere"
    ],
    "answer": 2,
    "explanation": "AWS Secrets Manager provides managed secret storage with built-in rotation workflows (via Lambda), scheduled rotation, and auditing/integration with IAM and CloudTrail.",
    "difficulty": "Medium"
  },
  {
    "id": "SAA-260",
    "domainId": "D1",
    "domain": "Design Secure Architectures",
    "section": "ACM",
    "question": "You will expose a web app through an Application Load Balancer at app.example.com. You want a public TLS certificate managed by AWS with easy renewals. Which approach should you choose?",
    "choices": [
      "Request a public certificate in AWS Certificate Manager and validate via DNS in Route 53",
      "Upload a self-signed cert to the ALB",
      "Issue a private ACM cert from a Private CA",
      "Use CloudFront to auto-create a cert"
    ],
    "answer": 0,
    "explanation": "ACM public certificates are AWS-managed and renew automatically (when DNS validation remains in place). You then attach the ACM cert to the ALB HTTPS listener.",
    "difficulty": "Medium"
  },
  {
    "id": "SAA-261",
    "domainId": "D1",
    "domain": "Design Secure Architectures",
    "section": "Firewall Manager",
    "question": "Your org needs to enforce WAF rules and Shield protections across dozens of accounts and ALBs/CloudFront from a central place using AWS Organizations. Which service should you choose?",
    "choices": [
      "AWS Shield Advanced alone",
      "AWS Firewall Manager",
      "Amazon GuardDuty",
      "AWS Network Firewall"
    ],
    "answer": 1,
    "explanation": "AWS Firewall Manager is the AWS Organizations-integrated service for centrally configuring and enforcing AWS WAF rules and Shield Advanced protections across multiple accounts and resources.",
    "difficulty": "Hard"
  },
  {
    "id": "SAA-262",
    "domainId": "D1",
    "domain": "Design Secure Architectures",
    "section": "GuardDuty",
    "question": "Security wants managed threat detection that analyzes CloudTrail, VPC Flow Logs, and DNS logs to alert on anomalous IAM activity and known malicious IPs. Which service should you choose?",
    "choices": [
      "Amazon GuardDuty",
      "AWS Config",
      "AWS CloudTrail",
      "Amazon Inspector"
    ],
    "answer": 0,
    "explanation": "Amazon GuardDuty is a managed threat detection service that analyzes CloudTrail events, VPC Flow Logs, and DNS logs to generate security findings.",
    "difficulty": "Medium"
  },
  {
    "id": "SAA-263",
    "domainId": "D1",
    "domain": "Design Secure Architectures",
    "section": "VPC",
    "question": "You place workloads in IPv6-only private subnets and they must reach public Internet services while remaining non-routable from the Internet. Which gateway should you choose?",
    "choices": [
      "Internet Gateway",
      "NAT Gateway",
      "Egress-Only Internet Gateway",
      "Transit Gateway"
    ],
    "answer": 2,
    "explanation": "An Egress-Only Internet Gateway allows outbound-only IPv6 access to the internet while preventing inbound connections initiated from the internet.",
    "difficulty": "Medium"
  },
  {
    "id": "SAA-264",
    "domainId": "D4",
    "domain": "Design Cost-Optimized Architectures",
    "section": "VPC Endpoints",
    "question": "Instances in private subnets must access S3 without using a NAT Gateway to minimize cost and keep traffic off the Internet. Which integration should you choose?",
    "choices": [
      "Gateway VPC endpoint for S3",
      "Interface VPC endpoint for S3",
      "Public S3 with bucket policy Allow *",
      "VPC peering to the S3 VPC"
    ],
    "answer": 0,
    "explanation": "A Gateway VPC endpoint for S3 routes S3 traffic privately over the AWS network without a NAT Gateway, reducing cost and keeping traffic off the public internet.",
    "difficulty": "Medium"
  },
  {
    "id": "SAA-265",
    "domainId": "D2",
    "domain": "Design Resilient Architectures",
    "section": "Transit Gateway",
    "question": "You need to connect dozens of VPCs and on-prem networks in a hub-and-spoke topology with route propagation and centralized control, avoiding complex peering meshes. Which service should you choose?",
    "choices": [
      "VPC Peering",
      "Site-to-Site VPN per VPC",
      "AWS Transit Gateway",
      "AWS Direct Connect only"
    ],
    "answer": 2,
    "explanation": "AWS Transit Gateway provides hub-and-spoke connectivity for many VPCs and on-prem networks with centralized routing and route propagation, avoiding a complex full mesh of VPC peering connections.",
    "difficulty": "Medium"
  },
  {
    "id": "SAA-266",
    "domainId": "D2",
    "domain": "Design Resilient Architectures",
    "section": "Disaster Recovery",
    "question": "A payments platform needs minutes-level RTO and low data loss across two Regions but wants to avoid the full cost of active/active. It will keep a scaled-down copy of the app and database warm in the secondary Region and scale up on failover. Which DR strategy should you choose?",
    "choices": [
      "Pilot Light",
      "Backup & Restore",
      "Warm Standby",
      "Multi-Region Active/Active"
    ],
    "answer": 2,
    "explanation": "Warm Standby keeps a scaled-down but fully functional environment running in the secondary Region (app + database) and scales up on failover, providing minutes-level RTO with lower cost than active/active.",
    "difficulty": "Medium"
  },
  {
    "id": "SAA-267",
    "domainId": "D2",
    "domain": "Design Resilient Architectures",
    "section": "DMS",
    "question": "You must move an on-prem Oracle OLTP database to Amazon Aurora PostgreSQL with minutes of cutover downtime. The target schema needs conversion, and you want ongoing change data capture (CDC) until the cutover. Which approach should you choose?",
    "choices": [
      "Export/import with Data Pump only",
      "Glue ETL jobs into Aurora",
      "AWS Schema Conversion Tool (SCT) + AWS DMS replication task with CDC",
      "Snapshot/restore to Aurora"
    ],
    "answer": 2,
    "explanation": "SCT handles heterogeneous schema conversion (Oracle → Aurora PostgreSQL). DMS can do full load plus CDC replication so you keep the target nearly in sync and perform a short cutover window.",
    "difficulty": "Hard"
  },
  {
    "id": "SAA-268",
    "domainId": "D2",
    "domain": "Design Resilient Architectures",
    "section": "RDS",
    "question": "You’re upgrading RDS MySQL to a new major version and need a very short, controlled cutover with automatic replica synchronization and quick rollback if needed. Which feature should you choose?",
    "choices": [
      "Cross-Region read replica and manual promotion",
      "RDS Blue/Green Deployments",
      "DMS full load only",
      "Multi-AZ failover"
    ],
    "answer": 1,
    "explanation": "RDS Blue/Green Deployments lets you create a synchronized staging (green) environment, perform the upgrade there, and then switch over with a controlled cutover. It also supports rolling back by switching back if needed (depending on the situation).",
    "difficulty": "Hard"
  },
  {
    "id": "SAA-269",
    "domainId": "D2",
    "domain": "Design Resilient Architectures",
    "section": "Outposts",
    "question": "A factory site requires local, single-digit-ms latency and wants to run native AWS services (EC2, EBS, EKS, RDS) on-prem with AWS-managed hardware and the same APIs/console. Which service should you choose?",
    "choices": [
      "VMware Cloud on AWS",
      "AWS Outposts",
      "AWS Snowball Edge",
      "AWS Local Zones"
    ],
    "answer": 1,
    "explanation": "AWS Outposts brings AWS-managed hardware and many AWS services into your on-prem site, using the same AWS APIs/console and providing very low-latency local access.",
    "difficulty": "Medium"
  },
  {
    "id": "SAA-270",
    "domainId": "D2",
    "domain": "Design Resilient Architectures",
    "section": "AWS Backup",
    "question": "You need central policy-based backups for RDS, EFS, DynamoDB, EC2/EBS across multiple accounts and Regions with cross-account copy and backup vaults. Which service should you choose?",
    "choices": [
      "EBS snapshots with custom scripts",
      "AWS Backup with Backup Policies via AWS Organizations",
      "CloudFormation custom resources",
      "Systems Manager Automation documents"
    ],
    "answer": 1,
    "explanation": "AWS Backup provides a centralized managed backup service for multiple AWS data sources and supports backup vaults, cross-account copy, and policy-based backup management via AWS Organizations.",
    "difficulty": "Medium"
  },
  {
    "id": "SAA-271",
    "domainId": "D1",
    "domain": "Design Secure Architectures",
    "section": "CloudFormation",
    "question": "Security wants to ensure a stack can only create certain resources (for example, EC2 within specific subnets) even if the template is modified. Which configuration should you use?",
    "choices": [
      "Give CloudFormation full AdministratorAccess",
      "Attach a dedicated CloudFormation service role with a least-privilege IAM policy",
      "Use stack termination protection only",
      "Rely on drift detection"
    ],
    "answer": 1,
    "explanation": "A CloudFormation service role with least-privilege permissions enforces what the stack can create/update, even if someone modifies the template. Termination protection and drift detection don’t restrict what resources can be created.",
    "difficulty": "Medium"
  },
  {
    "id": "SAA-272",
    "domainId": "D3",
    "domain": "Design High-Performing Architectures",
    "section": "Pinpoint",
    "question": "Product needs to send bulk marketing campaigns with segmentation, A/B testing, and analytics dashboards across email and SMS, while engineering will keep transactional emails simple. Which service should you choose for the marketing use case?",
    "choices": [
      "Amazon Pinpoint",
      "Amazon SES only",
      "SNS",
      "SQS"
    ],
    "answer": 0,
    "explanation": "Amazon Pinpoint is designed for marketing engagement at scale (segmentation, campaigns, A/B testing, analytics) across channels like email and SMS. SES alone is better suited for transactional email sending without the marketing campaign features.",
    "difficulty": "Medium"
  },
  {
    "id": "SAA-273",
    "domainId": "D1",
    "domain": "Design Secure Architectures",
    "section": "Systems Manager",
    "question": "Your EC2 instances are in private subnets with no inbound rules. Ops needs interactive shell and port-forwarding for troubleshooting with full audit logs and no bastion hosts. Which service should you choose?",
    "choices": [
      "EC2 Instance Connect",
      "A public bastion with SSH keys",
      "Direct Connect",
      "AWS Systems Manager Session Manager"
    ],
    "answer": 3,
    "explanation": "SSM Session Manager provides interactive shell access and port forwarding without opening inbound SSH/RDP, and it can log sessions for auditing. This removes the need for bastion hosts.",
    "difficulty": "Medium"
  },
  {
    "id": "SAA-274",
    "domainId": "D4",
    "domain": "Design Cost-Optimized Architectures",
    "section": "Billing",
    "question": "Finance wants automatic detection of unusual daily spend and alerts without maintaining per-service thresholds. Which service should you choose?",
    "choices": [
      "AWS Budgets with fixed thresholds",
      "Cost Explorer saved reports",
      "Trusted Advisor",
      "AWS Cost Anomaly Detection with monitors and SNS notifications"
    ],
    "answer": 3,
    "explanation": "AWS Cost Anomaly Detection uses machine learning to detect unusual spend patterns and can alert via monitors (often routed through SNS) without you defining manual per-service thresholds.",
    "difficulty": "Medium"
  },
  {
    "id": "SAA-275",
    "domainId": "D2",
    "domain": "Design Resilient Architectures",
    "section": "MGN",
    "question": "You must migrate hundreds of on-prem VMs to AWS with block-level continuous replication, test cutovers, and a short final cutover window to EC2. Which service should you choose?",
    "choices": [
      "AWS Database Migration Service",
      "VMware Cloud on AWS",
      "AWS DataSync",
      "AWS Application Migration Service (MGN)"
    ],
    "answer": 3,
    "explanation": "AWS Application Migration Service (MGN) performs block-level continuous replication of servers to AWS, supports test cutovers, and enables a short final cutover to EC2. DMS is for databases, and DataSync is file/object transfer (not VM lift-and-shift).",
    "difficulty": "Hard"
  },
  {
    "id": "SAA-276",
    "domainId": "D1",
    "domain": "Design Secure Architectures",
    "section": "ACM",
    "question": "You are exposing https://app.example.com through an Application Load Balancer (ALB). You want a publicly trusted TLS certificate with automatic renewal and the least operational overhead. Which TWO actions should you take? (Choose TWO.)",
    "choices": [
      "Create a self-signed certificate and upload it to the ALB listener",
      "Request a public certificate in AWS Certificate Manager (ACM)",
      "Validate the ACM certificate using DNS validation in Route 53",
      "Create a private certificate using ACM Private CA and attach it to the public ALB",
      "Store the certificate in S3 and configure the ALB to fetch it on startup"
    ],
    "answer": [
      1,
      2
    ],
    "explanation": "Use ACM public certificates for publicly trusted TLS with managed renewals, and validate via Route 53 DNS. Self-signed and private CA certs are not publicly trusted by default, and ALB does not pull certs from S3.",
    "difficulty": "Easy"
  },
  {
    "id": "SAA-277",
    "domainId": "D1",
    "domain": "Design Secure Architectures",
    "section": "IAM",
    "question": "A security team wants to reduce risk by ensuring engineers do not attach permissions directly to individual IAM users, and instead manage permissions at scale. Which TWO practices best meet this goal? (Choose TWO.)",
    "choices": [
      "Attach policies directly to each IAM user for better visibility",
      "Use IAM groups with managed policies and add users to groups",
      "Use IAM roles for applications and workloads instead of long-term user keys",
      "Store access keys in Parameter Store and share them across users",
      "Enable S3 versioning on all buckets"
    ],
    "answer": [
      1,
      2
    ],
    "explanation": "Groups + policies scale permission management for many users. Roles reduce long-term credentials for workloads. The other options do not address scalable user permission management.",
    "difficulty": "Easy"
  },
  {
    "id": "SAA-278",
    "domainId": "D2",
    "domain": "Design Resilient Architectures",
    "section": "Route 53",
    "question": "You run two endpoints in an active-passive setup. If the primary endpoint fails, traffic must automatically shift to the standby. Which TWO Route 53 components do you configure? (Choose TWO.)",
    "choices": [
      "Latency-based routing policy",
      "Failover routing policy",
      "A Route 53 health check for the primary endpoint",
      "Weighted routing policy",
      "Geoproximity routing policy"
    ],
    "answer": [
      1,
      2
    ],
    "explanation": "Failover routing + health checks provide automated primary/secondary DNS failover. Weighted/latency/geoproximity are for different routing goals.",
    "difficulty": "Easy"
  },
  {
    "id": "SAA-279",
    "domainId": "D3",
    "domain": "Design High-Performing Architectures",
    "section": "ELB",
    "question": "A gaming service uses UDP for client-to-server communication and needs a load balancer that supports UDP and can scale to very high throughput. Which TWO AWS services together form the best front-door solution? (Choose TWO.)",
    "choices": [
      "Application Load Balancer",
      "Network Load Balancer",
      "Amazon Route 53",
      "Gateway Load Balancer",
      "AWS Global Accelerator"
    ],
    "answer": [
      1,
      4
    ],
    "explanation": "NLB supports UDP at Layer 4. Global Accelerator can improve global performance and provides static anycast IPs in front of the NLB for worldwide users.",
    "difficulty": "Easy"
  },
  {
    "id": "SAA-280",
    "domainId": "D4",
    "domain": "Design Cost-Optimized Architectures",
    "section": "S3",
    "question": "You store data that is frequently accessed for 30 days, then rarely accessed but still needs millisecond retrieval afterward. Which TWO storage classes best match this requirement over time? (Choose TWO.)",
    "choices": [
      "S3 Standard",
      "S3 Standard-IA",
      "S3 Glacier Deep Archive",
      "S3 One Zone-IA",
      "S3 Glacier Flexible Retrieval"
    ],
    "answer": [
      0,
      1
    ],
    "explanation": "S3 Standard fits frequent access; S3 Standard-IA fits infrequent access with millisecond retrieval. Glacier classes have longer retrieval times; One Zone-IA is single-AZ and only fits if you accept reduced resilience.",
    "difficulty": "Easy"
  },
  {
    "id": "SAA-281",
    "domainId": "D2",
    "domain": "Design Resilient Architectures",
    "section": "Auto Scaling",
    "question": "A web application must remain available during an AZ failure and automatically replace unhealthy instances. Which TWO AWS components should you implement? (Choose TWO.)",
    "choices": [
      "Run instances in a single AZ with a larger instance type",
      "An Auto Scaling Group spanning at least two AZs",
      "An Application Load Balancer across multiple AZs",
      "A single EC2 instance with an Elastic IP",
      "A local database on instance store"
    ],
    "answer": [
      1,
      2
    ],
    "explanation": "ASG across multiple AZs replaces unhealthy instances and maintains capacity. An ALB across AZs distributes traffic and stops routing to unhealthy targets.",
    "difficulty": "Easy"
  },
  {
    "id": "SAA-282",
    "domainId": "D1",
    "domain": "Design Secure Architectures",
    "section": "VPC Endpoints",
    "question": "Instances in private subnets must access Amazon S3 without traversing the public internet and without using a NAT Gateway. Which TWO configuration elements are required? (Choose TWO.)",
    "choices": [
      "A Gateway VPC endpoint for S3",
      "An Internet Gateway attached to the VPC",
      "A route table entry targeting the S3 Gateway endpoint",
      "A public Elastic IP on each instance",
      "A Site-to-Site VPN"
    ],
    "answer": [
      0,
      2
    ],
    "explanation": "Use an S3 Gateway VPC endpoint and add the endpoint route to the private subnet route tables. Internet gateways/EIPs are not needed for private S3 access through the endpoint.",
    "difficulty": "Easy"
  },
  {
    "id": "SAA-283",
    "domainId": "D1",
    "domain": "Design Secure Architectures",
    "section": "CloudTrail",
    "question": "After an incident, you must identify who changed a security group rule, from which IP, and the exact time. Which TWO AWS services/features should be used to capture and retain this information? (Choose TWO.)",
    "choices": [
      "AWS CloudTrail management events",
      "Amazon S3 access logs",
      "CloudTrail log file delivery to an S3 bucket",
      "Amazon CloudWatch Metrics only",
      "AWS WAF logs"
    ],
    "answer": [
      0,
      2
    ],
    "explanation": "CloudTrail management events record the API caller, source IP, and timestamp. Delivering CloudTrail logs to S3 retains the audit history.",
    "difficulty": "Easy"
  },
  {
    "id": "SAA-284",
    "domainId": "D3",
    "domain": "Design High-Performing Architectures",
    "section": "ElastiCache",
    "question": "A web tier needs an in-memory cache for session data with sub-millisecond latency and TTL eviction. Which TWO options are valid managed caching solutions on AWS? (Choose TWO.)",
    "choices": [
      "Amazon ElastiCache for Redis",
      "Amazon ElastiCache for Memcached",
      "Amazon S3 Glacier Instant Retrieval",
      "Amazon EFS",
      "Amazon RDS Multi-AZ"
    ],
    "answer": [
      0,
      1
    ],
    "explanation": "ElastiCache Redis and Memcached are managed in-memory caches. The other services are storage or databases, not in-memory cache engines.",
    "difficulty": "Easy"
  },
  {
    "id": "SAA-285",
    "domainId": "D4",
    "domain": "Design Cost-Optimized Architectures",
    "section": "EC2 Pricing",
    "question": "A team runs a steady baseline of EC2 usage 24/7 but also has unpredictable spikes. Which TWO purchasing models best minimize cost while handling both patterns? (Choose TWO.)",
    "choices": [
      "On-Demand Instances for the baseline",
      "Reserved Instances or Savings Plans for the baseline",
      "Spot Instances for the baseline with no interruptions",
      "On-Demand Instances for spikes",
      "Dedicated Hosts for spikes"
    ],
    "answer": [
      1,
      3
    ],
    "explanation": "Commitments (RI/Savings Plans) reduce baseline cost. On-Demand handles unpredictable spikes without commitment. Spot for baseline risks interruption; Dedicated Hosts increase cost.",
    "difficulty": "Easy"
  },
  {
    "id": "SAA-286",
    "domainId": "D1",
    "domain": "Design Secure Architectures",
    "section": "S3",
    "question": "A bucket must enforce encryption using a specific customer-managed KMS key (CMK). Developers sometimes upload objects without specifying encryption headers. Which TWO controls best enforce the requirement? (Choose TWO.)",
    "choices": [
      "Enable default encryption with SSE-S3 only",
      "Enable default encryption with SSE-KMS using the CMK",
      "Add a bucket policy that denies PutObject unless s3:x-amz-server-side-encryption is aws:kms",
      "Add a bucket policy condition that requires the specific KMS key ID",
      "Enable S3 Transfer Acceleration"
    ],
    "answer": [
      2,
      3
    ],
    "explanation": "Default encryption helps, but enforcement is best done by denying uploads that don’t use SSE-KMS and the required key ID via bucket policy conditions.",
    "difficulty": "Medium"
  },
  {
    "id": "SAA-287",
    "domainId": "D2",
    "domain": "Design Resilient Architectures",
    "section": "RDS",
    "question": "An OLTP application uses Amazon RDS MySQL. Analytics users need to run heavy read queries without impacting production performance. Which TWO options meet the requirement with the best fit? (Choose TWO.)",
    "choices": [
      "Create an RDS Read Replica and route analytics reads to it",
      "Enable RDS Multi-AZ and route analytics reads to the standby",
      "Use Amazon ElastiCache to cache all analytics queries",
      "Offload analytics to an Amazon Redshift cluster (ETL/ELT pipeline)",
      "Increase the production DB instance size only"
    ],
    "answer": [
      0,
      3
    ],
    "explanation": "Read replicas offload read traffic from the primary. Redshift is purpose-built for analytics and can be a better long-term warehouse. Multi-AZ standby isn’t for reads, and resizing alone doesn’t prevent contention.",
    "difficulty": "Medium"
  },
  {
    "id": "SAA-288",
    "domainId": "D2",
    "domain": "Design Resilient Architectures",
    "section": "SQS",
    "question": "Your SQS-triggered Lambda sometimes processes messages for up to 12 minutes. You want to prevent duplicate processing and also control concurrency so downstream RDS is not overwhelmed. Which TWO configurations should you apply? (Choose TWO.)",
    "choices": [
      "Set SQS visibility timeout greater than the maximum processing time",
      "Enable SQS long polling at 20 seconds",
      "Set a Reserved Concurrency limit on the Lambda function",
      "Increase Lambda memory to maximum",
      "Switch to an SNS topic instead of SQS"
    ],
    "answer": [
      0,
      2
    ],
    "explanation": "Visibility timeout prevents re-delivery during processing. Reserved Concurrency caps parallel executions and protects RDS. Long polling reduces empty receives but doesn’t stop duplicates or throttle concurrency.",
    "difficulty": "Medium"
  },
  {
    "id": "SAA-289",
    "domainId": "D3",
    "domain": "Design High-Performing Architectures",
    "section": "CloudFront",
    "question": "A global website serves mostly cacheable content. The company wants lower latency worldwide and reduced origin load. Which TWO services should be used together to meet this goal? (Choose TWO.)",
    "choices": [
      "Amazon CloudFront",
      "Amazon Route 53 Resolver inbound endpoints",
      "An Application Load Balancer as the origin",
      "AWS Global Accelerator only (no CDN)",
      "AWS Storage Gateway"
    ],
    "answer": [
      0,
      2
    ],
    "explanation": "CloudFront caches content at edge locations. ALB can serve as a scalable origin (routing to multiple targets) for dynamic and cacheable content.",
    "difficulty": "Medium"
  },
  {
    "id": "SAA-290",
    "domainId": "D4",
    "domain": "Design Cost-Optimized Architectures",
    "section": "S3",
    "question": "You have tens of millions of objects with unpredictable access patterns. You want automatic tiering without app changes and millisecond access when requested. Which TWO S3 options can satisfy this pattern? (Choose TWO.)",
    "choices": [
      "S3 Intelligent-Tiering",
      "S3 Standard-IA only",
      "S3 Lifecycle rules transitioning between Standard and Standard-IA",
      "S3 Glacier Deep Archive",
      "S3 One Zone-IA only"
    ],
    "answer": [
      0,
      2
    ],
    "explanation": "Intelligent-Tiering automatically optimizes based on access. Lifecycle transitions (Standard ↔ IA patterns) can reduce cost without app changes, though they’re rule-based rather than automatic learning. Deep Archive won’t meet millisecond access.",
    "difficulty": "Medium"
  },
  {
    "id": "SAA-291",
    "domainId": "D1",
    "domain": "Design Secure Architectures",
    "section": "Organizations",
    "question": "A company wants to centrally enforce that no account in an OU can disable CloudTrail or stop log delivery. Which TWO mechanisms are most appropriate? (Choose TWO.)",
    "choices": [
      "Service Control Policies (SCPs) denying cloudtrail:StopLogging and s3:PutBucketPolicy changes",
      "IAM inline policies on each developer user",
      "AWS Control Tower guardrails (detective/preventive) where applicable",
      "Security groups denying outbound HTTPS",
      "CloudFront Functions"
    ],
    "answer": [
      0,
      2
    ],
    "explanation": "SCPs set maximum permissions for accounts and can prevent disabling CloudTrail. Control Tower guardrails help enforce and monitor required configurations at scale.",
    "difficulty": "Medium"
  },
  {
    "id": "SAA-292",
    "domainId": "D2",
    "domain": "Design Resilient Architectures",
    "section": "DataSync",
    "question": "You need to migrate 150 TB from an on-prem NFS server to Amazon EFS with metadata preservation, scheduling, and incremental sync. Which TWO components are required? (Choose TWO.)",
    "choices": [
      "AWS DataSync agent deployed on-prem",
      "AWS Transfer Family SFTP server in AWS",
      "An AWS DataSync task configured from NFS to EFS",
      "Amazon CloudFront distribution",
      "Amazon EBS snapshots of the NFS server"
    ],
    "answer": [
      0,
      2
    ],
    "explanation": "DataSync uses an on-prem agent plus a configured DataSync task to move data from NFS to EFS with scheduling and verification.",
    "difficulty": "Medium"
  },
  {
    "id": "SAA-293",
    "domainId": "D3",
    "domain": "Design High-Performing Architectures",
    "section": "Kinesis",
    "question": "A team needs near real-time ingestion of clickstream events with multiple independent consumers and replay capability for 48 hours. Which TWO statements about the correct service are true? (Choose TWO.)",
    "choices": [
      "Amazon Kinesis Data Streams supports multiple consumers and configurable retention for replay",
      "Amazon Kinesis Data Firehose is best for sub-second consumer processing with replay",
      "Amazon Kinesis Data Streams is suited for low-latency stream processing",
      "Amazon SNS provides ordered replay for 48 hours by default",
      "Amazon SQS Standard guarantees strict ordering for all messages"
    ],
    "answer": [
      0,
      2
    ],
    "explanation": "Kinesis Data Streams supports low-latency processing, multiple consumers, and retention for replay. Firehose is optimized for delivery to destinations, not multi-consumer replay-first patterns.",
    "difficulty": "Medium"
  },
  {
    "id": "SAA-294",
    "domainId": "D1",
    "domain": "Design Secure Architectures",
    "section": "VPC",
    "question": "Workloads are IPv6-only in private subnets and must reach the internet outbound, but must not be reachable inbound from the internet. Which TWO items are part of the correct solution? (Choose TWO.)",
    "choices": [
      "Egress-only Internet Gateway",
      "Internet Gateway with inbound security group rules opened",
      "Routes in private subnet route tables to the egress-only internet gateway for ::/0",
      "NAT Gateway",
      "VPC peering to a public VPC"
    ],
    "answer": [
      0,
      2
    ],
    "explanation": "For IPv6 outbound-only internet, use an egress-only IGW and add ::/0 routes to it from private subnets. NAT Gateway is for IPv4.",
    "difficulty": "Medium"
  },
  {
    "id": "SAA-295",
    "domainId": "D4",
    "domain": "Design Cost-Optimized Architectures",
    "section": "Compute",
    "question": "A containerized batch job runs nightly for 2 hours and is not time-sensitive. The team wants to minimize cost and avoid managing servers. Which TWO compute options are the best fit? (Choose TWO.)",
    "choices": [
      "AWS Batch with a Fargate compute environment",
      "Amazon ECS on Fargate with scheduled tasks",
      "Amazon EC2 Dedicated Hosts",
      "AWS Lambda with a 3-hour timeout",
      "Amazon EKS with self-managed nodes kept running 24/7"
    ],
    "answer": [
      0,
      1
    ],
    "explanation": "Batch on Fargate or ECS Fargate scheduled tasks meet serverless container execution and reduce idle costs. Lambda cannot run for hours, and always-on node fleets increase cost.",
    "difficulty": "Medium"
  },
  {
    "id": "SAA-296",
    "domainId": "D1",
    "domain": "Design Secure Architectures",
    "section": "KMS",
    "question": "A company replicates encrypted objects from us-east-1 to eu-west-1. They must decrypt in both Regions without re-encrypting and ensure keys remain cryptographically equivalent. Which TWO KMS actions/features should be used? (Choose TWO.)",
    "choices": [
      "Create a KMS multi-Region primary key in us-east-1",
      "Create a replica key in eu-west-1 for the multi-Region key",
      "Use SSE-S3 because it decrypts cross-Region automatically",
      "Use a single-region key and share it directly into eu-west-1",
      "Use unrelated CMKs in each Region but keep the same alias name"
    ],
    "answer": [
      0,
      1
    ],
    "explanation": "Multi-Region keys are designed for cross-Region encrypt/decrypt without re-encryption by using linked primary + replica keys that are cryptographically equivalent.",
    "difficulty": "Hard"
  },
  {
    "id": "SAA-297",
    "domainId": "D1",
    "domain": "Design Secure Architectures",
    "section": "S3",
    "question": "S3 Cross-Region Replication is enabled for a source bucket using SSE-KMS. Replication fails due to access errors on the destination KMS key. Which TWO changes are most likely required to fix it while keeping destination objects SSE-KMS encrypted? (Choose TWO.)",
    "choices": [
      "Update the destination KMS key policy to allow the replication IAM role to use kms:Encrypt and kms:GenerateDataKey",
      "Disable versioning on the destination bucket to reduce complexity",
      "Ensure the replication IAM role has permissions to replicate objects to the destination bucket (s3:ReplicateObject, s3:ReplicateDelete, etc.)",
      "Turn off SSE-KMS on the source bucket",
      "Create an S3 Transfer Acceleration endpoint"
    ],
    "answer": [
      0,
      2
    ],
    "explanation": "CRR with SSE-KMS needs (1) S3 permissions for replication and (2) KMS key policy permissions on the destination CMK so the replication role can encrypt (and generate data keys).",
    "difficulty": "Hard"
  },
  {
    "id": "SAA-298",
    "domainId": "D1",
    "domain": "Design Secure Architectures",
    "section": "Organizations",
    "question": "A security team wants to ensure that even admins in member accounts cannot create internet-facing load balancers and cannot disable GuardDuty. The company uses AWS Organizations. Which TWO controls best enforce these requirements at scale? (Choose TWO.)",
    "choices": [
      "SCPs that explicitly deny elasticloadbalancing:CreateLoadBalancer with scheme=internet-facing and guardduty:DeleteDetector/StopMonitoringMembers",
      "IAM policies on each admin user, manually maintained per account",
      "Permission boundaries attached to every IAM role in every account",
      "AWS Config rules only, with email notifications",
      "Security groups that block 0.0.0.0/0"
    ],
    "answer": [
      0,
      2
    ],
    "explanation": "SCPs enforce maximum permissions across accounts. Permission boundaries further constrain what IAM roles/users can do even when admins try to expand permissions. Config alone is detective, not preventive.",
    "difficulty": "Hard"
  },
  {
    "id": "SAA-299",
    "domainId": "D2",
    "domain": "Design Resilient Architectures",
    "section": "Disaster Recovery",
    "question": "A critical payments platform requires minutes-level RTO and low RPO across two Regions, but cannot justify active/active cost. The secondary Region should run a scaled-down environment that can rapidly scale during failover. Which TWO elements best describe the correct approach? (Choose TWO.)",
    "choices": [
      "Warm Standby strategy",
      "Backup and restore strategy",
      "Keep a minimal but running copy of the application stack in the secondary Region",
      "Keep only backups in S3 Glacier Deep Archive and restore during disaster",
      "Multi-Region active/active with continuous traffic splitting"
    ],
    "answer": [
      0,
      2
    ],
    "explanation": "Warm standby keeps a reduced-capacity but running environment in the secondary Region and scales up on failover, providing minutes-level RTO with lower cost than active/active.",
    "difficulty": "Hard"
  },
  {
    "id": "SAA-300",
    "domainId": "D3",
    "domain": "Design High-Performing Architectures",
    "section": "CloudFront",
    "question": "A distribution must authenticate viewers at the edge by calling an external authorization API, then add/remove headers and potentially return a redirect before the request reaches the origin. Which TWO statements about the correct feature are true? (Choose TWO.)",
    "choices": [
      "Lambda@Edge can call external HTTPS endpoints during viewer/origin request processing",
      "CloudFront Functions can make network calls to external authorization APIs",
      "Lambda@Edge can modify headers and generate custom responses (including redirects)",
      "AWS WAF can call arbitrary external APIs for custom auth decisions",
      "ALB listener rules can run JavaScript code at the edge"
    ],
    "answer": [
      0,
      2
    ],
    "explanation": "Lambda@Edge supports external calls (within limits) and can modify headers or return responses like redirects. CloudFront Functions are lightweight and cannot call external services.",
    "difficulty": "Hard"
  },
  {
    "id": "SAA-301",
    "domainId": "D2",
    "domain": "Design Resilient Architectures",
    "section": "Networking",
    "question": "A company needs to connect dozens of VPCs across accounts plus on-prem networks in a hub-and-spoke topology, with centralized routing, route propagation, and minimal operational overhead. Which TWO statements describe the best solution? (Choose TWO.)",
    "choices": [
      "AWS Transit Gateway provides hub-and-spoke connectivity and centralized route tables",
      "VPC Peering is preferred because it automatically provides transitive routing",
      "Transit Gateway attachments simplify connecting many VPCs without a full mesh",
      "A separate Site-to-Site VPN per VPC is the simplest at large scale",
      "Direct Connect alone automatically connects VPC-to-VPC routing without a hub"
    ],
    "answer": [
      0,
      2
    ],
    "explanation": "Transit Gateway is built for centralized connectivity and avoids complex peering meshes. VPC peering is non-transitive and becomes operationally complex at scale.",
    "difficulty": "Hard"
  },
  {
    "id": "SAA-302",
    "domainId": "D1",
    "domain": "Design Secure Architectures",
    "section": "EKS",
    "question": "An EKS cluster runs workloads that must access DynamoDB securely without storing long-term AWS keys in pods. The solution must use IAM policies and be least privilege. Which TWO actions should you take? (Choose TWO.)",
    "choices": [
      "Enable IAM Roles for Service Accounts (IRSA) and map a Kubernetes service account to an IAM role",
      "Store AWS access keys in a ConfigMap and mount it into pods",
      "Attach a least-privilege IAM policy to the IRSA IAM role allowing required DynamoDB actions",
      "Assign AdministratorAccess to the node instance role so pods inherit it",
      "Expose DynamoDB through a public ALB and use basic auth"
    ],
    "answer": [
      0,
      2
    ],
    "explanation": "IRSA provides short-lived credentials to pods via an IAM role bound to a service account. Attach only the required DynamoDB permissions to that role for least privilege.",
    "difficulty": "Hard"
  },
  {
    "id": "SAA-303",
    "domainId": "D2",
    "domain": "Design Resilient Architectures",
    "section": "RDS",
    "question": "A company needs a very short, controlled database upgrade cutover and the ability to quickly roll back if issues occur. They are using Amazon RDS for MySQL and upgrading a major version. Which TWO steps/features best match this requirement? (Choose TWO.)",
    "choices": [
      "Use RDS Blue/Green Deployments to create a synchronized green environment",
      "Perform the major upgrade directly on the production instance during business hours",
      "Switch over to the green environment during a controlled maintenance window",
      "Rely on Multi-AZ failover to downgrade automatically",
      "Use S3 Lifecycle policies to archive old database logs"
    ],
    "answer": [
      0,
      2
    ],
    "explanation": "Blue/Green provides a synchronized staging environment to upgrade safely, then switch over with a short cutover. Multi-AZ is HA, not version rollback.",
    "difficulty": "Hard"
  },
  {
    "id": "SAA-304",
    "domainId": "D4",
    "domain": "Design Cost-Optimized Architectures",
    "section": "S3",
    "question": "You must update tags on 50 million objects across multiple S3 buckets and you need progress reporting with minimal custom code. Which TWO items form the most native, operationally simple solution? (Choose TWO.)",
    "choices": [
      "Use S3 Batch Operations to run a PutObjectTagging job",
      "Provide an S3 Batch Operations manifest listing objects to update",
      "Write a custom script with thousands of parallel threads and no job tracking",
      "Use S3 Transfer Acceleration to speed up tagging API calls",
      "Use S3 Storage Lens to apply tags"
    ],
    "answer": [
      0,
      1
    ],
    "explanation": "S3 Batch Operations is built for massive-scale object actions and provides job tracking/reporting. A manifest is the standard way to define the object set for the batch job.",
    "difficulty": "Hard"
  },
  {
    "id": "SAA-305",
    "domainId": "D2",
    "domain": "Design Resilient Architectures",
    "section": "Migration",
    "question": "You must migrate hundreds of on-prem VMs to AWS with block-level continuous replication, support test cutovers, and keep the final cutover window short. Which TWO statements describe the correct service/approach? (Choose TWO.)",
    "choices": [
      "AWS Application Migration Service (MGN) performs block-level replication for server migrations",
      "AWS DataSync is designed for VM block-level replication and cutover orchestration",
      "MGN supports launching test instances in AWS before final cutover",
      "AWS DMS is the primary service for lift-and-shift VM replication to EC2",
      "S3 Batch Operations is used to replicate running VM disks"
    ],
    "answer": [
      0,
      2
    ],
    "explanation": "MGN is purpose-built for lift-and-shift server migrations with continuous block-level replication and test cutovers. DataSync is for file transfers; DMS is for databases.",
    "difficulty": "Hard"
  },
  {
    "id": "SAA-306",
    "domainId": "D1",
    "domain": "Design Secure Architectures",
    "section": "IAM",
    "question": "A new AWS account was created for production. Which TWO best practices should be applied to the root user right away? (Choose TWO.)",
    "choices": [
      "Create access keys for the root user for daily CLI use",
      "Enable MFA on the root user",
      "Use the root user only for tasks that specifically require it",
      "Share the root password with the DevOps team for emergencies",
      "Attach AdministratorAccess to all IAM users instead of using the root user"
    ],
    "answer": [
      1,
      2
    ],
    "explanation": "Enable MFA on the root user and avoid using it for day-to-day operations; use it only when required.",
    "difficulty": "Easy"
  },
  {
    "id": "SAA-307",
    "domainId": "D3",
    "domain": "Design High-Performing Architectures",
    "section": "EC2",
    "question": "What is an AMI mainly used for?",
    "choices": [
      "A preconfigured image used to launch EC2 instances with an OS and optional software",
      "A tool to automatically scale EC2 instances based on CPU",
      "A managed service for long-term object storage",
      "A dedicated network interface for higher bandwidth"
    ],
    "answer": 0,
    "explanation": "An AMI is the template (OS + configuration) used to launch EC2 instances.",
    "difficulty": "Easy"
  },
  {
    "id": "SAA-308",
    "domainId": "D1",
    "domain": "Design Secure Architectures",
    "section": "Networking",
    "question": "Your EC2 instances are in private subnets and must download patches from the internet without being directly reachable from the internet. Which TWO components are typically required? (Choose TWO.)",
    "choices": [
      "Internet Gateway attached to the VPC",
      "NAT Gateway in a public subnet",
      "Route table in the private subnet pointing 0.0.0.0/0 to the NAT Gateway",
      "VPC peering to a public VPC owned by AWS",
      "An ALB in front of the instances to provide outbound internet"
    ],
    "answer": [
      1,
      2
    ],
    "explanation": "Private subnets use a NAT Gateway for outbound internet access, plus a route to the NAT in the private route table.",
    "difficulty": "Easy"
  },
  {
    "id": "SAA-309",
    "domainId": "D2",
    "domain": "Design Resilient Architectures",
    "section": "EC2",
    "question": "By default, what happens to an EC2 instance’s root EBS volume when the instance is terminated?",
    "choices": [
      "It is always kept",
      "It is automatically snapshotted",
      "It is deleted by default",
      "It is moved to another AZ"
    ],
    "answer": 2,
    "explanation": "The default behavior is to delete the root EBS volume on termination (unless you change the DeleteOnTermination flag).",
    "difficulty": "Easy"
  },
  {
    "id": "SAA-310",
    "domainId": "D3",
    "domain": "Design High-Performing Architectures",
    "section": "Access",
    "question": "Which TWO are valid ways to access AWS services programmatically? (Choose TWO.)",
    "choices": [
      "AWS CLI",
      "AWS SDKs",
      "FTP client",
      "Telnet",
      "Remote Desktop Protocol (RDP) to the AWS Console"
    ],
    "answer": [
      0,
      1
    ],
    "explanation": "Programmatic access is typically done using the AWS CLI or AWS SDKs (which call AWS APIs).",
    "difficulty": "Easy"
  },
  {
    "id": "SAA-311",
    "domainId": "D3",
    "domain": "Design High-Performing Architectures",
    "section": "ELB",
    "question": "Which load balancer is best suited for HTTP/HTTPS traffic with features like host-based and path-based routing?",
    "choices": [
      "Network Load Balancer (NLB)",
      "Application Load Balancer (ALB)",
      "Gateway Load Balancer (GWLB)",
      "Classic Load Balancer (CLB) only"
    ],
    "answer": 1,
    "explanation": "ALB is Layer 7 and supports routing features like host-based and path-based rules.",
    "difficulty": "Easy"
  },
  {
    "id": "SAA-312",
    "domainId": "D2",
    "domain": "Design Resilient Architectures",
    "section": "Auto Scaling",
    "question": "You want your application to automatically add EC2 instances during high load and replace unhealthy instances. Which TWO AWS components are the standard solution? (Choose TWO.)",
    "choices": [
      "Auto Scaling Group (ASG)",
      "Application Load Balancer (ALB)",
      "Amazon S3 lifecycle policies",
      "AWS Snowball Edge",
      "Amazon Route 53 private hosted zone only"
    ],
    "answer": [
      0,
      1
    ],
    "explanation": "An ASG handles scaling and health-based replacement, while an ALB distributes traffic and removes unhealthy targets.",
    "difficulty": "Easy"
  },
  {
    "id": "SAA-313",
    "domainId": "D4",
    "domain": "Design Cost-Optimized Architectures",
    "section": "EC2 Pricing",
    "question": "Which EC2 purchase option is typically best for short, unpredictable workloads with no long-term commitment?",
    "choices": [
      "Reserved Instances (3-year)",
      "Savings Plans (3-year)",
      "On-Demand Instances",
      "Dedicated Hosts"
    ],
    "answer": 2,
    "explanation": "On-Demand is best for short, unpredictable workloads because it has no long-term commitment.",
    "difficulty": "Easy"
  },
  {
    "id": "SAA-314",
    "domainId": "D3",
    "domain": "Design High-Performing Architectures",
    "section": "Storage",
    "question": "Which TWO statements accurately describe Amazon EBS vs Amazon EFS? (Choose TWO.)",
    "choices": [
      "EBS is block storage attached to a single EC2 instance (AZ-scoped)",
      "EFS is a managed NFS file system that can be mounted by many instances across AZs",
      "EBS can be mounted by unlimited instances across multiple AZs by default",
      "EFS is object storage for static websites",
      "EBS automatically replicates across Regions by default"
    ],
    "answer": [
      0,
      1
    ],
    "explanation": "EBS is AZ-scoped block storage for a single instance (typical use). EFS is shared file storage (NFS) across multiple instances and AZs.",
    "difficulty": "Easy"
  },
  {
    "id": "SAA-315",
    "domainId": "D3",
    "domain": "Design High-Performing Architectures",
    "section": "EC2",
    "question": "EC2 User Data scripts run…",
    "choices": [
      "Once, at the first start of the instance",
      "Every time the instance reboots",
      "Every hour automatically",
      "Only after the instance is terminated"
    ],
    "answer": 0,
    "explanation": "User Data runs at first boot by default (unless you build logic to run it again).",
    "difficulty": "Easy"
  },
  {
    "id": "SAA-316",
    "domainId": "D1",
    "domain": "Design Secure Architectures",
    "section": "Security Groups",
    "question": "By default, which TWO statements about a new Security Group are correct? (Choose TWO.)",
    "choices": [
      "It blocks all inbound traffic until you add inbound rules",
      "It allows all inbound traffic by default",
      "It allows all outbound traffic by default",
      "It blocks all outbound traffic by default",
      "It is stateless like a Network ACL"
    ],
    "answer": [
      0,
      2
    ],
    "explanation": "Default security group behavior is: inbound denied (no inbound rules) and outbound allowed (allow all outbound).",
    "difficulty": "Easy"
  },
  {
    "id": "SAA-317",
    "domainId": "D2",
    "domain": "Design Resilient Architectures",
    "section": "RDS",
    "question": "Which RDS feature provides automatic failover to another AZ with minimal application changes (same endpoint)?",
    "choices": [
      "RDS Read Replica",
      "RDS Multi-AZ deployment",
      "RDS snapshot",
      "RDS Performance Insights"
    ],
    "answer": 1,
    "explanation": "Multi-AZ provides a standby in another AZ and automatic failover with the same endpoint.",
    "difficulty": "Easy"
  },
  {
    "id": "SAA-318",
    "domainId": "D4",
    "domain": "Design Cost-Optimized Architectures",
    "section": "S3",
    "question": "You need to host a public dataset in S3 and want downloaders to pay request and data-transfer costs while you keep paying for storage. Which TWO statements are true? (Choose TWO.)",
    "choices": [
      "Enable Requester Pays on the bucket",
      "Requester Pays makes the bucket owner pay for all requests",
      "Requesters are charged for requests and data transfer when Requester Pays is enabled",
      "You must enable S3 Transfer Acceleration for Requester Pays to work",
      "Requester Pays prevents public access automatically"
    ],
    "answer": [
      0,
      2
    ],
    "explanation": "Requester Pays shifts request and transfer charges to the requester; the bucket owner still pays for storage.",
    "difficulty": "Easy"
  },
  {
    "id": "SAA-319",
    "domainId": "D1",
    "domain": "Design Secure Architectures",
    "section": "S3",
    "question": "A browser-based web app at https://app.example.com needs to call GET/PUT on an S3 bucket. Requests are blocked by the browser. What must be configured?",
    "choices": [
      "S3 CORS configuration allowing the origin and required methods/headers",
      "S3 Transfer Acceleration",
      "S3 Object Lock",
      "CloudTrail data events only"
    ],
    "answer": 0,
    "explanation": "Cross-origin browser requests require S3 CORS rules allowing the web app origin and the needed HTTP methods/headers.",
    "difficulty": "Easy"
  },
  {
    "id": "SAA-320",
    "domainId": "D2",
    "domain": "Design Resilient Architectures",
    "section": "Route 53",
    "question": "You want to split traffic between two endpoints: 80% to the old version and 20% to the new version. Which TWO Route 53 concepts are used? (Choose TWO.)",
    "choices": [
      "Weighted routing policy",
      "Two records (one per endpoint) with different weights",
      "Failover routing policy",
      "Geolocation routing policy",
      "Multi-Value Answer routing policy"
    ],
    "answer": [
      0,
      1
    ],
    "explanation": "Weighted routing uses multiple records with weights to control traffic percentage between endpoints.",
    "difficulty": "Easy"
  },
  {
    "id": "SAA-321",
    "domainId": "D2",
    "domain": "Design Resilient Architectures",
    "section": "Route 53",
    "question": "You need to map the zone apex (example.com) to an Application Load Balancer. Which Route 53 record type should you use?",
    "choices": [
      "CNAME record to the ALB DNS name",
      "Alias A record to the ALB",
      "NS record to the ALB",
      "TXT record containing the ALB name"
    ],
    "answer": 1,
    "explanation": "At the zone apex you use an Alias A record (CNAME isn’t allowed at the root in Route 53).",
    "difficulty": "Easy"
  },
  {
    "id": "SAA-322",
    "domainId": "D1",
    "domain": "Design Secure Architectures",
    "section": "CloudTrail",
    "question": "A security team needs to know who made AWS API calls, from which IP, and when. Which TWO steps/services provide this auditing capability? (Choose TWO.)",
    "choices": [
      "Enable AWS CloudTrail management events",
      "Enable Amazon GuardDuty only",
      "Deliver CloudTrail logs to an S3 bucket",
      "Enable S3 Transfer Acceleration",
      "Enable AWS Budgets"
    ],
    "answer": [
      0,
      2
    ],
    "explanation": "CloudTrail records API calls (identity, source IP, time), and delivering logs to S3 retains them for auditing.",
    "difficulty": "Easy"
  },
  {
    "id": "SAA-323",
    "domainId": "D3",
    "domain": "Design High-Performing Architectures",
    "section": "Lambda",
    "question": "What is the maximum duration a single AWS Lambda invocation can run before it times out (assuming you set it to the maximum)?",
    "choices": [
      "30 seconds",
      "5 minutes",
      "15 minutes",
      "1 hour"
    ],
    "answer": 2,
    "explanation": "Lambda has a maximum timeout of 15 minutes per invocation.",
    "difficulty": "Easy"
  },
  {
    "id": "SAA-324",
    "domainId": "D2",
    "domain": "Design Resilient Architectures",
    "section": "SQS",
    "question": "An SQS-triggered Lambda is processing a message and you don’t want SQS to deliver the same message again while processing is still in progress. Which TWO settings should be aligned? (Choose TWO.)",
    "choices": [
      "SQS visibility timeout should be greater than the maximum processing time",
      "SQS long polling must be set to 20 seconds",
      "Lambda function timeout should be less than or equal to the SQS visibility timeout",
      "Enable FIFO to automatically prevent all duplicates",
      "Enable S3 Versioning"
    ],
    "answer": [
      0,
      2
    ],
    "explanation": "Visibility timeout must cover processing time, and Lambda timeout should fit within that window to reduce duplicate deliveries.",
    "difficulty": "Easy"
  },
  {
    "id": "SAA-325",
    "domainId": "D3",
    "domain": "Design High-Performing Architectures",
    "section": "DynamoDB",
    "question": "Your DynamoDB traffic is unpredictable and you don’t want to manage read/write capacity planning. Which capacity mode should you use?",
    "choices": [
      "Provisioned capacity mode with manual scaling",
      "Provisioned capacity mode with auto scaling only",
      "On-demand capacity mode",
      "DAX cluster only"
    ],
    "answer": 2,
    "explanation": "On-demand automatically handles unpredictable workloads without capacity planning.",
    "difficulty": "Easy"
  },
  {
    "id": "SAA-326",
    "domainId": "D1",
    "domain": "Design Secure Architectures",
    "section": "Secrets Manager",
    "question": "You store database credentials and need automatic rotation every 30 days with managed workflows. Which TWO capabilities/services should you use? (Choose TWO.)",
    "choices": [
      "AWS Secrets Manager",
      "S3 bucket policies",
      "Secrets Manager rotation (uses a Lambda rotation function)",
      "EBS snapshots",
      "Route 53 health checks"
    ],
    "answer": [
      0,
      2
    ],
    "explanation": "Secrets Manager stores secrets and supports automatic rotation via a rotation Lambda function on a schedule.",
    "difficulty": "Easy"
  },
  {
    "id": "SAA-327",
    "domainId": "D1",
    "domain": "Design Secure Architectures",
    "section": "KMS",
    "question": "Which AWS service is used to create and manage encryption keys for services like S3, EBS, and RDS (SSE-KMS)?",
    "choices": [
      "AWS Certificate Manager (ACM)",
      "AWS Key Management Service (KMS)",
      "AWS Secrets Manager",
      "Amazon Cognito"
    ],
    "answer": 1,
    "explanation": "KMS manages encryption keys used by many AWS services for server-side encryption and cryptographic operations.",
    "difficulty": "Easy"
  },
  {
    "id": "SAA-328",
    "domainId": "D3",
    "domain": "Design High-Performing Architectures",
    "section": "CloudFront",
    "question": "You want to block viewers from specific countries from accessing your content at the edge. Which TWO CloudFront features can directly help? (Choose TWO.)",
    "choices": [
      "CloudFront geo restriction",
      "CloudFront signed URLs or signed cookies",
      "Route 53 weighted routing",
      "Security groups on the origin only",
      "S3 Object Lock"
    ],
    "answer": [
      0,
      1
    ],
    "explanation": "Geo restriction blocks by country at the edge, and signed URLs/cookies restrict access to authorized viewers.",
    "difficulty": "Easy"
  },
  {
    "id": "SAA-329",
    "domainId": "D3",
    "domain": "Design High-Performing Architectures",
    "section": "ECS",
    "question": "You want to run containers without managing EC2 instances. Which ECS launch type should you use?",
    "choices": [
      "EC2 launch type",
      "Fargate launch type",
      "On-premises launch type",
      "Dedicated Host launch type"
    ],
    "answer": 1,
    "explanation": "ECS on Fargate removes the need to manage EC2 instances for container workloads.",
    "difficulty": "Easy"
  },
  {
    "id": "SAA-330",
    "domainId": "D1",
    "domain": "Design Secure Architectures",
    "section": "VPC Endpoints",
    "question": "You want private subnets to reach Amazon S3 without using a NAT Gateway and without sending traffic over the public internet. Which TWO actions achieve this? (Choose TWO.)",
    "choices": [
      "Create a Gateway VPC endpoint for S3",
      "Create an Interface VPC endpoint for S3 and disable private DNS",
      "Update the private subnet route table to target the S3 Gateway endpoint",
      "Attach an Internet Gateway to the private subnet",
      "Assign Elastic IPs to the instances"
    ],
    "answer": [
      0,
      2
    ],
    "explanation": "Use an S3 Gateway VPC endpoint and add the endpoint route to the private route table.",
    "difficulty": "Easy"
  },
  {
    "id": "SAA-331",
    "domainId": "D2",
    "domain": "Design Resilient Architectures",
    "section": "S3",
    "question": "What is a hard prerequisite for enabling S3 Cross-Region Replication (CRR) between two buckets?",
    "choices": [
      "S3 Transfer Acceleration enabled on both buckets",
      "Versioning enabled on both source and destination buckets",
      "S3 Object Lock enabled on both buckets",
      "The buckets must be in the same Region"
    ],
    "answer": 1,
    "explanation": "CRR requires versioning enabled on both buckets.",
    "difficulty": "Easy"
  },
  {
    "id": "SAA-332",
    "domainId": "D3",
    "domain": "Design High-Performing Architectures",
    "section": "CloudWatch",
    "question": "You want to be alerted when an EC2 instance’s CPU utilization stays above 80% for 5 minutes. Which TWO services/features do you use? (Choose TWO.)",
    "choices": [
      "Amazon CloudWatch metric (CPUUtilization)",
      "Amazon CloudWatch alarm",
      "AWS CloudTrail",
      "Amazon Athena",
      "AWS Config"
    ],
    "answer": [
      0,
      1
    ],
    "explanation": "CloudWatch metrics provide CPUUtilization and CloudWatch alarms evaluate the threshold and trigger notifications/actions.",
    "difficulty": "Easy"
  },
  {
    "id": "SAA-333",
    "domainId": "D2",
    "domain": "Design Resilient Architectures",
    "section": "EBS",
    "question": "What is the primary purpose of an EBS snapshot?",
    "choices": [
      "To store objects for static website hosting",
      "To create a point-in-time backup of an EBS volume",
      "To encrypt a KMS key",
      "To distribute HTTP traffic across instances"
    ],
    "answer": 1,
    "explanation": "An EBS snapshot is a point-in-time backup of an EBS volume.",
    "difficulty": "Easy"
  },
  {
    "id": "SAA-334",
    "domainId": "D1",
    "domain": "Design Secure Architectures",
    "section": "ACM",
    "question": "You need a publicly trusted TLS certificate for an ALB and want AWS-managed renewals. What should you do?",
    "choices": [
      "Use a self-signed certificate and import it into ACM",
      "Request a public certificate in ACM and validate it (DNS or email)",
      "Create a certificate in Secrets Manager",
      "Use S3 to host the certificate and reference it from the ALB"
    ],
    "answer": 1,
    "explanation": "ACM public certificates are managed by AWS and support automatic renewal when validation remains in place.",
    "difficulty": "Easy"
  },
  {
    "id": "SAA-335",
    "domainId": "D4",
    "domain": "Design Cost-Optimized Architectures",
    "section": "S3",
    "question": "You store objects that are rarely accessed but must be retrieved in milliseconds, and you accept storing data in a single AZ to reduce cost. Which S3 storage class fits best?",
    "choices": [
      "S3 Standard",
      "S3 Standard-IA",
      "S3 One Zone-IA",
      "S3 Glacier Flexible Retrieval"
    ],
    "answer": 2,
    "explanation": "S3 One Zone-IA is for infrequent access with millisecond retrieval stored in a single AZ at lower cost.",
    "difficulty": "Easy"
  },
  {
    "id": "SAA-336",
    "domainId": "D3",
    "domain": "Design High-Performing Architectures",
    "section": "Athena",
    "question": "You want to run ad-hoc SQL queries directly against files in S3 without provisioning servers. Which service should you use?",
    "choices": [
      "Amazon Athena",
      "Amazon RDS",
      "Amazon EC2",
      "Amazon ElastiCache"
    ],
    "answer": 0,
    "explanation": "Athena is serverless SQL for querying data in S3.",
    "difficulty": "Easy"
  },
  {
    "id": "SAA-337",
    "domainId": "D2",
    "domain": "Design Resilient Architectures",
    "section": "Disaster Recovery",
    "question": "Which disaster recovery strategy has the lowest cost but typically the highest RTO/RPO among common DR patterns?",
    "choices": [
      "Multi-Region Active/Active",
      "Warm Standby",
      "Pilot Light",
      "Backup & Restore"
    ],
    "answer": 3,
    "explanation": "Backup & Restore is usually the lowest cost, but it has longer recovery time and potentially more data loss compared to warm standby or active/active.",
    "difficulty": "Easy"
  },
  {
    "id": "SAA-338",
    "domainId": "D1",
    "domain": "Design Secure Architectures",
    "section": "Organizations",
    "question": "What is the main purpose of an AWS Organizations Service Control Policy (SCP)?",
    "choices": [
      "Grant permissions to IAM users in an account",
      "Set the maximum permissions for member accounts/OUs (guardrails)",
      "Encrypt data at rest for all services",
      "Provide DDoS protection for CloudFront"
    ],
    "answer": 1,
    "explanation": "SCPs define the permission boundaries (maximum allowed) for accounts in an organization; they do not grant permissions by themselves.",
    "difficulty": "Easy"
  },
  {
    "id": "SAA-339",
    "domainId": "D2",
    "domain": "Design Resilient Architectures",
    "section": "AWS Backup",
    "question": "You want a centralized managed service to back up resources like EBS, RDS, DynamoDB, and EFS using policies. Which service should you use?",
    "choices": [
      "AWS Backup",
      "AWS DataSync",
      "Amazon CloudFront",
      "AWS Glue"
    ],
    "answer": 0,
    "explanation": "AWS Backup is the managed centralized service for policy-based backups across multiple AWS services.",
    "difficulty": "Easy"
  },
  {
    "id": "SAA-340",
    "domainId": "D1",
    "domain": "Design Secure Architectures",
    "section": "WAF",
    "question": "A company uses CloudFront in front of multiple ALBs across several AWS accounts. Security wants to centrally enforce a baseline set of WAF rules across all accounts using AWS Organizations. Which service should be used?",
    "choices": [
      "AWS Shield Standard",
      "AWS Firewall Manager",
      "Amazon GuardDuty",
      "AWS Network Firewall"
    ],
    "answer": 1,
    "explanation": "AWS Firewall Manager integrates with AWS Organizations to centrally manage and enforce AWS WAF (and Shield Advanced) policies across multiple accounts and resources.",
    "difficulty": "Medium"
  },
  {
    "id": "SAA-341",
    "domainId": "D2",
    "domain": "Design Resilient Architectures",
    "section": "RDS",
    "question": "A production MySQL database runs on Amazon RDS. The analytics team must run heavy read queries without impacting the application’s performance. Which solution is the MOST suitable and cost-effective?",
    "choices": [
      "Enable RDS Multi-AZ and direct analytics queries to the standby instance",
      "Create an RDS Read Replica and direct analytics queries to the replica",
      "Increase the DB instance size and keep analytics on the primary",
      "Export data nightly to S3 and query with Athena only"
    ],
    "answer": 1,
    "explanation": "Read replicas offload read traffic from the primary DB, preventing analytics queries from impacting the production workload. Multi-AZ standby is not used for reads.",
    "difficulty": "Medium"
  },
  {
    "id": "SAA-342",
    "domainId": "D4",
    "domain": "Design Cost-Optimized Architectures",
    "section": "S3",
    "question": "A team stores large objects in S3. Objects are heavily accessed for the first 14 days, then rarely accessed for the next 60 days but must still be retrieved immediately (milliseconds). After that, the data is kept for compliance and can take hours to retrieve. Which lifecycle approach best meets the requirements at the lowest cost?",
    "choices": [
      "S3 Standard (14 days) → S3 Standard-IA (day 14–74) → S3 Glacier Flexible Retrieval (after day 74)",
      "S3 Standard (14 days) → S3 Glacier Deep Archive (after day 14)",
      "S3 Intelligent-Tiering (14 days) → S3 One Zone-IA (day 14–74) → S3 Glacier Instant Retrieval (after day 74)",
      "S3 One Zone-IA (14 days) → S3 Standard-IA (day 14–74) → S3 Glacier Deep Archive (after day 74)"
    ],
    "answer": 0,
    "explanation": "Standard fits frequent access, Standard-IA supports infrequent access with millisecond retrieval, and Glacier Flexible Retrieval supports long-term archiving with hour-level retrieval time.",
    "difficulty": "Medium"
  },
  {
    "id": "SAA-343",
    "domainId": "D1",
    "domain": "Design Secure Architectures",
    "section": "KMS",
    "question": "An S3 bucket uses SSE-KMS. A replication job to another Region fails with an error related to the destination KMS key. Which change is most likely required to allow replication to encrypt objects in the destination bucket?",
    "choices": [
      "Enable S3 Transfer Acceleration on the destination bucket",
      "Add permissions to the destination KMS key policy for the replication role to use kms:Encrypt and kms:GenerateDataKey",
      "Disable bucket versioning on the source bucket",
      "Enable MFA delete on the destination bucket"
    ],
    "answer": 1,
    "explanation": "For SSE-KMS replication, the replication IAM role must be allowed by the destination KMS key policy to perform encryption-related KMS actions (such as Encrypt and GenerateDataKey).",
    "difficulty": "Medium"
  },
  {
    "id": "SAA-344",
    "domainId": "D2",
    "domain": "Design Resilient Architectures",
    "section": "Disaster Recovery",
    "question": "A web platform must meet an RTO of under 30 minutes and an RPO of near zero for a regional disaster. The company can’t afford full active/active but can keep the secondary environment running at reduced capacity and scale it on failover. Which DR strategy is the best fit?",
    "choices": [
      "Backup and Restore",
      "Pilot Light",
      "Warm Standby",
      "Multi-Region Active/Active"
    ],
    "answer": 2,
    "explanation": "Warm standby keeps a scaled-down, fully functional environment running in the secondary Region and scales up during failover, meeting moderate RTO/RPO without active/active cost.",
    "difficulty": "Medium"
  },
  {
    "id": "SAA-345",
    "domainId": "D3",
    "domain": "Design High-Performing Architectures",
    "section": "Kinesis",
    "question": "A company needs to ingest clickstream events at high throughput with multiple consumer applications (analytics, fraud detection). Consumers must be able to replay events from the last 48 hours if processing logic changes. Which service best meets these requirements?",
    "choices": [
      "Amazon SNS",
      "Amazon SQS Standard",
      "Amazon Kinesis Data Streams",
      "Amazon Kinesis Data Firehose"
    ],
    "answer": 2,
    "explanation": "Kinesis Data Streams supports multiple consumers, low-latency processing, and configurable retention for replaying data (e.g., 48 hours).",
    "difficulty": "Medium"
  },
  {
    "id": "SAA-346",
    "domainId": "D1",
    "domain": "Design Secure Architectures",
    "section": "VPC Endpoints",
    "question": "Instances in private subnets must access S3 without using a NAT Gateway to reduce cost and keep traffic on the AWS network. What should you configure?",
    "choices": [
      "Interface VPC endpoint for S3 with private DNS disabled",
      "Gateway VPC endpoint for S3 and update route tables",
      "Internet Gateway and public IPs on the instances",
      "VPC peering to an AWS-managed S3 VPC"
    ],
    "answer": 1,
    "explanation": "S3 uses Gateway VPC endpoints (not Interface endpoints in most architectures) to route traffic privately without NAT. You must associate the endpoint with the route tables used by the subnets.",
    "difficulty": "Medium"
  },
  {
    "id": "SAA-347",
    "domainId": "D2",
    "domain": "Design Resilient Architectures",
    "section": "Outposts",
    "question": "A manufacturing site needs to run AWS services (EC2, EBS, EKS) on-premises with the same AWS APIs and console while achieving very low local latency. Which service is the BEST choice?",
    "choices": [
      "AWS Local Zones",
      "VMware Cloud on AWS",
      "AWS Outposts",
      "AWS Snowball Edge"
    ],
    "answer": 2,
    "explanation": "AWS Outposts brings AWS-managed infrastructure on-prem and supports native AWS services with consistent APIs and console experience.",
    "difficulty": "Medium"
  },
  {
    "id": "SAA-348",
    "domainId": "D4",
    "domain": "Design Cost-Optimized Architectures",
    "section": "Compute",
    "question": "A batch workload runs in containers for about 90 minutes each night. It is not time-sensitive and the team wants a serverless option without managing EC2 instances. Which solution is the MOST cost-effective?",
    "choices": [
      "AWS Lambda with the timeout increased to 2 hours",
      "Amazon ECS on Fargate with a scheduled task",
      "Amazon EKS with always-on managed node groups",
      "Amazon EC2 On-Demand instances running 24/7"
    ],
    "answer": 1,
    "explanation": "ECS Fargate supports serverless containers and can run scheduled tasks without managing servers. Lambda can’t run that long, and always-on nodes increase cost.",
    "difficulty": "Medium"
  },
  {
    "id": "SAA-349",
    "domainId": "D3",
    "domain": "Design High-Performing Architectures",
    "section": "ElastiCache",
    "question": "A web app is experiencing high read pressure on its RDS database due to frequently accessed session and user profile data. The data must be served with sub-millisecond latency and expire automatically. Which service is the BEST fit?",
    "choices": [
      "Amazon EFS",
      "Amazon ElastiCache for Redis",
      "Amazon S3 Standard",
      "Amazon Athena"
    ],
    "answer": 1,
    "explanation": "ElastiCache for Redis provides in-memory caching with very low latency and TTL expiration, reducing read load on RDS.",
    "difficulty": "Medium"
  },
  {
    "id": "SAA-350",
    "domainId": "D1",
    "domain": "Design Secure Architectures",
    "section": "Systems Manager",
    "question": "EC2 instances are in private subnets with no inbound access allowed. The operations team needs interactive shell access and port forwarding for troubleshooting without using bastion hosts, and all activity must be logged. Which service should be used?",
    "choices": [
      "EC2 Instance Connect",
      "AWS Systems Manager Session Manager",
      "Direct Connect",
      "Amazon Inspector"
    ],
    "answer": 1,
    "explanation": "SSM Session Manager provides interactive access without inbound SSH and supports logging/auditing to CloudWatch Logs/S3.",
    "difficulty": "Medium"
  },
  {
    "id": "SAA-351",
    "domainId": "D2",
    "domain": "Design Resilient Architectures",
    "section": "Networking",
    "question": "You need to connect dozens of VPCs and multiple on-premises networks in a hub-and-spoke design with centralized routing and route propagation. Which TWO services could be used to meet this requirement? (Choose TWO.)",
    "choices": [
      "AWS Transit Gateway",
      "VPC Peering",
      "AWS Direct Connect",
      "AWS Site-to-Site VPN",
      "Amazon Route 53 Resolver endpoints"
    ],
    "answer": [
      0,
      2
    ],
    "explanation": "Transit Gateway provides the hub for many VPCs and on-prem connections. Direct Connect can connect on-prem to AWS and can attach to Transit Gateway for centralized routing. (Site-to-Site VPN can also attach, but the question asks for TWO.)",
    "difficulty": "Medium"
  },
  {
    "id": "SAA-352",
    "domainId": "D3",
    "domain": "Design High-Performing Architectures",
    "section": "Global Accelerator",
    "question": "A global gaming app uses UDP and needs static anycast IPs and improved latency for worldwide users while balancing traffic to AWS endpoints. Which TWO AWS services should be used together? (Choose TWO.)",
    "choices": [
      "AWS Global Accelerator",
      "Application Load Balancer",
      "Network Load Balancer",
      "Amazon CloudFront",
      "AWS WAF"
    ],
    "answer": [
      0,
      2
    ],
    "explanation": "Global Accelerator provides static anycast IPs and optimized network paths for global users. Network Load Balancer supports UDP at Layer 4 and can serve as the regional endpoint.",
    "difficulty": "Medium"
  },
  {
    "id": "SAA-353",
    "domainId": "D1",
    "domain": "Design Secure Architectures",
    "section": "CloudFront",
    "question": "A company serves a global web app through Amazon CloudFront with an ALB origin. Security requires an authorization step at the edge: before any request reaches the origin, CloudFront must call an external authorization API, then either add/remove headers or return a redirect when access is denied. Which solution will meet these requirements with the LEAST operational overhead?",
    "choices": [
      "Attach AWS WAF to CloudFront and configure WAF to call the external authorization API",
      "Use Lambda@Edge on viewer request to call the authorization API and rewrite headers or return redirects",
      "Use CloudFront Functions to call the external authorization API before forwarding to the origin",
      "Move authorization to the origin and enforce it only in the application code"
    ],
    "answer": 1,
    "explanation": "Lambda@Edge can run on viewer request, perform external network calls (within limits), modify headers, and return custom responses. CloudFront Functions cannot call external services, and WAF cannot call arbitrary external authorization APIs.",
    "difficulty": "Hard"
  },
  {
    "id": "SAA-354",
    "domainId": "D2",
    "domain": "Design Resilient Architectures",
    "section": "RDS",
    "question": "A retail company runs a mission-critical RDS for MySQL database. They must upgrade to a new major version with a very short, controlled cutover and want an easy rollback if issues are found after the change. Which approach can be used to fulfill this requirement?",
    "choices": [
      "Perform an in-place major version upgrade and rely on Multi-AZ failover for rollback",
      "Use RDS Blue/Green Deployments and switch over when validation is complete",
      "Create a read replica, upgrade it, and promote it during cutover",
      "Export to S3, restore into a new DB, and repoint clients"
    ],
    "answer": 1,
    "explanation": "RDS Blue/Green Deployments supports safer, controlled upgrades with minimal downtime by keeping a synchronized staging environment and performing a switch-over when ready, with a practical rollback path.",
    "difficulty": "Hard"
  },
  {
    "id": "SAA-355",
    "domainId": "D1",
    "domain": "Design Secure Architectures",
    "section": "S3",
    "question": "A finance team stores monthly statements in Amazon S3. Regulations require WORM immutability for 7 years and protection against deletion by privileged users. Which combination of actions best satisfies the requirements while being the most cost-effective? (Select TWO.)",
    "choices": [
      "Enable S3 Versioning",
      "Enable S3 Object Lock in Compliance mode with a 7-year retention",
      "Enable S3 Transfer Acceleration",
      "Enable default encryption with SSE-S3",
      "Enable CloudTrail Insights"
    ],
    "answer": [
      0,
      1
    ],
    "explanation": "Object Lock (Compliance) provides WORM enforcement that cannot be bypassed and requires versioning. Together they satisfy immutability and retention requirements.",
    "difficulty": "Hard"
  },
  {
    "id": "SAA-356",
    "domainId": "D3",
    "domain": "Design High-Performing Architectures",
    "section": "DynamoDB",
    "question": "A SaaS platform serves users in North America and Europe. The app needs single-digit-millisecond reads in both Regions and must continue operating through a full regional outage. Writes must be accepted in either Region. Which solution will meet these requirements with the LEAST operational overhead?",
    "choices": [
      "DynamoDB Global Tables",
      "Aurora read replicas in each Region with manual failover",
      "S3 Cross-Region Replication plus Athena queries",
      "ElastiCache Global Datastore only"
    ],
    "answer": 0,
    "explanation": "DynamoDB Global Tables provide active-active, multi-Region replication with local low-latency reads and multi-Region writes, minimizing operational overhead for this pattern.",
    "difficulty": "Hard"
  },
  {
    "id": "SAA-357",
    "domainId": "D4",
    "domain": "Design Cost-Optimized Architectures",
    "section": "S3",
    "question": "A company stores project artifacts in S3. For 30 days objects are frequently accessed. After day 30, most objects are rarely accessed and can tolerate minutes-to-hours retrieval. However, objects under s3://bucket/hotfix/ must still be retrievable in milliseconds after day 30. Which solution is MOST cost-effective?",
    "choices": [
      "Keep all objects in S3 Standard indefinitely",
      "Use lifecycle rules: hotfix/ to S3 Standard-IA after 30 days, and the rest to S3 Glacier Flexible Retrieval",
      "Move the entire bucket to S3 One Zone-IA after 30 days",
      "Enable Intelligent-Tiering and disable lifecycle rules"
    ],
    "answer": 1,
    "explanation": "Standard-IA provides millisecond retrieval for infrequently accessed objects at lower cost than Standard, while Glacier Flexible Retrieval lowers cost for the rest with acceptable retrieval latency.",
    "difficulty": "Hard"
  },
  {
    "id": "SAA-358",
    "domainId": "D1",
    "domain": "Design Secure Architectures",
    "section": "Organizations",
    "question": "An OU has an SCP that denies s3:PutBucketPolicy. A developer in a member account has AdministratorAccess but cannot update a bucket policy for a valid business use case. How will the Architect fix this issue while keeping strong guardrails?",
    "choices": [
      "Remove the SCP and rely on IAM permissions in each account",
      "Refine the SCP to allow s3:PutBucketPolicy only under controlled conditions (for example, using tags/conditions)",
      "Enable ACLs and stop using bucket policies for cross-account access",
      "Use a separate AWS account with no SCPs and migrate the bucket there"
    ],
    "answer": 1,
    "explanation": "SCPs apply regardless of IAM AdministratorAccess. The correct approach is to adjust the guardrail to allow the action only when it meets defined constraints.",
    "difficulty": "Hard"
  },
  {
    "id": "SAA-359",
    "domainId": "D2",
    "domain": "Design Resilient Architectures",
    "section": "Disaster Recovery",
    "question": "A payments platform needs minutes-level RTO and low data loss across two Regions, but wants to avoid full active/active cost. It will keep a reduced-capacity environment running in the secondary Region and scale up on failover. Which DR strategy should you choose?",
    "choices": [
      "Backup & Restore",
      "Pilot Light",
      "Warm Standby",
      "Cold Standby"
    ],
    "answer": 2,
    "explanation": "Warm Standby keeps a scaled-down but running environment in the secondary Region and can scale quickly during failover, meeting tighter RTO/RPO than backup/restore or pilot light.",
    "difficulty": "Hard"
  },
  {
    "id": "SAA-360",
    "domainId": "D1",
    "domain": "Design Secure Architectures",
    "section": "EKS",
    "question": "A platform team runs workloads on Amazon EKS. Pods must call DynamoDB without storing long-term keys. Access must be least privilege per workload. Which combination of actions best satisfies the requirement while being the most cost-effective? (Select TWO.)",
    "choices": [
      "Enable IAM Roles for Service Accounts (IRSA)",
      "Store access keys in Kubernetes Secrets and rotate monthly",
      "Attach least-privilege DynamoDB permissions to the IAM role used by IRSA",
      "Give the node instance role AdministratorAccess",
      "Use CloudFront signed URLs to DynamoDB"
    ],
    "answer": [
      0,
      2
    ],
    "explanation": "IRSA provides short-lived credentials to pods, and attaching a least-privilege policy to the mapped IAM role ensures per-workload access without long-term keys.",
    "difficulty": "Hard"
  },
  {
    "id": "SAA-361",
    "domainId": "D3",
    "domain": "Design High-Performing Architectures",
    "section": "FSx",
    "question": "A research team runs HPC jobs that need a POSIX file system with very low latency and high throughput. The dataset is stored in S3 and must be processed as a mounted file system without manual copy steps. Which solution will meet these requirements with the LEAST operational overhead?",
    "choices": [
      "Amazon FSx for Lustre linked to the S3 dataset",
      "Amazon EFS with lifecycle policies",
      "S3 Glacier Instant Retrieval mounted via NFS",
      "AWS Storage Gateway File Gateway"
    ],
    "answer": 0,
    "explanation": "FSx for Lustre is optimized for HPC and can link to S3, presenting data as a high-performance file system with minimal operational effort.",
    "difficulty": "Hard"
  },
  {
    "id": "SAA-362",
    "domainId": "D4",
    "domain": "Design Cost-Optimized Architectures",
    "section": "Compute",
    "question": "A containerized microservice requires a steady compute baseline 24/7, but also has unpredictable spikes. The company wants to lower cost while avoiding capacity risk during spikes. Which combination best satisfies the requirements?",
    "choices": [
      "Savings Plans for baseline usage and On-Demand for spikes",
      "Spot for baseline usage and Spot for spikes",
      "Dedicated Hosts for baseline and On-Demand for spikes",
      "Only On-Demand so scaling is always flexible"
    ],
    "answer": 0,
    "explanation": "Savings Plans reduce cost for steady usage. On-Demand covers spikes without interruption risk or capacity constraints typical of Spot.",
    "difficulty": "Hard"
  },
  {
    "id": "SAA-363",
    "domainId": "D2",
    "domain": "Design Resilient Architectures",
    "section": "SQS",
    "question": "An order-processing system uses SQS with a Lambda consumer. During spikes, Lambda scales too aggressively and overwhelms the downstream database. How will the Architect fix this issue?",
    "choices": [
      "Set Reserved Concurrency on the Lambda function and tune batch size",
      "Increase SQS long polling to 20 seconds",
      "Enable FIFO so Lambda cannot scale out",
      "Decrease visibility timeout to reduce retries"
    ],
    "answer": 0,
    "explanation": "Reserved Concurrency caps parallel executions, throttling throughput. Batch size tuning further controls processing rate without changing producers.",
    "difficulty": "Hard"
  },
  {
    "id": "SAA-364",
    "domainId": "D1",
    "domain": "Design Secure Architectures",
    "section": "VPC Endpoints",
    "question": "Instances in private subnets must access S3 without using NAT and the security team wants to allow access only to a single bucket from those subnets. Which solution will meet these requirements with the LEAST operational overhead?",
    "choices": [
      "Create an S3 Gateway VPC endpoint and restrict the bucket policy to the endpoint",
      "Use a NAT Gateway and restrict the bucket policy to the NAT public IP",
      "Use an Internet Gateway and Network ACLs to block inbound traffic",
      "Use VPC peering to an S3 VPC and restrict routes"
    ],
    "answer": 0,
    "explanation": "Gateway endpoints keep traffic on the AWS network without NAT. Bucket policy conditions can restrict access to requests coming via a specific VPC endpoint.",
    "difficulty": "Hard"
  },
  {
    "id": "SAA-365",
    "domainId": "D1",
    "domain": "Design Secure Architectures",
    "section": "Secrets Manager",
    "question": "A company stores database credentials in AWS Secrets Manager. Auditors require proof of which IAM principal retrieved secret values and from which IP address. Which approach best meets the requirement?",
    "choices": [
      "Enable CloudTrail and review Secrets Manager API events",
      "Enable VPC Flow Logs and search for AWS endpoint connections",
      "Enable CloudWatch metrics for Secrets Manager and export them",
      "Enable AWS Config to record changes to secret rotation schedule"
    ],
    "answer": 0,
    "explanation": "CloudTrail logs Secrets Manager API calls (including GetSecretValue), capturing identity and source IP, which is what auditors need.",
    "difficulty": "Hard"
  },
  {
    "id": "SAA-366",
    "domainId": "D1",
    "domain": "Design Secure Architectures",
    "section": "KMS",
    "question": "You enable S3 Cross-Region Replication on a bucket that uses SSE-KMS. Replication fails due to an access error on the destination KMS key. Which of the following must be implemented in the current architecture to satisfy the new requirement?",
    "choices": [
      "Update the destination KMS key policy to allow the replication role to use KMS encryption actions",
      "Disable SSE-KMS on the source bucket and switch to SSE-S3",
      "Enable S3 Transfer Acceleration on both buckets",
      "Disable versioning on the destination bucket"
    ],
    "answer": 0,
    "explanation": "For SSE-KMS replication, the replication role must be allowed by the destination key policy to perform encrypt/data key actions so replicas can be encrypted at the destination.",
    "difficulty": "Hard"
  },
  {
    "id": "SAA-367",
    "domainId": "D3",
    "domain": "Design High-Performing Architectures",
    "section": "Kinesis",
    "question": "A company ingests telemetry at high throughput. Multiple consumers need sub-second processing and the ability to replay 72 hours of events after code changes. Which service should you choose?",
    "choices": [
      "Amazon Kinesis Data Streams",
      "Amazon SNS standard topic",
      "Amazon SQS standard queue",
      "Amazon Kinesis Data Firehose only"
    ],
    "answer": 0,
    "explanation": "Kinesis Data Streams supports multiple consumers and configurable retention for replay. SNS/SQS don’t provide the same stream replay pattern, and Firehose is delivery-focused without consumer replay semantics.",
    "difficulty": "Hard"
  },
  {
    "id": "SAA-368",
    "domainId": "D3",
    "domain": "Design High-Performing Architectures",
    "section": "Global Accelerator",
    "question": "A multiplayer game uses UDP and needs static anycast IPs and improved performance for global users to AWS endpoints. Which combination of actions best satisfies the requirements while being the most cost-effective? (Select TWO.)",
    "choices": [
      "Use AWS Global Accelerator for the entrypoint",
      "Use Application Load Balancer as the regional endpoint",
      "Use Network Load Balancer as the regional endpoint",
      "Use CloudFront as the entrypoint for UDP",
      "Use S3 Transfer Acceleration for game packets"
    ],
    "answer": [
      0,
      2
    ],
    "explanation": "Global Accelerator provides static anycast IPs and optimized routing. NLB supports UDP and high throughput as a regional endpoint.",
    "difficulty": "Hard"
  },
  {
    "id": "SAA-369",
    "domainId": "D3",
    "domain": "Design High-Performing Architectures",
    "section": "Aurora",
    "question": "A read-heavy application uses Aurora MySQL. The team wants to scale read capacity with minimal changes and ensure fast writer failover. Which solution best meets these requirements?",
    "choices": [
      "Add Aurora Replicas and use the reader endpoint for reads",
      "Increase the writer instance size only",
      "Move reads into S3 Select",
      "Use periodic snapshots to improve read performance"
    ],
    "answer": 0,
    "explanation": "Aurora Replicas increase read capacity, and the reader endpoint distributes read traffic. Aurora managed failover improves resilience without complex application changes.",
    "difficulty": "Hard"
  },
  {
    "id": "SAA-370",
    "domainId": "D1",
    "domain": "Design Secure Architectures",
    "section": "KMS",
    "question": "A company encrypts data in us-east-1 and replicates ciphertext to eu-west-1. They must decrypt in both Regions without re-encrypting and want AWS-managed equivalent keys. Which approach should you choose?",
    "choices": [
      "Use KMS multi-Region keys with a replica key in the second Region",
      "Use one single-Region key and share it to the other Region",
      "Use SSE-S3 so decryption works anywhere",
      "Use two unrelated CMKs and keep the alias name identical"
    ],
    "answer": 0,
    "explanation": "KMS multi-Region keys are designed to provide cryptographically related keys across Regions so ciphertext can be decrypted in either Region without re-encryption.",
    "difficulty": "Hard"
  },
  {
    "id": "SAA-371",
    "domainId": "D2",
    "domain": "Design Resilient Architectures",
    "section": "Migration",
    "question": "A company must migrate hundreds of on-prem VMs to AWS. They require continuous block-level replication, the ability to launch test cutovers, and a short final cutover window. Which combination of actions best satisfies the given set of requirements while being the most cost-effective? (Select TWO.)",
    "choices": [
      "Use AWS Application Migration Service (MGN) for replication",
      "Use AWS DataSync for continuous block replication",
      "Perform test cutovers by launching test instances from replicated data",
      "Use AWS DMS to replicate VM blocks",
      "Use S3 Batch Operations to import VM images"
    ],
    "answer": [
      0,
      2
    ],
    "explanation": "MGN provides continuous block-level replication and supports test cutovers by launching test instances, enabling a short final cutover window.",
    "difficulty": "Hard"
  },
  {
    "id": "SAA-372",
    "domainId": "D4",
    "domain": "Design Cost-Optimized Architectures",
    "section": "EFS",
    "question": "A pipeline stores temporary processing files on Amazon EFS. Files are heavily used for 7 days, then rarely accessed but must remain available for 90 days. The team wants to reduce storage cost without changing the app. Which solution should you implement?",
    "choices": [
      "Enable EFS lifecycle management to transition to EFS Infrequent Access after 7 days",
      "Move files to EBS gp3 after 7 days via cron jobs",
      "Replace EFS with instance store to reduce cost",
      "Replicate EFS to another Region and delete the primary copy"
    ],
    "answer": 0,
    "explanation": "EFS lifecycle management automatically transitions infrequently accessed files to EFS IA, lowering cost while keeping the same file system interface.",
    "difficulty": "Hard"
  },
  {
    "id": "SAA-373",
    "domainId": "D1",
    "domain": "Design Secure Architectures",
    "section": "IAM",
    "question": "A company must allow a third-party auditor to review CloudWatch logs and CloudTrail events in a dedicated audit account without giving write permissions. The auditor should not need long-term access keys. Which solution will meet these requirements with the LEAST operational overhead?",
    "choices": [
      "Create an IAM user in the audit account and email the access keys to the auditor",
      "Create an IAM role in the audit account and allow the auditor’s AWS account to assume it with read-only permissions",
      "Create a root user in the audit account and enable MFA, then share the credentials",
      "Attach AdministratorAccess to an auditor IAM user to avoid missing permissions"
    ],
    "answer": 1,
    "explanation": "Cross-account role assumption is the standard pattern for third-party access without distributing long-term keys. You can scope the role to read-only access.",
    "difficulty": "Hard"
  },
  {
    "id": "SAA-374",
    "domainId": "D2",
    "domain": "Design Resilient Architectures",
    "section": "Route 53",
    "question": "A company runs active-passive endpoints in two Regions. If the primary endpoint fails health checks, traffic must move to standby automatically, then return to primary when healthy. Which solution should be used?",
    "choices": [
      "Route 53 failover routing with health checks",
      "Route 53 weighted routing without health checks",
      "CloudFront geo restriction",
      "An ALB spanning both Regions"
    ],
    "answer": 0,
    "explanation": "Route 53 failover routing uses health checks to shift traffic to a secondary endpoint when the primary is unhealthy and can restore traffic when it becomes healthy again.",
    "difficulty": "Hard"
  },
  {
    "id": "SAA-375",
    "domainId": "D1",
    "domain": "Design Secure Architectures",
    "section": "ACM",
    "question": "A company has dozens of internet-facing ALBs in multiple accounts. Each ALB requires a publicly trusted TLS certificate with automatic renewal, and operations wants minimal per-application work. Which approach can be used to fulfill this requirement?",
    "choices": [
      "Use AWS Certificate Manager public certificates and validate using DNS in Route 53 hosted zones",
      "Use self-signed certificates and rotate them quarterly",
      "Use ACM Private CA so browsers trust certificates automatically",
      "Use OpenSSL on EC2 and copy certificates to each ALB manually"
    ],
    "answer": 0,
    "explanation": "ACM public certificates are publicly trusted and support managed renewal when DNS validation is kept in place, minimizing operational overhead compared with manual certificate creation and rotation.",
    "difficulty": "Hard"
  },
  {
    "id": "SAA-376",
    "domainId": "D3",
    "domain": "Design High-Performing Architectures",
    "section": "S3",
    "question": "A data lake stores tens of millions of objects in S3 with highly unpredictable access. The team wants automatic cost optimization with millisecond retrieval when accessed and no retrieval fees. Which storage class should be used?",
    "choices": [
      "S3 Intelligent-Tiering",
      "S3 Standard-IA",
      "S3 One Zone-IA",
      "S3 Glacier Instant Retrieval"
    ],
    "answer": 0,
    "explanation": "S3 Intelligent-Tiering automatically moves objects between access tiers based on usage patterns while maintaining millisecond retrieval and avoiding retrieval fees for access tiers.",
    "difficulty": "Hard"
  },
  {
    "id": "SAA-377",
    "domainId": "D4",
    "domain": "Design Cost-Optimized Architectures",
    "section": "Cost Management",
    "question": "Finance wants automatic detection of unusual daily spend and alerts, without maintaining per-service thresholds. Which solution best meets this need?",
    "choices": [
      "AWS Cost Anomaly Detection with monitors and notifications",
      "AWS Budgets with static thresholds per service",
      "Cost Explorer with a monthly report export",
      "Trusted Advisor checks only"
    ],
    "answer": 0,
    "explanation": "Cost Anomaly Detection uses machine learning to detect unusual spend patterns and can alert via configured monitors, reducing manual threshold tuning.",
    "difficulty": "Hard"
  },
  {
    "id": "SAA-378",
    "domainId": "D1",
    "domain": "Design Secure Architectures",
    "section": "Networking",
    "question": "A global company has two VPCs in different AWS Regions: one for HR and one for Finance. The departments must be able to access each other’s resources. Security also mandates in-line inspection to actively block malicious traffic patterns between the VPCs. Which network architecture design should the Solutions Architect set up to satisfy these requirements?",
    "choices": [
      "Create Amazon Route 53 traffic policies between the VPCs and enable Route 53 Resolver DNS Firewall to inspect and block inter-VPC traffic",
      "Connect the VPCs using VPC peering across Regions, then use security groups to inspect and block vulnerability exploits in transit",
      "Build an AWS Direct Connect Gateway with VPC associations, then enable AWS Security Hub to inspect and block traffic between the VPCs",
      "Deploy an AWS Transit Gateway with inter-Region peering, attach both VPCs, and use AWS Network Firewall in a dedicated inspection VPC to enforce in-line traffic inspection and blocking"
    ],
    "answer": 3,
    "explanation": "Transit Gateway supports scalable hub-and-spoke connectivity, including inter-Region TGW peering. AWS Network Firewall provides stateful, in-line inspection and blocking. Route 53/DNS Firewall is DNS-focused, Security Hub is posture management, and security groups are not an IPS for in-line inspection.",
    "difficulty": "Hard"
  },
  {
    "id": "SAA-379",
    "domainId": "D2",
    "domain": "Design Resilient Architectures",
    "section": "S3",
    "question": "A company stores critical documents in Amazon S3 in us-east-1. The compliance team requires that the same data exist in eu-west-1 for disaster recovery. Only objects under the prefix legal/ should replicate, and replicated objects must remain encrypted using SSE-KMS with a destination KMS key. Which solution best meets these requirements with the LEAST operational overhead?",
    "choices": [
      "Enable S3 Cross-Region Replication with a replication rule filtered to legal/, keep versioning enabled, and update the destination KMS key policy to allow the replication role to encrypt with the destination key",
      "Enable S3 Transfer Acceleration on both buckets and configure a bucket policy to copy new objects to the destination bucket automatically",
      "Create a Lambda function triggered by S3 events to copy objects across Regions and use KMS decrypt/encrypt calls inside the function for each object",
      "Run a nightly AWS DataSync task to move objects from the source bucket to the destination bucket and enable default encryption on the destination"
    ],
    "answer": 0,
    "explanation": "CRR supports prefix filters, requires versioning, and works with SSE-KMS when the destination key policy allows the replication role to encrypt. It is the lowest-ops native solution compared with custom Lambda or scheduled copy jobs.",
    "difficulty": "Hard"
  },
  {
    "id": "SAA-380",
    "domainId": "D3",
    "domain": "Design High-Performing Architectures",
    "section": "ECS",
    "question": "A company runs an internal API on Amazon ECS using the Fargate launch type behind an ALB. During deployments, traffic spikes and some containers are terminated while still handling requests, causing a burst of 5xx errors. The team wants a solution that reduces deployment errors without changing application code. Which approach should the Solutions Architect recommend?",
    "choices": [
      "Configure ECS service deployment to use a higher desired count and enable deployment circuit breaker with automatic rollback, ensuring tasks are drained properly before termination",
      "Switch from ALB to NLB so that connections are preserved and tasks are never terminated during deployments",
      "Enable S3 static website hosting for the API endpoints and route traffic through CloudFront to avoid container termination issues",
      "Move the API to Lambda@Edge so scaling is global and deployments never cause any 5xx responses"
    ],
    "answer": 0,
    "explanation": "ECS deployment settings (including deployment configuration and circuit breaker) help reduce failed deployments and roll back automatically. Proper draining/health checks and controlled deployment behavior mitigate 5xx spikes without changing code.",
    "difficulty": "Hard"
  },
  {
    "id": "SAA-381",
    "domainId": "D4",
    "domain": "Design Cost-Optimized Architectures",
    "section": "EC2 Pricing",
    "question": "A data processing workload runs 24/7 on EC2 and is expected to remain steady for at least 2 years. The company wants to reduce compute cost but must be able to change instance families if needed later. Which purchasing option provides the best balance of savings and flexibility?",
    "choices": [
      "Purchase Standard Reserved Instances for a specific instance family and size for 2 years to maximize discount",
      "Use Spot Instances for the entire workload and rely on instance interruption handling for cost savings",
      "Use Compute Savings Plans to cover the baseline usage while retaining flexibility across instance families and Regions",
      "Use Dedicated Hosts so the workload qualifies for the biggest discount while keeping full flexibility"
    ],
    "answer": 2,
    "explanation": "Compute Savings Plans provide discounts for steady usage while remaining flexible across instance families, sizes, and Regions compared with Standard RIs. Spot is risky for 24/7 steady workloads, and Dedicated Hosts are for compliance/licensing needs, not general cost optimization.",
    "difficulty": "Hard"
  },
  {
    "id": "SAA-382",
    "domainId": "D2",
    "domain": "Design Resilient Architectures",
    "section": "Route 53",
    "question": "A company has an application deployed in two Regions. Users should normally go to the closest Region, but if one Region becomes unhealthy, all traffic must fail over to the healthy Region automatically. Which Route 53 configuration best meets the requirements?",
    "choices": [
      "Geolocation routing so users are forced to specific Regions based on country and never fail over automatically",
      "Latency-based routing combined with health checks on both endpoints to route to the lowest-latency healthy Region",
      "Weighted routing set to 50/50 so both Regions receive traffic equally, and remove health checks to avoid DNS flapping",
      "Multi-Value Answer routing with a long TTL so clients cache answers and reduce Route 53 query costs"
    ],
    "answer": 1,
    "explanation": "Latency-based routing directs users to the lowest-latency endpoint and, with health checks, removes unhealthy endpoints from DNS responses for automatic failover behavior.",
    "difficulty": "Hard"
  },
  {
    "id": "SAA-383",
    "domainId": "D1",
    "domain": "Design Secure Architectures",
    "section": "IAM",
    "question": "A company wants developers to access production resources only through federated SSO and must avoid long-term IAM user access keys. Access should be granted temporarily and audited. Which approach best satisfies these requirements with the LEAST operational overhead?",
    "choices": [
      "Create IAM users for each developer and rotate access keys every 30 days using an internal script",
      "Use IAM roles with AWS IAM Identity Center (AWS SSO) so developers obtain short-lived credentials through federation",
      "Share a single IAM user among all developers and enforce MFA to prevent misuse",
      "Store AWS access keys in AWS Secrets Manager and issue them to developers only when needed"
    ],
    "answer": 1,
    "explanation": "Identity Center (SSO) with IAM roles provides federated access with temporary credentials and centralized auditing. It eliminates long-term keys and reduces operational burden compared with rotating user keys.",
    "difficulty": "Hard"
  },
  {
    "id": "SAA-384",
    "domainId": "D3",
    "domain": "Design High-Performing Architectures",
    "section": "CloudFront",
    "question": "A company serves large downloadable files globally from an S3 origin behind CloudFront. Security requires that only paid subscribers can download files, and the access mechanism must work even if the S3 bucket is private. Which solution will meet these requirements?",
    "choices": [
      "Make the S3 bucket public-read and rely on application-side authentication only",
      "Use CloudFront signed URLs or signed cookies and restrict S3 access to CloudFront using an origin access control (OAC) or similar mechanism",
      "Enable S3 Transfer Acceleration and require users to authenticate with IAM user access keys",
      "Use Route 53 weighted routing to send subscribers to a different S3 bucket"
    ],
    "answer": 1,
    "explanation": "Signed URLs/cookies enforce viewer authorization at CloudFront, and OAC/OAI-style access ensures the S3 bucket remains private and only CloudFront can fetch objects.",
    "difficulty": "Hard"
  },
  {
    "id": "SAA-385",
    "domainId": "D2",
    "domain": "Design Resilient Architectures",
    "section": "SQS",
    "question": "A payment pipeline uses standard SQS and a Lambda consumer. The business now requires strict ordering for events per customer and exactly-once processing semantics to avoid double-charging. Which solution best meets the requirement with minimal redesign?",
    "choices": [
      "Keep the standard queue and increase the visibility timeout so messages are processed only once",
      "Use an SNS standard topic to broadcast messages and rely on retries for ordering",
      "Migrate to an SQS FIFO queue and use Message Group IDs per customer along with deduplication",
      "Use Kinesis Data Firehose to deliver data into S3 and process it from there in order"
    ],
    "answer": 2,
    "explanation": "SQS FIFO supports ordering and deduplication features (exactly-once processing semantics within FIFO constraints), and Message Group IDs maintain ordering per customer.",
    "difficulty": "Hard"
  },
  {
    "id": "SAA-386",
    "domainId": "D1",
    "domain": "Design Secure Architectures",
    "section": "Network Firewall",
    "question": "A company centralizes outbound internet access from multiple VPCs using a shared egress VPC. Security now requires stateful inspection, domain-based allow/deny controls, and centralized logging for all egress traffic. Which solution should be implemented?",
    "choices": [
      "Enable VPC Flow Logs and block domains by adding route table blackhole entries",
      "Deploy AWS Network Firewall in the egress VPC and route traffic through firewall endpoints with centralized logging",
      "Use security groups with outbound rules to inspect and block domain names at Layer 7",
      "Attach AWS WAF to the NAT Gateway so it can inspect and block outbound requests"
    ],
    "answer": 1,
    "explanation": "AWS Network Firewall provides stateful inspection and filtering with centralized logging for VPC traffic. Security groups and WAF don’t provide the required in-line egress inspection for arbitrary outbound traffic.",
    "difficulty": "Hard"
  },

  {
    "id": "SAA-387",
    "domainId": "D1",
    "domain": "Design Secure Architectures",
    "section": "IAM",
    "question": "Which feature lets you grant temporary permissions to access AWS resources?",
    "choices": [
      "IAM Users",
      "IAM Groups",
      "IAM Roles",
      "Resource Tags"
    ],
    "answer": 2,
    "explanation": "IAM roles are assumed to obtain temporary security credentials rather than long-term static credentials.",
    "difficulty": "Easy"
  },
  {
    "id": "SAA-388",
    "domainId": "D3",
    "domain": "Design High-Performing Architectures",
    "section": "S3",
    "question": "Which S3 feature allows uploading large objects by splitting them into parts that can be retried independently?",
    "choices": [
      "S3 Event Notifications",
      "S3 Multipart Upload",
      "S3 Object Lock",
      "S3 Inventory"
    ],
    "answer": 1,
    "explanation": "Multipart Upload breaks an object into parts, enabling parallel upload and independent retries.",
    "difficulty": "Easy"
  },
  {
    "id": "SAA-389",
    "domainId": "D2",
    "domain": "Design Resilient Architectures",
    "section": "ELB",
    "question": "Which AWS service distributes incoming HTTP/HTTPS traffic across targets and supports path-based routing?",
    "choices": [
      "Network Load Balancer",
      "Application Load Balancer",
      "Gateway Load Balancer",
      "AWS Direct Connect"
    ],
    "answer": 1,
    "explanation": "An Application Load Balancer operates at Layer 7 and supports routing features like path-based rules.",
    "difficulty": "Easy"
  },
  {
    "id": "SAA-390",
    "domainId": "D4",
    "domain": "Design Cost-Optimized Architectures",
    "section": "EC2 Pricing",
    "question": "Which EC2 pricing model provides the biggest discounts but can be interrupted with little notice?",
    "choices": [
      "On-Demand Instances",
      "Reserved Instances",
      "Spot Instances",
      "Dedicated Hosts"
    ],
    "answer": 2,
    "explanation": "Spot Instances offer deep discounts but can be interrupted when AWS needs the capacity back.",
    "difficulty": "Easy"
  }
]